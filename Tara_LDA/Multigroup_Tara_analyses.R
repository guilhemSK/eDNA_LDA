# Specify absolute paths to data and saved results:
#####################
# Data folder path:
data_folder = "/Users/guilhemsommeria-klein/Desktop/Post-doc_ENS/Donnees_Tara"
# Path to cluster data folder - workspace 2:
data_folder_workspace2 = "/Users/guilhemsommeria-klein/Desktop/Serveur_Bioclust.kingdoms.workspace2/Donnees_Tara"
# Path to cluster data folder - workspace 3:
data_folder_workspace3 = "/Users/guilhemsommeria-klein/Desktop/Serveur_Bioclust.kingdoms.workspace3/Donnees_Tara"
# Path to cluster data folder - data:
data_folder_workspace0 = "/Users/guilhemsommeria-klein/Desktop/Serveur_Bioclust.data/Donnees_Tara"
# Path to saved results:
code_folder = "/Users/guilhemsommeria-klein/Desktop/Code/Projects/eDNA_LDA"
results_folder = paste0(code_folder,"/Tara_LDA/Saved_results")
#####################

# General option panel:
#####################
old_data = 0
data_Federico = 1
data_V4 = 0
data_psbO = 0

noArcticNoBiomark = 0
noCoastalArcticNoBiomark = 0
ArcticOnly = 0
noLagoon = 1
# Diversity threshold for selecting the taxonomic groups of interest:
div_threshold = 2

# Splitting the data by taxonomic group and merging them by station and by depth:
# Influences the result of other analyses!
split_byStation = 0
all_data_coord = 0
split_byStationByDepth_CompleteSizeRange = 1
# Should the dataset with all taxa also be merged byStationbyDepth?
alltaxa = 1

# Plotting the diversity map for each group
diversity_maps = 0

# only for data_Federico:
function_plots = 0

mean_group_size = 0

travel_time = 0
travel_time_per_OTU = 1
travel_time_per_assemblage = 0
travel_time_vs_size = 0
# particle_thres indicates a threshold for the number of exchanged particles above which stations are considered connected.
# If particle_thres = 0, the mean number of exchanged particles is directly used to compute connectivity.
particle_thres = 10
# For particle_thres = 10 or particle_thres = 1,000, connectivity is computed based on the minimum travel times between pairs of stations that fulfill the particle_thres criterium rather than solely on the number of exchanged particles.
# An additional threshold on the minimum travel time below which stations are considered connected, travel_time_threshold, needs to be set.
# If travel_time_threshold = 0, connectivity is computed by directly averaging the minimum travel times.
# NaN entries for minimum travel times (corresponding to a nb of exchanged particles lower than particle_thres) are set to the maximum value taken by the minimum travel time across the matrix.
# The value of travel_time_threshold has no effect if particle_thres is neither equal to 10 or 1000.
# travel_time_threshold = 0
travel_time_threshold = 1.5
# travel_time_threshold = 2
# If expTmin = 1, the minimum travel time is transformed as 1 - exp(-t_min/travel_time_threshold), and then averaged to compute connectivity.
# NaN entries for the minimum travel times (corresponding to a nb of exchanged particles lower than particle_thres) are set to 1 (asymptotic value of 1 - exp(-t_min/travel_time_threshold) for large t_min).
# expTmin = 1 requires travel_time_threshold > 0 (and particle_thres = 10 or particle_thres = 1,000).
expTmin = 1

optimalK_comput = 0
optimalK_mpar = 0
optimalK_100r = 1
optimalK_vs_size = 0
optimalK_vs_travel_time_perOTU = 0

stability = 0
stability_vs_size = 0
stability_vs_optimalK = 0
stability_vs_travel_time_perOTU = 0

environmental_data = 1
abiotic_pca = 1
biotic_pca = 1
dis_MEM = 0
# rda_lda or rda_all ; rda_lda or rda_all can be combined with abiotic_dissimilarity_all
rda_lda = 1
varpart_lda = 1
# global_selection indicates whether the variable selection procedure is applied to all sets of variables simultaneously or independently for each set
global_selection = 0
rda_all = 0
abiotic_dissimilarity_all = 0
relative_abiotic_sd_per_OTU = 0
relative_abiotic_dissimilarity_per_OTU = 0
plot_a.biotic = 1

endemic_ubiquist = 0
####################

library(data.table)

if (data_Federico)
{
  groups_to_remove = c("undetermined_eukaryote","other_filosan_*","other_myzozoan_*","undetermined_alveolate","environmental_samples",
                     "Unknown","other_eukaryotes_*","other_prasinophytes","other_core_chlorophytes","other_endomyxan_*",
                     "other_MAST_*","undetermined_archaeplastida",
                     "other_Lobosa","undetermined_incertae_sedis","other_heterotrophic_stramenopiles_*","undetermined_stramenopiles","other_lower_Fungi_*",
                     "other_Ochrophyta_*","undetermined_MAST","undetermined_opisthokonts","undetermined_filosan","undetermined_holozoan",
                     "undetermined_ochrophyta","undetermined_thecofilosan","undetermined_fungi","other_Discoba")
} else if (data_V4)
{
  # for V4, groups_to_remove already removed from taxo_groups, etc.
  groups_to_remove = c("other_Cercozoa","other_Stramenopiles","other_Alveolata","other_Chlorophyta","other_Amoebozoa","other_Fungi","other_MAST_*")
} else if (data_psbO)
{
  groups_to_remove = ""
}

if (data_Federico)
{
  marker = "18S_V9"
  short_marker = ""
} else if (data_V4)
{
  marker = "18S_V4"
  short_marker = "V4_"
} else if (data_psbO)
{
  marker = "psbO"
  short_marker = "psbO_"
}

if (noLagoon)
{
  noLagoon_insert = "_noLagoon"
  lagoon_stations = c("TARA_043","TARA_046","TARA_049","TARA_054","TARA_057","TARA_113","TARA_114","TARA_115","TARA_116","TARA_117","TARA_118","TARA_119","TARA_120","TARA_121")
} else
  noLagoon_insert = ""

if (!noArcticNoBiomark && !noCoastalArcticNoBiomark && !ArcticOnly)
{
  noArcticNoBiomark_insert = ""
  Arctic_insert = "/All_stations"
} else if (ArcticOnly)
{
  noArcticNoBiomark_insert = "_ArcticOnly"
  Arctic_insert = "/Arctic"
} else if (noArcticNoBiomark)
{
  noArcticNoBiomark_insert = "_noArcticNoBiomark"
  Arctic_insert = "/All_stations_but_Arctic"
} else if (noCoastalArcticNoBiomark)
{
  noArcticNoBiomark_insert = "_noCoastalArcticNoBiomark"
  Arctic_insert = "/Arctic2stations"
} else if (NorthAtlantic)
{
  noArcticNoBiomark_insert = "_NorthAtlantic"
  Arctic_insert = "/NorthAtlantic"
}

# Specify absolute path to figure folder:
######################
# Figure folder path:
figure_path = "/Users/guilhemsommeria-klein/Desktop/Manuscrits/Tara/Figures"
# Marker-specific figure folder path:
figure_folder = paste0(figure_path,"/Gibbs",Arctic_insert,"/",substr(short_marker,1,nchar(short_marker)-1))
######################

if (abiotic_pca)
{
  abiotic_pca_insert = "_abioticPCA"
} else
{
  abiotic_pca_insert = ""
}

if (biotic_pca)
{
  biotic_pca_insert = "_bioticPCA"
} else
{
  biotic_pca_insert = ""
}

if (dis_MEM)
{
  dis_MEM_insert = "_dist-based.MEM"
} else
  dis_MEM_insert = ""

if (rda_all)
{
  rda_insert = "_OTU-based"
} else if (rda_lda)
{
  rda_insert = "_LDA-based"
}

if (abiotic_dissimilarity_all)
{
  mantel_insert = "_OTU-based"
}

if (split_byStation || all_data_coord || split_byStationByDepth_CompleteSizeRange)
{
  if (old_data)
  {
    setwd(paste0(data_folder,"/18S_V9_TARA/"))
    
    sample_ref = read.table("TV9_corr_st_lat_long_nocross.txt", colClasses="vector", sep=",", header=T)
    
    colnames(sample_ref)[which(colnames(sample_ref) == "newname")] = "Station.label"
    colnames(sample_ref)[which(colnames(sample_ref) == "fraction")] = "Fraction.size"
    colnames(sample_ref)[which(colnames(sample_ref) == "sample")] = "Sample.id"
    colnames(sample_ref)[which(colnames(sample_ref) == "template")] = "Template"
    
    short_data_insert = "Tara"
    short_barcode_insert = "18SV9"
    # data2m stores OTU counts for samples
    data2m = fread(paste(short_data_insert,"_",short_barcode_insert,"_sequences_counts.txt",sep=""), colClasses="vector", sep=" ")
    #taxo_ref = read.table(paste(short_data_insert,"_",short_barcode_insert,"_taxo_ref_table_assignScore.txt",sep=""), colClasses="vector", sep=" ")
    
    # samples_data2 stores sample names ordered as in data2m
    samples_data2m = colnames(data2m)
    data2m = apply(data2m,2,as.numeric)
    
    # using the coordinates of TARAV9SampleGrid_allSamples.csv
    setwd(paste0(data_folder,"/Raw_V9_data/"))
    All_stations_coor = read.table("TARAV9SampleGrid_allSamples.csv", header=T, sep=";", colClasses="vector")
    stations_names = levels(as.factor(sample_ref$Station.label))
    for (station in stations_names)
    {
      if (noLagoon && any(lagoon_stations == station))
        sample_ref = sample_ref[-which(sample_ref$Station.label==station),]
      else
      {
        sample_ref$Latitude[which(sample_ref$Station.label==station)] = All_stations_coor$Latitude..decima.ldegrees.[which(All_stations_coor$STATION == station)]
        sample_ref$Longitude[which(sample_ref$Station.label==station)] = All_stations_coor$Longitude..Decimal.degrees.[which(All_stations_coor$STATION == station)]
      }
    }
    
    if (!noArcticNoBiomark)
    {
      setwd(paste0(data_folder,"/Raw_V9_data/"))
      All_stations_coor = read.table("TARAV9SampleGrid_allSamples.csv", header=T, sep=";", colClasses="vector")
      All_samples_noCoor = read.table("globaldataset_v9_samples.csv", header=T, sep=";", colClasses="vector")
      
      NewSamples_indices = 904:nrow(All_samples_noCoor)
      
      New_sample_ref = rbind(sample_ref,matrix(nrow=length(NewSamples_indices),ncol=ncol(sample_ref),dimnames=list(904:nrow(All_samples_noCoor),colnames(sample_ref))))
      New_sample_ref[NewSamples_indices,1] = All_samples_noCoor$Sample_seq_id[NewSamples_indices]
      New_sample_ref[NewSamples_indices,2] = NA
      New_sample_ref[NewSamples_indices,3] = All_samples_noCoor$Depth[NewSamples_indices]
      New_sample_ref[NewSamples_indices,4] = All_samples_noCoor$Fraction[NewSamples_indices]
      New_sample_ref[NewSamples_indices,5] = All_samples_noCoor$Template[NewSamples_indices]
      New_sample_ref[NewSamples_indices,6:7] = NA
      #New_sample_ref[NewSamples_indices,8:9] = as.numeric(New_sample_ref[NewSamples_indices,8:9])
      New_sample_ref[NewSamples_indices,10] = NA
      New_sample_ref[NewSamples_indices,11] = All_samples_noCoor$Station[NewSamples_indices]
      
      # Taking all station coordinates from "globaldataset_v9_samples.csv":
      #stations_names = levels(as.factor(All_samples_noCoor$Station))
      # Taking only the Arctic and Biomark coordinates from "globaldataset_v9_samples.csv":
      stations_names = levels(as.factor(All_samples_noCoor$Station[NewSamples_indices]))
      
      for (station in stations_names)
      {
        New_sample_ref[which(New_sample_ref[,11]==station),8] = All_stations_coor$Latitude..decima.ldegrees.[which(All_stations_coor$STATION == station)]
        New_sample_ref[which(New_sample_ref[,11]==station),9] = All_stations_coor$Longitude..Decimal.degrees.[which(All_stations_coor$STATION == station)]
      }
      New_sample_ref = New_sample_ref[-which(New_sample_ref[,11]=="NAPLES2009"),]
      New_sample_ref = New_sample_ref[-which(New_sample_ref[,11]=="OSLO2009"),]
      
      sample_ref = New_sample_ref
      rownames(sample_ref) = 1:nrow(sample_ref)
    } 
    
    #taxa_insert = "AllTaxa"
    #taxa_insert = c("Diplonemida","Dinophyceae","Metazoa","Collodaria","Bacillariophyta","Ciliophora","Phaeodaria","MALV-IV","MALV-I","MALV-II","Ascetosporea","Foraminifera","Phaeophyceae","Acantharea","Mamiellophyceae")
    
    #########################
    
    # station_names stores stations ordered as in sample_ref
    stations_names = levels(as.factor(sample_ref$Station.label))
    #stations_names = stations_names[-c(which(stations_names=="TARA_017"),which(stations_names=="TARA_062"))]
    #stations_names = stations_names[-which(stations_names=="TARA_017")]
    
    setwd(paste0(data_folder,"/Raw_V9_data/"))
    taxo_ref = read.table(paste(short_data_insert,"_",short_barcode_insert,"_taxo_ref_table_assignScore.txt",sep=""), colClasses="vector", sep=" ", header = T)
    # Removing bacteria, archaea, and taxonomic groups starting with a "?" 
    data2m = data2m[!(taxo_ref$taxogroup == "Bacteria" | taxo_ref$taxogroup == "Archaea" | substr(taxo_ref$taxogroup,1,1) == "?"),]
    taxo_ref = taxo_ref[!(taxo_ref$taxogroup == "Bacteria" | taxo_ref$taxogroup == "Archaea" | substr(taxo_ref$taxogroup,1,1) == "?"),]
  } else if (data_Federico)  
  {
    full_data = readRDS(paste0(data_folder,"/Raw_V9_data/data_clean_v2.rds"))
    
    sample_ref = full_data[[2]]
    # data2m should have OTUs as rows and samples as columns:
    data2m = t(full_data[[1]]) 
    taxo_ref = full_data[[3]]
    
    rm(full_data)
    
    sample_ref = as.data.frame(lapply(sample_ref,as.vector),stringsAsFactors = F)
    sample_ref$Depth[which(sample_ref$Depth == "SRF")] = "SUR"
    
    if (noLagoon)
    {
      data2m = data2m[,!sample_ref$Station.label %in% lagoon_stations]
      sample_ref = sample_ref[!sample_ref$Station.label %in% lagoon_stations,]
    }
    
    if (noArcticNoBiomark || noCoastalArcticNoBiomark || ArcticOnly)
    {
      split_sample_names = lapply(as.character(sample_ref$Sample.id),strsplit,split="",fixed=T)
      split_sample_names_2firstLetters = vector(length = length(split_sample_names), mode = "character")
      for (i in 1:length(split_sample_names))
      {
        split_sample_names_2firstLetters[i] = paste(split_sample_names[[i]][[1]][1:2],collapse="")
      }
      if (noArcticNoBiomark)
      {
        data2m = data2m[,-which(split_sample_names_2firstLetters == "TA")]
        sample_ref = sample_ref[-which(split_sample_names_2firstLetters == "TA"),]
      } else if (noCoastalArcticNoBiomark)
      {
        data2m = data2m[,-which(split_sample_names_2firstLetters == "TA" & sample_ref$Station.label != "TARA_155" & sample_ref$Station.label != "TARA_158")]
        sample_ref = sample_ref[-which(split_sample_names_2firstLetters == "TA" & sample_ref$Station.label != "TARA_155" & sample_ref$Station.label != "TARA_158"),]
      } else if (ArcticOnly)
      {
        # !!! Rerun for Arctic without 155 !!!
        data2m = data2m[,which(split_sample_names_2firstLetters == "TA" & sample_ref$Station.label != "TARA_155")]
        sample_ref = sample_ref[which(split_sample_names_2firstLetters == "TA" & sample_ref$Station.label != "TARA_155"),]
      }
    }
    
    samples_data2m = colnames(data2m)
    stations_names = levels(as.factor(sample_ref$Station.label))
  } else if (data_V4)
  {
    full_data = readRDS(paste0(data_folder,"/18S_V4_Federico/18S_protists_size1_v2_GuilhemSommeriaKlein.rds"))
    
    # data2m should have OTUs as rows and samples as columns
    data2m = t(full_data$reads)
    #
    sample_ref = full_data$samp
    rownames(sample_ref) = sample_ref$Sample.id
    sample_ref = sample_ref[order(factor(rownames(sample_ref),levels=colnames(data2m))),]
    #
    taxo_ref = full_data$motus
    rownames(taxo_ref) = taxo_ref$amplicon
    taxo_ref = taxo_ref[,c("taxogroup2","taxonomy")]
    
    rm(full_data)
    
    sample_ref = as.data.frame(lapply(sample_ref,as.vector),stringsAsFactors = F)
    sample_ref$Depth[sample_ref$Depth == "SRF"] = "SUR" 
    
    ##############
    # # Cross-checking the data with PANGAEA:
    sample_ref_pangaea = read.table(file = paste0(data_folder,"/Abiotic_data_Pangaea/TARA_SAMPLES_CONTEXT_ENV-WATERCOLUMN_no.intro.tab"),
                                    sep = "\t",
                                    header = TRUE)
    # # Removing the "TARA_" sample prefix of the PANGAEA sample names:
    # sample_ref_pangaea[,1] = substr(sample_ref_pangaea[,1],6,15)
    # # Investigating in PANGAEA the depths of the samples that have missing depth in V4 data:
    # sample_ref_pangaea[sample_ref_pangaea[,1] %in% sample_ref$PANGAEA[is.na(sample_ref$Depth)],c(1,6,12:15)]
    # # Depth stats across PANGAEA and V4 samples:
    # table(factor(sample_ref_pangaea[sample_ref_pangaea[,1] %in% sample_ref$PANGAEA,12]))
    # table(factor(sample_ref$Depth))
    # # Checking the identity of samples with size.fraction mismatch:
    # sample_ref[sample_ref$PANGAEA %in% sample_ref_pangaea[sample_ref_pangaea[,16] != "0.80",1],]
    # sample_ref_pangaea[sample_ref_pangaea[,1] %in% sample_ref$PANGAEA & sample_ref_pangaea[,16] != "0.80",1:20]
    ################
    
    # Based on PANGAEA:
    ##################
    sample_ref$Depth[sample_ref$PANGAEA == "A100001686"] = "DCM"
    # Removing "[MIX] marine epipelagic wind mixed layer" samples, 
    # corresponding to stations where the distinction between surface and DCM could not be made: 
    data2m = data2m[,!is.na(sample_ref$Depth)]
    sample_ref = sample_ref[!is.na(sample_ref$Depth),] 
    # Correcting the size fractions of two samples based on PANGAEA:
    sample_ref$Fraction.size[sample_ref$PANGAEA == "N000001290"] = "20-180"
    
    ##############
    # # Comparing total counts between V4 and V9:
    # sum(data2m[,sample_ref$PANGAEA %in% sample_ref_v9$Pangaea_sample_id])
    # sample_ref_v9$Pangaea_sample_id = substr(sample_ref_v9$Pangaea_sample_id,6,15)
    # sum(data2m_v9[,sample_ref_v9$Pangaea_sample_id %in% sample_ref$PANGAEA])
    ##############
    
    if (noLagoon)
    {
      data2m = data2m[,!sample_ref$Station.label %in% lagoon_stations]
      sample_ref = sample_ref[!sample_ref$Station.label %in% lagoon_stations,]
    }
    
    samples_data2m = colnames(data2m)
    stations_names = levels(as.factor(sample_ref$Station.label))
  } else if (data_psbO)
  {
    data2m = read.table(file = paste0(data_folder,"/psbO_Juan/MSP.MATOU-v2.metaG.matrix36.tsv"),
                        sep = "\t", 
                        header = TRUE)
    
    # Building sample_ref from the sample codes in data2m:
    sample_ref = matrix(nrow = ncol(data2m), ncol = 6, 
                        dimnames = list(colnames(data2m),c("Sample.id","Station.label","Depth","Index","Fraction.size","Sequence.type")), data = "NA")
    for (i in 1:ncol(data2m))
    {
      # Removing the "X" prefix:
      sample_code = substr(colnames(data2m)[i],2,nchar(colnames(data2m)[i]))
      # Adding 0s in front of the station number if it is less than 3-figure long:
      while (is.na(as.numeric(substr(sample_code,1,3))))
        sample_code = paste0("0",sample_code)
      # Retrieving the sample index (which may be of length 1 or 2 characters):
      sample.index = NULL
      char_i = 7
      while (!is.na(as.numeric(substr(sample_code,char_i,char_i))))
      {
        sample.index = paste0(sample.index,substr(sample_code,char_i,char_i))
        char_i = char_i+1
      }
      # Decomposing the sample code into 5 attributes:
      sample_ref[i,] = c(colnames(data2m)[i],
                         substr(sample_code,1,3),
                         substr(sample_code,4,6),
                         if (is.null(sample.index)) NA else sample.index,
                         substr(sample_code,char_i,char_i+3),
                         substr(sample_code,char_i+4,char_i+5))
    }
    sample_ref = as.data.frame(sample_ref)
    
    size.fraction_codes = c("BBCC","GGKK","GGMM","GGQQ","GGZZ","MMQQ","QQSS","SSUU","AACC","CCII","IIQQ","EEGG","CCKK","KKQQ","KKZZ","CCEE","EEOO","YYYY","AAZZ","ZZZZ","GGSS","SSZZ","TTZZ","QQRR","GGRR")
    size.frations = c("0.1-0.2","0.8-3","0.8-5","0.8-20","0.8-inf","5-20","20-180","180-2000","0-0.2","0.2-1.6","1.6-20","0.45-0.8","0.22-3","3-20","3-inf","0.2-0.45","0.45-8","pool","0-inf","inf-inf","0.8-180","180-inf","300-inf","20-200","0.8-200")
    for (i in 1:length(size.fraction_codes))
    {
      if (any(sample_ref$Fraction.size == size.fraction_codes[i]))
        sample_ref$Fraction.size[sample_ref$Fraction.size == size.fraction_codes[i]] = size.frations[i]
    }
    
    sequence.type_codes = c("11","12")
    sequence.types = c("Meta-DNA","Meta-DNA_WGA")
    for (i in sequence.type_codes)
      sample_ref$Sequence.type[sample_ref$Sequence.type == sequence.type_codes[i]] = sequence.types[i]
    
    sample_ref$Station.label = paste0("TARA_",sample_ref$Station.label)
    
    #Building taxo_ref:
    taxo_ref = read.table(file = paste0(data_folder,"/psbO_Juan/MSP.taxonomy.corrected.tsv"),
                          sep = "\t", 
                          header = TRUE,
                          row.names = 1)
    additional_taxo_ref = read.table(file = paste0(data_folder,"/psbO_Juan/missing_psbO.tsv"),
                                     sep = "\t", 
                                     header = F,
                                     row.names = 1)
    rownames(additional_taxo_ref) = substr(rownames(additional_taxo_ref),10,nchar(rownames(additional_taxo_ref)))
    taxo_groups_v9 = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    taxo_group_psb0 = vector(length = nrow(taxo_ref) + nrow(additional_taxo_ref), mode = "character")
    for (i in 1:nrow(taxo_ref))
    {
      lineage_split = c(strsplit(taxo_ref$lineage[i], split = ";", fixed = T)[[1]],taxo_ref$last_taxon[i]) 
      group_candidates = lineage_split %in% taxo_groups_v9 & lineage_split != "Unknown"
      if (length(which(group_candidates)) == 1)
        taxo_group_psb0[i] = lineage_split[group_candidates]
      else if (length(which(group_candidates)) == 0)
        taxo_group_psb0[i] = NA
      else if (length(which(group_candidates)) > 1)
        taxo_group_psb0[i] = paste(lineage_split[group_candidates], collapse = "-")
    }
    for (i in 1:nrow(additional_taxo_ref))
    {
      taxo_id = additional_taxo_ref[i,1]
      if (taxo_id %in% taxo_groups_v9 & taxo_id != "Unknown")
        taxo_group_psb0[i + nrow(taxo_ref)] = taxo_id
      else
        taxo_group_psb0[i + nrow(taxo_ref)] = NA
    }
    taxo_ref = rbind(taxo_ref,
                     matrix(nrow = nrow(additional_taxo_ref),
                            ncol = 4,
                            dimnames = list(rownames(additional_taxo_ref),colnames(taxo_ref)),
                            data = rep("NA",4*nrow(additional_taxo_ref))))
    taxo_ref = cbind(taxo_ref,taxogroup2 = taxo_group_psb0)
    ###
    taxo_ref = taxo_ref[rownames(taxo_ref) %in% rownames(data2m),]
    taxo_ref = taxo_ref[order(factor(rownames(taxo_ref),levels=rownames(data2m))),]
    
    if (noLagoon)
    {
      data2m = data2m[,!sample_ref$Station.label %in% lagoon_stations]
      sample_ref = sample_ref[!sample_ref$Station.label %in% lagoon_stations,]
    }
    
    samples_data2m = colnames(data2m)
    stations_names = levels(as.factor(sample_ref$Station.label))
  }
  
  # Removing OTU with null count after the removal of some of the stations
  taxo_ref = taxo_ref[rowSums(data2m) != 0,]
  data2m = data2m[rowSums(data2m) != 0,]
}

if (split_byStation)
{ 
  # data2mNew stores OTU counts for stations ordered as in sample_ref
  data2mNew = matrix(nrow=nrow(data2m),ncol=length(stations_names),data=0)
  colnames(data2mNew) = stations_names
  # coord stores spatial coordinates for stations ordred as in sample_ref
  coord = data.frame(Lat=vector(length=length(stations_names),mode="numeric"),Long=vector(length=length(stations_names)))
  rownames(coord) = stations_names
  station_index = 0
  # Loop over all stations
  for (station in stations_names)
  {
    station_index = station_index+1
    # Looking for the samples corresponding to the current station in sample_ref:
    samples_indices = which(sample_ref$Station.label==station)
    # Saving the spatial coordinates of the current station:
    coord[station_index,] = c(as.numeric(sample_ref$Latitude[samples_indices][1]),as.numeric(sample_ref$Longitude[samples_indices][1]))
    
    if (!all(as.numeric(sample_ref$Latitude[samples_indices])==coord[station_index,1]) || !all(as.numeric(sample_ref$Longitude[samples_indices])==coord[station_index,2]))
      stop("Not all samples belonging to the same station have equal coordinates")
    
    # Storing the names of the samples corresponding to the current station, so as to look for them in data2m:
    samples_names = sample_ref$Sample.id[samples_indices]
    # Storing the indices of those samples in data2m
    samples_indices_data2m = vector(length=length(samples_indices),mode="numeric")
    sample_index = 0
    # Loop over all samples cooresponding to the current station
    for (sample in samples_names)
    {
      sample_index = sample_index+1
      samples_indices_data2m[sample_index] = which(samples_data2m==sample)
    }
    # Summing OTU counts for all samples corresponding to the current station:
    if (length(samples_indices_data2m) > 1)
      data2mNew[,station_index] = rowSums(data2m[,samples_indices_data2m])
    else
      data2mNew[,station_index] = data2m[,samples_indices_data2m]
  }
  setwd(paste0(data_folder,"/18S_V9_TARA_byStation",noArcticNoBiomark_insert,noLagoon_insert))
  data2m = data2mNew
  save(data2m,file="data2m.Rdata")
  save(coord,file="coord.Rdata")
} else if (all_data_coord)
{
  # coord stores stations' coordinates while keeping samples' original ordering from data2m 
  coord = data.frame(Lat=vector(length=ncol(data2m),mode="numeric"),Long=vector(length=ncol(data2m),mode="numeric"))
  for (station in stations_names)
  {
    #station_index = station_index+1
    # Looking for the samples corresponding to the current station in sample_ref:
    samples_indices = which(sample_ref$Station.label==station)
    if (!all(as.numeric(sample_ref$Latitude[samples_indices])==as.numeric(sample_ref$Latitude[samples_indices][1])) || !all(as.numeric(sample_ref$Longitude[samples_indices])==as.numeric(sample_ref$Longitude[samples_indices][1])))
      stop("Not all samples belonging to the same station have equal coordinates.")
    # Storing the names of the samples corresponding to the current station, so as to look for them in data2m:
    samples_names = sample_ref$Sample.id[samples_indices]
    # Loop over all samples cooresponding to the current station
    for (sample in samples_names)
    {
      # Storing the index of the sample in data2m
      sample_index_data2m = which(samples_data2m==sample)
      if (length(sample_index_data2m)>1)
        stop("Sample duplicate in data2m.")
      # Saving the spatial coordinates of the sample in coord:
      coord[sample_index_data2m,] = c(as.numeric(sample_ref$Latitude[samples_indices][1]),as.numeric(sample_ref$Longitude[samples_indices][1]))
    } 
  }
  
  setwd(paste0(data_folder,"/18S_V9_TARA"))
  save(coord,file="coord.Rdata")
} else if (split_byStationByDepth_CompleteSizeRange)
{ 
  samples_stations = sample_ref$Station.label
  samples_depths = sample_ref$Depth
  samples_fractions = sample_ref$Fraction.size
  
  if (data_Federico)
  {
    coord = list()
    coord_SUR = list()
    coord_DCM = list()
  }
  station_depth_names = list()
  stations_names_SUR = list()
  stations_names_DCM = list()
  #stations_names_remaining = list()
  data2mNew = list()
  data2mNew_SUR = list()
  data2mNew_DCM = list()
  
  All_samples_indices = list()
  All_samples_indices_data2m = list() 
  
  station_depth_index = 0
  station_index_SUR = 0
  station_index_DCM = 0
  station_index = 0
  # Loop over all stations
  for (station in stations_names)
  {
    station_flag = 0
    for (depth in c("SUR","DCM"))
    {
      # Looking for the samples corresponding to the current station in sample_ref:
      # samples_indices = which(samples_stations == station)
      # samples_indices = samples_indices[which(samples_depths[samples_indices] == depth)]
      samples_indices = which(samples_stations == station & samples_depths == depth)
      #samples_indices = samples_indices[which(samples_templates[samples_indices] == "DNA")]
      
      if (
        (length(samples_indices) > 0) 
        && (
          (
            (
              (any(samples_fractions[samples_indices]=="0.8-5") && any(samples_fractions[samples_indices]=="5-20"))
              || (any(samples_fractions[samples_indices]=="0.8-3") && any(samples_fractions[samples_indices]=="3-20"))
              || any(samples_fractions[samples_indices]=="0.8-20")
            )
            && (
              ((any(samples_fractions[samples_indices]=="20-180") || any(samples_fractions[samples_indices]=="20-200")) && any(samples_fractions[samples_indices]=="180-2000"))
              || any(samples_fractions[samples_indices]=="20-2000")
            )
          ) 
          || any(samples_fractions[samples_indices]=="0.8->") || any(samples_fractions[samples_indices]=="0.8-inf")
          || (any(samples_fractions[samples_indices]=="0.8-3") && any(samples_fractions[samples_indices]=="3-inf"))
        )
      )
      {
        cat("\n",station,depth)
        
        if (station_flag == 0)
        {
          station_index = station_index+1
          station_flag = 1
        }
        
        station_depth_index = station_depth_index+1
        # Storing the names of the samples corresponding to the current station, so as to look for them in data2m:
        samples_names = sample_ref$Sample.id[samples_indices]
        # Storing the indices of those samples in data2m
        # samples_indices_data2m = vector(length=length(samples_indices),mode="numeric")
        # sample_index = 0
        # for (sample in samples_names)
        # { 
        #   sample_index = sample_index+1
        #   samples_indices_data2m[sample_index] = which(samples_data2m == sample)
        # }
        samples_indices_data2m = which(samples_data2m %in% samples_names)
        
        # samples_indices and samples_indices_data2m are identical for data_Federico (i.e., sample orders are the same), 
        # but not in old_data and data_V4
        All_samples_indices[[station_depth_index]] = samples_indices
        All_samples_indices_data2m[[station_depth_index]] = samples_indices_data2m
        
        # Summing OTU counts for all samples corresponding to the current station:
        if (length(samples_indices_data2m) > 1)
          data2mNew[[station_depth_index]] = rowSums(data2m[,samples_indices_data2m])
        else
          data2mNew[[station_depth_index]] = data2m[,samples_indices_data2m]
        
        station_depth_names[[station_depth_index]] = paste(station,depth)
        #stations_names_remaining[[station_index]] = station
        
        # Saving the spatial coordinates of the current station:
        if (data_Federico)
          coord[[station_depth_index]] = c(as.numeric(sample_ref$Latitude[samples_indices][1]),as.numeric(sample_ref$Longitude[samples_indices][1]))
        #         if (!all(as.numeric(sample_ref$Latitude[samples_indices])==coord[[station_depth_index]][1]) || !all(as.numeric(sample_ref$Longitude[samples_indices+1])==coord[[station_depth_index]][2]))
        #           stop("Not all samples belonging to the same station have equal coordinates")
        
        if (depth == "SUR")
        {
          station_index_SUR = station_index_SUR+1
          if (data_Federico)
            coord_SUR[[station_index_SUR]] = c(as.numeric(sample_ref$Latitude[samples_indices][1]),as.numeric(sample_ref$Longitude[samples_indices][1]))
          #           if (!all(as.numeric(sample_ref$Latitude[samples_indices])==coord_SUR[[station_index_SUR]][1]) || !all(as.numeric(sample_ref$Longitude[samples_indices])==coord_SUR[[station_index_SUR]][2]))
          #             stop("Not all samples belonging to the same station have equal coordinates") 
          
          stations_names_SUR[[station_index_SUR]] = station   
          
          if (length(samples_indices_data2m) > 1)
            data2mNew_SUR[[station_index_SUR]] = rowSums(data2m[,samples_indices_data2m])
          else
            data2mNew_SUR[[station_index_SUR]] = data2m[,samples_indices_data2m]
        } else if (depth == "DCM")
        {
          station_index_DCM = station_index_DCM + 1
          if (data_Federico)
            coord_DCM[[station_index_DCM]] = c(as.numeric(sample_ref$Latitude[samples_indices][1]),as.numeric(sample_ref$Longitude[samples_indices][1]))
          #           if (!all(as.numeric(sample_ref$Latitude[samples_indices])==coord_DCM[[station_index_DCM]][1]) || !all(as.numeric(sample_ref$Longitude[samples_indices])==coord_DCM[[station_index_DCM]][2]))
          #             stop("Not all samples belonging to the same station have equal coordinates")
          
          stations_names_DCM[[station_index_DCM]] = station 
          
          if (length(samples_indices_data2m) > 1)
            data2mNew_DCM[[station_index_DCM]] = rowSums(data2m[,samples_indices_data2m])
          else
            data2mNew_DCM[[station_index_DCM]] = data2m[,samples_indices_data2m]
        }
      }
    }
  }
  
  # data2mNew stores OTU counts for stations ordered as in sample_ref
  data2mNew = matrix(ncol=length(data2mNew),data=unlist(data2mNew))
  #colnames(data2mNew) = station_depth_names
  data2mNew_SUR = matrix(ncol=length(data2mNew_SUR),data=unlist(data2mNew_SUR))
  #colnames(data2mNew_SUR) = stations_names_SUR
  data2mNew_DCM = matrix(ncol=length(data2mNew_DCM),data=unlist(data2mNew_DCM))
  #colnames(data2mNew_DCM) = stations_names_DCM
  
  # Removing OTUs with null count after the "complete size range" filter
  taxo_ref = taxo_ref[rowSums(data2mNew) != 0,]
  data2m = data2m[rowSums(data2mNew) != 0,]
  data2mNew = data2mNew[rowSums(data2mNew) != 0,]
  
  taxo_ref_SUR = taxo_ref[rowSums(data2mNew_SUR) != 0,]
  data2mNew_SUR = data2mNew_SUR[rowSums(data2mNew_SUR) != 0,]
  
  taxo_ref_DCM = taxo_ref[rowSums(data2mNew_DCM) != 0,]
  data2mNew_DCM = data2mNew_DCM[rowSums(data2mNew_DCM) != 0,]
  
  All_samples_indices = unlist(All_samples_indices)
  sample_ref = sample_ref[All_samples_indices,]
  All_samples_indices_data2m = unlist(All_samples_indices_data2m)
  data2m = data2m[,All_samples_indices_data2m]
  
  # setwd(figure_folder)
  # load(paste0("group_sizes_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata"))
  # taxa_insert0_indices = vector(length = length(taxa_insert0), mode = "numeric")
  # for (i in 1:length(taxa_insert0))
  # {
  #   taxa_insert0_indices[i] = which(taxo_groups == taxa_insert0[i])
  # }
  # taxa_insert = taxo_groups[-taxa_insert0_indices]
  
  # coord stores spatial coordinates for stations ordered as in sample_ref
  if (old_data || data_Federico)
  {
    coord = as.data.frame(t(data.frame(coord)))
    colnames(coord) = c("y","x")
    rownames(coord) = station_depth_names
    coord_SUR = as.data.frame(t(data.frame(coord_SUR)))
    colnames(coord_SUR) = c("y","x")
    rownames(coord_SUR) = stations_names_SUR
    coord_DCM = as.data.frame(t(data.frame(coord_DCM)))
    colnames(coord_DCM) = c("y","x")
    rownames(coord_DCM) = stations_names_DCM
  } else if (data_V4 || data_psbO)
  {
    load(paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa_noLagoon/coord.Rdata"))
    # unlist(station_depth_names)[!unlist(station_depth_names) %in% rownames(coord)]
    # Obtaining missing coords from PANGAEA:
    sample_ref_pangaea = read.table(file = paste0(data_folder,"/Abiotic_data_Pangaea/TARA_SAMPLES_CONTEXT_ENV-WATERCOLUMN_no.intro.tab"),
                                    sep = "\t",
                                    header = TRUE)
    coord_supp = matrix(nrow = 2, ncol = 2, dimnames = list(c("TARA_047 DCM","TARA_175 DCM"),colnames(coord)),
                        data = as.numeric(c(colMeans(sample_ref_pangaea[sample_ref_pangaea$Station == "TARA_047",c("Latitude","Longitude")]),
                                 coord["TARA_175 SUR",])), byrow = T)
    # colMeans(sample_ref_pangaea[sample_ref_pangaea$Station == "TARA_175",c("Latitude","Longitude")],na.rm = T)
    coord = rbind(coord,as.matrix(coord_supp))
    coord = coord[rownames(coord) %in% unlist(station_depth_names),]
    coord = coord[order(factor(rownames(coord),levels=unlist(station_depth_names))),]
  }
  
  # data2m_beforeMerging = data2m 
  # taxo_ref_beforeMerging = taxo_ref
  
  # Removing unwanted taxo_groups and computing the diversity per group
  if (old_data)
  {
    taxo_groups_OTUs = taxo_ref$taxogroup
  } else
  {
    taxo_groups_OTUs = taxo_ref$taxogroup2
  }
  taxo_groups = levels(as.factor(taxo_groups_OTUs))
  diversity = table(as.factor(taxo_groups_OTUs))
  taxo_groups = taxo_groups[diversity >= div_threshold]
  diversity = diversity[diversity >= div_threshold]
  
  taxo_ref = taxo_ref[taxo_groups_OTUs %in% taxo_groups,]
  data2mNew = data2mNew[taxo_groups_OTUs %in% taxo_groups,]
  data2m = data2m[taxo_groups_OTUs %in% taxo_groups,]
  taxo_groups_OTUs = taxo_groups_OTUs[taxo_groups_OTUs %in% taxo_groups]
  
  taxo_groups = taxo_groups[sort.int(diversity,index.return = T,decreasing = T)$ix]
  diversity = sort(diversity,decreasing = T)
  
  #All_OTU_indices = c(All_OTU_indices,which(taxo_groups_OTUs == group))
  
  # group_index = 0
  # groups_to_remove = vector(length = length(taxo_groups), mode = "logical")
  # All_OTU_indices = NULL
  # diversity = vector(length = length(taxo_groups), mode = "numeric")
  # for (group in taxo_groupsNew)
  # {
  #   group_index = group_index+1
  #   diversity[group_index] = length(which(taxo_groups_OTUs == group))
  # }  
  #   
  #   if ((substr(group,1,1) == "?") || (diversity[group_index] < div_threshold))
  #   {
  #     groups_to_remove[group_index] = TRUE
  #   } else
  #     All_OTU_indices = c(All_OTU_indices,which(taxo_groups_OTUs == group))
  # }
  
  data2m0 = data2m
  coord0 = coord
  taxo_ref0 = taxo_ref
  
  # alltaxa data only include the groups that have diversity above "div_threshold"
  if (alltaxa)
  {
    #setwd(paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxa_insert))
    foldername = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
    if (!file.exists(foldername))
      dir.create(foldername)
    setwd(foldername)
    data2m = data2mNew
    save(data2m,file="data2m.Rdata",version=2)
    save(coord,file="coord.Rdata",version=2)
    save(taxo_ref,file="taxo_ref.Rdata",version=2)
    save(data2m0,file="data2m_unmerged.Rdata",version=2)
    save(sample_ref,file="sample_ref.Rdata",version=2)
    
    # foldername = paste0(data_folder,"/",marker,"_TARA_Surface_CompleteSizeRange_byStation_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
    # if (!file.exists(foldername))
    #   dir.create(foldername)
    # setwd(foldername)
    # data2m = data2mNew_SUR
    # taxo_ref = taxo_ref_SUR
    # save(data2m,file="data2m.Rdata")
    # coord = coord_SUR
    # save(coord,file="coord.Rdata")
    # save(taxo_ref,file="taxo_ref.Rdata")
    # 
    # foldername = paste0(data_folder,"/",marker,"_TARA_DCM_CompleteSizeRange_byStation_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
    # if (!file.exists(foldername))
    #   dir.create(foldername)
    # setwd(foldername)
    # data2m = data2mNew_DCM
    # taxo_ref = taxo_ref_DCM
    # save(data2m,file="data2m.Rdata")
    # coord = coord_DCM
    # save(coord,file="coord.Rdata")
    # save(taxo_ref,file="taxo_ref.Rdata")
  } 
  
  coord = coord0
  
  # Dealing with inconsistent spelling of "Archamoebae":
  Archamoebae_done = 0
  taxo_groups_modif = vector(length = length(taxo_groups), mode = "character")
  i_taxa = 0
  # taxo_groupsNew_modif_logical = vector(length = length(taxo_groupsNew), mode = "logical")
  for (taxa in taxo_groups) 
  {
    i_taxa = i_taxa+1
    data2m = data2mNew
    taxo_ref = taxo_ref0
    # Dealing with inconsistent spelling of "Archamoebae":
    if (old_data && (taxa == "Archamoebae" || taxa == "Archamoeba") && Archamoebae_done == 0)
    {
      data2m = data2m[(taxo_groups_OTUs =="Archamoebae" | taxo_groups_OTUs =="Archamoeba"),]
      taxo_ref = taxo_ref[(taxo_groups_OTUs =="Archamoebae" | taxo_groups_OTUs =="Archamoeba"),]
      taxa = "Archamoebae"
      Archamoebae_done = 1
    } else
    # Splitting the data taxonomic group by taxonomic group:  
    {
      data2m = data2m[taxo_groups_OTUs == taxa,]
      taxo_ref = taxo_ref[taxo_groups_OTUs == taxa,]
    }
    
    #All_OTU_indices = c(All_OTU_indices,which(taxo_groups_OTUs == group))
    
    taxa = paste(strsplit(taxa,split=" ",fixed=T)[[1]],collapse="_")
    taxa = paste(strsplit(taxa,split="&",fixed=T)[[1]],collapse="and")
    taxa = paste(strsplit(taxa,split="(",fixed=T)[[1]],collapse="")
    taxa = paste(strsplit(taxa,split=")",fixed=T)[[1]],collapse="")
    # taxa = paste(strsplit(taxa,split=" ",fixed=T)[[1]],collapse="-")
    # taxa = paste(strsplit(taxa,split=",",fixed=T)[[1]],collapse="")
    # taxa = paste(strsplit(taxa,split="*",fixed=T)[[1]],collapse="")
    # taxa = paste(strsplit(taxa,split="&",fixed=T)[[1]],collapse="and")
    # taxa = paste(strsplit(taxa,split="(",fixed=T)[[1]],collapse="")
    # taxa = paste(strsplit(taxa,split=")",fixed=T)[[1]],collapse="")
    taxo_groups_modif[i_taxa] = taxa
    # taxo_groupsNew_modif_logical[taxa_i] = (taxa != taxa0)
    
    if (nrow(data2m) !=0 && nrow(taxo_ref) != 0 && !taxa %in% groups_to_remove)
    {
      foldername = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxa,noArcticNoBiomark_insert,noLagoon_insert)
      if (!file.exists(foldername))
        dir.create(foldername)
      setwd(foldername)
      save(data2m,file="data2m.Rdata",version=2)
      save(coord,file="coord.Rdata",version=2)
      save(taxo_ref,file="taxo_ref.Rdata",version=2)
    }
  }
  
  diversity = diversity[!taxo_groups_modif %in% groups_to_remove]
  taxo_groups_modif = taxo_groups_modif[!taxo_groups_modif %in% groups_to_remove]
  # saveRDS(taxo_groups_modif,paste0("/Users/guilhemsommeria-klein/Desktop/Serveur_Bioclust/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # saveRDS(taxo_groups,paste0("/Users/guilhemsommeria-klein/Desktop/Serveur_Bioclust/taxo_groups_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # saveRDS(diversity,paste0("/Users/guilhemsommeria-klein/Desktop/Serveur_Bioclust/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # saveRDS(taxo_groups_modif,paste0(results_folder,"/",short_marker,"taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  saveRDS(taxo_groups_modif,paste0(results_folder,"/",short_marker,"taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"),version=2)
  # saveRDS(diversity,paste0(results_folder,"/",short_marker,"diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  saveRDS(diversity,paste0(results_folder,"/",short_marker,"diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"),version=2)
  
  data2m = data2m0
  taxo_ref = taxo_ref0
}

# # Copying coorect coord to the cluster (to correct a mistake):
# for (taxon in taxo_groups_modif)
# {
#   cluster.data.folder_name = paste0(data_folder_workspace3,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,"_noLagoon")
#   local.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,"_noLagoon")
#   command = paste0("cp ",local.data.folder_name,"/coord.Rdata ",
#                    cluster.data.folder_name,"/")
#   system(command, intern=TRUE)
# }

devtools::source_url("https://github.com/guilhemSK/eDNA_LDA/raw/main/Tara_LDA/Normalized.VI_fun.R")

###########
if (data_Federico)
{
  for (marker_case in c("18S_V4","psbO"))
  {
    data.folder_name = paste0(data_folder,"/",marker_case,"_TARA_CompleteSizeRange_byStationByDepth_AllTAxa",noArcticNoBiomark_insert,noLagoon_insert)
    load(paste0(data.folder_name,"/coord.Rdata"))
    
    # selected_stations contains the stations effectively used for the decomposition, in the same order as in spatial_topicmix_kriged, with the names used in Iudicone's travel_time_matrix
    # i.e., converts rownames(coord) into the names in travel_time_matrix
    selected_stations.l = lapply(strsplit(rownames(coord),split=" ",fixed=T),strsplit,split="_",fixed=T)
    selected_stations = vector(length = nrow(coord), mode = "character")
    for (i in 1:nrow(coord))
    {
      selected_stations[i] = paste(selected_stations.l[[i]][[1]][2],selected_stations.l[[i]][[2]][1],sep = "_")
      station_split = strsplit(selected_stations[i],split="",fixed=T)[[1]]
      if (station_split[1] == "0")
      {
        j = 1
        while (station_split[j] == "0")
          j = j+1
        selected_stations[i] = paste(station_split[-(1:(j-1))],collapse = "")
      }
    }
    
    stations_depths = as.data.frame(matrix(nrow=nrow(coord),ncol=2,dimnames = list(rownames(coord),c("Station","Depth"))))
    for (station_depth_index in 1:nrow(coord))
    {
      stations_depths[station_depth_index,] = c(strsplit(rownames(coord)[station_depth_index],split=" ",fixed=T)[[1]][1],
                                                strsplit(rownames(coord)[station_depth_index],split=" ",fixed=T)[[1]][2])
    }
    
    if (marker_case == "18S_V4")
    {
      stations_depths_V4 = stations_depths
      selected_stations_V4 = selected_stations
      coord_V4 = coord
    } else if (marker_case == "psbO")
    {
      stations_depths_psbO = stations_depths
      selected_stations_psbO = selected_stations
      coord_psbO = coord
    }
  }
}

########
data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_AllTAxa",noArcticNoBiomark_insert,noLagoon_insert)
load(paste0(data.folder_name,"/coord.Rdata"))

# selected_stations contains the stations effectively used for the decomposition, in the same order as in spatial_topicmix_kriged, with the names used in Iudicone's travel_time_matrix
# i.e., converts rownames(coord) into the names in travel_time_matrix
selected_stations.l = lapply(strsplit(rownames(coord),split=" ",fixed=T),strsplit,split="_",fixed=T)
selected_stations = vector(length = nrow(coord), mode = "character")
for (i in 1:nrow(coord))
{
  selected_stations[i] = paste(selected_stations.l[[i]][[1]][2],selected_stations.l[[i]][[2]][1],sep = "_")
  station_split = strsplit(selected_stations[i],split="",fixed=T)[[1]]
  if (station_split[1] == "0")
  {
    j = 1
    while (station_split[j] == "0")
      j = j+1
    selected_stations[i] = paste(station_split[-(1:(j-1))],collapse = "")
  }
}

stations_depths = as.data.frame(matrix(nrow=nrow(coord),ncol=2,dimnames = list(rownames(coord),c("Station","Depth"))))
for (station_depth_index in 1:nrow(coord))
{
  stations_depths[station_depth_index,] = c(strsplit(rownames(coord)[station_depth_index],split=" ",fixed=T)[[1]][1],
                                            strsplit(rownames(coord)[station_depth_index],split=" ",fixed=T)[[1]][2])
}

if (data_Federico)
{
  stations_depths_V9 = stations_depths
  selected_stations_V9 = selected_stations
  coord_V9 = coord
}
###########

# if (i_taxon == 1)
# {
#   Arctic_stations = rownames(coord)[which(rownames(coord) == "TARA_158 SUR"):nrow(coord)]
#   NorthAtlantic_stations = rownames(coord)[which(rownames(coord) == "TARA_141 SUR"):which(rownames(coord) == "TARA_155 DCM")]
# }

# Testing the output on server:
# taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs.rds"))
# taxo_groups_ok = vector(length = length(taxo_groups), mode = "numeric")
# k = 0
# for (taxon in taxo_groups)
# {
#   k = k+1
#   #taxon = "AllTaxa"
#   data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
#   taxo_groups_ok[k] = (file.exists(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics8_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence")) == 1)
# }

if (group_rarefaction)
{
  if (data_Federico)
  {
    taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100
  }
  
  tot_reads = vector(length = length(taxo_groups), mode = "numeric")
  nb.reads_200 = diversity.200 = nb.reads_250 = diversity.250 = nb.reads_300 = diversity.300 = nb.reads_350 = diversity.350 = nb.reads_500 = diversity.500 = nb.reads_1000 = diversity.1000 = vector(length = length(taxo_groups), mode = "numeric")
  mean_prevalence.200 = mean_prevalence.250 = mean_prevalence.300 = mean_prevalence.350 = mean_prevalence.500 = mean_prevalence.1000 = mean_prevalence = vector(length = length(taxo_groups), mode = "numeric")
  median_prevalence.200 = median_prevalence.250 = median_prevalence.300 = median_prevalence.350 = median_prevalence.500 = median_prevalence.1000 = median_prevalence = vector(length = length(taxo_groups), mode = "numeric")
  mean_prevalence.250.random = mean_prevalence.350.random = vector(length = length(taxo_groups), mode = "numeric")
  median_prevalence.250.random = median_prevalence.350.random = vector(length = length(taxo_groups), mode = "numeric")
  diversity.104 = diversity.105 = diversity.106 = vector(length = length(taxo_groups), mode = "numeric")
  names(diversity.104) = names(diversity.105) = names(diversity.106) = taxo_groups
  for (taxon in taxo_groups[selected_groups])
  {
    if (taxon != "AllTaxa")
      i_taxon = which(taxo_groups == taxon)
    cat("\n",ifelse(taxon=="AllTaxa","AllTaxa",paste(i_taxon,"/",length(taxo_groups))))
    
    # data.folder_name = paste0(data_folder_workspace3,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    
    load(paste0(data.folder_name,"/data2m.Rdata"))
    data2m0 = data2m
    # tot_reads[i_taxon] = sum(data2m)
    # data2m_occ = data2m
    # data2m_occ[data2m_occ > 0] = 1
    # mean_prevalence[i_taxon] = mean(rowSums(data2m_occ))
    # median_prevalence[i_taxon] = median(rowSums(data2m_occ))
    # remove(data2m_occ)
    remove(data2m)
    # diversity.bis[i_taxon] = nrow(data2m)
    load(paste0(data.folder_name,"/coord.Rdata"))
    load(paste0(data.folder_name,"/taxo_ref.Rdata"))
    taxo_ref0 = taxo_ref
    # if (nrow(data2m0) > 200)
    # {
    #   rarefied_data2m_fun <- function(nb_reads_raref){round(data2m0*nb_reads_raref/tot_reads[i_taxon])}
    #   nb_reads_raref_taxon = round(uniroot(f = function(nb_reads_raref) length(which(rowSums(rarefied_data2m_fun(nb_reads_raref)) != 0)) - 200,
    #                                        interval = c(200,tot_reads[i_taxon]))$root)
    #   raref_diversity = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon)) != 0))
    #   raref_diversity_minus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon - 1)) != 0))
    #   raref_diversity_plus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon + 1)) != 0))
    #   sort_raref_diversity = sort.int(c(abs(raref_diversity-200),abs(raref_diversity_minus.1-200),abs(raref_diversity_plus.1-200)), decreasing=F, index.return = T)
    #   if (sort_raref_diversity$ix[1] == 1)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon
    #   } else if (sort_raref_diversity$ix[1] == 2)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon - 1
    #   } else if (sort_raref_diversity$ix[1] == 3)
    #     nb_reads_raref_taxon = nb_reads_raref_taxon + 1
    #   rarefied_data2m_200 = rarefied_data2m_fun(nb_reads_raref_taxon)
    #   taxo_ref = taxo_ref0[rowSums(rarefied_data2m_200) != 0,]
    #   rarefied_data2m_200 = rarefied_data2m_200[rowSums(rarefied_data2m_200) != 0,]
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".200",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   data2m = rarefied_data2m_200
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   diversity.200[i_taxon] = nrow(data2m)
    #   nb.reads_200[i_taxon] = nb_reads_raref_taxon
    #   data2m_occ = data2m
    #   data2m_occ[data2m_occ > 0] = 1
    #   mean_prevalence.200[i_taxon] = mean(rowSums(data2m_occ))
    #   median_prevalence.200[i_taxon] = median(rowSums(data2m_occ))
    #   remove(data2m_occ)
    #   remove(data2m)
    #   remove(rarefied_data2m_200)
    #   remove(taxo_ref)
    # }
    # if (nrow(data2m0) > 350)
    # {
    #   rarefied_data2m_fun <- function(nb_reads_raref){round(data2m0*nb_reads_raref/tot_reads[i_taxon])}
    #   nb_reads_raref_taxon = round(uniroot(f = function(nb_reads_raref) length(which(rowSums(rarefied_data2m_fun(nb_reads_raref)) != 0)) - 350,
    #                                        interval = c(350,tot_reads[i_taxon]))$root)
    #   raref_diversity = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon)) != 0))
    #   raref_diversity_minus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon - 1)) != 0))
    #   raref_diversity_plus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon + 1)) != 0))
    #   sort_raref_diversity = sort.int(c(abs(raref_diversity-350),abs(raref_diversity_minus.1-350),abs(raref_diversity_plus.1-350)), decreasing=F, index.return = T)
    #   if (sort_raref_diversity$ix[1] == 1)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon
    #   } else if (sort_raref_diversity$ix[1] == 2)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon - 1
    #   } else if (sort_raref_diversity$ix[1] == 3)
    #     nb_reads_raref_taxon = nb_reads_raref_taxon + 1
    #   rarefied_data2m_350 = rarefied_data2m_fun(nb_reads_raref_taxon)
    #   taxo_ref = taxo_ref0[rowSums(rarefied_data2m_350) != 0,]
    #   rarefied_data2m_350 = rarefied_data2m_350[rowSums(rarefied_data2m_350) != 0,]
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".350",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   data2m = rarefied_data2m_350
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   nb.reads_350[i_taxon] = nb_reads_raref_taxon
    #   diversity.350[i_taxon] = nrow(data2m)
    #   data2m_occ = data2m
    #   data2m_occ[data2m_occ > 0] = 1
    #   mean_prevalence.350[i_taxon] = mean(rowSums(data2m_occ))
    #   median_prevalence.350[i_taxon] = median(rowSums(data2m_occ))
    #   remove(data2m_occ)
    #   remove(data2m)
    #   remove(rarefied_data2m_350)
    #   remove(taxo_ref)
    # }
    # if (nrow(data2m0) > 300)
    # {
    #   rarefied_data2m_fun <- function(nb_reads_raref){round(data2m0*nb_reads_raref/tot_reads[i_taxon])}
    #   nb_reads_raref_taxon = round(uniroot(f = function(nb_reads_raref) length(which(rowSums(rarefied_data2m_fun(nb_reads_raref)) != 0)) - 300,
    #                                        interval = c(300,tot_reads[i_taxon]))$root)
    #   raref_diversity = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon)) != 0))
    #   raref_diversity_minus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon - 1)) != 0))
    #   raref_diversity_plus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon + 1)) != 0))
    #   sort_raref_diversity = sort.int(c(abs(raref_diversity-300),abs(raref_diversity_minus.1-300),abs(raref_diversity_plus.1-300)), decreasing=F, index.return = T)
    #   if (sort_raref_diversity$ix[1] == 1)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon
    #   } else if (sort_raref_diversity$ix[1] == 2)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon - 1
    #   } else if (sort_raref_diversity$ix[1] == 3)
    #     nb_reads_raref_taxon = nb_reads_raref_taxon + 1
    #   rarefied_data2m_300 = rarefied_data2m_fun(nb_reads_raref_taxon)
    #   taxo_ref = taxo_ref0[rowSums(rarefied_data2m_300) != 0,]
    #   rarefied_data2m_300 = rarefied_data2m_300[rowSums(rarefied_data2m_300) != 0,]
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".300",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   data2m = rarefied_data2m_300
    #   save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   nb.reads_300[i_taxon] = nb_reads_raref_taxon
    #   diversity.300[i_taxon] = nrow(data2m)
    #   data2m_occ = data2m
    #   data2m_occ[data2m_occ > 0] = 1
    #   mean_prevalence.300[i_taxon] = mean(rowSums(data2m_occ))
    #   median_prevalence.300[i_taxon] = median(rowSums(data2m_occ))
    #   remove(data2m_occ)
    #   remove(data2m)
    #   remove(rarefied_data2m_300)
    #   remove(taxo_ref)
    # }
    if (nrow(data2m0) > 200)
    {
      for (i in 6:10)
      {
        subsample_indices = sample(1:nrow(data2m0),200)
        data2m = data2m0[subsample_indices,]
        taxo_ref = taxo_ref0[subsample_indices,]
        new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".200.random.",i,noArcticNoBiomark_insert,noLagoon_insert)
        if (!file.exists(new.data.folder_name))
        {
          dir.create(new.data.folder_name)
          save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
        }
        save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
        save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
        # save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
        # data2m_occ = data2m
        # data2m_occ[data2m_occ > 0] = 1
        # mean_prevalence.200.random[i_taxon] = mean(rowSums(data2m_occ))
        # median_prevalence.200.random[i_taxon] = median(rowSums(data2m_occ))
        remove(data2m)
        # remove(data2m_occ)
        remove(taxo_ref)
      }
    }
    # if (nrow(data2m0) > 250)
    # {
    #   subsample_indices = sample(1:nrow(data2m0),250)
    #   data2m = data2m0[subsample_indices,]
    #   taxo_ref = taxo_ref0[subsample_indices,]
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".250.random",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   data2m_occ = data2m
    #   data2m_occ[data2m_occ > 0] = 1
    #   mean_prevalence.250.random[i_taxon] = mean(rowSums(data2m_occ))
    #   median_prevalence.250.random[i_taxon] = median(rowSums(data2m_occ))
    #   remove(data2m)
    #   remove(data2m_occ)
    #   remove(taxo_ref)
    # }
    # if (nrow(data2m0) > 350)
    # {
    #   subsample_indices = sample(1:nrow(data2m0),350)
    #   data2m = data2m0[subsample_indices,]
    #   taxo_ref = taxo_ref0[subsample_indices,]
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".350.random",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #   data2m_occ = data2m
    #   data2m_occ[data2m_occ > 0] = 1
    #   mean_prevalence.350.random[i_taxon] = mean(rowSums(data2m_occ))
    #   median_prevalence.350.random[i_taxon] = median(rowSums(data2m_occ))
    #   remove(data2m)
    #   remove(data2m_occ)
    #   remove(taxo_ref)
    # }
    if (nrow(data2m0) > 400)
    {
      for (i in 6:10)
      {
        subsample_indices = sample(1:nrow(data2m0),400)
        data2m = data2m0[subsample_indices,]
        taxo_ref = taxo_ref0[subsample_indices,]
        new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".400.random.",i,noArcticNoBiomark_insert,noLagoon_insert)
        if (!file.exists(new.data.folder_name))
        {
          dir.create(new.data.folder_name)
          save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
        }
        save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
        save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
        # save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
        # data2m_occ = data2m
        # data2m_occ[data2m_occ > 0] = 1
        # mean_prevalence.400.random[i_taxon] = mean(rowSums(data2m_occ))
        # median_prevalence.400.random[i_taxon] = median(rowSums(data2m_occ))
        remove(data2m)
        # remove(data2m_occ)
        remove(taxo_ref)
      }
    }
    if (nrow(data2m0) > 800)
    {
      for (i in 6:10)
      {
        subsample_indices = sample(1:nrow(data2m0),800)
        data2m = data2m0[subsample_indices,]
        taxo_ref = taxo_ref0[subsample_indices,]
        new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".800.random.",i,noArcticNoBiomark_insert,noLagoon_insert)
        if (!file.exists(new.data.folder_name))
        {
          dir.create(new.data.folder_name)
          save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
        }
        save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
        save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
        # save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
        # data2m_occ = data2m
        # data2m_occ[data2m_occ > 0] = 1
        # mean_prevalence.800.random[i_taxon] = mean(rowSums(data2m_occ))
        # median_prevalence.800.random[i_taxon] = median(rowSums(data2m_occ))
        remove(data2m)
        # remove(data2m_occ)
        remove(taxo_ref)
      }
    }
    # if (nrow(data2m0) > 500)
    # {
    #   rarefied_data2m_fun <- function(nb_reads_raref){round(data2m0*nb_reads_raref/tot_reads[i_taxon])}
    #   nb_reads_raref_taxon = round(uniroot(f = function(nb_reads_raref) length(which(rowSums(rarefied_data2m_fun(nb_reads_raref)) != 0)) - 500,
    #                                        interval = c(500,tot_reads[i_taxon]))$root)
    #   raref_diversity = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon)) != 0))
    #   raref_diversity_minus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon - 1)) != 0))
    #   raref_diversity_plus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon + 1)) != 0))
    #   sort_raref_diversity = sort.int(c(abs(raref_diversity-500),abs(raref_diversity_minus.1-500),abs(raref_diversity_plus.1-500)), decreasing=F, index.return = T)
    #   if (sort_raref_diversity$ix[1] == 1)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon
    #   } else if (sort_raref_diversity$ix[1] == 2)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon - 1
    #   } else if (sort_raref_diversity$ix[1] == 3)
    #     nb_reads_raref_taxon = nb_reads_raref_taxon + 1
    #   rarefied_data2m_500 = rarefied_data2m_fun(nb_reads_raref_taxon)
    #   taxo_ref = taxo_ref0[rowSums(rarefied_data2m_500) != 0,]
    #   rarefied_data2m_500 = rarefied_data2m_500[rowSums(rarefied_data2m_500) != 0,]
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".500",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   data2m = rarefied_data2m_500
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   nb.reads_500[i_taxon] = nb_reads_raref_taxon
    #   diversity.500[i_taxon] = nrow(data2m)
    #   data2m_occ = data2m
    #   data2m_occ[data2m_occ > 0] = 1
    #   mean_prevalence.500[i_taxon] = mean(rowSums(data2m_occ))
    #   median_prevalence.500[i_taxon] = median(rowSums(data2m_occ))
    #   remove(data2m_occ)
    #   remove(data2m)
    #   remove(rarefied_data2m_500)
    #   remove(taxo_ref)
    # }
    # if (nrow(data2m0) > 1000)
    # {
    #   rarefied_data2m_fun <- function(nb_reads_raref){round(data2m0*nb_reads_raref/tot_reads[i_taxon])}
    #   nb_reads_raref_taxon = round(uniroot(f = function(nb_reads_raref) length(which(rowSums(rarefied_data2m_fun(nb_reads_raref)) != 0)) - 1000,
    #                                        interval = c(1000,tot_reads[i_taxon]))$root)
    #   raref_diversity = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon)) != 0))
    #   raref_diversity_minus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon - 1)) != 0))
    #   raref_diversity_plus.1 = length(which(rowSums(rarefied_data2m_fun(nb_reads_raref_taxon + 1)) != 0))
    #   sort_raref_diversity = sort.int(c(abs(raref_diversity-1000),abs(raref_diversity_minus.1-1000),abs(raref_diversity_plus.1-1000)), decreasing=F, index.return = T)
    #   if (sort_raref_diversity$ix[1] == 1)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon
    #   } else if (sort_raref_diversity$ix[1] == 2)
    #   {
    #     nb_reads_raref_taxon = nb_reads_raref_taxon - 1
    #   } else if (sort_raref_diversity$ix[1] == 3)
    #     nb_reads_raref_taxon = nb_reads_raref_taxon + 1
    #   rarefied_data2m_1000 = rarefied_data2m_fun(nb_reads_raref_taxon)
    #   taxo_ref = taxo_ref0[rowSums(rarefied_data2m_1000) != 0,]
    #   rarefied_data2m_1000 = rarefied_data2m_1000[rowSums(rarefied_data2m_1000) != 0,]
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".1000",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   data2m = rarefied_data2m_1000
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   nb.reads_1000[i_taxon] = nb_reads_raref_taxon
    #   diversity.1000[i_taxon] = nrow(data2m)
    #   data2m_occ = data2m
    #   data2m_occ[data2m_occ > 0] = 1
    #   mean_prevalence.1000[i_taxon] = mean(rowSums(data2m_occ))
    #   median_prevalence.1000[i_taxon] = median(rowSums(data2m_occ))
    #   remove(data2m_occ)
    #   remove(data2m)
    #   remove(rarefied_data2m_1000)
    #   remove(taxo_ref)
    # }
    # if (tot_reads[i_taxon] > 10^4)
    # {
    #   rarefied_data2m_10.4 = round(data2m0*10^4/tot_reads[i_taxon])
    #   taxo_ref = taxo_ref0[rowSums(rarefied_data2m_10.4) != 0,]
    #   rarefied_data2m_10.4 = rarefied_data2m_10.4[rowSums(rarefied_data2m_10.4) != 0,]
    #   diversity.104[i_taxon] = nrow(rarefied_data2m_10.4)
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".104",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   data2m = rarefied_data2m_10.4
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   remove(data2m)
    #   remove(rarefied_data2m_10.4)
    #   remove(taxo_ref)
    # }
    # if (tot_reads[i_taxon] > 10^5)
    # {
    #   rarefied_data2m_10.5 = round(data2m0*10^5/tot_reads[i_taxon])
    #   taxo_ref = taxo_ref0[rowSums(rarefied_data2m_10.5) != 0,]
    #   rarefied_data2m_10.5 = rarefied_data2m_10.5[rowSums(rarefied_data2m_10.5) != 0,]
    #   diversity.105[i_taxon] = nrow(rarefied_data2m_10.5)
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".105",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   data2m = rarefied_data2m_10.5
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   remove(data2m)
    #   remove(rarefied_data2m_10.5)
    #   remove(taxo_ref)
    # }
    # if (tot_reads[i_taxon] > 10^6)
    # {
    #   rarefied_data2m_10.6 = round(data2m0*10^6/tot_reads[i_taxon])
    #   taxo_ref = taxo_ref0[rowSums(rarefied_data2m_10.6) != 0,]
    #   rarefied_data2m_10.6 = rarefied_data2m_10.6[rowSums(rarefied_data2m_10.6) != 0,]
    #   diversity.106[i_taxon] = nrow(rarefied_data2m_10.6)
    #   new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,".106",noArcticNoBiomark_insert,noLagoon_insert)
    #   if (!file.exists(new.data.folder_name))
    #   {
    #     dir.create(new.data.folder_name)
    #     save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
    #     save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    #   }
    #   data2m = rarefied_data2m_10.6
    #   # save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    #   remove(data2m)
    #   remove(rarefied_data2m_10.6)
    #   remove(taxo_ref)
    # }
    remove(data2m0)
    remove(taxo_ref0)
  }
  saveRDS(tot_reads,file=paste0(results_folder,"/",short_marker,"Total.read.numbers.rds"),version=2)
  saveRDS(list(diversity.104,diversity.105,diversity.106),file=paste0(results_folder,"/Rarefied_diversity.104.105.106.rds"),version=2)
  saveRDS(list(nb.reads_200,diversity.200),file=paste0(results_folder,"/",short_marker,"Total.read.numbers.200_diversity.200.rds"),version=2)
  saveRDS(list(nb.reads_250,diversity.250),file=paste0(results_folder,"/",short_marker,"Total.read.numbers.250_diversity.250.rds"),version=2)
  saveRDS(list(nb.reads_300,diversity.300),file=paste0(results_folder,"/",short_marker,"Total.read.numbers.300_diversity.300.rds"),version=2)
  saveRDS(list(nb.reads_350,diversity.350),file=paste0(results_folder,"/",short_marker,"Total.read.numbers.350_diversity.350.rds"),version=2)
  saveRDS(list(nb.reads_500,diversity.500),file=paste0(results_folder,"/",short_marker,"Total.read.numbers.500_diversity.500.rds"),version=2)
  saveRDS(list(nb.reads_1000,diversity.1000),file=paste0(results_folder,"/",short_marker,"Total.read.numbers.1000_diversity.1000.rds"),version=2)
  saveRDS(list(mean_prevalence,mean_prevalence.200,mean_prevalence.250,mean_prevalence.300,mean_prevalence.350,mean_prevalence.500,mean_prevalence.1000),
          file=paste0(results_folder,"/",short_marker,"mean_OTU.prevalence.200.250.300.350.500.1000.rds"),version=2)
  saveRDS(list(median_prevalence,median_prevalence.200,median_prevalence.250,median_prevalence.300,median_prevalence.350,median_prevalence.500,median_prevalence.1000),
          file=paste0(results_folder,"/",short_marker,"median_OTU.prevalence.200.250.300.350.500.1000.rds"),version=2)
  saveRDS(list(mean_prevalence.250.random,mean_prevalence.350.random),
          file=paste0(results_folder,"/",short_marker,"mean_OTU.prevalence.250.350.random.rds"),version=2)
  saveRDS(list(median_prevalence.250.random,median_prevalence.350.random),
          file=paste0(results_folder,"/",short_marker,"median_OTU.prevalence.250.350.random.rds"),version=2)
  
  #################
  data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
  
  load(paste0(data.folder_name,"/data2m.Rdata"))
  data2m0 = data2m
  # diversity.bis[i_taxon] = nrow(data2m)
  load(paste0(data.folder_name,"/coord.Rdata"))
  load(paste0(data.folder_name,"/taxo_ref.Rdata"))
  taxo_ref0 = taxo_ref
  # if (nrow(data2m0) > 
  for (i_div in 1:length(diversity[selected_groups]))
  {
    cat("\n",paste(i_div,"/",length(taxo_groups[selected_groups])))
    div = as.vector(diversity[selected_groups])[i_div]
    subsample_indices = sample(1:nrow(data2m0),div)
    data2m = data2m0[subsample_indices,]
    taxo_ref = taxo_ref0[subsample_indices,]
    new.data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_random.group.div.",i_div,noArcticNoBiomark_insert,noLagoon_insert)
    if (!file.exists(new.data.folder_name))
    {
      dir.create(new.data.folder_name)
      save(taxo_ref, file = paste0(new.data.folder_name,"/taxo_ref.Rdata"),version=2)
      save(coord, file = paste0(new.data.folder_name,"/coord.Rdata"),version=2)
    }
    save(data2m, file = paste0(new.data.folder_name,"/data2m.Rdata"),version=2)
    remove(data2m)
    remove(taxo_ref)
  }
  remove(data2m0)
  remove(taxo_ref0)
  
  ###################
  mean_prevalence.random.group = median_prevalence.random.group = vector(length = length(taxo_groups), mode = "numeric")
  prevalence.5.random.group = prevalence.10.random.group = prevalence.20.random.group = prevalence.50.random.group = vector(length = length(taxo_groups), mode = "numeric")
  # prevalence.random.group = list()
  for (ii_taxon in 1:length(which(selected_groups)))
  {
    taxon = paste0("random.group.div.",ii_taxon)
    i_taxon = which(as.vector(diversity) == as.vector(diversity)[selected_groups][ii_taxon])
    data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    load(paste0(data.folder_name,"/data2m.Rdata"))
    data2m_occ = data2m
    data2m_occ[data2m_occ > 0] = 1
    # prevalence.random.group[[ii_taxon]] = rowSums(data2m_occ)
    prevalence.10.random.group[i_taxon] = length(which(rowSums(data2m_occ) > 10))
    prevalence.5.random.group[i_taxon] = length(which(rowSums(data2m_occ) > 5))
    prevalence.20.random.group[i_taxon] = length(which(rowSums(data2m_occ) > 20))
    prevalence.50.random.group[i_taxon] = length(which(rowSums(data2m_occ) > 50))
    mean_prevalence.random.group[i_taxon] = mean(rowSums(data2m_occ))
    median_prevalence.random.group[i_taxon] = median(rowSums(data2m_occ))
  }
}

if (diversity_maps)
{
  # To perform kriging:
  library(kriging)
  # To plot the kriged maps:
  library(ggplot2)
  library(gridExtra)
  library(scales)
  library(gstat)
  # To call grid.newpage()
  library(grid)
  # To plot shapes using readOGR (not available on cluster):
  library(rgdal)
  library(sp)
  library(rgeos)
  library(maptools)
  # To use raster manipulating functions:
  library(raster)
  # To use coltorgb:
  library(grDevices)
  library(ggtree)
  
  background_map_path = data_folder
  background_map_file = "ne_50m_ocean"
  # Loading background map: 
  background = readOGR(dsn = paste0(background_map_path,"/",background_map_file), layer = background_map_file)
  background@data$id = rownames(background@data)
  backgroundPoints = fortify(background, region="id")
  backgroundGgplot = merge(backgroundPoints, background@data, by="id") 
  
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  increasing_llh = readRDS(paste0(data_folder,"/Increasing_llh_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  alpha_best_real = readRDS(paste0(data_folder,"/alpha_best_real_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  tmp.plot = list()
  range_int = list()
  k = 0
  for (taxon in taxo_groups[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh])
  {
    k = k+1
    #taxon = "AllTaxa"
    data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    load(paste0(data.folder_name,"/data2m.Rdata"))
    load(paste0(data.folder_name,"/coord.Rdata"))
    data2m[data2m>1] = 1
    diversity_per_station = colSums(data2m)
    
    tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
    z.pred.k = diversity_per_station
    
    stations_names = levels(as.factor(stations_depths$Station))
    
    range_int[[k]] = range(z.pred.k)
    
    for (station in stations_names)
    {
      samples_indices_data2m = which(stations_depths$Station == station)
      
      if (length(samples_indices_data2m) == 1)
      {
        if (stations_depths$Depth[samples_indices_data2m] == "SUR")
        {
          pie = ggplot(data.frame(x=c(z.pred.k[samples_indices_data2m],NA),y=c(1,1)), aes(x=1, y, fill=x))
        } else if (stations_depths$Depth[samples_indices_data2m] == "DCM")
        {
          pie = ggplot(data.frame(x=c(NA,z.pred.k[samples_indices_data2m]),y=c(1,1)), aes(x=1, y, fill=x))
        }
      } else
        pie = ggplot(data.frame(x=z.pred.k[samples_indices_data2m],y=rep(1,length(samples_indices_data2m))), aes(x=1, y, fill=x))
      
      # if (col_range == "natural")
      # else if (col_range == "standard")
      #range_int = c(0,1)
      pie = pie + 
        #             scale_fill_brewer(palette="color.pal.heat") +
        #             scale_fill_brewer(palette="heat.colors") +
        scale_fill_gradientn(limits = c(0,range_int[[k]][2]), colours = c("cyan","blue","red"), values = c(0,ifelse(range_int[[k]][2] == 1,NA,max(1,range_int[[k]][1])/range_int[[k]][2]),1), na.value="transparent", guide = "colourbar") +
        #scale_fill_gradientn(colours=color.pal.heat(2)) +
        #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
        geom_bar(stat="identity", width=1) + 
        coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
        xlab(NULL) + ylab(NULL) + 
        theme_transparent()
      #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
      tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[samples_indices_data2m[1]],coord$y[samples_indices_data2m[1]],width=0.09, height=0.09)        
    }
  }
  
  # # test.pie = ggplot(data.frame(x=c(0,1,2,3,4,5,6),y=rep(1,7)), aes(x=1, y, fill=x)) +
  # test.pie = ggplot(data.frame(x=c(0,1),y=rep(1,2)), aes(x=1, y, fill=x)) +
  #   #scale_fill_gradient2(limits = c(0,6), low="yellow", high="red", mid = "blue", midpoint = 1, na.value="transparent", guide = "colourbar") +
  #   scale_fill_gradientn(colours = c("cyan","blue","red"), values = c(0,NA,1), na.value="transparent", guide = "colourbar") +
  #   geom_bar(stat="identity", width=1) +
  #   coord_polar(theta="y",start=3*pi/2) + theme_tree() +
  #   xlab(NULL) + ylab(NULL) +
  #   theme_transparent()
  # pdf("test.pdf")
  # print(test.pie)
  # dev.off()
  
  #tmp.plot0 = tmp.plot
  #tmp.plot = tmp.plot0
  k = 0
  for (taxon in taxo_groups[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh])
  {
    k = k+1
    tmp.plot[[k]] = tmp.plot[[k]] +
      coord_equal() +
      #labs(fill=paste0("Assemblage ",k)) +  
      theme_minimal() + ggtitle(paste(taxon,": ",range_int[[k]][1],"-",range_int[[k]][2],"OTUs")) +
      #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
      #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
      theme(legend.position="bottom", legend.text=element_text(size=7),
            legend.title=element_text(size=8), axis.title=element_blank(),
            axis.text = element_blank(), panel.background = element_blank(),
            panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
            plot.title=element_text(hjust=0), plot.margin=unit(c(2,2,2,2),"mm")) +
      # theme(legend.position="bottom", legend.text=element_text(size=7), 
      #       legend.title=element_text(size=8), axis.title=element_blank(), 
      #       axis.text = element_blank(), panel.background = element_blank(),
      #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
      #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
      guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
  }
  
  pdf(paste0(figure_folder,"/Diversity_maps_byGroup_selected.pdf"))
  for (k in 1:length(taxo_groups[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]))
    #for (k in 1:2)
    print(tmp.plot[[k]])
  dev.off()
  #spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics10_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
}

# Results in diversity_function are independent of the split-merge process above
if (data_Federico && function_plots)
{
  # taxo_ref -> taxo_refNew?
  # taxo_groups -> taxo_groupsNew?
  
  foldername = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
  load(paste0(foldername,"/taxo_ref.Rdata"))
  
  taxo_groups_OTUs = taxo_ref$taxogroup2
  
  # taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs.rds"))
  taxo_groups = levels(as.factor(taxo_groups_OTUs))[sort.int(table(as.factor(taxo_groups_OTUs)),index.return = T,decreasing = T)$ix]
  
  functions_OTUs = taxo_ref$Function
  functions = levels(as.factor(functions_OTUs))
  function_proportions = matrix(nrow = length(taxo_groups), ncol = length(functions), data = 0, dimnames = list(taxo_groups,functions))
  group_index = 0
  for (group in taxo_groups)
  {
    group_index = group_index+1
    fun_index = 0
    for (fun in functions)
    {
      fun_index = fun_index+1
      function_proportions[group_index,fun_index] = length(which(functions_OTUs[which(taxo_groups_OTUs == group)] == fun))/diversity[group_index]
    }
  }
  
  pdf(figure_folder,"/Function_proportion_per_group_CompleteSizeRange_byStationByDepth_noArcticNoBiomark.pdf")
  par(mar=c(5.1,5.1,4.1,2.1))
  for (j in 1:length(functions))
  {
    plot(function_proportions[,j], ylab = "Proportion", xlab = "Taxonomic group", main = functions[j], ylim = c(0,1), cex.main = 2, cex.lab = 2, cex.axis = 1.5)
  }
  dev.off()
  
  library(colorspace)
  
  #########
  plot_div_threshold = 500
  function_barplot = function_proportions[which(diversity>plot_div_threshold),]*log10(diversity[which(diversity>plot_div_threshold)])
  colours = rainbow_hcl(length(functions))[sample(1:length(functions),length(functions))]
  pdf(paste0(figure_folder,"/Diversity_>",plot_div_threshold,"OTUs_CompleteSizeRange_byStationByDepth_noArcticNoBiomark.pdf"))
  par(mar=c(7.1,4.1,4.1,2.1))
  x= barplot(t(function_barplot), space = 1, col = colours, 
             legend.text = T, xaxt="n", args.legend = list(bty = "n", x= length(diversity[which(diversity>plot_div_threshold)])*3-35, y=5, cex= 0.7))
  labs = taxo_groups[which(diversity>plot_div_threshold)]
  text(cex=0.7, x=x+1.7, y=-0.2, labels = labs, xpd=TRUE, srt=45, pos=2)
  title(ylab = "log10 diversity")
  dev.off()
  ########
  
  #########
  plot_div_threshold = 1
  function_barplot = function_proportions[which(diversity>plot_div_threshold),]*log10(diversity[which(diversity>plot_div_threshold)])
  colours = rainbow_hcl(length(functions))[sample(1:length(functions),length(functions))]
  pdf(paste0(figure_folder,"/Diversity_>",plot_div_threshold,"OTUs_CompleteSizeRange_byStationByDepth_noArcticNoBiomark.pdf"))
  par(mar=c(7.1,4.1,4.1,0.1))
  x= barplot(t(function_barplot), space = 1, col = colours, 
             legend.text = T, xaxt="n", args.legend = list(bty = "n", x= length(diversity[which(diversity>plot_div_threshold)])*2, y=5, cex= 0.7))
  labs = taxo_groups[which(diversity>plot_div_threshold)]
  text(cex=0.4, x=x+3, y=-0.2, labels = labs, xpd=TRUE, srt=45, pos=2)
  title(ylab = "log10 diversity")
  dev.off()
  ########
  
  functionalTags_OTUs = data.frame(chloroplast = taxo_ref$chloroplast,symb_small = taxo_ref$symb_small,
                                   symb_host = taxo_ref$symb_host,calcification = taxo_ref$calcification,strontification = taxo_ref$strontification)
  functionalTags = list()
  functionalTags$chloroplast = levels(as.factor(functionalTags_OTUs$chloroplast))
  functionalTags$symb_small = levels(as.factor(functionalTags_OTUs$symb_small))
  functionalTags$symb_host = levels(as.factor(functionalTags_OTUs$symb_host))
  functionalTags$calcification = levels(as.factor(functionalTags_OTUs$calcification))
  functionalTags$strontification = levels(as.factor(functionalTags_OTUs$strontification))
  
  functionalTags_proportions = list()
  functionalTags_proportions$chloroplast = matrix(nrow = length(taxo_groups), ncol = length(functionalTags$chloroplast), data = 0, 
                                                  dimnames = list(taxo_groups,functionalTags$chloroplast))
  functionalTags_proportions$symb_small = matrix(nrow = length(taxo_groups), ncol = length(functionalTags$symb_small), data = 0, 
                                                 dimnames = list(taxo_groups,functionalTags$symb_small))
  functionalTags_proportions$symb_host = matrix(nrow = length(taxo_groups), ncol = length(levels(as.factor(functionalTags_OTUs$symb_host))), data = 0, 
                                                dimnames = list(taxo_groups,functionalTags$symb_host))
  functionalTags_proportions$calcification = matrix(nrow = length(taxo_groups), ncol = length(functionalTags$calcification), data = 0, 
                                                    dimnames = list(taxo_groups,functionalTags$calcification))
  functionalTags_proportions$strontification = matrix(nrow = length(taxo_groups), ncol = length(functionalTags$strontification), data = 0, 
                                                      dimnames = list(taxo_groups,functionalTags$strontification))
  group_index = 0
  for (group in taxo_groups)
  {
    group_index = group_index+1
    fun_index = 0
    for (fun in functionalTags$chloroplast)
    {
      fun_index = fun_index+1
      functionalTags_proportions$chloroplast[group_index,fun_index] = length(which(functionalTags_OTUs$chloroplast[which(taxo_groups_OTUs == group)] == fun))/diversity[group_index]
    }
    fun_index = 0
    for (fun in functionalTags$symb_small)
    {
      fun_index = fun_index+1
      functionalTags_proportions$symb_small[group_index,fun_index] = length(which(functionalTags_OTUs$symb_small[which(taxo_groups_OTUs == group)] == fun))/diversity[group_index]
    }
    fun_index = 0
    for (fun in functionalTags$symb_host)
    {
      fun_index = fun_index+1
      functionalTags_proportions$symb_host[group_index,fun_index] = length(which(functionalTags_OTUs$symb_host[which(taxo_groups_OTUs == group)] == fun))/diversity[group_index]
    }
    fun_index = 0
    for (fun in functionalTags$calcification)
    {
      fun_index = fun_index+1
      functionalTags_proportions$calcification[group_index,fun_index] = length(which(functionalTags_OTUs$calcification[which(taxo_groups_OTUs == group)] == fun))/diversity[group_index]
    }
    fun_index = 0
    for (fun in functionalTags$strontification)
    {
      fun_index = fun_index+1
      functionalTags_proportions$strontification[group_index,fun_index] = length(which(functionalTags_OTUs$strontification[which(taxo_groups_OTUs == group)] == fun))/diversity[group_index]
    }
  }
  
  #save(diversity,taxo_groups,file="diversity-taxo_group_80plusOTUs_noArcticNoBiomark_noLagoon.Rdata")
  
  # pdf("Diversity_pie1_CompleteSizeRange_byStationByDepth_noArcticNoBiomark.pdf")
  # pie(c(243887,42236,890,101776,41984),labels = c("15 selected groups\n243,887 OTUs","64 other >80-OTU groups\n42,236 OTUs","24 <80-OTU groups\n890 OTUs","27 '?' groups\n101,776 OTUs","unclassified OTUs\n41,984 OTUs"),col = terrain.colors(5))
  # dev.off()
  
  # pdf("Diversity_pie23_CompleteSizeRange_byStationByDepth_noArcticNoBiomark.pdf")
  # pie(sort(diversity,decreasing=T)[which(sort(diversity,decreasing=T)>1000)], labels = taxo_groups[sort.int(diversity,index.return = T,decreasing = T)$ix[1:23]],col = rainbow(23))
  # dev.off()
  
  #########
  # colours = "grey"
  # pdf("Diversity_>500OTUs_CompleteSizeRange_byStationByDepth_noArcticNoBiomark.pdf")
  # par(mar=c(7.1,4.1,4.1,2.1))
  # x= barplot(log10(sort(diversity[-which(diversity<501)],decreasing=T)), space = 1, col = colours)
  # labs = taxo_groups[-which(diversity<501)][sort.int(diversity[-which(diversity<501)],index.return = T,decreasing = T)$ix]
  # text(cex=0.7, x=x+1.7, y=-0.2, labels = labs, xpd=TRUE, srt=45, pos=2)
  # title(ylab = "log10 diversity")
  # dev.off()
  # ########
  
  for (i in 1:5)
  {
    if (i == 1)
    {
      functionalTags_proportions_matrix = functionalTags_proportions$chloroplast
      functionalTags_vector = functionalTags$chloroplast
      fun_insert = "Chloroplast"
    } else if (i == 2)
    {
      functionalTags_proportions_matrix = functionalTags_proportions$symb_small
      functionalTags_vector = functionalTags$symb_small
      fun_insert = "Symbiont"
    } else if (i == 3)
    {
      functionalTags_proportions_matrix = functionalTags_proportions$symb_host
      functionalTags_vector = functionalTags$symb_host
      fun_insert = "Symbiotic_host"
    } else if (i == 4)
    {
      functionalTags_proportions_matrix = functionalTags_proportions$calcification
      functionalTags_vector = functionalTags$calcification
      fun_insert = "Calcification"
    } else if (i == 5)
    {
      functionalTags_proportions_matrix = functionalTags_proportions$strontification
      functionalTags_vector = functionalTags$strontification
      fun_insert = "Strontification"
    }
    
    #########
    plot_div_threshold = 500
    function_barplot = functionalTags_proportions_matrix[which(diversity>plot_div_threshold),]*log10(diversity[which(diversity>plot_div_threshold)])
    colours = rainbow_hcl(length(functionalTags_vector))[sample(1:length(functionalTags_vector),length(functionalTags_vector))]
    pdf(paste0(figure_folder,"/",fun_insert,"_>",plot_div_threshold,"OTUs_CompleteSizeRange_byStationByDepth_noArcticNoBiomark.pdf"))
    par(mar=c(7.1,4.1,4.1,2.1))
    x = barplot(t(function_barplot), space = 1, col = colours, 
                legend.text = T, xaxt="n", args.legend = list(bty = "n", x= length(diversity[which(diversity>plot_div_threshold)])*3-35, y=5, cex= 0.7))
    labs = taxo_groups[which(diversity>plot_div_threshold)]
    text(cex=0.7, x=x+1.7, y=-0.2, labels = labs, xpd=TRUE, srt=45, pos=2)
    title(ylab = "log10 diversity")
    dev.off()
    ########
    
    pdf(paste0(figure_folder,"/",fun_insert,"_function_proportion_per_group_CompleteSizeRange_byStationByDepth_noArcticNoBiomark.pdf"))
    par(mar=c(5.1,5.1,4.1,2.1))
    for (j in 1:length(functionalTags_vector))
    {
      plot(functionalTags_proportions_matrix[,j], ylab = "Proportion", xlab = "Taxonomic group", main = functionalTags_vector[j], ylim = c(0,1), cex.main = 2, cex.lab = 2, cex.axis = 1.5)
    }
    dev.off()
  }
}  

if (mean_group_size)
{
  #   coord = list()
  #   coord_SUR = list()
  #   coord_DCM = list()
  #   station_depth_names = list()
  #   stations_names_SUR = list()
  #   stations_names_DCM = list()
  #   data2mNew = list()
  #   data2mNew_SUR = list()
  #   data2mNew_DCM = list()
  #   
  #   last_index_Small = 0
  #   last_index_Medium = 0
  #   last_index_Large = 0
  #   last_index_ExtraLarge = 0
  #   data2mSmall = matrix(nrow=nrow(data2m),ncol=ncol(data2m),data=0)
  #   data2mMedium = matrix(nrow=nrow(data2m),ncol=ncol(data2m),data=0)
  #   data2mLarge = matrix(nrow=nrow(data2m),ncol=ncol(data2m),data=0)
  #   data2mExtraLarge = matrix(nrow=nrow(data2m),ncol=ncol(data2m),data=0)
  
  # To have a quick look at the taxonomic repartition of the dataset:
  # sort(table(taxo_ref$V4[-which(substr(taxo_ref$V4,1,1) == "?")]),decreasing=T)
  
  foldername = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
  load(paste0(foldername,"/sample_ref.Rdata"))
  samples_stations = sample_ref$Station.label
  samples_depths = sample_ref$Depth
  samples_fractions = sample_ref$Fraction.size
  samples_templates = sample_ref$Template
  stations_names = levels(as.factor(sample_ref$Station.label))
  
  load(paste0(foldername,"/data2m_unmerged.Rdata"))
  data2m = data2m0
  samples_data2m = colnames(data2m)
  
  load(paste0(foldername,"/taxo_ref.Rdata"))
  taxo_groups_OTUs = taxo_ref$taxogroup2
  
  # taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_2plusOTUs.rds"))
  taxo_groups = levels(as.factor(taxo_groups_OTUs))[sort.int(table(as.factor(taxo_groups_OTUs)),index.return = T,decreasing = T)$ix]
  
  mean_sizes = c(mean(c(mean(c(0.8,3)),mean(c(0.8,5)))),mean(c(mean(c(3,20)),mean(c(5,20)))),mean(c(20,180)),mean(c(180,2000)))
  
  # load(paste0(foldername,"/coord.Rdata"))
  # Arctic_stations = rownames(coord)[which(rownames(coord) == "TARA_158 SUR"):nrow(coord)]
  # Arctic_stations = lapply(lapply(Arctic_stations,strsplit," ",fixed=T),function(g) g[[1]][1])
  
  size_absoluteAbund = vector(length = length(taxo_groups), mode = "numeric")
  size_relativeAbund = vector(length = length(taxo_groups), mode = "numeric")
  sd_size_absoluteAbund = vector(length = length(taxo_groups), mode = "numeric")
  sd_size_relativeAbund = vector(length = length(taxo_groups), mode = "numeric")
  read_abundance = vector(length = length(taxo_groups), mode = "numeric")
  n.four.fractions = matrix(nrow=length(taxo_groups),ncol=4,
                            dimnames=list(taxo_groups,c("0.8-5","5,20","20-180","180-2000")),
                            data=0)
  p.four.fractions = matrix(nrow=length(taxo_groups),ncol=4,
                            dimnames=list(taxo_groups,c("0.8-5","5,20","20-180","180-2000")),
                            data=0)
  group_index = 0
  for (group in taxo_groups)
  {
    group_index = group_index +1
    cat(paste0("\n",group," ",group_index,"/",length(taxo_groups)))
    OTU_indices = which(taxo_groups_OTUs == group)
    
    size_absoluteAbund_squared = 0
    size_relativeAbund_squared = 0
    station_depth_index = 0
    # for (station in stations_names[stations_names %in% Arctic_stations])
    for (station in stations_names)
    {
      for (depth in c("SUR","DCM"))
      {
        # Looking for the samples corresponding to the current station in sample_ref:
        samples_indices = which(samples_stations == station)
        samples_indices = samples_indices[which(samples_depths[samples_indices] == depth)]
        #samples_indices = samples_indices[which(samples_templates[samples_indices] == "DNA")]
        
        # Because of the filtering at the merging byStationbyDepth step, the if conditions below are actually unnecessary
        if (
          (any(samples_fractions[samples_indices]=="0.8-3") || any(samples_fractions[samples_indices]=="0.8-5") || any(samples_fractions[samples_indices]=="0.8-inf"))
          &&
          (any(samples_fractions[samples_indices]=="3-20") || any(samples_fractions[samples_indices]=="5-20"))  
          &&
          any(samples_fractions[samples_indices]=="20-180") && any(samples_fractions[samples_indices]=="180-2000")
        )
        {
          # Choosing only one size fraction among overlapping size fractions (it occurs rarely)
          if (old_data)
          {
            # Picking 0.8-3 over 0.8-inf:
            if (any(samples_fractions[samples_indices]=="0.8-3") && any(samples_fractions[samples_indices]=="0.8-5"))
              samples_indices = samples_indices[-which(samples_fractions[samples_indices] == "0.8-5")]
            if (any(samples_fractions[samples_indices]=="0.8-3") && any(samples_fractions[samples_indices]=="0.8-inf"))
              samples_indices = samples_indices[-which(samples_fractions[samples_indices] == "0.8-inf")]
          }
          if (any(samples_fractions[samples_indices]=="0.8-5") && any(samples_fractions[samples_indices]=="0.8-inf"))
            samples_indices = samples_indices[-which(samples_fractions[samples_indices] == "0.8-inf")]
          if (any(samples_fractions[samples_indices]=="3-20") && any(samples_fractions[samples_indices]=="5-20"))
            samples_indices = samples_indices[-which(samples_fractions[samples_indices] == "3-20")]
          
          # Choosing in priority the sample with "DNA", then "WGA/DNA", then "RNA"
          for (size_fraction in c("0.8-inf","0.8-3","0.8-5","3-20","5-20","20-180","180-2000"))
          {
            if (length(which(samples_fractions[samples_indices]==size_fraction))>1)
            {
              matching_fraction_indices = which(samples_fractions[samples_indices]==size_fraction)
              if (length(which(samples_templates[samples_indices[matching_fraction_indices]]=="DNA"))>0)
              {
                nonMatching_template_indices = which(samples_templates[samples_indices[matching_fraction_indices]]!="DNA")
                samples_indices = samples_indices[-which(samples_indices == samples_indices[matching_fraction_indices[nonMatching_template_indices]])]
              } else
              {
                nonMatching_template_indices = which(samples_templates[samples_indices[matching_fraction_indices]]!="WGA/DNA")
                samples_indices = samples_indices[-which(samples_indices == samples_indices[matching_fraction_indices[nonMatching_template_indices]])]
              }
            } 
          }
          
          if (length(c(samples_indices[which(samples_fractions[samples_indices]=="0.8-3")],samples_indices[which(samples_fractions[samples_indices]=="0.8-5")],samples_indices[which(samples_fractions[samples_indices]=="0.8-inf")]))!=1
              || length(c(samples_indices[which(samples_fractions[samples_indices]=="3-20")],samples_indices[which(samples_fractions[samples_indices]=="5-20")]))!=1)
            stop(paste("Wrong number of size fractions:",group,station,depth))
          
          sample_index = vector(length=4,mode="numeric")
          # Storing the names of the samples corresponding to the current station, so as to look for them in data2m:
          sample_index[1] = c(samples_indices[which(samples_fractions[samples_indices]=="0.8-3")],samples_indices[which(samples_fractions[samples_indices]=="0.8-5")],samples_indices[which(samples_fractions[samples_indices]=="0.8-inf")])
          sample_index[2] = c(samples_indices[which(samples_fractions[samples_indices]=="3-20")],samples_indices[which(samples_fractions[samples_indices]=="5-20")])
          sample_index[3] = samples_indices[which(samples_fractions[samples_indices]=="20-180")]
          sample_index[4] = samples_indices[which(samples_fractions[samples_indices]=="180-2000")]
          size_absoluteAbund_inSample = 0
          size_relativeAbund_inSample = 0
          size_absoluteAbund_squared_inSample = 0
          size_relativeAbund_squared_inSample = 0
          denom_size_absoluteAbund = 0
          denom_size_relativeAbund = 0
          for (fraction in 1:4)
          {
            sample = sample_ref$Sample.id[sample_index[fraction]]
            sample_index_data2m = which(samples_data2m==sample)
            
            term1 = sum(data2m[OTU_indices,sample_index_data2m])
            term2 = sum(data2m[,sample_index_data2m])
            size_absoluteAbund_inSample = size_absoluteAbund_inSample + term1*mean_sizes[fraction]
            size_relativeAbund_inSample = size_relativeAbund_inSample + term1*mean_sizes[fraction]/term2
            
            n.four.fractions[group_index,fraction] = term1 + n.four.fractions[group_index,fraction]
            p.four.fractions[group_index,fraction] = term1/term2 + p.four.fractions[group_index,fraction]
            
            size_absoluteAbund_squared_inSample = size_absoluteAbund_squared_inSample + term1*mean_sizes[fraction]^2
            size_relativeAbund_squared_inSample = size_relativeAbund_squared_inSample + term1*mean_sizes[fraction]^2/term2
            denom_size_absoluteAbund = denom_size_absoluteAbund + term1
            denom_size_relativeAbund = denom_size_relativeAbund + term1/term2
          }
          # if denom_size_absoluteAbund = 0, there is no OTU of the current group in this station and at this depth (station-depth), therefore it is not taken into account
          if (denom_size_absoluteAbund > 0)
          {
            station_depth_index = station_depth_index+1
            read_abundance[group_index] = read_abundance[group_index] + denom_size_absoluteAbund
            size_absoluteAbund[group_index] = size_absoluteAbund[group_index] + size_absoluteAbund_inSample/denom_size_absoluteAbund
            size_relativeAbund[group_index] = size_relativeAbund[group_index] + size_relativeAbund_inSample/denom_size_relativeAbund
            size_absoluteAbund_squared = size_absoluteAbund_squared + size_absoluteAbund_squared_inSample/denom_size_absoluteAbund
            size_relativeAbund_squared = size_relativeAbund_squared + size_relativeAbund_squared_inSample/denom_size_relativeAbund
          }
        }
      }
    }
    # station_depth_index is the number of stations-depths taken into account for the current group
    # The mean over stations and depths is taken by considering each station-depth as having an equivalent weight,
    # irrespective of how abundant the group is in the station-depth (debatable)
    read_abundance[group_index] = read_abundance[group_index]/station_depth_index
    size_absoluteAbund[group_index] = size_absoluteAbund[group_index]/station_depth_index
    size_relativeAbund[group_index] = size_relativeAbund[group_index]/station_depth_index
    size_absoluteAbund_squared = size_absoluteAbund_squared/station_depth_index
    size_relativeAbund_squared = size_relativeAbund_squared/station_depth_index
    sd_size_absoluteAbund[group_index] = sqrt(size_absoluteAbund_squared - size_absoluteAbund[group_index]^2)
    sd_size_relativeAbund[group_index] = sqrt(size_relativeAbund_squared - size_relativeAbund[group_index]^2)
  }
  
  ###############################
  save(read_abundance,size_absoluteAbund,size_relativeAbund,sd_size_absoluteAbund,sd_size_relativeAbund,n.four.fractions,p.four.fractions,file=paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"0.Rdata"))
  # save(read_abundance,size_absoluteAbund,size_relativeAbund,sd_size_absoluteAbund,sd_size_relativeAbund,file=paste0("group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_0.8inf.Rdata"))
  # save(read_abundance,size_absoluteAbund,size_relativeAbund,sd_size_absoluteAbund,sd_size_relativeAbund,file=paste0("group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_NoSmallSizeFraction.Rdata"))
  # save(read_abundance,size_absoluteAbund,size_relativeAbund,sd_size_absoluteAbund,sd_size_relativeAbund,file=paste0("group_sizes_byStationByDepth_",div_threshold,"plusOTUs_ArcticOnly",noLagoon_insert,"_No0.8inf.Rdata"))
  
  library(ggplot2)
  library(gridExtra)
  
  #setwd(paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa_noArcticNoBiomark_noLagoon/Rtopicmodels_LDA_VEM_nb_topics3_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence"))
  
  #plot.size_absoluteAbund = qplot(x = x, y = y, data=data.frame(x=1:length(size_absoluteAbund),y=log10(sort(size_absoluteAbund,decreasing=T))), label=taxo_groups[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix], geom="point") +
  #plot.size_absoluteAbund = qplot(x = x, y = y, data=data.frame(x=log10(read_abundance),y=size_absoluteAbund), label=taxo_groups[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix], geom="point") +
  plot.size_absoluteAbund = qplot(x = x, y = y, data=data.frame(x=1:length(size_absoluteAbund),y=sort(size_absoluteAbund,decreasing=T)), label=taxo_groups[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix], geom="point") +
    #scale_fill_gradientn(colours=color.pal(7), labels=trans_format("identity", function(x) round(x,0))) +
    #scale_fill_gradientn(colours=color.pal(7), labels=trans_format("identity", scientific_format())) +
    # geom_errorbar(aes(ymax = y + sd_size_absoluteAbund[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix],
    #                   ymin = y - sd_size_absoluteAbund[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix])) +
    theme_bw() +
    #ggtitle(paste(letters[i],"-",plot_labels[i])) +
    ggtitle("Mean sizes using absolute\n read abundances") +
    #ylim(0,max(data.skl$y))
    #     scale_y_continuous(limits=c(5,395), expand = c(0,0)) +
    #     scale_x_continuous(limits=c(5,295), expand = c(0,0)) +
    #     theme(legend.position="bottom", legend.text=element_text(size=11),
    #         legend.title=element_text(size=12), axis.title=element_blank(),
    #         axis.text = element_blank(),
    #         plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm"))
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=9),
          plot.margin=unit(c(1,1,1,0),"mm")) +
    #labs(x="Size rank", y="log10(Mean size) (micron)")
    labs(x="Size rank", y="Mean size (micron)") +
    #labs(x="Read abundance (log10)", y="Mean size (micron)")
    #xlim(min(diversity),5) +
    #geom_smooth(method='lm') +
    geom_text(mapping = NULL, stat = "identity",size=2,
              #hjust=0, nudge_x = 0.2,
              #nudge_y = c(0,0,0,0,0,0,0,0), hjust=0, nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
              nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
              #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
              hjust=0, nudge_x = 2,
              parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
  
  #plot.size_relativeAbund = qplot(x = x, y = y, data=data.frame(x=1:length(size_relativeAbund),y=log10(sort(size_relativeAbund,decreasing=T))), label=taxo_groups[sort.int(size_relativeAbund,decreasing=T,index=T)$ix], geom="point") +
  #plot.size_relativeAbund = qplot(x = x, y = y, data=data.frame(x=log10(read_abundance),y=size_relativeAbund), label=taxo_groups[sort.int(size_relativeAbund,decreasing=T,index=T)$ix], geom="point") +
  plot.size_relativeAbund = qplot(x = x, y = y, data=data.frame(x=1:length(size_relativeAbund),y=sort(size_relativeAbund,decreasing=T)), label=taxo_groups[sort.int(size_relativeAbund,decreasing=T,index=T)$ix], geom="point") +
    #scale_fill_gradientn(colours=color.pal(7), labels=trans_format("identity", function(x) round(x,0))) +
    #scale_fill_gradientn(colours=color.pal(7), labels=trans_format("identity", scientific_format())) +
    # geom_errorbar(aes(ymax = y + sd_size_relativeAbund[sort.int(size_relativeAbund,decreasing=T,index=T)$ix],
    #                          ymin = y - sd_size_relativeAbund[sort.int(size_relativeAbund,decreasing=T,index=T)$ix])) +
    theme_bw() +
    #ggtitle(paste(letters[i],"-",plot_labels[i])) +
    ggtitle("Mean sizes using relative\n read abundances") +
    #ylim(0,max(data.skl$y))
    #     scale_y_continuous(limits=c(5,395), expand = c(0,0)) +
    #     scale_x_continuous(limits=c(5,295), expand = c(0,0)) +
    #     theme(legend.position="bottom", legend.text=element_text(size=11),
    #         legend.title=element_text(size=12), axis.title=element_blank(),
    #         axis.text = element_blank(),
    #         plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm"))
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=9),
          plot.margin=unit(c(1,1,1,0),"mm")) +
    #labs(x="Read abundance (log10)", y="Mean size (micron)")
    #labs(x="Size rank", y="log10(Mean size) (micron)")
    labs(x="Size rank", y="Mean size (micron)") +
    #xlim(min(diversity),5) +
    #geom_smooth(method='lm') +
    geom_text(mapping = NULL, stat = "identity",size=2,
              #hjust=0, nudge_x = 0.2,
              #nudge_y = c(0,0,0,0,0,0,0,0), hjust=0, nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
              nudge_y = c(rep(0,2),10,0,-10,rep(0,length(size_relativeAbund)-5)),
              #nudge_y = c(rep(0,2),0.05,0,-0.04,rep(0,length(size_relativeAbund)-5)),
              hjust=0, nudge_x = 2,
              parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
  
  ggsave(filename = paste0(figure_folder,"/Mean_size_of_taxo_groups_vs_size_rank_",div_threshold,"plusOTUs.pdf"), do.call("arrangeGrob", c(list(plot.size_relativeAbund, plot.size_absoluteAbund), nrow=1)),
         height = 10/4, width = 2*10/4)
  
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds")) 
  
  #plot.size_absoluteAbund = qplot(x = x, y = y, data=data.frame(x=1:length(size_absoluteAbund),y=log10(sort(size_absoluteAbund,decreasing=T))), label=taxo_groups[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix], geom="point") +
  #plot.size_absoluteAbund = qplot(x = x, y = y, data=data.frame(x=log10(read_abundance),y=size_absoluteAbund), label=taxo_groups[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix], geom="point") +
  plot.size_absoluteAbund_diversity = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)),y=log10(size_absoluteAbund)), label=taxo_groups, geom="point") +
    #scale_fill_gradientn(colours=color.pal(7), labels=trans_format("identity", function(x) round(x,0))) +
    #scale_fill_gradientn(colours=color.pal(7), labels=trans_format("identity", scientific_format())) +
    # geom_errorbar(aes(ymax = y + sd_size_absoluteAbund[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix],
    #                   ymin = y - sd_size_absoluteAbund[sort.int(size_absoluteAbund,decreasing=T,index=T)$ix])) +
    theme_bw() +
    #ggtitle(paste(letters[i],"-",plot_labels[i])) +
    ggtitle("Mean sizes using absolute\n read abundances") +
    #ylim(0,max(data.skl$y))
    #     scale_y_continuous(limits=c(5,395), expand = c(0,0)) +
    #     scale_x_continuous(limits=c(5,295), expand = c(0,0)) +
    #     theme(legend.position="bottom", legend.text=element_text(size=11),
    #         legend.title=element_text(size=12), axis.title=element_blank(),
    #         axis.text = element_blank(),
    #         plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm"))
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=9),
          plot.margin=unit(c(1,1,1,0),"mm")) +
    #labs(x="Size rank", y="log10(Mean size) (micron)")
    labs(x="OTU richness (log10)", y="Mean size (micron, log10)") +
    geom_smooth(method='lm')
  #labs(x="Read abundance (log10)", y="Mean size (micron)")
  #xlim(min(diversity),5) +
  #geom_smooth(method='lm') +
  # geom_text(mapping = NULL, stat = "identity",size=2,
  #           #hjust=0, nudge_x = 0.2,
  #           #nudge_y = c(0,0,0,0,0,0,0,0), hjust=0, nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
  #           nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
  #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
  #           hjust=0, nudge_x = 2,
  #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
  
  #plot.size_relativeAbund = qplot(x = x, y = y, data=data.frame(x=1:length(size_relativeAbund),y=log10(sort(size_relativeAbund,decreasing=T))), label=taxo_groups[sort.int(size_relativeAbund,decreasing=T,index=T)$ix], geom="point") +
  #plot.size_relativeAbund = qplot(x = x, y = y, data=data.frame(x=log10(read_abundance),y=size_relativeAbund), label=taxo_groups[sort.int(size_relativeAbund,decreasing=T,index=T)$ix], geom="point") +
  plot.size_relativeAbund_diversity = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)),y=log10(size_relativeAbund)), label=taxo_groups, geom="point") +
    #scale_fill_gradientn(colours=color.pal(7), labels=trans_format("identity", function(x) round(x,0))) +
    #scale_fill_gradientn(colours=color.pal(7), labels=trans_format("identity", scientific_format())) +
    # geom_errorbar(aes(ymax = y + sd_size_relativeAbund[sort.int(size_relativeAbund,decreasing=T,index=T)$ix],
    #                          ymin = y - sd_size_relativeAbund[sort.int(size_relativeAbund,decreasing=T,index=T)$ix])) +
    theme_bw() +
    #ggtitle(paste(letters[i],"-",plot_labels[i])) +
    ggtitle("Mean sizes using relative\n read abundances") +
    #ylim(0,max(data.skl$y))
    #     scale_y_continuous(limits=c(5,395), expand = c(0,0)) +
    #     scale_x_continuous(limits=c(5,295), expand = c(0,0)) +
    #     theme(legend.position="bottom", legend.text=element_text(size=11),
    #         legend.title=element_text(size=12), axis.title=element_blank(),
    #         axis.text = element_blank(),
    #         plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm"))
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=9),
          plot.margin=unit(c(1,1,1,0),"mm")) +
    #labs(x="Read abundance (log10)", y="Mean size (micron)")
    #labs(x="Size rank", y="log10(Mean size) (micron)")
    labs(x="OTU richness (log10)", y="Mean size (micron, log10)") +
    #xlim(min(diversity),5) +
    geom_smooth(method='lm')
  # geom_text(mapping = NULL, stat = "identity",size=2,
  #           #hjust=0, nudge_x = 0.2,
  #           #nudge_y = c(0,0,0,0,0,0,0,0), hjust=0, nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
  #           nudge_y = c(rep(0,2),10,0,-10,rep(0,length(size_relativeAbund)-5)),
  #           #nudge_y = c(rep(0,2),0.05,0,-0.04,rep(0,length(size_relativeAbund)-5)),
  #           hjust=0, nudge_x = 2,
  #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
  
  ggsave(filename = paste0(figure_folder,"/Size_log_vs_log_diversity_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.size_relativeAbund_diversity, plot.size_absoluteAbund_diversity), nrow=1)),
         height = 10/4, width = 2*10/4)
  
  # pdf("Mean_size_vs_log10_diversity.pdf")
  # #par(mar = c(5, 4, 4, 2) + 0.1)
  # par(mar = c(5, 5, 4, 2) + 0.1)
  # par(cex.lab=1.5, cex.axis=1.5)
  # plot(size_absoluteAbund,as.vector(log10(diversity)),ann=F)
  # #lines(range(size_absoluteAbund),log10(80)*c(1,1),lty=2)
  # title(xlab="Mean size using absolute read abundances",ylab="Number of OTUs (log10)")
  # dev.off()
}

if (mean_travel_time_connectivity)
{
  travel.folder_name = paste0(data_folder,"/Abiotic_data")
  
  if (particle_thres == 1000)
  {
    travel_time_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_1000.csv"),sep="\t",header=T,row.names=1)
    travel_time_matrix = travel_time_matrix[,-ncol(travel_time_matrix)]
    
    travel_time_matrix_75m = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_75m_1000.csv"),sep="\t",header=T,row.names=1)
    travel_time_matrix_75m = travel_time_matrix_75m[,-ncol(travel_time_matrix_75m)]
    DCM_indices = which(matrix(unlist(strsplit(rownames(travel_time_matrix),split="_",fixed=T)),nrow=2)[2,] == "DCM")
    travel_time_matrix[DCM_indices,DCM_indices] = travel_time_matrix_75m[DCM_indices,DCM_indices]
    max_travel_time_matrix = max(travel_time_matrix[!is.nan(as.matrix(travel_time_matrix))])
  } else if (particle_thres == 10)
  {
    travel_time_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_10.csv"),sep="\t",header=T,row.names=1)
    travel_time_matrix = travel_time_matrix[,-ncol(travel_time_matrix)]
    max_travel_time_matrix = max(travel_time_matrix[!is.nan(as.matrix(travel_time_matrix))])
  } else
  {
    exchanged_particle_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_num_points_surface_10.csv"),sep="\t",header=T,row.names=1)
    exchanged_particle_matrix = exchanged_particle_matrix[,-ncol(exchanged_particle_matrix)]
    if (particle_thres > 0)
      exchanged_particle_matrix[exchanged_particle_matrix < particle_thres] = NaN
  }
  
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  optimalK = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  i_taxon = 0
  if (travel_time_per_assemblage)
  {
    taxon_metrics = list()
    prop_within_topic_vect = vector(length = length(taxo_groups), mode = "numeric")
    names(prop_within_topic_vect) = taxo_groups
  }
  if (travel_time_per_OTU)
  {
    prop_within_OTU_vect = vector(length = length(taxo_groups), mode = "numeric")
    names(prop_within_OTU_vect) = taxo_groups
    prop_within_OTU_allOTUs = list()
    occupancy_perOTU = list()
  }
  for (taxon in taxo_groups)
  {
    i_taxon = i_taxon+1
    # taxon = "AllTaxa"
    
    # data.folder_name = paste0(data_folder,"/Old_data/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    # data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    
    if (travel_time_per_assemblage)
    {
      nb_topics = optimalK[i_taxon]
      spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
      # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/1st_best_realization/Spatial_topicmix_kriged.rds"))
      
      load(paste0(data.folder_name,"/coord.Rdata"))
      
      # Adding rownames to spatial_topicmix_kriged:
      # i_taxon = 0
      # for (taxon in taxo_groups)
      # {
      #   i_taxon = i_taxon+1
      #   # taxon = "AllTaxa"
      #   nb_topics = optimalK[i_taxon]
      #   # data.folder_name = paste0(data_folder,"/Old_data/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      #   data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      #   spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/3rd_best_realization_maxmatching/Spatial_topicmix_kriged.rds"))
      #   # Setting the rownames of spatial_topicmix_kriged to the rownames of coord in all taxonomic groups:
      #   load(paste0(data.folder_name,"/data2m.Rdata"))
      #   coord_taxon = coord[colSums(data2m) != 0,]
      #   if (all(spatial_topicmix_kriged[[1]]$y == coord_taxon$y) && all(spatial_topicmix_kriged[[1]]$x == coord_taxon$x))
      #   {
      #     for (k in 1:nb_topics)
      #       rownames(spatial_topicmix_kriged[[k]]) = rownames(coord_taxon)
      #     saveRDS(spatial_topicmix_kriged,paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/3rd_best_realization_maxmatching/Spatial_topicmix_kriged.rds"))
      #   } else
      #     stop("spatial_topicmix_kriged and coord don't match")
      # }
      
      # loading the station names associated with spatial_topicmix_kriged
      coord = coord[rownames(spatial_topicmix_kriged[[1]]),]
      
      # selected_stations contains the stations effectively used for the decomposition, in the same order as in spatial_topicmix_kriged, with the names used in Iudicone's travel_time_matrix
      # i.e., converts rownames(coord_taxo) into the names in travel_time_matrix
      selected_stations.l = lapply(strsplit(rownames(coord),split=" ",fixed=T),strsplit,split="_",fixed=T)
      selected_stations = vector(length = nrow(coord), mode = "character")
      for (i in 1:nrow(coord))
      {
        selected_stations[i] = paste(selected_stations.l[[i]][[1]][2],selected_stations.l[[i]][[2]][1],sep = "_")
        station_split = strsplit(selected_stations[i],split="",fixed=T)[[1]]
        if (station_split[1] == "0")
        {
          j = 1
          while (station_split[j] == "0")
            j = j+1
          selected_stations[i] = paste(station_split[-(1:(j-1))],collapse = "")
        }
      }
      # selected_travel_time_matrix selects and reorders the stations according to rownames(coord_taxo)
      selected_travel_time_matrix = travel_time_matrix[selected_stations,paste0("X",selected_stations)]
      
      # str_lengths = unlist(lapply(strsplit(colnames(travel_time_matrix),split="",fixed=T),length))
      # substr(colnames(travel_time_matrix),2,str_lengths)
      
      topicmix = matrix(nrow = nrow(coord), ncol = nb_topics, data = 0)
      for (k in 1:nb_topics)
        topicmix[,k] = spatial_topicmix_kriged[[k]]$z.pred
      dominant_topic = vector(length = nrow(topicmix), mode = "numeric")
      for (i in 1:length(dominant_topic))
      {
        if (length(which(topicmix[i,] == max(topicmix[i,]))) == 1)
          dominant_topic[i] = which(topicmix[i,] == max(topicmix[i,]))
        else
          dominant_topic[i] = sample(which(topicmix[i,] == max(topicmix[i,])),1)
      }
      
      nan_nb = 0
      #weighted_within_topic_mean_travel_time = 0
      ik = matrix(nrow = nb_topics, ncol = nb_topics, data = 0)
      between_within_topic_travel_time = matrix(nrow = nb_topics, ncol = nb_topics, data = 0)
      between_within_topic_prop = matrix(nrow = nb_topics, ncol = nb_topics, data = 0)
      for (i in 2:length(selected_stations))
      {
        for (j in 1:(i-1))
        {
          station_i = strsplit(strsplit(rownames(coord)[i],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
          station_j = strsplit(strsplit(rownames(coord)[j],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
          # If station label is different
          if (station_i != station_j)
          {
            travel_time_ij = selected_travel_time_matrix[i,j]
            if (is.nan(travel_time_ij))
            {
              travel_time_ij = max_travel_time_matrix
              nan_nb = nan_nb+1
            }
            between_within_topic_travel_time[dominant_topic[i],dominant_topic[j]] = travel_time_ij + between_within_topic_travel_time[dominant_topic[i],dominant_topic[j]]
            between_within_topic_travel_time[dominant_topic[j],dominant_topic[i]] = between_within_topic_travel_time[dominant_topic[i],dominant_topic[j]]
            ik[dominant_topic[i],dominant_topic[j]] = ik[dominant_topic[i],dominant_topic[j]] + 1
            ik[dominant_topic[j],dominant_topic[i]] = ik[dominant_topic[i],dominant_topic[j]]
            if (travel_time_ij < 2)
            {
              between_within_topic_prop[dominant_topic[i],dominant_topic[j]] = between_within_topic_prop[dominant_topic[i],dominant_topic[j]] + 1
              between_within_topic_prop[dominant_topic[j],dominant_topic[i]] = between_within_topic_prop[dominant_topic[i],dominant_topic[j]]
            }
          }
        }
      }
      cat("\n",nan_nb,"NaN out of",sum(ik[lower.tri(ik,diag=T)]),"travel times (",nan_nb/sum(ik[lower.tri(ik,diag=T)])*100,"% )")
      
      #overall_mean = sum(between_within_topic_travel_time[lower.tri(between_within_topic_travel_time,diag=T)])/sum(ik[lower.tri(ik,diag=T)])
      mean_between_topic = sum(between_within_topic_travel_time[lower.tri(between_within_topic_travel_time,diag=F)])/sum(ik[lower.tri(ik,diag=F)])
      prop_between_topic = sum(between_within_topic_prop[lower.tri(between_within_topic_prop,diag=F)])/sum(ik[lower.tri(ik,diag=F)])
      mean_within_topic = sum(diag(between_within_topic_travel_time))/sum(diag(ik))
      prop_within_topic = sum(diag(between_within_topic_prop))/sum(diag(ik))
      metrics_byTopic = matrix(nrow = nb_topics, ncol = 10, data = 0)
      colnames(metrics_byTopic) = c("Mean_travel_time_within_assemblage",
                                    "Mean_prop_within_assemblage",
                                    #"Mean_distance_to_assemblage","Mean_within_assemblage_distance_over_mean_distance_to_assemblage",
                                    #"Mean_within_assemblage_distance_over_overall_mean","Mean_distance_to_assemblage_over_overall_mean","Overall_mean",
                                    "Mean_travel_time_within_assemblage_over_max_travel_time",
                                    "Mean_travel_time_within_assemblage_over_mean_travel_time_between_assemblages",
                                    #"Mean_distance_to_assemblage_over_mean_between_topics",
                                    "Mean_within-assemblage_tt_across_assemblages","Mean_between-assemblage_tt","Mean_within_to_mean_between_tt_ratio",
                                    "Mean_within-assemblage_prop_across_assemblages","Mean_between-assemblage_prop","Mean_within_to_mean_between_tt_ratio")
      for (k in 1:nb_topics)
      {
        within_topic_mean = between_within_topic_travel_time[k,k]/ik[k,k]
        within_topic_prop = between_within_topic_prop[k,k]/ik[k,k]
        #between_topic_mean = sum(between_within_topic_travel_time[k,-k])/sum(ik[k,-k])
        metrics_byTopic[k,] = c(within_topic_mean,
                                within_topic_prop,
                                #between_topic_mean,within_topic_mean/between_topic_mean,
                                #within_topic_mean/overall_mean,between_topic_mean/overall_mean,overall_mean,
                                within_topic_mean/max_travel_time_matrix,
                                within_topic_mean/mean_between_topic,
                                #between_topic_mean/mean_between_topic,
                                mean_within_topic,mean_between_topic,mean_within_topic/mean_between_topic,
                                prop_within_topic,prop_between_topic,prop_within_topic/prop_between_topic)
      }
      metrics_byTopic = as.data.frame(metrics_byTopic)
      taxon_metrics[[i_taxon]] = metrics_byTopic
      saveRDS(metrics_byTopic,file = paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/mean_travel_times_metrics_optimalK.rds"))
      
      prop_within_topic_vect[i_taxon] = prop_within_topic
    }
    
    if (travel_time_per_OTU)
    {
      load(paste0(data.folder_name,"/data2m.Rdata"))
      if (i_taxon == 1)
      {
        load(paste0(data.folder_name,"/coord.Rdata"))
        # coord is saved in case travel_time_per_OTU and travel_time_per_assemblage are run simultaneously, 
        # in which case coord is modified for each taxon
        coord0 = coord
        
        selected_stations.l = lapply(strsplit(rownames(coord),split=" ",fixed=T),strsplit,split="_",fixed=T)
        selected_stations = vector(length = nrow(coord), mode = "character")
        for (i in 1:nrow(coord))
        {
          selected_stations[i] = paste(selected_stations.l[[i]][[1]][2],selected_stations.l[[i]][[2]][1],sep = "_")
          station_split = strsplit(selected_stations[i],split="",fixed=T)[[1]]
          if (station_split[1] == "0")
          {
            j = 1
            while (station_split[j] == "0")
              j = j+1
            selected_stations[i] = paste(station_split[-(1:(j-1))],collapse = "")
          }
        }
        if (particle_thres == 10 || particle_thres == 1000)
        {
          selected_travel_time_matrix = travel_time_matrix[selected_stations,paste0("X",selected_stations)]
          selected_travel_time_matrix0 = selected_travel_time_matrix
        } else
        {
          selected_exchanged_particle_matrix = exchanged_particle_matrix[selected_stations,paste0("X",selected_stations)]
          selected_exchanged_particle_matrix0 = selected_exchanged_particle_matrix
        }
        # selected_travel_time_matrix is saved in case travel_time_per_OTU and travel_time_per_assemblage are run simultaneously, 
        # in which case selected_travel_time_matrix is modified for each taxon (same for exchanged_particle_matrix if particle_thres = 0)
        
        
        # Computing the 'null' connectivity value obtained for an OTU present in every station-depth
        ik_null = 0
        prop_within_OTU_null = 0
        for (i in 2:nrow(coord))
        {
          for (j in 1:(i-1))
          {
            station_i = strsplit(strsplit(rownames(coord)[i],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
            station_j = strsplit(strsplit(rownames(coord)[j],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
            # If station label is different
            if (station_i != station_j)
            {
              ik_null = ik_null+1
              if (particle_thres == 10 || particle_thres == 1000)
              {
                travel_time_ij = selected_travel_time_matrix[i,j]
                if (expTmin)
                {
                  if (is.nan(travel_time_ij))
                    travel_time_ij = 1
                  else
                    travel_time_ij = 1 - exp(-travel_time_ij/travel_time_threshold)
                } else
                {
                  if (is.nan(travel_time_ij))
                    travel_time_ij = max_travel_time_matrix
                }
                # if (travel_time_ij < ifelse(travel_time_threshold > 0, travel_time_threshold, max_travel_time_matrix))
                if (travel_time_threshold == 0 || expTmin == 1)
                {
                  prop_within_OTU_null = prop_within_OTU_null+travel_time_ij
                } else
                {
                  if (travel_time_ij < travel_time_threshold)
                    prop_within_OTU_null = prop_within_OTU_null+1
                }
              } else
              {
                exchanged_particle_ij = selected_exchanged_particle_matrix[i,j]
                if (is.nan(exchanged_particle_ij))
                  exchanged_particle_ij = 0
                if (particle_thres == 0)
                {
                  prop_within_OTU_null = prop_within_OTU_null + exchanged_particle_ij
                } else 
                {
                  if (exchanged_particle_ij > 0)
                    prop_within_OTU_null = prop_within_OTU_null + 1
                }
              }
            }
          }
        }
        prop_within_OTU_null = prop_within_OTU_null/ik_null
      } else
      {
        coord = coord0
        if (particle_thres == 10 || particle_thres == 1000)
          selected_travel_time_matrix = selected_travel_time_matrix0
        else 
          selected_exchanged_particle_matrix = selected_exchanged_particle_matrix0
      }
      
      nan_nb = 0
      tot_nb = 0
      no_common_otu_nb = 0
      # ik and prop_within_OTU are vectors of length the number of OTUs in the taxonomic groups
      # They record the number of pairs of stations-depths (belonging to different stations) where the OTU is observed, 
      # and the subset of those where the travel time is below travel_time_threshold, respectively
      # For particle_thres = 0, prop_within_OTU records the sum of exchanged particles among stations-depths where the OTU is observed
      prop_within_OTU = vector(length = nrow(data2m), mode = "numeric")
      ik = vector(length = nrow(data2m), mode = "numeric")
      for (i in 2:nrow(coord))
      {
        for (j in 1:(i-1))
        {
          station_i = strsplit(strsplit(rownames(coord)[i],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
          station_j = strsplit(strsplit(rownames(coord)[j],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
          # If station label is different
          if (station_i != station_j)
          {
            if (particle_thres == 10 || particle_thres == 1000)
            {
              tot_nb = tot_nb+1
              travel_time_ij = selected_travel_time_matrix[i,j]
              if (expTmin)
              {
                if (is.nan(travel_time_ij))
                {
                  travel_time_ij = 1
                  nan_nb = nan_nb+1
                } else
                  travel_time_ij = 1 - exp(-travel_time_ij/travel_time_threshold)
              } else
              {
                if (is.nan(travel_time_ij))
                {
                  travel_time_ij = max_travel_time_matrix
                  nan_nb = nan_nb+1
                }
              }
              ii_vect = which(data2m[,j] !=0 & data2m[,i] !=0)
              if (length(ii_vect) > 0)
              {
                for (ii in ii_vect)
                {
                  ik[ii] = ik[ii]+1
                  if (travel_time_threshold == 0 || expTmin == 1)
                  {
                    prop_within_OTU[ii] = prop_within_OTU[ii] + travel_time_ij
                  } else
                  {
                    # if (travel_time_ij < ifelse(travel_time_threshold > 0, travel_time_threshold, max_travel_time_matrix))
                    if (travel_time_ij < travel_time_threshold)
                      prop_within_OTU[ii] = prop_within_OTU[ii]+1
                  }
                }
              } else
                no_common_otu_nb = no_common_otu_nb+1
            } else if (particle_thres != 10 && particle_thres != 1000)
            {
              exchanged_particle_ij = exchanged_particle_matrix[i,j]
              tot_nb = tot_nb+1
              if (is.nan(exchanged_particle_ij))
              {
                exchanged_particle_ij = 0
                nan_nb = nan_nb+1
              }
              ii_vect = which(data2m[,j] !=0 & data2m[,i] !=0)
              if (length(ii_vect) > 0)
              {
                for (ii in ii_vect)
                {
                  ik[ii] = ik[ii]+1
                  if (particle_thres == 0)
                  {
                    prop_within_OTU[ii] = prop_within_OTU[ii] + exchanged_particle_ij
                  } else 
                  {
                    if (exchanged_particle_ij > 0)
                      prop_within_OTU[ii] = prop_within_OTU[ii] + 1
                  }
                }
              } else
                no_common_otu_nb = no_common_otu_nb+1
            } 
          }
        }
      }
      cat("\n",nan_nb,"NaN out of",tot_nb,"travel times (",nan_nb/tot_nb*100,"% )")
      cat("\n",no_common_otu_nb,"no common OTU out of",tot_nb,"travel times (",no_common_otu_nb/tot_nb*100,"% )")
      
      if (length(which(ik>0)) > 0)
      {
        # The OTUs that are only present in a single station-depth or in the two depths of a single station are removed from the count when computing the proportion:
        prop_within_OTU = prop_within_OTU[ik > 0]/ik[ik > 0]
        prop_within_OTU_allOTUs[[i_taxon]] = prop_within_OTU
        data2m[data2m>0] = 1
        # Propotion of the stations-depths where each OTU retained in the travel time computation is present:
        occupancy_perOTU[[i_taxon]] = rowSums(data2m)[ik > 0]/ncol(data2m)
        # Lastly, the mean is taken over the OTUs:
        prop_within_OTU_vect[i_taxon] = mean(prop_within_OTU)
      } else
      {
        prop_within_OTU_vect[i_taxon] = NA
        occupancy_perOTU[[i_taxon]] = NA
        prop_within_OTU_allOTUs[[i_taxon]] = NA
      }
    }
  }
  
  if (travel_time_per_assemblage)
  {
    if (particle_thres == 0)
    {
      saveRDS(prop_within_topic_vect,paste0(results_folder,"/Connectivity_nbExchangedParticles_meanPerAssemblage_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    } else if (particle_thres == 10 || particle_thres == 1000)
    {
      saveRDS(prop_within_topic_vect,paste0(results_folder,"/Connectivity_",travel_time_threshold,"yearTminProportion_meanPerAssemblage_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    } else
      saveRDS(prop_within_topic_vect,paste0(results_folder,"/Connectivity_",particle_thres,"particlesThres_meanPerAssemblage_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  }
  if (travel_time_per_OTU)
  {
    if (particle_thres == 0)
    {
      saveRDS(list(prop_within_OTU_vect,prop_within_OTU_null,prop_within_OTU_allOTUs),paste0(results_folder,"/Connectivity_nbExchangedParticles_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      # saveRDS(prop_within_OTU_allOTUs,paste0(results_folder,"/Connectivity_nbExchangedParticles_allOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    } else if (particle_thres == 10 || particle_thres == 1000)
    {
      if (!expTmin)
        saveRDS(list(prop_within_OTU_vect,prop_within_OTU_null,prop_within_OTU_allOTUs),
              paste0(results_folder,"/Connectivity_",travel_time_threshold,"yearTminThres_",particle_thres,"particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      else 
        saveRDS(list(prop_within_OTU_vect,prop_within_OTU_null,prop_within_OTU_allOTUs),
                paste0(results_folder,"/Connectivity_expTmin_",travel_time_threshold,"yearTminThres_",particle_thres,"particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    } else
      saveRDS(list(prop_within_OTU_vect,prop_within_OTU_null,prop_within_OTU_allOTUs),
              paste0(results_folder,"/Connectivity_",particle_thres,"particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  }
  # saveRDS(prop_within_OTU_allOTUs,paste0(results_folder,"/Connectivity_2yearTminProportion_allOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # saveRDS(occupancy_perOTU,paste0(results_folder,"/Occupancy_allOTus_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  library(ggplot2)
  library(gridExtra)
  
  # increasing_llh = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # alpha_best_real = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # selected_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
  selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  # Plotting the correlation coefficient with body size as a function of the threshold used:
  #########################################################################################
  # All stations:
  selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs_noLagoon.rds"))
  sd_prop_within_OTU_vect = vector(length = length(c(100,300,400,500,600,700,800,900,1001,1100,1200,1400,1600,1800)), mode = "numeric")
  for (i_part in 1:length(c(100,300,400,500,600,700,800,900,1001,1100,1200,1400,1600,1800)))
  {
    nb_part = c(100,300,400,500,600,700,800,900,1001,1100,1200,1400,1600,1800)[i_part]
    sd_prop_within_OTU_vect[i_part] = sd(readRDS(paste0(results_folder,"/Connectivity_",nb_part,"particlesThres_meanPerOTU_2plusOTUs_noLagoon.rds"))[[1]][selected_groups],na.rm=T)
  }
  pdf(paste0(figure_folder,"/Adj_R2_vs_particle_thres_OTU_connectivity_noLagoon.pdf"))
  par(mar = c(4,5,1,1))
  #par(cex.lab = 1.5, cex.axis = 1.5)
  par(cex = 1.5)
  plot(c(100,300,400,500,600,700,800,900,1000,1100,1200,1400,1600,1800),c(0.0717,0.1039,0.1519,0.1798,0.1486,0.1173,0.09274,0.04172,0.04858,0.05039,0.04897,-0.006086,-0.005939,-0.009371),ann=F,type = "o",ylim=c(-0.02,0.25))
  lines(c(100,300,400,500,600,700,800,900,1000,1100,1200,1400,1600,1800),sd_prop_within_OTU_vect,col="blue",type="o")
  abline(v = 500, lty = 2)
  abline(v = 1100, lty = 2)
  title(xlab = "Number of particle threshold", ylab = "Adj. R2 between mean OTU connectivity\n and body size across groups")
  dev.off()
  
  selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs_noLagoon.rds"))
  sd_prop_within_OTU_vect = vector(length = length(c(0.5,0.75,1,1.25,1.5,2,3,4,5,6,7,8,9,10,15)), mode = "numeric")
  for (i_t_min in 1:length(c(0.5,0.75,1,1.25,1.5,2,3,4,5,6,7,8,9,10,15)))
  {
    t_min = c(0.5,0.75,1,1.25,1.5,2,3,4,5,6,7,8,9,10,15)[i_t_min]
    sd_prop_within_OTU_vect[i_t_min] = sd(readRDS(paste0(results_folder,"/Connectivity_",t_min,"yearTminThres_10particlesThres_meanPerOTU_2plusOTUs_noLagoon.rds"))[[1]][selected_groups],na.rm=T)
  }  
  # All stations - time threshold:
  pdf(paste0(figure_folder,"/Adj_R2_vs_tmin_thres_OTU_connectivity_10particlesThres_noLagoon.pdf"))
  par(mar = c(4,5,1,1))
  #par(cex.lab = 1.5, cex.axis = 1.5)
  par(cex = 1.5)
  plot(c(0.5,0.75,1,1.25,1.5,2,3,4,5,6,7,8,9,10,15),c(0.2163,0.2748,0.2882,0.2687,0.2366,0.2449,0.1767,0.1323,0.1436,0.1508,0.152,0.1619,0.1549,0.1114,0.08155),ann=F,type = "o",ylim=c(-0.02,0.35))
  lines(c(0.5,0.75,1,1.25,1.5,2,3,4,5,6,7,8,9,10,15),sd_prop_within_OTU_vect,col="blue",type="o")
  abline(v = 1, lty = 2)
  abline(v = 8, lty = 2)
  title(xlab = "Min. travel time threshold (year)", ylab = "Adj. R2 between mean OTU connectivity\n and body size across groups")
  dev.off()
  
  ##############
  # Arctic only:
  selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs_ArcticOnly_noLagoon.rds"))
  sd_prop_within_OTU_vect = vector(length = length(c(100,1001,1500,1625,1700,1750,2000,2500,5000)), mode = "numeric")
  for (i_part in 1:length(c(100,1001,1500,1625,1700,1750,2000,2500,5000)))
  {
    nb_part = c(100,1001,1500,1625,1700,1750,2000,2500,5000)[i_part]
    sd_prop_within_OTU_vect[i_part] = sd(readRDS(paste0(results_folder,"/Connectivity_",nb_part,"particlesThres_meanPerOTU_2plusOTUs_ArcticOnly_noLagoon.rds"))[[1]][selected_groups],na.rm=T)
  }
  pdf(paste0(figure_folder,"/Adj_R2_vs_particle_thres_OTU_connectivity_ArcticOnly_noLagoon.pdf"))
  par(mar = c(4,5,1,1))
  #par(cex.lab = 1.5, cex.axis = 1.5)
  par(cex = 1.5)
  plot(c(100,1001,1500,1625,1700,1750,2000,2500,5000),c(-0.01153,0.0757,0.08246,0.0902,0.07852,0.06636,-0.004305,-0.01326,-0.01021),ann=F,type = "o",ylim=c(-0.02,0.25))
  lines(c(100,1001,1500,1625,1700,1750,2000,2500,5000),sd_prop_within_OTU_vect,col="blue",type="o")
  # plot(c(100,1001,1500,1625,1700,1750,2000,2500,5000),c(-0.01235,-0.006962,-0.00443,-0.0121,-0.0134,-0.01335,-0.01336,-0.01185,-0.009138),ann=F,type = "o",ylim=c(-0.02,0.25))
  abline(v = 1625, lty = 2)
  title(xlab = "Number of particle threshold", ylab = "Adj. R2 between mean OTU connectivity\n and body size across groups")
  dev.off()
  
  selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs_ArcticOnly_noLagoon.rds"))
  sd_prop_within_OTU_vect = vector(length = length(c(0.5,1,1.5,2,4,10)), mode = "numeric")
  for (i_t_min in 1:length(c(0.5,1,1.5,2,4,10)))
  {
    t_min = c(0.5,1,1.5,2,4,10)[i_t_min]
    sd_prop_within_OTU_vect[i_t_min] = sd(readRDS(paste0(results_folder,"/Connectivity_",t_min,"yearTminThres_10particlesThres_meanPerOTU_2plusOTUs_ArcticOnly_noLagoon.rds"))[[1]][selected_groups],na.rm=T)
  }  
  # Arctic only - time threshold:
  pdf(paste0(figure_folder,"/Adj_R2_vs_tmin_thres_OTU_connectivity_10particlesThres_ArcticOnly_noLagoon.pdf"))
  par(mar = c(4,5,1,1))
  #par(cex.lab = 1.5, cex.axis = 1.5)
  par(cex = 1.5)
  plot(c(0.5,1,1.5,2,4,10),c(0.06037,0.09318,0.09668,0.08987,-0.003136,-0.0118),ann=F,type = "o",ylim=c(-0.02,0.35))
  lines(c(0.5,1,1.5,2,4,10),sd_prop_within_OTU_vect,col="blue",type="o")
  abline(v = 1.5, lty = 2)
  title(xlab = "Min. travel time threshold (year)", ylab = "Adj. R2 between mean OTU connectivity\n and body size across groups")
  dev.off()
  
  ######################
  # Non-Arctic stations:
  pdf(paste0(figure_folder,"/Adj_R2_vs_particle_thres_OTU_connectivity_noArcticNoBiomark_noLagoon.pdf"))
  par(mar = c(4,5,1,1))
  #par(cex.lab = 1.5, cex.axis = 1.5)
  par(cex = 1.5)
  plot(c(100,300,400,450,500,550,600,700,800,1001),c(0.06455,0.1418,0.1965,0.207,0.2448,0.2378,0.2247,0.2046,0.1777,0.02629),ann=F,type = "o",ylim=c(-0.02,0.25))
  abline(v = 500, lty = 2)
  title(xlab = "Number of particle threshold", ylab = "Adj. R2 between mean OTU connectivity\n and body size across groups")
  dev.off()
  
  # Non-Arctic stations - time threshold:
  pdf(paste0(figure_folder,"/Adj_R2_vs_tmin_thres_OTU_connectivity_10particlesThres_noArcticNoBiomark_noLagoon.pdf"))
  par(mar = c(4,5,1,1))
  #par(cex.lab = 1.5, cex.axis = 1.5)
  par(cex = 1.5)
  plot(c(0.5,1,5,6,6.5,7,8,10,15,30,50),c(0.162,0.267,0.2901,0.3377,0.3454,0.3349,0.3267,0.3078,0.2619,0.2072,0.1734),ann=F,type = "o",ylim=c(-0.02,0.35))
  abline(v = 6.5, lty = 2)
  title(xlab = "Min. travel time threshold (year)", ylab = "Adj. R2 between mean OTU connectivity\n and body size across groups")
  dev.off()
  
  #######################
  # pdf("Nb_exchanged_part_vs_t_min_noArcticNoBiomark.pdf")
  # plot(as.matrix(selected_travel_time_matrix),as.matrix(selected_exchanged_particle_matrix),ann=F)
  # title(xlab = "t_min", ylab = "Nb. of exchanged particles")
  # dev.off()
  
  #########################
  # Travel time comparison:
  #########################
  prop_within_OTU_vect0 = readRDS(paste0(results_folder,"/Connectivity_1.5yearTminThres_10particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
  
  plot.thres.connectivity.vs.expTmin.connectivity = ggplot(data=data.frame(x=1-prop_within_OTU_vect0[selected_groups],y=prop_within_OTU_vect[selected_groups])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    #ggtitle(colnames(adjr2)[j]) +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Threshold-based OTU connectivity\n through currents", y="Smoothed OTU connectivity\n through currents") +
    geom_smooth(aes(x,y),method='lm') 
  pdf("expTmin.OTU.connectivity_vs_threshold.based.OTU.connectivity_thres1.5_selected.pdf")
  print(plot.thres.connectivity.vs.expTmin.connectivity)
  dev.off()
  
  if (travel_time_per_assemblage)
  {
    plot.traveltime_log_diversity = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)),y=prop_within_topic_vect), label=taxo_groups, geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(7,1,1,0.5),"mm")) +
      labs(x="OTU richness (log10)",y="Mean travel time connectivity within assemblages") +
      xlim(range(log10(as.vector(diversity))[!is.nan(prop_within_topic_vect)])) +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/Travel_time_prop_vs_diversity_log10_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_diversity), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    plot.traveltime_log_diversity = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)[1:61]),y=prop_within_topic_vect[1:61]), label=taxo_groups[1:61], geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(7,1,1,0.5),"mm")) +
      labs(x="OTU richness (log10)",y="Mean travel time connectivity within assemblages") +
      #xlim(min(optimalK),11) +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/Travel_time_prop_vs_diversity_log10_ggplot_61first.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_diversity), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    pdf(paste0(figure_folder,"/Travel_time_connectivity_byAssemblage_hist.pdf"))
    hist(unlist(lapply(taxon_metrics,function(g) g$`Mean_prop_within_assemblage`)), ann = F)
    title(xlab = "Travel time connectivity per assemblage", ylab = "Frequency", cex.lab = 1.3)
    dev.off()
    
    pdf(paste0(figure_folder,"/Travel_time_connectivity_byAssemblage_hist_61first.pdf"))
    hist(unlist(lapply(taxon_metrics,function(g) g$`Mean_prop_within_assemblage`))[1:sum(optimalK[1:61])], ann = F)
    title(xlab = "Travel time connectivity per assemblage", ylab = "Frequency", cex.lab = 1.3)
    dev.off()
  }
  
  if (travel_time_per_OTU)
  {
    # prop_within_OTU_null = 0.1361972
    
    # pdf(paste0("Travel_time_connectivity_byOTU_",travel_time_threshold,"years_",particle_thres,"particlesThres_hist.pdf"))
    # pdf(paste0("Travel_time_connectivity_byOTU_",travel_time_threshold,"years_hist.pdf"))
    pdf(paste0(figure_folder,"/Connectivity_byOTU_",particle_thres,"particlesThres",noArcticNoBiomark_insert,"_hist.pdf"))
    # pdf(paste0("Connectivity_byOTU_",travel_time_threshold,"yearTminThres_",particle_thres,"particlesThres",noArcticNoBiomark_insert,"_hist.pdf"))
    hist(unlist(prop_within_OTU_allOTUs), ann = F)
    abline(v = prop_within_OTU_null, lty=2)
    # title(xlab = "Travel time connectivity per OTU", ylab = "Frequency", cex.lab = 1.3)
    title(xlab = "Connectivity per OTU", ylab = "Frequency", cex.lab = 1.3)
    dev.off()
    
    if (particle_thres == 0)
    {
      pdf(paste0(figure_folder,"/Particle_nb_connectivity_byOTU_hist",noArcticNoBiomark_insert,"1.pdf"))
      # hist(unlist(prop_within_OTU_allOTUs)/prop_within_OTU_null, ann = F)
      # abline(v = 1, lty=2)
      # title(xlab = "Mean relative number of exchanged particles per OTU", ylab = "Frequency", cex.lab = 1.3)
      hist(unlist(prop_within_OTU_allOTUs), ann = F)
      abline(v = prop_within_OTU_null, lty=2)
      title(xlab = "Mean number of exchanged particles per OTU", ylab = "Frequency", cex.lab = 1.3)
      dev.off()
    }
    
    # pdf("Travel_time_connectivity_byOTU_vs_OTU_occupancy.pdf")
    # plot(unlist(occupancy_perOTU),unlist(prop_within_OTU_allOTUs), ann = F)
    # title(ylab = "Travel time connectivity", xlab = "Fraction of stations where the OTU is present", cex.lab = 1.3)
    # dev.off()
    
    plot.traveltime_allOTUs_occupancy = qplot(x = x, y = y, data=data.frame(x=unlist(occupancy_perOTU),y=unlist(prop_within_OTU_allOTUs)), geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(7,5,1,0.5),"mm")) +
      labs(x="Fraction of stations where the OTU is present",y="Travel time connectivity") +
      # xlim(range(log10(as.vector(diversity))[!is.nan(prop_within_OTU_vect)])) +
      # geom_smooth(method='lm') +
      geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed")
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/Travel_time_connectivity_byOTU_",travel_time_threshold,"years_",particle_thres,"particlesThres_vs_OTU_occupancy_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_allOTUs_occupancy), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    plot.traveltime_log_diversity = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)),y=prop_within_OTU_vect), label=taxo_groups, geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(7,1,1,0.5),"mm")) +
      labs(x="OTU richness (log10)",y="Mean travel time connectivity within OTUs") +
      xlim(range(log10(as.vector(diversity))[!is.nan(prop_within_OTU_vect)])) +
      geom_smooth(method='lm') +
      geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed")
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/Travel_time_prop_OTU_",travel_time_threshold,"years_",particle_thres,"particlesThres_vs_diversity_log10_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_diversity), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    plot.traveltime_log_diversity = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]
                                                                        ,y=prop_within_OTU_vect[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]), geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(7,1,1,0.5),"mm")) +
      labs(x="OTU richness (log10)",y="Mean travel time connectivity within OTUs") +
      xlim(range(log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh])) +
      geom_smooth(method='lm') +
      geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed")
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/Travel_time_prop_OTU_",travel_time_threshold,"years_",particle_thres,"particlesThres_vs_diversity_log10_ggplot_selected.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_diversity), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    # summary(lm(log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh] ~ prop_within_OTU_vect[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]))
    
    ############################
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # dominant_function_simplified  = dominant_function
    # dominant_function_simplified[dominant_function == "copepoda" & "other metazoa" & "pteropoda"] = "Metazoa"
    functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
    ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
    
    # prop_within_OTU_vect_2yr = readRDS(paste0(results_folder,"/Connectivity_2yearTminProportion_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # prop_within_OTU_vect_1.5yr = readRDS(paste0(results_folder,"/Connectivity_1.5yearTminProportion_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # travel_time_threshold = max_travel_time_matrix
    prop_within_OTU_vect_1000particles = readRDS(paste0(results_folder,"/Connectivity_1000particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    names(prop_within_OTU_vect_1000particles) = taxo_groups
    prop_within_OTU_vect_particle_nb = readRDS(paste0(results_folder,"/Connectivity_nbExchangedParticles_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    names(prop_within_OTU_vect_particle_nb) = taxo_groups
    taxo_groups_Arctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noLagoon_insert,".rds"))
    
    # plot.traveltime_log_size = qplot(x = x, y = y, colour = dominant_function[selected_groups], data=data.frame(x=prop_within_OTU_vect_2yr[selected_groups], y=prop_within_OTU_vect_phys[selected_groups]), geom="point") +
    # plot.traveltime_log_size = qplot(x = x, y = y, colour = dominant_function[selected_groups], data=data.frame(x=prop_within_OTU_vect_2yr[selected_groups], y=prop_within_OTU_vect_1.5yr[selected_groups]), geom="point") +
    plot.traveltime_log_size = qplot(x = x, y = y, colour = dominant_function[selected_groups], data=data.frame(y=prop_within_OTU_vect_particle_nb[taxo_groups_Arctic[selected_groups]]/prop_within_OTU_null, x=prop_within_OTU_vect_1000particles[taxo_groups_Arctic[selected_groups]]), geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=16),
            text = element_text(size=12),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(7,20,1,10),"mm"),
            legend.position="bottom",
            legend.text=element_text(size=10),
            legend.title=element_text(size=16, hjust = 10)) +
      # labs(x="Mean OTU connectivity per group - 2 year thres.", y="Mean OTU connectivity per group") +
      # labs(x="Mean OTU connectivity per group - 2 year thres.", y="Mean OTU connectivity per group - 1.5 year thres.") +
      labs(x="Mean OTU connectivity per group\n - 1000-particle threshold", y="Mean OTU connectivity per group\n - relative number of particles") +
      # xlim(range(prop_within_OTU_vect_2yr[selected_groups])) +
      # ylim(range(prop_within_OTU_vect_phys[selected_groups])) +
      # ylim(range(prop_within_OTU_vect_1.5yr[selected_groups])) +
      ylim(c(0,4.5)) +
      geom_smooth(method='lm', se = F, mapping = aes(x,y), inherit.aes = F, colour = "grey") +
      scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
      guides(colour = guide_legend(title.position="bottom"))
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    # ggsave(filename = paste0("Travel_time_prop_OTU_",travel_time_threshold,"yearTminProportion_vs_2yearTminProportion_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"), 
    # ggsave(filename = paste0("Travel_time_prop_OTU_1.5yearTminProportion_vs_2yearTminProportion_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"),
    ggsave(filename = paste0(figure_folder,"/Particle_nb_connectivity_vs_travel_time_prop_OTU_1000particlesThres_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"),
           do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)), height = 1.5*4, width = 1.5*4)
    
    ############################
    # prop_within_OTU_vect_noArctic = readRDS(paste0(results_folder,"/Connectivity_",travel_time_threshold,"yearTminProportion_meanPerOTU_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
    # prop_within_OTU_vect_noArctic = readRDS(paste0(results_folder,"/Connectivity_nbExchangedParticles_meanPerOTU_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
    prop_within_OTU_vect_noArctic = readRDS(paste0(results_folder,"/Connectivity_1000particlesThres_meanPerOTU_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
    taxo_groups_noArctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
    names(prop_within_OTU_vect_noArctic) = taxo_groups_noArctic
    
    # prop_within_OTU_vect_Arctic = readRDS(paste0(results_folder,"/Connectivity_",travel_time_threshold,"yearTminProportion_meanPerOTU_2plusOTUs",noLagoon_insert,".rds"))
    prop_within_OTU_vect_Arctic = readRDS(paste0(results_folder,"/Connectivity_nbExchangedParticles_meanPerOTU_2plusOTUs",noLagoon_insert,".rds"))[[1]]
    prop_within_OTU_vect_ArcticOnly = readRDS(paste0(results_folder,"/Connectivity_nbExchangedParticles_meanPerOTU_2plusOTUs_ArcticOnly",noLagoon_insert,".rds"))[[1]]
    taxo_groups_Arctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noLagoon_insert,".rds"))
    names(prop_within_OTU_vect_Arctic) = taxo_groups_Arctic
    taxo_groups_ArcticOnly = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs_ArcticOnly",noLagoon_insert,".rds"))
    names(prop_within_OTU_vect_ArcticOnly) = taxo_groups_ArcticOnly
    
    prop_within_OTU_vect_Arctic = readRDS(paste0(results_folder,"/Connectivity_1000particlesThres_meanPerOTU_2plusOTUs",noLagoon_insert,".rds"))
    prop_within_OTU_vect_ArcticOnly = readRDS(paste0(results_folder,"/Connectivity_1000particlesThres_meanPerOTU_2plusOTUs_ArcticOnly",noLagoon_insert,".rds"))
    taxo_groups_Arctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noLagoon_insert,".rds"))
    names(prop_within_OTU_vect_Arctic) = taxo_groups_Arctic
    taxo_groups_ArcticOnly = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs_ArcticOnly",noLagoon_insert,".rds"))
    names(prop_within_OTU_vect_ArcticOnly) = taxo_groups_ArcticOnly
    
    increasing_llh_Arctic = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs",noLagoon_insert,".rds"))
    alpha_best_real_Arctic = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs",noLagoon_insert,".rds"))
    selected_groups_Arctic = !(taxo_groups_Arctic %in% groups_to_remove) & alpha_best_real_Arctic<1 & increasing_llh_Arctic
    dominant_function_Arctic = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noLagoon_insert,".rds"))
    
    plot.traveltime_log_size = qplot(x = x, y = y, colour = dominant_function_Arctic[selected_groups_Arctic], 
                                     data=data.frame(x=prop_within_OTU_vect_noArctic[taxo_groups_Arctic[selected_groups_Arctic]], 
                                                     # y=prop_within_OTU_vect_Arctic[selected_groups_Arctic]), 
                                                     y=prop_within_OTU_vect_ArcticOnly[taxo_groups_Arctic[selected_groups_Arctic]]), 
                                     geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=16),
            text = element_text(size=12),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(7,20,1,10),"mm"),
            legend.position="bottom",
            legend.text=element_text(size=10),
            legend.title=element_text(size=16, hjust = 10)) +
      # labs(x="Mean OTU connectivity per group no Arctic", y="Mean OTU connectivity per group all data") +
      labs(x="Mean OTU connectivity per group no Arctic", y="Mean OTU connectivity per group Arctic") +
      # ylim(range(prop_within_OTU_vect_Arctic[selected_groups_Arctic][-which(prop_within_OTU_vect_Arctic[selected_groups_Arctic] == max(prop_within_OTU_vect_Arctic[selected_groups_Arctic]))])) +
      # xlim(range(prop_within_OTU_vect_noArctic[taxo_groups_Arctic[selected_groups_Arctic]][-which(prop_within_OTU_vect_Arctic[selected_groups_Arctic] == max(prop_within_OTU_vect_Arctic[selected_groups_Arctic]))])) +
      # xlim(range(prop_within_OTU_vect_noArctic[taxo_groups_Arctic[selected_groups_Arctic]][-which(prop_within_OTU_vect_noArctic[taxo_groups_Arctic[selected_groups_Arctic]] == max(prop_within_OTU_vect_noArctic[taxo_groups_Arctic[selected_groups_Arctic]]))])) +
      geom_smooth(method='lm', se = F, mapping = aes(x,y), inherit.aes = F, colour = "grey") +
      scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
      guides(colour = guide_legend(title.position="bottom"))
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    # ggsave(filename = paste0("Travel_time_prop_OTU_",travel_time_threshold,"yearTminProportion_Arctic_vs_noArctic_ggplot_",div_threshold,"plusOTUs_functionColors_selected.pdf"),
    #        do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),height = 1.5*4, width = 1.5*4)
    # ggsave(filename = paste0("Particle_nb_connectivity_Arctic_vs_noArctic_ggplot_",div_threshold,"plusOTUs_functionColors_selected.pdf"),
    #        do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),height = 1.5*4, width = 1.5*4)
    ggsave(filename = paste0(figure_folder,"/Particle_nb_prop_OTU_1000particlesThres_ArcticOnly_vs_noArctic_ggplot_",div_threshold,"plusOTUs_functionColors_selected.pdf"),
           do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),height = 1.5*4, width = 1.5*4)
    # ggsave(filename = paste0("Particle_nb_connectivity_ArcticOnly_vs_noArctic_ggplot_",div_threshold,"plusOTUs_functionColors_selected.pdf"), 
    #        do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),height = 1.5*4, width = 1.5*4)
  }
  
  if (travel_time_vs_size)
  {
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata"))
    # load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs_noArcticNoBiomark",noLagoon_insert,".Rdata")) 
    # taxo_groups_noArctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
    # names(size_absoluteAbund) = taxo_groups_noArctic
    
    if (travel_time_per_assemblage)
    {
      plot.traveltime_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund)[selected_groups],y=prop_within_topic_vect[selected_groups]), geom="point") +
        theme_bw() +
        #ggtitle("Mean similarity across real. vs. size") +
        theme(axis.title=element_text(size=12),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(7,1,1,0.5),"mm")) +
        labs(x="Mean body size (log10)", y="Mean travel time connectivity within assemblages") +
        #xlim(min(optimalK[1:61]),10) +
        # xlim(range(log10(size_absoluteAbund[!is.nan(prop_within_topic_vect)]))) +
        xlim(range(log10(size_absoluteAbund[selected_groups]))) +
        geom_smooth(method='lm')
      # geom_text(mapping = NULL, stat = "identity",size=3,
      #           #hjust=0, nudge_x = 0.2,
      #           nudge_y = 0,
      #           nudge_x = 0.1,
      #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
      #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
      #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
      #           hjust=0, 
      #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
      
      ggsave(filename = paste0(figure_folder,"/Travel_time_prop_vs_size_log10_ggplot_selected.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),
             height = 1.5*10/4, width = 1.5*10/4)
      
      plot.traveltime_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund[1:61]),y=prop_within_topic_vect[1:61]), label=taxo_groups[1:61], geom="point") +
        theme_bw() +
        #ggtitle("Mean similarity across real. vs. size") +
        theme(axis.title=element_text(size=12),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(7,1,1,0.5),"mm")) +
        labs(x="Mean body size (log10)", y="Mean travel time connectivity within assemblages") +
        #xlim(min(optimalK[1:61]),10) +
        #xlim(range(log10(size_absoluteAbund[!is.nan(prop_within_topic_vect)]))) +
        geom_smooth(method='lm')
      # geom_text(mapping = NULL, stat = "identity",size=3,
      #           #hjust=0, nudge_x = 0.2,
      #           nudge_y = 0,
      #           nudge_x = 0.1,
      #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
      #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
      #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
      #           hjust=0, 
      #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
      
      ggsave(filename = paste0(figure_folder,"/Travel_time_prop_vs_size_log10_ggplot_61first.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),
             height = 1.5*10/4, width = 1.5*10/4)
    }
    
    if (travel_time_per_OTU)
    {
      if (particle_thres == 0)
      {
        plot.traveltime_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund[taxo_groups_Arctic[selected_groups]]),y=prop_within_OTU_vect[taxo_groups_Arctic[selected_groups]]/prop_within_OTU_null), geom="point") +
          theme_bw() +
          #ggtitle("Mean similarity across real. vs. size") +
          theme(axis.title=element_text(size=12),
                plot.title=element_text(hjust=0, size=12),
                plot.margin=unit(c(7,1,1,0.5),"mm")) +
          labs(x="Mean body size (log10)", y="Mean OTU connectivity per group") +
          ylim(c(0,4.2)) +
          # xlim(range(log10(size_absoluteAbund[!is.na(prop_within_OTU_vect) & !is.na(size_absoluteAbund)]))) +
          geom_smooth(method='lm') +
          geom_hline(yintercept = 1, linetype = "dashed")
        
        ggsave(filename = paste0(figure_folder,"/Particle_nb_OTU_connectivity_vs_size_log10_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),
               height = 1.5*10/4, width = 1.5*10/4)
      } else if (particle_thres > 0)
      {
        plot.traveltime_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=prop_within_OTU_vect[selected_groups]), label=taxo_groups[selected_groups], geom="point") +
          theme_bw() +
          #ggtitle("Mean similarity across real. vs. size") +
          theme(axis.title=element_text(size=12),
                plot.title=element_text(hjust=0, size=12),
                plot.margin=unit(c(7,1,1,0.5),"mm")) +
          # labs(x="Mean body size (log10)", y="Mean OTU connectivity per group") +
          labs(x="Mean body size (log10)", y="Connectivity through currents") +
          # xlim(range(log10(size_absoluteAbund[!is.na(prop_within_OTU_vect) & !is.na(size_absoluteAbund)]))) +
          # ylim(c(0,1)) +
          geom_smooth(method='lm') 
          # geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed")
        # geom_text(mapping = NULL, stat = "identity",size=3,
        #           #hjust=0, nudge_x = 0.2,
        #           nudge_y = 0,
        #           nudge_x = 0.1,
        #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
        #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
        #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
        #           hjust=0, 
        #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
        
        if (travel_time_threshold != 10 && travel_time_threshold != 1000)
        {
          ggsave(filename = paste0(figure_folder,"/Travel_time_prop_OTU_",particle_thres,"particlesThres_vs_size_log10_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),
                 height = 1.5*10/4, width = 1.5*10/4)
        } else
          ggsave(filename = paste0(figure_folder,"/Travel_time_prop_OTU_",travel_time_threshold,"yearTminThres_",particle_thres,"particlesThres_vs_size_log10_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"),
                 do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),
                 height = 1.5*10/4, width = 1.5*10/4)
      }
      
      # summary(lm(log10(size_absoluteAbund) ~prop_within_OTU_vect))
      
      taxo_groups_allData = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noLagoon_insert,".rds"))
      increasing_llh_allData = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs",noLagoon_insert,".rds"))
      alpha_best_real_allData = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs",noLagoon_insert,".rds"))
      selected_groups_allData = !(taxo_groups_allData %in% groups_to_remove) & alpha_best_real_allData<1 & increasing_llh_allData
      load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noLagoon_insert,".Rdata")) 
      size_absoluteAbund_allData = size_absoluteAbund
      
      taxo_groups_noArctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
      increasing_llh_noArctic = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
      alpha_best_real_noArctic = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
      selected_groups_noArctic = !(taxo_groups_noArctic %in% groups_to_remove) & alpha_best_real_noArctic<1 & increasing_llh_noArctic
      load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs_noArcticNoBiomark",noLagoon_insert,".Rdata")) 
      size_absoluteAbund_noArctic = size_absoluteAbund
      
      # plot.traveltime_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund)[selected_groups],y=prop_within_OTU_vect[selected_groups]), geom="point") +
      # plot.traveltime_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund)[selected_groups],y=as.vector(prop_within_OTU_vect[taxo_groups_allData[selected_groups]])), geom="point") +
      # plot.traveltime_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund_allData)[selected_groups_allData],y=as.vector(prop_within_OTU_vect[taxo_groups_allData[selected_groups_allData]])), geom="point") +
      plot.traveltime_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund_noArctic)[selected_groups_noArctic],y=as.vector(prop_within_OTU_vect[taxo_groups_noArctic[selected_groups_noArctic]])), geom="point") +
        theme_bw() +
        #ggtitle("Mean similarity across real. vs. size") +
        theme(axis.title=element_text(size=12),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(7,1,1,0.5),"mm")) +
        labs(x="Mean body size (log10)", y="Mean OTU connectivity per group") +
        # xlim(range(log10(size_absoluteAbund[selected_groups]))) +
        geom_smooth(method='lm') +
        geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed")
      # geom_text(mapping = NULL, stat = "identity",size=3,
      #           #hjust=0, nudge_x = 0.2,
      #           nudge_y = 0,
      #           nudge_x = 0.1,
      #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
      #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
      #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
      #           hjust=0, 
      #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
      
      # ggsave(filename = paste0("Travel_time_prop_OTU_",travel_time_threshold,"yearTminProportion_vs_size_log10_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),
      #        height = 1.5*10/3, width = 1.5*10/3)
      ggsave(filename = paste0(figure_folder,"/Travel_time_prop_OTU_",particle_thres,"particlesThres_vs_size_log10_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),
             height = 1.5*10/3, width = 1.5*10/3)
      
      # summary(lm(log10(size_absoluteAbund)[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh] ~ prop_within_OTU_vect[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]))
      
      ###########################
      # Computing dominant_function:
      # foldername = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
      # load(paste0(foldername,"/taxo_ref.Rdata"))
      # taxo_groups_OTUs = taxo_ref$taxogroup2
      # # taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs.rds"))
      # taxo_groups_nomodif = levels(as.factor(taxo_groups_OTUs))[sort.int(table(as.factor(taxo_groups_OTUs)),index.return = T,decreasing = T)$ix]
      # 
      # functions_OTUs = taxo_ref$Function
      # dominant_function = vector(length = length(taxo_groups), mode = "character")
      # names(dominant_function) = taxo_groups
      # functions = levels(as.factor(functions_OTUs))
      # group_index = 0
      # for (group in taxo_groups_nomodif)
      # {
      #   group_index = group_index+1
      #   fun_index = 0
      #   function_proportions = vector(length = length(functions), mode = "numeric")
      #   for (fun in functions)
      #   {
      #     fun_index = fun_index+1
      #     function_proportions[fun_index] = length(which(functions_OTUs[which(taxo_groups_OTUs == group)] == fun))
      #   }
      #   if (length(functions[function_proportions == max(function_proportions)]) == 1)
      #   {
      #     dominant_function[group_index] = functions[function_proportions == max(function_proportions)]
      #   } else
      #   {
      #     cat(group)
      #     dominant_function[group_index] = sample(functions[function_proportions == max(function_proportions)],1)
      #   }
      # }
      # saveRDS(dominant_function,paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      ############################
      
      dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      # dominant_function_simplified  = dominant_function
      # dominant_function_simplified[dominant_function == "copepoda" & "other metazoa" & "pteropoda"] = "Metazoa"
      functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
      ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
      
      plot.traveltime_log_size = qplot(x = x, y = y, colour = dominant_function[selected_groups], data=data.frame(x=log10(size_absoluteAbund)[selected_groups], y=prop_within_OTU_vect[selected_groups]), geom="point") +
        theme_bw() +
        #ggtitle("Mean similarity across real. vs. size") +
        theme(axis.title=element_text(size=16),
              text = element_text(size=12),
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(7,20,1,10),"mm"),
              legend.position="bottom",
              legend.text=element_text(size=10),
              legend.title=element_text(size=16, hjust = 10)) +
        labs(x="Mean body size (log10)", y="Mean OTU connectivity per group") +
        xlim(range(log10(size_absoluteAbund[selected_groups]))) +
        geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed") +
        scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
        # geom_smooth(method='lm') +
        guides(colour = guide_legend(title.position="bottom"))
      # geom_text(mapping = NULL, stat = "identity",size=3,
      #           #hjust=0, nudge_x = 0.2,
      #           nudge_y = 0,
      #           nudge_x = 0.1,
      #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
      #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
      #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
      #           hjust=0, 
      #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
      
      ggsave(filename = paste0(figure_folder,"/Travel_time_prop_OTU_",travel_time_threshold,"yearTminProportion_",particle_thres,"particlesThres_vs_size_log10_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"), do.call("arrangeGrob", c(list(plot.traveltime_log_size), nrow=1)),
             height = 1.5*4, width = 1.5*4)
    }
  }
  
  if (travel_time_vs_stability)
  {
    if (travel_time_per_assemblage)
    {
      plot.traveltime_stability = qplot(x = x, y = y, data=data.frame(x=mean_sim[selected_groups],y=prop_within_topic_vect[selected_groups]), geom="point") +
        theme_bw() +
        #ggtitle("Mean similarity across real. vs. size") +
        theme(axis.title=element_text(size=12),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(7,1,1,0.5),"mm")) +
        labs(x="Mean similarity across 100 real.", y="Mean travel time connectivity within assemblages") +
        #xlim(min(optimalK[1:61]),10) +
        # xlim(range(log10(size_absoluteAbund[!is.nan(prop_within_topic_vect)]))) +
        xlim(range(mean_sim[selected_groups])) +
        geom_smooth(method='lm')
      # geom_text(mapping = NULL, stat = "identity",size=3,
      #           #hjust=0, nudge_x = 0.2,
      #           nudge_y = 0,
      #           nudge_x = 0.1,
      #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
      #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
      #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
      #           hjust=0, 
      #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
      
      ggsave(filename = figure_folder,"/Travel_time_prop_vs_stability_ggplot_selected.pdf", do.call("arrangeGrob", c(list(plot.traveltime_stability), nrow=1)),
             height = 1.5*10/4, width = 1.5*10/4)
    }
  }
}

if (optimalK_comput)
{
  taxo_groups = readRDS(paste0(results_folder,"/",short_marker,"taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/",short_marker,"diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds")) 
  # alpha_best_real = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # increasing_llh = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  # selected_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100
  
  data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_AllTAxa",noArcticNoBiomark_insert,noLagoon_insert)
  load(paste0(data.folder_name,"/coord.Rdata"))
  
  tot_reads = readRDS(paste0(results_folder,"/Total.read.numbers.rds"))
  
  # Loading multi-K comparison to local computer:
  # for (taxon in taxo_groups)
  # {
  #   cluster.data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
  #                                     taxon,noArcticNoBiomark_insert,noLagoon_insert,"/Rtopicmodels_LDA_VEM_alpha0.1_nb_topics2-35_nb_real10_em_tol1e-06_var_tol1e-08_occurrence")
  #   local.data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
  #                                   taxon,noArcticNoBiomark_insert,noLagoon_insert,"/")
  #   command = paste0("cp -r ",cluster.data.folder_name," ",
  #                    local.data.folder_name)
  #   system(command, intern=TRUE)
  # }
  
  library(ggplot2)
  library(gridExtra)
  
  # raref = NULL
  # raref = ".104"
  # raref = ".106"
  # raref = ".200"
  # raref = ".300"
  # raref = ".350.random"
  # raref = ".800.random"
  # raref = ".200.random"
  # raref = ".400.random"
  # raref = ".800.random"
  raref = "random.group.div"
  # raref = ".350"
  # raref = ".350.random"
  # raref = ".500"
  
  # reals = 10
  reals = NULL
  
  topic_range = "2-25"
  # topic_range = "2-30"
  # topic_range = "2-30"
  
  spline_df = 6
  
  # nb_real = 50
  # nb_real = 20
  nb_real = 100
  thin = 25
  # thin = 50
  # nb_iter = 10000
  nb_iter = 1000
  burnin_mpar0 = 2000
  burnin_mpar1 = 500
  
  optimalK_mpar_posteriorLlh = 0
  all_posterior_samples = 0
  
  optimalK_mpar_perplexity = 0
  fold_size = 10
  # fold_size = 2
  optimalK_mpar_prevalence.perplexity = 1
  optimalK_assemblage_prevalence = 0
  
  optimalK_mpar = 0
  optimalK_100r = 0
  
  if (!is.null(raref))
  {
    raref_taxo_groups = taxo_groups[selected_groups & 
                                      tot_reads > (if (raref == ".104") 10^4 else if (raref == ".105") 10^5 else if (raref == ".106") 10^6 else 0) &
                                      diversity > (if (raref == ".200") 200 else if (raref == ".250") 250 else if (raref == ".300") 300 else if (raref == ".350") 350
                                                   else if (raref == ".500") 500 else if (raref == ".1000") 1000 
                                                   else if (raref == ".250.random") 250 else if (raref == ".350.random") 350 
                                                   else if (raref == ".200.random") 200 else if (raref == ".400.random") 400 else if (raref == ".800.random") 800
                                                   else 100)]
    
    if (!is.null(reals))
    {
      raref_taxo_groups = paste0(rep(paste0(raref_taxo_groups,raref,"."),each=reals),
                                 rep(1:reals,length(raref_taxo_groups)))
    } else if (raref == "random.group.div")
    {
      raref_taxo_groups = paste0(raref,".",1:length(taxo_groups[selected_groups]))
    } else
      raref_taxo_groups = paste0(raref_taxo_groups,raref)
  }
  
  ii_taxon = 0
  # nrowDoc_trace = vector(length = length(taxo_groups)+1, mode ="numeric")
  if (optimalK_mpar_posteriorLlh)
  {
    # optimalK_posteriorLlh = matrix(ncol = length(taxo_groups), nrow = 4, data = 0)
    # plot.posteriorLlh.cor.optimalK = list()
    # plot.posteriorLlh = list()
    plot.posteriorLlh.errbar = list()
    # plot.spline.posteriorLlh = list()
    plot.spline.posteriorLlh.derivative = list()
    # plot.spline.posteriorLlh.derivative2 = list()
    plot.spline.posteriorLlh.EvannoDelta = list()
    plot.posteriorLlh.EvannoDelta = list()
    # plot.spline.posteriorLlh.derivative3 = list()
    # plot.spline.posteriorLlh.derivative4 = list()
    # optimalK_derivative4 = matrix(nrow = length(taxo_groups), ncol = 2, data=0)
    optimalK_max.llh = matrix(nrow = length(taxo_groups), ncol = 2, data=0)
    optimalK_sd.max.llh = matrix(nrow = length(taxo_groups), ncol = 2, data=0)
    optimalK_Evanno = matrix(nrow = length(taxo_groups), ncol = 2, data=0)
    optimalK_noSpline_Evanno = vector(length = length(taxo_groups), mode = "numeric")
    
    optimalK_max.llh.allTaxa = vector(length = 2, mode = "numeric")
    optimalK_sd.max.llh.allTaxa = vector(length = 2, mode = "numeric")
    optimalK_Evanno_AllTaxa = vector(length = 2, mode = "numeric")
  }
  if (optimalK_mpar_perplexity)
  {
    if (is.null(reals))
    {
      # optimalK_sd.min.crossValid = matrix(nrow = length(taxo_groups), ncol = 2, data = 0)
      optimalK_min.crossValid = matrix(nrow = length(taxo_groups), ncol = 2, data = 0)
      optimalK_min.crossValid.allTaxa = vector(length = 2, mode = "numeric")
      # optimalK_sd.min.crossValid.allTaxa = vector(length = 2, mode = "numeric")
      optimalK_crossValid_corCumul = matrix(nrow = length(taxo_groups), ncol = 3, data = 0)
      optimalK_crossValid_corCumul.allTaxa = vector(length = 3, mode = "numeric")
      # plot.perplexity.cor.optimalK = list()
      # plot.perplexity = list()
      plot.spline.perplexity = list()
      plot.spline.perplexity.derivative = list()
      plot.spline.perplexity.derivative2 = list()
      plot.spline.perplexity.corrCumul = list()
    } else
    {
      optimalK_min.crossValid = matrix(nrow = length(taxo_groups), ncol = reals, dimnames = list(taxo_groups,paste0("Samples",1:reals)), data = 0)
      optimalK_min.crossValid.allTaxa = vector(length = reals, mode = "numeric")
    }
  }
  if (optimalK_mpar_prevalence.perplexity)
  {
    if (is.null(reals))
    {
      optimalK_min.crossValid = readRDS(paste0(results_folder,"/",short_marker,
                                               if (!is.null(raref) && raref == "random.group.div") paste0(raref,"_")
                                               else if (!is.null(raref)) paste0(paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)],collapse=""),"_") 
                                               else "",
                                               "optimalK_min.crossValid_Gibbs",fold_size,"sampleFolds",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin_mpar1,
                                               "_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    } else
      optimalK_min.crossValid = readRDS(paste0(results_folder,"/",short_marker,
                                               if (!is.null(raref)) paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)],collapse="") else "",
                                               if (!is.null(reals)) paste0(".1-",reals) else "", 
                                               "_optimalK_min.crossValid_Gibbs",fold_size,"sampleFolds",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin_mpar1,
                                               "_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    
    if (is.null(reals))
    {
      optimalK_prevalence.min.crossValid = vector(length = length(taxo_groups), mode = "numeric")
      optimalK_prevalence.min.crossValid1 = vector(length = length(taxo_groups), mode = "numeric")
    } else
    {
      optimalK_prevalence.min.crossValid = matrix(nrow = length(taxo_groups), ncol = reals, dimnames = list(taxo_groups,paste0("Samples",1:reals)), data = 0)
      optimalK_prevalence.min.crossValid.allTaxa = vector(length = reals, mode = "numeric")
    }
  }
  if (optimalK_assemblage_prevalence)
  {
    # optimalK_min.crossValid = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs",fold_size,"sampleFolds2-35t_iter",nb_iter,"thin",thin,"burnin",burnin,"_2plusOTUs_noLagoon.rds"))[,1]
    plot.prevalence = list()
    plot.prevalence.SUR = vector(length = length(taxo_groups)+1, mode="list")
    plot.occurrence = list()
    plot.spline.perplexity.prevalence = list()
    plot.posteriorLlh.errbar.prevalence = list()
  }
  if (optimalK_mpar)
  {
    plot.K = list()
    plot.llh = list()
    plot.llh.allpoints = list()
    # plot.llh.allpoints.movmean = list()
    plot.llh.derivative = list()
    plot.llh.diff.ratio = list()
    plot.mean.sim.vs.K = list()
    plot.sim.intercept.vs.K = list()
    optimalK = vector(length = length(taxo_groups), mode = "numeric")
    optimalK2 = vector(length = length(taxo_groups), mode = "numeric")
    # optimalK_movmean = vector(length = length(taxo_groups), mode = "numeric")
    increasing_llh = vector(length = length(taxo_groups), mode = "logical")
  }
  if (optimalK_100r)
  {
    plot.K.100r = list()
    plot.K.100r.max = list()
    plot.llh.100r = list()
    plot.max.llh.100r = list()
    plot.llh.derivative.100r = list()
    plot.max.llh.derivative.100r = list() 
    plot.mean.sim.vs.K = list()
    plot.sim.intercept.vs.K = list()
    optimalK100r = vector(length = length(taxo_groups), mode = "numeric")
    optimalK100r_max = vector(length = length(taxo_groups), mode = "numeric")
    increasing_llh100r = vector(length = length(taxo_groups), mode = "logical")
    increasing_llh100r_max = vector(length = length(taxo_groups), mode = "logical")
  }
  for (taxon in (if (!is.null(raref)) raref_taxo_groups else taxo_groups[selected_groups]))
  # for (taxon in taxo_groups[1:54])
  # for (taxon in taxo_groups)
  # for (taxon in c("AllTaxa",taxo_groups))
  {
    if (!is.null(raref) && raref != "random.group.div")
    {
      true_taxon = strsplit(taxon,split=".",fixed=T)[[1]][1]
      if (!is.null(reals))
        real = as.numeric(strsplit(taxon,split=".",fixed=T)[[1]][length(strsplit(taxon,split=".",fixed=T)[[1]])])
      ii_taxon = ii_taxon+1
    } else if (!is.null(raref) && raref == "random.group.div")
    {
      ii_taxon = as.numeric(strsplit(taxon,split=".",fixed=T)[[1]][length(strsplit(taxon,split=".",fixed=T)[[1]])])
      true_taxon = taxo_groups[selected_groups][ii_taxon]
    } else
    {
      true_taxon = taxon
      ii_taxon = ii_taxon+1
    }
    if (true_taxon != "AllTaxa")
      i_taxon = which(true_taxon == taxo_groups)
    cat("\n",ifelse(true_taxon=="AllTaxa","AllTaxa",paste0(i_taxon,if (!is.null(reals)) paste0(".",real) else "","/",length(taxo_groups))))
    
    # data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    data.folder_name = paste0(data_folder_workspace2,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",
                              taxon,noArcticNoBiomark_insert,noLagoon_insert)
      
    ####### Computations based on Gibbs sampling cross-validation mpar = 1 ###############################
    if (optimalK_mpar_perplexity)
    {
      if (data_V4)
      {
        # if (i_taxon == 1)
        # {
        #   topic_range = "2-25"
        #   burnin = 500
        # } else
        # {
          topic_range = "2-30"
          burnin = 2000
        # }
      }
      
      # crossValid_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics2-20_post-predictive-cross-valid_nb_iter1000_fold_size10_occurrence/")
      # crossValid_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",topic_range,"_post-predictive-cross-valid_nb_iter1000_meanPosteriorDistributedLlh_thin25_burnin500_fold_size",fold_size,"_occurrence/")
      crossValid_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",topic_range,"_post-predictive-cross-valid_fold_size",fold_size,"_nb_iter",nb_iter,"_thin",thin,"_burnin",burnin_mpar1,"_occurrence/")
      # crossValid_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",topic_range,"_post-predictive-cross-valid_nb_iter",nb_iter,"_thin",thin,"_burnin",burnin,"_fold_size",fold_size,"_occurrence/")
      perplexity_file = paste0(crossValid_folder_name,"perplexity.Rdata")
      if (file.exists(perplexity_file))
      {
        load(perplexity_file)
        if (nrow(perplexity_mpar) > 1)
        {
          spline_mean = smooth.spline(nb_topics_range,colMeans(perplexity_mpar),df=spline_df)
          spline_median = smooth.spline(nb_topics_range,apply(perplexity_mpar,2,median),df=spline_df)
          
          derivative = matrix(nrow = length(nb_topics_range)-1, ncol = 2, data=0)
          coor_derivative = vector(length = length(nb_topics_range)-1, mode="numeric")
          # noSpline_derivative = vector(length = length(nb_topics_range)-1, mode="numeric")
          for (i in 2:length(nb_topics_range))
          {
            # noSpline_derivative[i-1] = (LLH_final0[1,i] - LLH_final0[1,i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
            # derivative[i-1,1] = (mean(perplexity_mpar[,i]) - mean(perplexity_mpar[,i-1]))/(nb_topics_range[i] - nb_topics_range[i-1])
            # derivative[i-1,2] = (median(perplexity_mpar[,i]) - median(perplexity_mpar[,i-1]))/(nb_topics_range[i] - nb_topics_range[i-1])
            derivative[i-1,1] = (spline_mean$y[i] - spline_mean$y[i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
            derivative[i-1,2] = (spline_median$y[i] - spline_median$y[i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
            coor_derivative[i-1] = (nb_topics_range[i] + nb_topics_range[i-1])/2
          }
          # Splining the first derivative:
          derivative[,1] = smooth.spline(coor_derivative,derivative[,1],df=spline_df)$y
          derivative[,2] = smooth.spline(coor_derivative,derivative[,2],df=spline_df)$y
          
          # Computing the 2nd derivative of the splined posterior distributed mean llh, based on the splined 1st derivative,
          # for the mean across realizations or the median:
          derivative2 = matrix(nrow = nrow(derivative)-1, ncol = 2, data=0)
          coor_derivative2 = vector(length = nrow(derivative)-1, mode="numeric")
          # noSpline_derivative2 = vector(length = nrow(derivative)-1, mode="numeric")
          # noSpline_Evanno_delta = vector(length = nrow(derivative)-1, mode="numeric")
          # Evanno_delta = vector(length = nrow(derivative)-1, mode="numeric")
          for (i in 2:nrow(derivative))
          {
            derivative2[i-1,1] = (derivative[i,1] - derivative[i-1,1])/(coor_derivative[i] - coor_derivative[i-1])
            derivative2[i-1,2] = (derivative[i,2] - derivative[i-1,2])/(coor_derivative[i] - coor_derivative[i-1])
            # noSpline_derivative2[i-1] = (noSpline_derivative[i] - noSpline_derivative[i-1])/(coor_derivative[i] - coor_derivative[i-1])
            coor_derivative2[i-1] = (coor_derivative[i] + coor_derivative[i-1])/2
            # Computing Evanno's delta on the non-splined values:
            # noSpline_Evanno_delta[i-1] = abs(noSpline_derivative2[i-1])/sd(LLH_final[,i])
            # Evanno_delta[i-1,2] = abs(derivative2[i-1,2])/sd(LLH_final[,i])
          }
          # Splining the second derivative:
          derivative2[,1] = smooth.spline(coor_derivative2,derivative2[,1],df=spline_df)$y
          derivative2[,2] = smooth.spline(coor_derivative2,derivative2[,2],df=spline_df)$y
          # for (i in 2:nrow(derivative))
          #   Evanno_delta[i-1] = abs(derivative2[i-1])/sd(LLH_final[,i])
          
          index = sort.int(spline_mean$y,decreasing = F,index.return = T)$ix[1]
          if (is.null(reals))
          {
            if (true_taxon == "AllTaxa")
              optimalK_min.crossValid.allTaxa[1] = nb_topics_range[index]
            else
              optimalK_min.crossValid[i_taxon,1] = nb_topics_range[index]
          } else
          {
            if (true_taxon == "AllTaxa")
              optimalK_min.crossValid.allTaxa[real] = nb_topics_range[index]
            else
              optimalK_min.crossValid[i_taxon,real] = nb_topics_range[index]
          }
          # i = 1
          # while (i < length(nb_topics_range)+1 && spline_mean$y[i] - sd(perplexity_mpar[,index]) > spline_mean$y[index])
          #   i = i+1
          # if (taxon == "AllTaxa")
          #   optimalK_sd.min.crossValid.allTaxa[1] = nb_topics_range[i]
          # else
          #   optimalK_sd.min.crossValid[i_taxon,1] = nb_topics_range[i]
          
          if (is.null(reals))
          {
            if (index>2)
            {
              cor_cumul = vector(length = index-2, mode = "numeric")
              cor_cumul_reverse = vector(length = index-2, mode = "numeric")
              if (index > 4)
                cor_cumul_mean = vector(length = index-4, mode = "numeric")
              for (ii in 2:(index-1))
              {
                cor_cumul[ii-1] = abs(cor(nb_topics_range[1:(ii+1)],spline_mean$y[1:(ii+1)]))
                cor_cumul_reverse[ii-1] = abs(cor(nb_topics_range[(index-ii):index],spline_mean$y[(index-ii):index]))
                if (index > 4 && ii < index-2)
                  cor_cumul_mean[ii-1] = cor_cumul[ii-1] + cor(nb_topics_range[(ii+1):index],spline_mean$y[(ii+1):index])
              }
              if (true_taxon == "AllTaxa")
              {
                optimalK_crossValid_corCumul.allTaxa[1] = nb_topics_range[3:index][which(cor_cumul == max(cor_cumul))]
                optimalK_crossValid_corCumul.allTaxa[2] = rev(nb_topics_range[1:(index-2)])[which(cor_cumul_reverse == max(cor_cumul_reverse))]
                if (index > 4)
                  optimalK_crossValid_corCumul.allTaxa[3] = nb_topics_range[3:(index-2)][which(cor_cumul_mean == max(cor_cumul_mean))]
                # optimalK_crossValid_corCumul[1,i_taxon] = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)])[which(abs(cor_cumul[-1]) == max(abs(cor_cumul[-1])))]
              } else 
              {
                optimalK_crossValid_corCumul[i_taxon,1] = nb_topics_range[3:index][which(cor_cumul == max(cor_cumul))]
                optimalK_crossValid_corCumul[i_taxon,2] = rev(nb_topics_range[1:(index-2)])[which(cor_cumul_reverse == max(cor_cumul_reverse))]
                if (index > 4)
                  optimalK_crossValid_corCumul[i_taxon,3] = nb_topics_range[3:(index-2)][which(cor_cumul_mean == max(cor_cumul_mean))]
              }
            }
            
            index = sort.int(spline_median$y,decreasing = F,index.return = T)$ix[1]
            if (true_taxon == "AllTaxa")
              optimalK_min.crossValid.allTaxa[2] = nb_topics_range[index]
            else 
              optimalK_min.crossValid[i_taxon,2] = nb_topics_range[index]
            # i = 1
            # while (i < length(nb_topics_range)+1 && spline_median$y[i] - sd(perplexity_mpar[,index]) > spline_median$y[index])
            #   i = i+1
            # if (taxon == "AllTaxa")
            #   optimalK_sd.min.crossValid.allTaxa[2] = nb_topics_range[i]
            # else
            #   optimalK_sd.min.crossValid[i_taxon,2] = nb_topics_range[i]
            
            # cor_cumul_median = vector(length = length(nb_topics_range)-1, mode = "numeric")
            # for (i_K in 1:(length(nb_topics_range)-1))
            # {
            #   range_K = (length(nb_topics_range)-i_K):length(nb_topics_range)
            #   cor_cumul_median[i_K] = cor(nb_topics_range[range_K],apply(perplexity_mpar[,range_K],2,median))
            # }
            # optimalK_crossValid[1,i_taxon] = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)])[which(abs(cor_cumul[-1]) == max(abs(cor_cumul[-1])))]
            
            # plot.perplexity.cor.optimalK[[i_taxon]] = ggplot(data = data.frame(K = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)]), cor = abs(cor_cumul[-1]), cor_median = abs(cor_cumul_median[-1]))) +
            #   geom_line(aes(x = K, y = cor), size = 0.4) +
            #   geom_line(aes(x = K, y = cor_median), size = 0.4, col = "blue") +
            #   geom_vline(xintercept=optimalK_crossValid[1,i_taxon], linetype= 2, size = 0.4) +
            #   geom_vline(xintercept=optimalK_crossValid[2,i_taxon], linetype= 2, size = 0.4, col = "blue") +
            #   theme_bw() + 
            #   theme(axis.title=element_text(size=9),
            #         plot.title=element_text(hjust=0, size=15),
            #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
            #   ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
            #   labs(x="Number K of assemblages", y="Perplexity cumulative correlation")
            # 
            # plot.perplexity[[i_taxon]] = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range,rep,nrow(perplexity_mpar))), llh = as.vector(perplexity_mpar))) +
            #   geom_boxplot(aes(x=as.factor(K),y=llh), size = 0.4, outlier.size = 0.4, outlier.color = "darkgrey") +
            #   geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = colMeans(perplexity_mpar)), aes(x = K, y = llh), size = 0.4) +
            #   geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = apply(perplexity_mpar,2,median)), aes(x = K, y = llh), size = 0.4, col = "blue") +
            #   # geom_vline(xintercept=optimalK_crossValid[1,i_taxon]-1, linetype = "longdash", size = 0.4) +
            #   # geom_vline(xintercept=optimalK_crossValid[2,i_taxon]-1, linetype = "longdash", size = 0.4, col = "blue") +
            #   scale_x_discrete(breaks = seq(from = nb_topics_range[1], to = nb_topics_range[length(nb_topics_range)], by = 3)) +
            #   theme_bw() +
            #   theme(axis.title=element_text(size=9),
            #         axis.text=element_text(size=9),
            #         plot.title=element_text(hjust=0, size=10),
            #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
            #   ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
            #   labs(x="Number K of assemblages", y="Perplexity 10-sample fold")
            
            
            plot.spline.perplexity[[ii_taxon]] = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range,rep,nrow(perplexity_mpar))), llh = as.vector(perplexity_mpar))) +
              geom_boxplot(aes(x=as.factor(K),y=llh), size = 0.4, outlier.size = 0.4, outlier.color = "darkgrey") +
              geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = spline_mean$y), aes(x = K, y = llh), size = 0.4) +
              geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = spline_median$y), aes(x = K, y = llh), size = 0.4, col = "blue") +
              # geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_sd.min.crossValid.allTaxa[1],optimalK_sd.min.crossValid[i_taxon,1])), linetype = "longdash", size = 0.4) +
              # geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_sd.min.crossValid.allTaxa[2],optimalK_sd.min.crossValid[i_taxon,2])), linetype = "longdash", size = 0.4, col = "blue") +
              geom_vline(xintercept = which(nb_topics_range ==ifelse(true_taxon=="AllTaxa",optimalK_min.crossValid.allTaxa[1],optimalK_min.crossValid[i_taxon,1])), linetype = "dotted", size = 0.4) +
              geom_vline(xintercept = which(nb_topics_range == ifelse(true_taxon=="AllTaxa",optimalK_min.crossValid.allTaxa[2],optimalK_min.crossValid[i_taxon,2])), linetype = "dotted", size = 0.4, col = "blue") +
              scale_x_discrete(breaks = seq(from = nb_topics_range[1], to = nb_topics_range[length(nb_topics_range)], by = 3)) +
              theme_bw() +
              theme(axis.title=element_text(size=9),
                    axis.text=element_text(size=9),
                    plot.title=element_text(hjust=0, size=10),
                    plot.margin=unit(c(1,1,1,0.5),"mm")) +
              ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
              labs(x="Number K of assemblages", y=paste0(spline_df,"-df-splined ",fold_size,"-sample-fold perplexity"))
            
            plot.spline.perplexity.corrCumul[[ii_taxon]] = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range,rep,nrow(perplexity_mpar))), llh = as.vector(perplexity_mpar))) +
              geom_boxplot(aes(x=as.factor(K),y=llh), size = 0.4, outlier.size = 0.4, outlier.color = "darkgrey") +
              geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = spline_mean$y), aes(x = K, y = llh), size = 0.4) +
              # geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = spline_median$y), aes(x = K, y = llh), size = 0.4, col = "blue") +
              geom_vline(xintercept = which(nb_topics_range == ifelse(true_taxon=="AllTaxa",optimalK_min.crossValid.allTaxa[1],optimalK_min.crossValid[i_taxon,1])), linetype = "dotted", size = 0.4) +
              geom_vline(xintercept = which(nb_topics_range == ifelse(true_taxon=="AllTaxa",optimalK_crossValid_corCumul.allTaxa[1],optimalK_crossValid_corCumul[i_taxon,1])), linetype = "longdash", size = 0.4) +
              geom_vline(xintercept = which(nb_topics_range == ifelse(true_taxon=="AllTaxa",optimalK_crossValid_corCumul.allTaxa[2],optimalK_crossValid_corCumul[i_taxon,2])), linetype = "longdash", size = 0.4, col = "blue") +
              geom_vline(xintercept = which(nb_topics_range == ifelse(true_taxon=="AllTaxa",optimalK_crossValid_corCumul.allTaxa[3],optimalK_crossValid_corCumul[i_taxon,3])), linetype = "longdash", size = 0.4, col = "green") +
              scale_x_discrete(breaks = seq(from = nb_topics_range[1], to = nb_topics_range[length(nb_topics_range)], by = 3)) +
              theme_bw() +
              theme(axis.title=element_text(size=9),
                    axis.text=element_text(size=9),
                    plot.title=element_text(hjust=0, size=10),
                    plot.margin=unit(c(1,1,1,0.5),"mm")) +
              ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
              labs(x="Number K of assemblages", y=paste0(spline_df,"-df-splined ",fold_size,"-sample-fold perplexity"))
            
            plot.spline.perplexity.derivative[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative,y1=derivative[,1],y2=derivative[,2])) +
              geom_line(aes(x,y1)) +
              geom_line(aes(x,y2),col="blue") +
              # geom_vline(xintercept = ifelse(taxon=="AllTaxa",optimalK_sd.min.crossValid.allTaxa[1],optimalK_sd.min.crossValid[i_taxon,1]), linetype = "longdash", size = 0.4) +
              # geom_vline(xintercept = ifelse(taxon=="AllTaxa",optimalK_sd.min.crossValid.allTaxa[2],optimalK_sd.min.crossValid[i_taxon,2]), linetype = "longdash", size = 0.4, col = "blue") +
              geom_vline(xintercept = ifelse(true_taxon=="AllTaxa",optimalK_min.crossValid.allTaxa[1],optimalK_min.crossValid[i_taxon,1]), linetype = "dotted", size = 0.4) +
              geom_vline(xintercept = ifelse(true_taxon=="AllTaxa",optimalK_min.crossValid.allTaxa[2],optimalK_min.crossValid[i_taxon,2]), linetype = "dotted", size = 0.4, col = "blue") +
              # geom_point(aes(x,y)) +
              # geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
              #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
              theme_bw() +
              ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
              theme(axis.title=element_text(size=9),
                    plot.title=element_text(hjust=0, size=15),
                    plot.margin=unit(c(1,1,1,0.5),"mm")) +
              labs(x="Number K of assemblages", y=paste0("1st derivative of ",spline_df,"-df-splined ",fold_size,"-sample-fold perplexity"))
            
            plot.spline.perplexity.derivative2[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative2,y1=derivative2[,1],y2=derivative2[,2])) +
              geom_line(aes(x,y1)) +
              geom_line(aes(x,y2),col="blue") +
              # geom_point(aes(x,y)) +
              # geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
              #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
              theme_bw() +
              ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
              theme(axis.title=element_text(size=9),
                    plot.title=element_text(hjust=0, size=15),
                    plot.margin=unit(c(1,1,1,0.5),"mm")) +
              labs(x="Number K of assemblages", y=paste0("2nd derivative of ",spline_df,"-df-splined ",fold_size,"-sample-fold perplexity"))
          }
          na.fill = F
        } else
        {
          na.fill = T
        }
      } else 
      {
        na.fill = T
      }
      
      if (na.fill)
      {
        if (is.null(reals))
        {
          if (true_taxon == "AllTaxa")
          {
            # optimalK_sd.min.crossValid.allTaxa = c(NA,NA) 
            optimalK_min.crossValid.allTaxa = c(NA,NA)
            optimalK_crossValid_corCumul.allTaxa = c(NA,NA,NA)
          } else
          {
            # optimalK_sd.min.crossValid[i_taxon,] = c(NA,NA)
            optimalK_min.crossValid[i_taxon,] = c(NA,NA)
            optimalK_crossValid_corCumul[i_taxon,] = c(NA,NA,NA)
          }
          # plot.perplexity.cor.optimalK[[i_taxon]] = NA
          # plot.perplexity[[i_taxon]] = NA
          plot.spline.perplexity.corrCumul[[ii_taxon]] = NA
          plot.spline.perplexity[[ii_taxon]] = NA
          plot.spline.perplexity.derivative[[ii_taxon]] = NA
          plot.spline.perplexity.derivative2[[ii_taxon]] = NA
        } else
        {
          if (true_taxon == "AllTaxa")
          {
            # optimalK_sd.min.crossValid.allTaxa = c(NA,NA) 
            optimalK_min.crossValid.allTaxa[real] = NA
          } else
          {
            # optimalK_sd.min.crossValid[i_taxon,] = c(NA,NA)
            optimalK_min.crossValid[i_taxon,real] = NA
          }
        }
      }
    }
    
    ##### Computing the prevalence-corrected min-cross-validation optimal K using mpar = 0 results for K = optimalK_min.crossValid
    if (optimalK_mpar_prevalence.perplexity)
    {
      if (is.null(reals))
      {
        if (true_taxon != "AllTaxa")
          nb_topics = optimalK_min.crossValid[i_taxon]
        else
          nb_topics = optimalK_min.crossValid.allTaxa
      } else
      {
        if (true_taxon != "AllTaxa")
          nb_topics = optimalK_min.crossValid[i_taxon,real]
        else
          nb_topics = optimalK_min.crossValid.allTaxa[real]
      }
      # Gibbs_VEM_insert == "_GibbsShortChainNoAverage10sampleFold")
      documents_file_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin_mpar0,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds")
      if (file.exists(documents_file_name))
      {
        spatial_topicmix_kriged = readRDS(documents_file_name)
        # selecting the z.pred columns in all topics:
        documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
        # setting one topic per column
        documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("assemblage",1:nb_topics)))
        
        if (is.null(reals))
        {
          if (true_taxon != "AllTaxa")
            optimalK_prevalence.min.crossValid[i_taxon] = length(which(apply(documents,2,mean) > 1/nrow(documents)))
          else
            optimalK_prevalence.min.crossValid.allTaxa = length(which(apply(documents,2,mean) > 1/nrow(documents)))
          
          topic_vector_SUR = apply(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",],2,mean) > 1/nrow(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",])
          topic_vector_DCM = apply(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",],2,mean) > 1/nrow(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",])
          if (true_taxon != "AllTaxa")
          {
            optimalK_prevalence.min.crossValid1[i_taxon] = length(which(topic_vector_SUR | topic_vector_DCM))
          } else
            optimalK_prevalence.min.crossValid1.allTaxa = length(which(topic_vector_SUR | topic_vector_DCM))
        } else
        {
          if (true_taxon != "AllTaxa")
            optimalK_prevalence.min.crossValid[i_taxon,real] = length(which(apply(documents,2,mean) > 1/nrow(documents)))
          else
            optimalK_prevalence.min.crossValid.allTaxa[real] = length(which(apply(documents,2,mean) > 1/nrow(documents)))
        }
      } else
      {
        if (is.null(reals))
        {
          if (true_taxon == "AllTaxa")
          {
            optimalK_prevalence.min.crossValid.allTaxa = NA
            optimalK_prevalence.min.crossValid1.allTaxa = NA
          } else
          {
            optimalK_prevalence.min.crossValid[i_taxon] = NA
            optimalK_prevalence.min.crossValid1[i_taxon] = NA
          }
        } else
        {
          if (true_taxon == "AllTaxa")
          {
            optimalK_prevalence.min.crossValid.allTaxa[real] = NA
          } else
          {
            optimalK_prevalence.min.crossValid[i_taxon,real] = NA
          }
        }
      }
    }
    
    if (optimalK_assemblage_prevalence)
    {
      if (taxon != "AllTaxa")
        nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
      else
        nb_topics = optimalK_prevalence.min.crossValid.allTaxa
      # Gibbs_VEM_insert == "_GibbsShortChainNoAverage10sampleFold")
      documents_file_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds")
      if (file.exists(documents_file_name))
      {
        spatial_topicmix_kriged = readRDS(documents_file_name)
        # selecting the z.pred columns in all topics:
        documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
        # setting one topic per column
        documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("assemblage",1:nb_topics)))
        
        # nrowDoc_trace[ii_taxon] = nrow(documents)
        
        plot.prevalence[[ii_taxon]] = ggplot(data=data.frame(x=1:nb_topics,y=sort(apply(documents,2,mean), decreasing = T))) +
          geom_point(aes(x,y)) +
          scale_y_log10() +
          # theme_bw() +
          theme_classic() +
          # geom_point(aes(x,y)) +
          geom_hline(yintercept = 1/nrow(documents), linetype = "dashed") +
          #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
          # theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Community types in decreasing order of prevalence", y="Prevalence of community type")
        
        plot.prevalence.SUR[[ii_taxon]] = ggplot(data=data.frame(x=1:nb_topics,y=sort(apply(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",],2,mean), decreasing = T))) +
          geom_point(aes(x,y)) +
          scale_y_log10() +
          # theme_bw() +
          theme_classic() +
          # geom_point(aes(x,y)) +
          geom_hline(yintercept = 1/nrow(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]), linetype = "dashed") +
          #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
          # theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Community types in decreasing order of Surf. prevalence", y="Surf. prevalence of community type")
        
        nb_presence_stations_k = vector(length = nb_topics, mode = "numeric")
        for (k in 1:nb_topics)
        {
          nb_presence_stations_k[k] = length(which(documents[,k]>0.1))
        }
        
        plot.occurrence[[ii_taxon]] = ggplot(data=data.frame(x=1:nb_topics,y=sort(nb_presence_stations_k, decreasing = T))) +
          geom_point(aes(x,y)) +
          scale_y_log10() +
          # theme_bw() +
          theme_classic() +
          # geom_point(aes(x,y)) +
          #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
          # theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Community types in decreasing order of occurrence", y="Number of stations\n where community type is present at >10%")
        
        crossValid_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",topic_range,"_post-predictive-cross-valid_nb_iter",nb_iter,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_fold_size",fold_size,"_occurrence/")
        perplexity_file = paste0(crossValid_folder_name,"perplexity.Rdata")
        if (file.exists(perplexity_file))
        {
          load(perplexity_file)
          if (nrow(perplexity_mpar) > 1)
          {
            spline_mean = smooth.spline(nb_topics_range,colMeans(perplexity_mpar),df=spline_df)
            
            plot.spline.perplexity.prevalence[[ii_taxon]] = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range,rep,nrow(perplexity_mpar))), llh = as.vector(perplexity_mpar))) +
              geom_boxplot(aes(x=as.factor(K),y=llh), size = 0.4, outlier.size = 0.4, outlier.color = "darkgrey") +
              geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = spline_mean$y), aes(x = K, y = llh), size = 0.4) +
              geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_prevalence.min.crossValid.allTaxa,optimalK_prevalence.min.crossValid[i_taxon])), linetype = "longdash", size = 0.4) +
              geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",21,optimalK_min.crossValid[i_taxon])), linetype = "dotted", size = 0.4) +
              scale_x_discrete(breaks = seq(from = nb_topics_range[1], to = nb_topics_range[length(nb_topics_range)], by = 3)) +
              theme_bw() +
              theme(axis.title=element_text(size=9),
                    axis.text=element_text(size=9),
                    plot.title=element_text(hjust=0, size=10),
                    plot.margin=unit(c(1,1,1,0.5),"mm")) +
              ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
              labs(x="Number K of assemblages", y=paste0(spline_df,"-df-splined ",fold_size,"-sample-fold perplexity"))
          }
        } else
          plot.spline.perplexity.prevalence[[ii_taxon]] = NA
        
        posteriorLlh_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",topic_range,"_elbow-AIC_nb_iter",nb_iter,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_nb_real",nb_real,"_occurrence/")
        posteriorLlh_file = paste0(posteriorLlh_folder_name,"AIC-llh.Rdata")
        if (file.exists(posteriorLlh_file))
        {
          load(posteriorLlh_file)
          spline_mean = smooth.spline(nb_topics_range,colMeans(LLH_final),df=spline_df)
          
          plot.posteriorLlh.errbar.prevalence[[ii_taxon]] = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range,rep,nrow(LLH_final))), llh = as.vector(LLH_final))) +
            geom_boxplot(aes(x=as.factor(K),y=llh), size = 0.4, outlier.size = 0.4, outlier.color = "darkgrey") +
            geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = spline_mean$y), aes(x = K, y = llh), size = 0.4) +
            geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_prevalence.min.crossValid.allTaxa,optimalK_prevalence.min.crossValid[i_taxon])), linetype = "longdash", size = 0.4) +
            geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",21,optimalK_min.crossValid[i_taxon])), linetype = "dotted", size = 0.4) +
            theme_bw() +
            scale_x_discrete(breaks = seq(from = nb_topics_range[1], to = nb_topics_range[length(nb_topics_range)], by = 3)) +
            theme(axis.title=element_text(size=9),
                  axis.text=element_text(size=9),
                  plot.title=element_text(hjust=0, size=10),
                  plot.margin=unit(c(1,1,1,0.5),"mm")) +
            ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
            labs(x="Number K of assemblages", y="Mean posterior-distributed log-likelihood")
        } else
          plot.posteriorLlh.errbar.prevalence[[ii_taxon]] = NA
      } else
      {
        cat("\n","No available file.")
        plot.prevalence[[ii_taxon]] = NA
        plot.occurrence[[ii_taxon]] = NA
        plot.spline.perplexity.prevalence[[ii_taxon]] = NA
        plot.posteriorLlh.errbar.prevalence[[ii_taxon]] = NA
      }
    }
    
    ####### Computations based on Gibbs sampling posterior-sampled llh mpar = 1 ###############################
    if (optimalK_mpar_posteriorLlh)
    {
      # posteriorLlh_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics2-15_elbow-AIC_nb_iter1000_meanPosteriorDistributedLlh_thin25_burnin500_nb_real10_occurrence/")
      # posteriorLlh_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",topic_range,"_elbow-AIC_nb_iter1000_meanPosteriorDistributedLlh_thin25_burnin500_nb_real100_occurrence/")
      # posteriorLlh_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",topic_range,"_elbow-AIC_nb_iter1000_meanPosteriorDistributedLlh_thin25_burnin500_nb_real50_occurrence/")
      posteriorLlh_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",topic_range,"_elbow-AIC_nb_iter",nb_iter,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_nb_real",nb_real,"_occurrence/")
      posteriorLlh_file = paste0(posteriorLlh_folder_name,"AIC-llh.Rdata")
      posteriorLlh_allSamples_file = paste0(posteriorLlh_folder_name,"posterior_sampled_logLiks.rds")
      if (ifelse(all_posterior_samples,file.exists(posteriorLlh_file) && file.exists(posteriorLlh_allSamples_file),file.exists(posteriorLlh_file)))
      {
        load(posteriorLlh_file)
        mean_median_sd_log_llh = matrix(nrow = length(nb_topics_range), ncol = 3, data = 0)
        if (all_posterior_samples)
        {
          sampled_logLiks_mpar = readRDS(posteriorLlh_allSamples_file)
          criterion = matrix(nrow = nrow(LLH_final), ncol = ncol(LLH_final), data = 0)
          for (par_index in 1:length(sampled_logLiks_mpar))
            criterion[,par_index] = rowMeans(sampled_logLiks_mpar[[par_index]]) - apply(sampled_logLiks_mpar[[par_index]],1,var)/2
        } else
          criterion = LLH_final
        mean_median_sd_log_llh[,1] = colMeans(criterion)
        mean_median_sd_log_llh[,2] = apply(criterion,2,median)
        mean_median_sd_log_llh[,3] = apply(criterion,2,sd)
        spline_mean = smooth.spline(nb_topics_range,mean_median_sd_log_llh[,1],df=spline_df)
        spline_median = smooth.spline(nb_topics_range,mean_median_sd_log_llh[,2],df=spline_df)
        
        # Computing the 1st derivative of the splined posterior distributed mean llh,
        # for the mean across realizations or the median.
        # Computing also the 1st derivative of the non-splined llh, to compute Evanno's alpha.
        derivative = matrix(nrow = length(nb_topics_range)-1, ncol = 2, data=0)
        coor_derivative = vector(length = length(nb_topics_range)-1, mode="numeric")
        noSpline_derivative = vector(length = length(nb_topics_range)-1, mode="numeric")
        for (i in 2:length(nb_topics_range))
        {
          noSpline_derivative[i-1] = (mean_median_sd_log_llh[i,1] - mean_median_sd_log_llh[i-1,1])/(nb_topics_range[i] - nb_topics_range[i-1])
          derivative[i-1,1] = (spline_mean$y[i] - spline_mean$y[i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
          derivative[i-1,2] = (spline_median$y[i] - spline_median$y[i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
          coor_derivative[i-1] = (nb_topics_range[i] + nb_topics_range[i-1])/2
        }
        # Splining the first derivative:
        derivative[,1] = smooth.spline(coor_derivative,derivative[,1],df=spline_df)$y
        derivative[,2] = smooth.spline(coor_derivative,derivative[,2],df=spline_df)$y
        
        # Computing the 2nd derivative of the splined posterior distributed mean llh, based on the splined 1st derivative,
        # for the mean across realizations or the median:
        derivative2 = matrix(nrow = nrow(derivative)-1, ncol = 2, data=0)
        coor_derivative2 = vector(length = nrow(derivative)-1, mode="numeric")
        noSpline_derivative2 = vector(length = nrow(derivative)-1, mode="numeric")
        noSpline_Evanno_delta = vector(length = nrow(derivative)-1, mode="numeric")
        Evanno_delta = vector(length = nrow(derivative)-1, mode="numeric")
        for (i in 2:nrow(derivative))
        {
          derivative2[i-1,1] = (derivative[i,1] - derivative[i-1,1])/(coor_derivative[i] - coor_derivative[i-1])
          derivative2[i-1,2] = (derivative[i,2] - derivative[i-1,2])/(coor_derivative[i] - coor_derivative[i-1])
          noSpline_derivative2[i-1] = (noSpline_derivative[i] - noSpline_derivative[i-1])/(coor_derivative[i] - coor_derivative[i-1])
          coor_derivative2[i-1] = (coor_derivative[i] + coor_derivative[i-1])/2
          # Computing Evanno's delta on the non-splined values:
          noSpline_Evanno_delta[i-1] = abs(noSpline_derivative2[i-1])/mean_median_sd_log_llh[i,3]
          # Evanno_delta[i-1,2] = abs(derivative2[i-1,2])/sd(LLH_final[,i])
        }
        # Splining the second derivative:
        derivative2[,1] = smooth.spline(coor_derivative2,derivative2[,1],df=spline_df)$y
        derivative2[,2] = smooth.spline(coor_derivative2,derivative2[,2],df=spline_df)$y
        for (i in 2:nrow(derivative))
          Evanno_delta[i-1] = abs(derivative2[i-1])/mean_median_sd_log_llh[i,3]
        
        # derivative3 = matrix(nrow = nrow(derivative2)-1, ncol = 2, data=0)
        # coor_derivative3 = vector(length = nrow(derivative2)-1, mode="numeric")
        # for (i in 2:nrow(derivative2))
        # {
        #   derivative3[i-1,1] = (derivative2[i,1] - derivative2[i-1,1])/(coor_derivative2[i] - coor_derivative2[i-1])
        #   derivative3[i-1,2] = (derivative2[i,2] - derivative2[i-1,2])/(coor_derivative2[i] - coor_derivative2[i-1])
        #   coor_derivative3[i-1] = (coor_derivative2[i] + coor_derivative2[i-1])/2
        # }
        # derivative3[,1] = smooth.spline(coor_derivative3,derivative3[,1],df=spline_df)$y
        # derivative3[,2] = smooth.spline(coor_derivative3,derivative3[,2],df=spline_df)$y
        # 
        # derivative4 = matrix(nrow = nrow(derivative3)-1, ncol = 2, data=0)
        # coor_derivative4 = vector(length = nrow(derivative3)-1, mode="numeric")
        # for (i in 2:nrow(derivative3))
        # {
        #   derivative4[i-1,1] = (derivative3[i,1] - derivative3[i-1,1])/(coor_derivative3[i] - coor_derivative3[i-1])
        #   derivative4[i-1,2] = (derivative3[i,2] - derivative3[i-1,2])/(coor_derivative3[i] - coor_derivative3[i-1])
        #   coor_derivative4[i-1] = (coor_derivative3[i] + coor_derivative3[i-1])/2
        # }
        # derivative4[,1] = smooth.spline(coor_derivative4,derivative4[,1],df=spline_df)$y
        # derivative4[,2] = smooth.spline(coor_derivative4,derivative4[,2],df=spline_df)$y
        
        # Evanno delta based on smoothed curves:
        optimalK_Evanno_i_taxon = coor_derivative2[sort.int(Evanno_delta,decreasing=T,index.return = T)$ix]
        if (optimalK_Evanno_i_taxon[1] != coor_derivative2[1])
        {
          if (taxon == "AllTaxa")
            optimalK_Evanno_AllTaxa[1] = optimalK_Evanno_i_taxon[1]
          else   
            optimalK_Evanno[i_taxon,1] = optimalK_Evanno_i_taxon[1]
        } else
        {
          i = 1
          while (optimalK_Evanno_i_taxon[i+1] == coor_derivative2[1]+i)
            i = i+1
          if (taxon == "AllTaxa")
            optimalK_Evanno_AllTaxa[1] = optimalK_Evanno_i_taxon[i+1]
          else  
            optimalK_Evanno[i_taxon,1] = optimalK_Evanno_i_taxon[i+1]
        }
        if (!all_posterior_samples && nb_real==100 && thin==25 && nb_iter==1000 && burnin==500)
        {
          # For one group (MALV-III), there is no peak; manual selection:
          if (taxon == "MALV-III")
            optimalK_Evanno[i_taxon,1] = 7
        }
        
        # Evanno delta based on smoothed curves:
        optimalK_Evanno_i_taxon = coor_derivative2[sort.int(noSpline_Evanno_delta,decreasing=T,index.return = T)$ix]
        if (optimalK_Evanno_i_taxon[1] != coor_derivative2[1])
        {
          if (taxon == "AllTaxa")
            optimalK_Evanno_AllTaxa[2] = optimalK_Evanno_i_taxon[1]
          else
            optimalK_Evanno[i_taxon,2] = optimalK_Evanno_i_taxon[1]
        } else
        {
          i = 1
          while (optimalK_Evanno_i_taxon[i+1] == coor_derivative2[1]+i)
            i = i+1
          if (taxon == "AllTaxa")
            optimalK_Evanno_AllTaxa[2] = optimalK_Evanno_i_taxon[i+1]
          else 
            optimalK_Evanno[i_taxon,2] = optimalK_Evanno_i_taxon[i+1]
        }
        
        # Evanno delta based on raw curves:
        optimalK_noSpline_Evanno_i_taxon = coor_derivative2[sort.int(noSpline_Evanno_delta,decreasing=T,index.return = T)$ix]
        if (optimalK_noSpline_Evanno_i_taxon[1] != coor_derivative2[1])
        {
          if (taxon == "AllTaxa")
            optimalK_noSpline_Evanno_AllTaxa = optimalK_noSpline_Evanno_i_taxon[1]
          else
            optimalK_noSpline_Evanno[i_taxon] = optimalK_noSpline_Evanno_i_taxon[1]
        } else
        {
          i = 1
          while (optimalK_noSpline_Evanno_i_taxon[i+1] == coor_derivative2[1]+i)
            i = i+1
          if (taxon == "AllTaxa")
            optimalK_noSpline_Evanno_AllTaxa = optimalK_noSpline_Evanno_i_taxon[i+1]
          else 
            optimalK_noSpline_Evanno[i_taxon] = optimalK_noSpline_Evanno_i_taxon[i+1]
        }
        
        # # Selecting K as the lowest value of the splined 4th derivative (or the second lowest if the lowest is K = 4),
        # # except if the maximum of the splined llh occurs at a lower K value, in which case that value is selected
        # optimalK_derivative4_i_taxon = coor_derivative4[sort.int(derivative4[,1],index.return = T)$ix]
        # if (optimalK_derivative4_i_taxon[1] != 4)
        #   optimalK_derivative4[i_taxon,1] = optimalK_derivative4_i_taxon[1]
        # else
        #   optimalK_derivative4[i_taxon,1] = optimalK_derivative4_i_taxon[2]
        # if (coor_derivative4[sort.int(spline_mean$y[nb_topics_range %in% coor_derivative4],decreasing = T,index.return = T)$ix[1]] < optimalK_derivative4[i_taxon,1])
        #   optimalK_derivative4[i_taxon,1] = coor_derivative4[sort.int(spline_mean$y[nb_topics_range %in% coor_derivative4],decreasing = T,index.return = T)$ix[1]]
        # 
        # # Same for the median across realizations (instead of the mean across realizations) of the posterior-distributed mean llh:
        # optimalK_derivative4_i_taxon = coor_derivative4[sort.int(derivative4[,2],index.return = T)$ix]
        # if (optimalK_derivative4_i_taxon[1] != 4)
        #   optimalK_derivative4[i_taxon,2] = optimalK_derivative4_i_taxon[1]
        # else
        #   optimalK_derivative4[i_taxon,2] = optimalK_derivative4_i_taxon[2]
        # if (coor_derivative4[sort.int(spline_median$y[nb_topics_range %in% coor_derivative4],decreasing = T,index.return = T)$ix[1]] < optimalK_derivative4[i_taxon,2])
        #   optimalK_derivative4[i_taxon,2] = coor_derivative4[sort.int(spline_median$y[nb_topics_range %in% coor_derivative4],decreasing = T,index.return = T)$ix[1]]
        
        if (!all_posterior_samples && taxon == "MALV-V" && nb_real==100 && thin==25 && nb_iter==1000 && burnin==500)
        {
          optimalK_max.llh[i_taxon,1] = 16
          index = which(nb_topics_range == optimalK_max.llh[i_taxon,1])
        } else
        {
          index = sort.int(spline_mean$y,decreasing = T,index.return = T)$ix[1]
          if (taxon == "AllTaxa")
            optimalK_max.llh.allTaxa[1] = nb_topics_range[index]
          else
            optimalK_max.llh[i_taxon,1] = nb_topics_range[index]
        }
        i = 1
        while (i < length(nb_topics_range)+1 && spline_mean$y[i] + mean_median_sd_log_llh[index,3] < spline_mean$y[index])
          i = i+1
        if (taxon == "AllTaxa")
          optimalK_sd.max.llh.allTaxa[1] = nb_topics_range[i]
        else
          optimalK_sd.max.llh[i_taxon,1] = nb_topics_range[i]
        
        if (!all_posterior_samples && taxon == "MALV-V" && nb_real==100 && thin==25 && nb_iter==1000 && burnin==500)
        {
          optimalK_max.llh[i_taxon,2] = 16
          index = which(nb_topics_range == optimalK_max.llh[i_taxon,2])
        } else
        {
          index = sort.int(spline_median$y,decreasing = T,index.return = T)$ix[1]
          if (taxon == "AllTaxa")
            optimalK_max.llh.allTaxa[2] = nb_topics_range[index]
          else
            optimalK_max.llh[i_taxon,2] = nb_topics_range[index]
        }
        i = 1
        while (i < length(nb_topics_range)+1 && spline_median$y[i] + mean_median_sd_log_llh[index,3] < spline_median$y[index])
          i = i+1
        if (taxon == "AllTaxa")
          optimalK_sd.max.llh.allTaxa[2] = nb_topics_range[i]
        else
          optimalK_sd.max.llh[i_taxon,2] = nb_topics_range[i]
        
        # cor_cumul = vector(length = length(nb_topics_range)-1, mode = "numeric")
        # cor_cumul_median = vector(length = length(nb_topics_range)-1, mode = "numeric")
        # for (i_K in 1:(length(nb_topics_range)-1))
        # {
        #   # Cumulative correlation is computed strating from the end of the topic range and coming back towards smaller topic numbers:
        #   range_K = (length(nb_topics_range)-i_K):length(nb_topics_range)
        #   # Using the cumulative correlation of the mean across realizations:
        #   # cor_cumul[i_K] = cor(nb_topics_range[range_K],LLH_final0[1,range_K])
        #   cor_cumul[i_K] = cor(nb_topics_range[range_K],spline_mean$y[range_K])
        #   # Using the cumulative correlation of the median across realizations:
        #   # cor_cumul_median[i_K] = cor(nb_topics_range[range_K],apply(LLH_final[,range_K],2,median))
        #   cor_cumul_median[i_K] = cor(nb_topics_range[range_K],spline_median$y[range_K])
        # }
        # optimalK_posteriorLlh[1,i_taxon] = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)])[which(abs(cor_cumul[-1]) == max(abs(cor_cumul[-1])))]
        # optimalK_posteriorLlh[2,i_taxon] = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)])[which(abs(cor_cumul_median[-1]) == max(abs(cor_cumul_median[-1])))]
        # optimalK_posteriorLlh[3,i_taxon] = nb_topics_range[LLH_final0[1,] == max(LLH_final0[1,])]
        # optimalK_posteriorLlh[4,i_taxon] = nb_topics_range[apply(LLH_final,2,median) == max(apply(LLH_final,2,median))]
        
        # plot.posteriorLlh.cor.optimalK[[i_taxon]] = ggplot(data = data.frame(K = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)]),
        #                                                                      cor = abs(cor_cumul[-1]), cor_median = abs(cor_cumul_median[-1]))) +
        #   geom_line(aes(x = K, y = cor), size = 0.4) +
        #   geom_line(aes(x = K, y = cor_median), size = 0.4, col = "blue") +
        #   geom_vline(xintercept=optimalK_posteriorLlh[1,i_taxon], linetype= 2, size = 0.4) +
        #   geom_vline(xintercept=optimalK_posteriorLlh[2,i_taxon], linetype= 2, size = 0.4, col = "blue") +
        #   theme_bw() + 
        #   theme(axis.title=element_text(size=9),
        #         plot.title=element_text(hjust=0, size=15),
        #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
        #   ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        #   labs(x="Number K of assemblages", y="Posterior likelihood cumulative correlation")
        # 

        plot.posteriorLlh.errbar[[i_taxon]] = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range,rep,nrow(criterion))), llh = as.vector(criterion))) +
          geom_boxplot(aes(x=as.factor(K),y=llh), size = 0.4, outlier.size = 0.4, outlier.color = "darkgrey") +
          geom_point(data = data.frame(K = seq_along(nb_topics_range), llh = mean_median_sd_log_llh[,1]), aes(x = K, y = llh), size = 0.4) +
          geom_point(data = data.frame(K = seq_along(nb_topics_range), llh = mean_median_sd_log_llh[,2]), aes(x = K, y = llh), size = 0.4, col = "blue") +
          geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = spline_mean$y), aes(x = K, y = llh), size = 0.4) +
          geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = spline_median$y), aes(x = K, y = llh), size = 0.4, col = "blue") +
          geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_sd.max.llh.allTaxa[1],optimalK_sd.max.llh[i_taxon,1])), linetype = "longdash", size = 0.4) +
          # geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_sd.max.llh.allTaxa[2],optimalK_sd.max.llh[i_taxon,2])), linetype = "longdash", size = 0.4, col = "blue") +
          geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_max.llh.allTaxa[1],optimalK_max.llh[i_taxon,1])), linetype = "dotted", size = 0.4) +
          # geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_max.llh.allTaxa[2],optimalK_max.llh[i_taxon,2])), linetype = "dotted", size = 0.4, col = "blue") +
          geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_Evanno_AllTaxa[1],optimalK_Evanno[i_taxon,1])), linetype = "longdash", size = 0.4, col = "red") +
          geom_vline(xintercept = which(nb_topics_range == ifelse(taxon=="AllTaxa",optimalK_noSpline_Evanno_AllTaxa,optimalK_noSpline_Evanno[i_taxon])), linetype = "dotted", size = 0.4, col = "red") +
          theme_bw() +
          scale_x_discrete(breaks = seq(from = nb_topics_range[1], to = nb_topics_range[length(nb_topics_range)], by = 3)) +
          theme(axis.title=element_text(size=9),
                axis.text=element_text(size=9),
                plot.title=element_text(hjust=0, size=10),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
          labs(x="Number K of assemblages", y="Mean posterior-distributed log-likelihood")
        
        # plot.spline.posteriorLlh[[ii_taxon]] = ggplot(data = data.frame(K = nb_topics_range, llh1 = LLH_final0[1,], llh2 = apply(LLH_final,2,median),
        #                                                                 sp.llh1 = spline_mean$y, sp.llh2 = spline_median$y)) +
        #   geom_point(aes(x = K, y = llh1), size = 0.4) +
        #   geom_point(aes(x = K, y = llh2), size = 0.4, col = "blue") +
        #   geom_line(aes(x = K, y = sp.llh1), size = 0.4) +
        #   geom_line(aes(x = K, y = sp.llh2), size = 0.4, col = "blue") +
        #   geom_vline(xintercept=optimalK_derivative4[i_taxon,1], linetype = "longdash", size = 0.4) +
        #   geom_vline(xintercept=optimalK_derivative4[i_taxon,2], linetype = "longdash", size = 0.4, col = "blue") +
        #   geom_vline(xintercept=optimalK_Evanno[i_taxon], linetype = "longdash", size = 0.4, col = "red") +
        #   theme_bw() +
        #   theme(axis.title=element_text(size=9),
        #         plot.title=element_text(hjust=0, size=15),
        #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
        #   ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        #   labs(x="Number K of assemblages", y=paste0(spline_df,"-df-splined mean posterior-distributed log-likelihood"))
        # 
        plot.spline.posteriorLlh.derivative[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative,y1=derivative[,1],y2=derivative[,2])) +
          geom_line(aes(x,y1)) +
          geom_line(aes(x,y2),col="blue") +
          # geom_point(aes(x,y)) +
          # geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
          #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
          theme_bw() +
          ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Number K of assemblages", y=paste0("1st derivative of ",spline_df,"-df-splined log-likelihood"))
        
        # if (i_taxon == 14)
        #   derivative_Cnidaria14 = derivative
        
        # plot.spline.posteriorLlh.derivative2[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative2,y1=derivative2[,1],y2=derivative2[,2])) +
        #   geom_line(aes(x,y1)) +
        #   geom_line(aes(x,y2),col="blue") +
        #   # geom_point(aes(x,y)) +
        #   # geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
        #   #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
        #   theme_bw() +
        #   ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        #   theme(axis.title=element_text(size=9),
        #         plot.title=element_text(hjust=0, size=15),
        #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
        #   labs(x="Number K of assemblages", y=paste0("2nd derivative of ",spline_df,"-df-splined log-likelihood"))
        
        plot.spline.posteriorLlh.EvannoDelta[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative2,y=Evanno_delta)) +
          geom_line(aes(x,y)) +
          # geom_point(aes(x,y)) +
          geom_vline(xintercept = ifelse(taxon=="AllTaxa",optimalK_Evanno_AllTaxa[1],optimalK_Evanno[i_taxon,1]), linetype = "longdash", col = "red") +
          #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
          theme_bw() +
          ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Number K of assemblages", y=paste0("Evanno delta ",spline_df,"-df-splined log-likelihood"))
        
        plot.posteriorLlh.EvannoDelta[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative2,y=noSpline_Evanno_delta)) +
          geom_line(aes(x,y)) +
          # geom_point(aes(x,y)) +
          geom_vline(xintercept = ifelse(taxon=="AllTaxa",optimalK_noSpline_Evanno_AllTaxa,optimalK_noSpline_Evanno[i_taxon]), linetype = "longdash", col = "red") +
          #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
          theme_bw() +
          ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Number K of assemblages", y="Evanno delta log-likelihood")
        
        # plot.spline.posteriorLlh.derivative3[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative3,y1=derivative3[,1],y2=derivative3[,2])) +
        #   geom_line(aes(x,y1)) +
        #   geom_line(aes(x,y2),col="blue") +
        #   # geom_point(aes(x,y)) +
        #   # geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
        #   #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
        #   theme_bw() +
        #   ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        #   theme(axis.title=element_text(size=9),
        #         plot.title=element_text(hjust=0, size=15),
        #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
        #   labs(x="Number K of assemblages", y=paste0("3rd derivative of ",spline_df,"-df-splined log-likelihood"))
        # 
        # plot.spline.posteriorLlh.derivative4[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative4,y1=derivative4[,1],y2=derivative4[,2])) +
        #   geom_line(aes(x,y1)) +
        #   geom_line(aes(x,y2),col="blue") +
        #   # geom_point(aes(x,y)) +
        #   # geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
        #   #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
        #   theme_bw() +
        #   ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        #   theme(axis.title=element_text(size=9),
        #         plot.title=element_text(hjust=0, size=15),
        #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
        #   labs(x="Number K of assemblages", y=paste0("4th derivative of ",spline_df,"-df-splined log-likelihood"))
        
      } else 
      {
        # optimalK_posteriorLlh[,i_taxon] = rep(NA,4)
        optimalK_max.llh[i_taxon,] = rep(NA,2)
        optimalK_sd.max.llh[i_taxon,] = rep(NA,2)
        optimalK_Evanno[i_taxon,] = rep(NA,2)
        # plot.posteriorLlh.cor.optimalK[[i_taxon]] = NA
        # plot.posteriorLlh[[i_taxon]] = NA
        # plot.spline.posteriorLlh[[ii_taxon]] = NA
        plot.posteriorLlh.errbar[[ii_taxon]] = NA
        plot.spline.posteriorLlh.derivative[[ii_taxon]] = NA
        # plot.spline.posteriorLlh.derivative2[[ii_taxon]] = NA
        plot.spline.posteriorLlh.EvannoDelta[[ii_taxon]] = NA
        plot.posteriorLlh.EvannoDelta[[ii_taxon]] = NA
        # plot.spline.posteriorLlh.derivative3[[ii_taxon]] = NA
        # plot.spline.posteriorLlh.derivative4[[ii_taxon]] = NA
      }
    }
    
    ####### Computations based on VEM mpar = 1 ###############################
    if (optimalK_mpar)
    {
      mpar.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_alpha0.1_nb_topics2-35_nb_real10_em_tol1e-06_var_tol1e-08_occurrence/")
      setwd(mpar.folder_name)
      # load("AIC-llh.Rdata")
      # plot.K[[i_taxon]] = qplot(x = x, y = y, data=data.frame(x=nb_topics_range,y=LLH_final0[1,]), geom="point") +
      #   geom_errorbar(aes(ymax = y + LLH_final0[2,],
      #                     ymin = y - LLH_final0[2,]), size = 0.3, width = 0.5) +
      #   theme_bw() +
      #   ggtitle(paste(taxon,"-",c(430773,sort(diversity0, decreasing = T))[i_taxon],"OTUs")) +
      #   theme(axis.title=element_text(size=9),
      #         plot.title=element_text(hjust=0, size=15),
      #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
      #   labs(x="Number K of assemblages", y="Log-likelihood")
      
      load("AIC-llh.Rdata")
      llh = LLH_final0[1,]
      sd_llh = LLH_final0[2,]
      llh_allpoints = as.vector(LLH_final)
      nb_real = 10
      nb_topics_range_allpoints = unlist(lapply(nb_topics_range,rep,nb_real))
      
      # llh_movmean = vector(length = length(nb_topics_range), mode="numeric")
      # llh_movmean[1] = mean(llh[c(1,2)])
      # for (i in 2:(length(nb_topics_range)-1))
      #   llh_movmean[i] = mean(llh[(i-1):(i+1)])
      # llh_movmean[length(nb_topics_range)] = mean(llh[c(nb_topics_range-1,nb_topics_range)])
      
      derivative = vector(length = length(nb_topics_range)-1, mode="numeric")
      llh_ratio = vector(length = length(nb_topics_range)-1, mode="numeric")
      # derivative_movmean = vector(length = length(nb_topics_range)-1, mode="numeric")
      coor_derivative = vector(length = length(nb_topics_range)-1, mode="numeric")
      for (i in 2:length(nb_topics_range))
      {
        derivative[i-1] = (llh[i] - llh[i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
        if (i > 2)
          llh_ratio[i-1] = derivative[i-1]/derivative[i-2]
        # derivative_movmean[i-1] = (llh_movmean[i] - llh_movmean[i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
        coor_derivative[i-1] = (nb_topics_range[i] + nb_topics_range[i-1])/2
      }
      
      # Taking the minimum value of llh_ratio (i.e., the largest drop in the likelihood derivative) before the derivative becomes negative as indicating the optimal K value:
      if (derivative[1] < 0)
      {
        optimalK2[i_taxon] = nb_topics_range[1]
      } else 
      {
        optimalK2[i_taxon] = nb_topics_range[2]
        i = 3
        while (i < length(nb_topics_range) && derivative[i] > 0)
        {
          if (llh_ratio[i] < min(llh_ratio[2:(i-1)]) && mean(sd_llh[i:(i+1)]) < derivative[i] && mean(sd_llh[(i-1):i]) < derivative[i-1])
            optimalK2[i_taxon] = nb_topics_range[i]
          i = i+1
        }
      }
      
      # derivative2.data = readRDS("llh.derivative2.data.rds")
      # derivative2 = derivative2.data$derivative2
      # coor_derivative2 = derivative2.data$coor_derivative2
      
      derivative2 = vector(length = length(derivative)-1, mode="numeric")
      # derivative2_movmean = vector(length = length(derivative)-1, mode="numeric")
      coor_derivative2 = vector(length = length(derivative)-1, mode="numeric")
      for (i in 2:length(derivative))
      {
        derivative2[i-1] = (derivative[i] - derivative[i-1])/(coor_derivative[i] - coor_derivative[i-1])
        # derivative2_movmean[i-1] = (derivative_movmean[i] - derivative_movmean[i-1])/(coor_derivative[i] - coor_derivative[i-1])
        coor_derivative2[i-1] = (coor_derivative[i] + coor_derivative[i-1])/2
      }
      
      i = 1
      while (derivative2[i] < 0 && i < length(derivative2)+1)
        i = i+1
      if (i < length(derivative2)+1)
      {
        optimalK[i_taxon] = coor_derivative2[i]
      } else
        optimalK[i_taxon] = NA
      
      i = 2
      stop = F
      if (!is.na(optimalK[i_taxon]))
      {
        while (i < optimalK[i_taxon]+1 && !stop)
        {
          if (llh[i] < llh[i-1])
            stop = T
          i = i+1
        }
        increasing_llh[i_taxon] = !stop
      } else 
        increasing_llh[i_taxon] = NA
      
      # i = 1
      # while (derivative2_movmean[i] < 0 && i < length(derivative2_movmean)+1)
      #   i = i+1
      # if (i < length(derivative2_movmean)+1)
      # {
      #   optimalK_movmean[i_taxon] = coor_derivative2[i]
      # } else
      #   optimalK_movmean[i_taxon] = NA
      
      ######### Figures:
      ###################
      
      plot.llh[[ii_taxon]] = ggplot(data=data.frame(x=nb_topics_range,y=llh)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        # geom_errorbar(aes(x, ymax = y + sd_llh,
        #                   ymin = y - sd_llh), inherit.aes = T, width = 0.1, show.legend = F) +
        geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
        geom_vline(xintercept = optimalK2[i_taxon], linetype = "dashed", colour = "red") +
        #geom_text(mapping=aes(x=optimal_K, y=min(derivative2.data$derivative2), label=optimal_K), size=6, angle=0, vjust= 0, hjust= 2) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Log-likelihood")
      
      plot.llh.diff.ratio[[ii_taxon]] = ggplot(data=data.frame(x=nb_topics_range[-length(nb_topics_range)],y=llh_ratio)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        geom_vline(xintercept = optimalK2[i_taxon], linetype = "dashed") +
        #geom_text(mapping=aes(x=optimal_K, y=min(derivative2.data$derivative2), label=optimal_K), size=6, angle=0, vjust= 0, hjust= 2) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Log-likelihood difference ratio")
      
      plot.llh.allpoints[[ii_taxon]] = ggplot(data=data.frame(x=nb_topics_range_allpoints,y=llh_allpoints)) +
        geom_point(aes(x,y)) +
        geom_line(data = data.frame(x=nb_topics_range,y=llh), aes(x,y)) +
        geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
        geom_vline(xintercept = optimalK2[i_taxon], linetype = "dashed", colour = "red") +
        #geom_text(mapping=aes(x=optimal_K, y=min(derivative2.data$derivative2), label=optimal_K), size=6, angle=0, vjust= 0, hjust= 2) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Log-likelihood")
      
      # plot.llh.allpoints.movmean[[ii_taxon]] = ggplot(data=data.frame(x=nb_topics_range_allpoints,y=llh_allpoints)) +
      #   geom_point(aes(x,y)) +
      #   geom_line(data = data.frame(x=nb_topics_range,y=llh_movmean), aes(x,y)) +
      #   geom_vline(xintercept = optimalK_movmean[i_taxon], linetype = "dashed") +
      #   #geom_text(mapping=aes(x=optimal_K, y=min(derivative2.data$derivative2), label=optimal_K), size=6, angle=0, vjust= 0, hjust= 2) +
      #   theme_bw() +
      #   ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
      #   theme(axis.title=element_text(size=9),
      #         plot.title=element_text(hjust=0, size=15),
      #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
      #   labs(x="Number K of assemblages", y="Smoothed log-likelihood")
      
      plot.llh.derivative[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative,y=derivative)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
        #geom_text(mapping=aes(x=optimal_K, y=min(derivative2.data$derivative2), label=optimal_K), size=6, angle=0, vjust= 0, hjust= 2) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Derivative of log-likelihood")
      
      plot.K[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative2,y=derivative2)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        geom_vline(xintercept = optimalK[i_taxon], linetype = "dashed") +
        #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="2nd derivative of log-likelihood")
    }
    
    ####### Computations based on VEM mpar = 0 - 100 real ###############################
    if (optimalK_100r)
    {
      #nb_topics_range100r = 3:16
      if (!i_taxon %in% c(1,7))
        nb_topics_range100r = 3:20
      else 
        nb_topics_range100r = 3:16
      mean_sim = vector(length = length(nb_topics_range100r), mode = "numeric")
      sim_intercept = vector(length = length(nb_topics_range100r), mode = "numeric")
      llh_allpoints100r = list()
      max_llh100r = vector(length = length(nb_topics_range100r), mode = "numeric")
      llh100r = vector(length = length(nb_topics_range100r), mode = "numeric")
      sd_llh100r = vector(length = length(nb_topics_range100r), mode = "numeric")
      for (K in nb_topics_range100r)
      {
        K.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",K,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/")
        setwd(K.folder_name)
        
        stability_file = "Stability_assessment_samplewise_maxmatching/Stability_samplewise.rds"
        if (file.exists(stability_file))
        {
          stability_data.frame = readRDS(stability_file)
          mean_sim[K-2] = stability_data.frame$`Normalized ES`[1]
          sim_intercept[K-2] = stability_data.frame$`Normalized ES=f(llh) intercept`[1]
        } else 
        {
          mean_sim[K-2] = NA
          sim_intercept[K-2] = NA
        }
        
        ordered_real = readRDS("Ordered_realizations.rds")
        max_llh100r[K-2] = ordered_real$x[1]
        llh100r[K-2] = mean(ordered_real$x)
        sd_llh100r[K-2] = sd(ordered_real$x)
        llh_allpoints100r[[K-2]] = ordered_real$x
      }
      
      derivative100r = vector(length = length(nb_topics_range100r)-1, mode="numeric")
      derivative100r_max = vector(length = length(nb_topics_range100r)-1, mode="numeric")
      # llh_ratio100r = vector(length = length(nb_topics_range100r)-1, mode="numeric")
      # derivative_movmean = vector(length = length(nb_topics_range)-1, mode="numeric")
      coor_derivative100r = vector(length = length(nb_topics_range100r)-1, mode="numeric")
      for (i in 2:length(nb_topics_range100r))
      {
        derivative100r[i-1] = (llh100r[i] - llh100r[i-1])/(nb_topics_range100r[i] - nb_topics_range100r[i-1])
        derivative100r_max[i-1] = (max_llh100r[i] - max_llh100r[i-1])/(nb_topics_range100r[i] - nb_topics_range100r[i-1])
        # if (i > 2)
        #   llh_ratio100r[i-1] = derivative100r[i-1]/derivative100r[i-2]
        # derivative_movmean[i-1] = (llh_movmean[i] - llh_movmean[i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
        coor_derivative100r[i-1] = (nb_topics_range100r[i] + nb_topics_range100r[i-1])/2
      }
      
      derivative100r2 = vector(length = length(derivative100r)-1, mode="numeric")
      derivative100r2_max = vector(length = length(derivative100r)-1, mode="numeric")
      # derivative2_movmean = vector(length = length(derivative)-1, mode="numeric")
      coor_derivative100r2 = vector(length = length(derivative100r)-1, mode="numeric")
      for (i in 2:length(derivative100r))
      {
        derivative100r2[i-1] = (derivative100r[i] - derivative100r[i-1])/(coor_derivative100r[i] - coor_derivative100r[i-1])
        derivative100r2_max[i-1] = (derivative100r_max[i] - derivative100r_max[i-1])/(coor_derivative100r[i] - coor_derivative100r[i-1])
        # derivative2_movmean[i-1] = (derivative_movmean[i] - derivative_movmean[i-1])/(coor_derivative[i] - coor_derivative[i-1])
        coor_derivative100r2[i-1] = (coor_derivative100r[i] + coor_derivative100r[i-1])/2
      }
      
      i = 1
      while (derivative100r2[i] < 0 && i < length(derivative100r2)+1)
        i = i+1
      if (i < length(derivative100r2)+1)
      {
        optimalK100r[i_taxon] = coor_derivative100r2[i]
      } else
        optimalK100r[i_taxon] = NA
      
      i = 1
      while (derivative100r2_max[i] < 0 && i < length(derivative100r2_max)+1)
        i = i+1
      if (i < length(derivative100r2_max)+1)
      {
        optimalK100r_max[i_taxon] = coor_derivative100r2[i]
      } else
        optimalK100r_max[i_taxon] = NA
      
      i = 2
      stop = F
      if (!is.na(optimalK100r[i_taxon]))
      {
        while (nb_topics_range100r[i] < optimalK100r[i_taxon]+1 && !stop)
        {
          if (llh100r[i] < llh100r[i-1])
            stop = T
          i = i+1
        }
        increasing_llh100r[i_taxon] = !stop
      } else 
        increasing_llh100r[i_taxon] = NA
      
      i = 2
      stop = F
      if (!is.na(optimalK100r_max[i_taxon]))
      {
        while (nb_topics_range100r[i] < optimalK100r_max[i_taxon]+1 && !stop)
        {
          if (max_llh100r[i] < max_llh100r[i-1])
            stop = T
          i = i+1
        }
        increasing_llh100r_max[i_taxon] = !stop
      } else 
        increasing_llh100r_max[i_taxon] = NA
      
      ######### Figures:
      ###################
      plot.llh.derivative.100r[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative100r,y=derivative100r)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        geom_vline(xintercept = optimalK100r[i_taxon], linetype = "dashed") +
        #geom_text(mapping=aes(x=optimal_K, y=min(derivative2.data$derivative2), label=optimal_K), size=6, angle=0, vjust= 0, hjust= 2) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Derivative of log-likelihood")
      
      plot.K.100r[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative100r2,y=derivative100r2)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        geom_vline(xintercept = optimalK100r[i_taxon], linetype = "dashed") +
        #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="2nd derivative of log-likelihood")
      
      plot.max.llh.derivative.100r[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative100r,y=derivative100r_max)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        geom_vline(xintercept = optimalK100r_max[i_taxon], linetype = "dashed") +
        #geom_text(mapping=aes(x=optimal_K, y=min(derivative2.data$derivative2), label=optimal_K), size=6, angle=0, vjust= 0, hjust= 2) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Derivative of maximum log-likelihood")
      
      plot.K.100r.max[[ii_taxon]] = ggplot(data=data.frame(x=coor_derivative100r2,y=derivative100r2_max)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        geom_vline(xintercept = optimalK100r_max[i_taxon], linetype = "dashed") +
        #geom_text(aes(x=optimalK[i_taxon], y=min(derivative2.data$derivative2), label=optimalK[i_taxon], size=6, angle=0, vjust= 0, hjust= 0)) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="2nd derivative of maximum log-likelihood")
      
      plot.llh.100r[[ii_taxon]] = ggplot(data = data.frame(x = as.factor(unlist(lapply(nb_topics_range100r,rep,100))), y = unlist(llh_allpoints100r))) +
        geom_boxplot(aes(x,y)) +
        geom_vline(xintercept = optimalK100r[i_taxon], linetype = "dashed") +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Log-likelihood")
      
      plot.max.llh.100r[[ii_taxon]] = ggplot(data=data.frame(x=nb_topics_range100r,y=max_llh100r)) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y)) +
        geom_vline(xintercept = optimalK100r_max[i_taxon], linetype = "dashed") +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Maximum log-likelihood")
      
      plot.mean.sim.vs.K[[ii_taxon]] = ggplot(data = data.frame(K = nb_topics_range100r,mean_sim)) + geom_point(aes(K,mean_sim)) + geom_line(aes(K,mean_sim)) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Mean similarity across 100 real.")
      
      plot.sim.intercept.vs.K[[ii_taxon]] = ggplot(data = data.frame(K = nb_topics_range100r,sim_intercept)) + geom_point(aes(K,sim_intercept)) + geom_line(aes(K,sim_intercept)) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number K of assemblages", y="Similarity intercept for 100 real.")
    }
  }
  
  if (optimalK_mpar)
  {
    saveRDS(optimalK,paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    saveRDS(increasing_llh,paste0(results_folder,"/Increasing_llh_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  }
  
  if (optimalK_100r)
  {
    saveRDS(optimalK100r,paste0(results_folder,"/OptimalK_100r_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    saveRDS(increasing_llh100r,paste0(results_folder,"/Increasing_llh_100r_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    saveRDS(optimalK100r_max,paste0(results_folder,"/OptimalK_100rBest_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    saveRDS(increasing_llh100r_max,paste0(results_folder,"/Increasing_llh_100rBest_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    selected_groups_100r = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh100r
    saveRDS(selected_groups_100r,paste0(results_folder,"/selected_groups_100r_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  }
  
  # setwd(figure_folder)
  
  # ggsave(filename = "llh_vs_K_15groups_geombar.pdf", do.call("arrangeGrob", c(plot.K, nrow=4)),
  #        height = 1.5*10, width = 1.5*10)
  # ggsave(filename = "llh.derivative2_vs_K.pdf", do.call("arrangeGrob", c(plot.K, nrow=4)),
  #        height = 1.5*10, width = 1.5*10)
  
  # [!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]
  
  if (optimalK_mpar_prevalence.perplexity)
  {
    saveRDS(optimalK_prevalence.min.crossValid,
            paste0(results_folder,"/",short_marker,
                   if (!is.null(raref) && raref == "random.group.div") raref
                   else if (!is.null(raref)) paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)],collapse="") 
                   else "",
                   if (!is.null(reals)) paste0(".1-",reals) else "",
                   "_optimalK_prevalence.min.crossValid_Gibbs",fold_size,"sampleFolds",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin_mpar1,"_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"),
            version=2)
  }
  
  if (optimalK_assemblage_prevalence)
  {
    # saveRDS(list(optimalK_prevalence.min.crossValid.allTaxa,optimalK_prevalence.min.crossValid),paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs",fold_size,"sampleFolds",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin,"_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    saveRDS(list(optimalK_prevalence.min.crossValid1.allTaxa,optimalK_prevalence.min.crossValid1),paste0(results_folder,"/optimalK_prevalenceSUR-DCM.min.crossValid_Gibbs",fold_size,"sampleFolds",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin,"_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    spl = split(plot.prevalence[c(T,selected_groups) & !is.na(plot.prevalence)],
                (seq_along(plot.prevalence[c(T,selected_groups) & !is.na(plot.prevalence)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/OrderedTopicLogPrevalence_GibbsShortChainNoAverage10sampleFold_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_+AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.prevalence.SUR[c(T,selected_groups) & !is.na(plot.prevalence.SUR)],
                (seq_along(plot.prevalence.SUR[c(T,selected_groups) & !is.na(plot.prevalence.SUR)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/OrderedTopicLogPrevalence_SUR.prevalence.optimalK_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_+AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.occurrence[c(T,selected_groups) & !is.na(plot.occurrence)],
                (seq_along(plot.occurrence[c(T,selected_groups) & !is.na(plot.occurrence)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/OrderedTopic0.10Occurrence_GibbsShortChainNoAverage10sampleFold_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_+AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.spline.perplexity.prevalence[c(T,selected_groups) & !is.na(plot.spline.perplexity.prevalence)],
                (seq_along(plot.spline.perplexity.prevalence[c(T,selected_groups) & !is.na(plot.spline.perplexity.prevalence)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplined",fold_size,"sampleFoldPerplexity_errbar_vs_K_prevalenceCorrectedOptimalK_Gibbs",topic_range,"t_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.posteriorLlh.errbar.prevalence[c(T,selected_groups) & !is.na(plot.posteriorLlh.errbar.prevalence)], 
                (seq_along(plot.posteriorLlh.errbar.prevalence[c(T,selected_groups) & !is.na(plot.posteriorLlh.errbar.prevalence)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplinedPosteriorLlh",ifelse(all_posterior_samples,"_allSamples",""),"_errbar_vs_K_prevalenceCorrectedMinCrossValidOptimalK_Gibbs",nb_real,"r",topic_range,"t_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noFirstGroups.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
  }
  
  if (optimalK_mpar_posteriorLlh)
  {
    saveRDS(optimalK_sd.max.llh,paste0(results_folder,"/optimalK_sd.max.llh_Gibbs",nb_real,"r",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin,"_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    # spl = split(plot.posteriorLlh.cor.optimalK[!(taxo_groups %in% groups_to_remove) & diversity > 100][-1], (seq_along(plot.posteriorLlh.cor.optimalK[!(taxo_groups %in% groups_to_remove) & diversity > 100][-1])-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/PosteriorLlh_cumCorr_vs_K_Gibbs100r_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noDinophyceae.pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
    # 
    # spl = split(plot.posteriorLlh[!(taxo_groups %in% groups_to_remove) & diversity > 100][-1], (seq_along(plot.posteriorLlh[!(taxo_groups %in% groups_to_remove) & diversity > 100][-1])-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/PosteriorLlh_vs_K_Gibbs100r_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noDinophyceae.pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
    
    spl = split(plot.posteriorLlh.errbar[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.posteriorLlh.errbar)], 
                (seq_along(plot.posteriorLlh.errbar[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.posteriorLlh.errbar)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplinedPosteriorLlh",ifelse(all_posterior_samples,"_allSamples",""),"_vs_K_errbar_Gibbs",nb_real,"r",topic_range,"t_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noFirstGroups.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    # spl = split(plot.spline.posteriorLlh[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.spline.posteriorLlh)], 
    #             (seq_along(plot.spline.posteriorLlh[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.spline.posteriorLlh)])-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/",spline_df,"dfSplinedPosteriorLlh_vs_K_Gibbs100r",topic_range,"t_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noFirstGroups.pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
    
    spl = split(plot.spline.posteriorLlh.derivative[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.spline.posteriorLlh.derivative)], 
                (seq_along(plot.spline.posteriorLlh.derivative[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.spline.posteriorLlh.derivative)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplinedPosteriorLlh",ifelse(all_posterior_samples,"_allSamples",""),"_derivative_vs_K_Gibbs",nb_real,"r",topic_range,"t_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noDinophyceae.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    # spl = split(plot.spline.posteriorLlh.derivative2[!(taxo_groups %in% groups_to_remove) & diversity > 100][-1], (seq_along(plot.spline.posteriorLlh.derivative2[!(taxo_groups %in% groups_to_remove) & diversity > 100][-1])-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/",spline_df,"dfSplinedPosteriorLlh_derivative2_vs_K_Gibbs100r",topic_range,"t_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noDinophyceae.pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
    
    spl = split(plot.spline.posteriorLlh.EvannoDelta[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.spline.posteriorLlh.EvannoDelta)], 
                (seq_along(plot.spline.posteriorLlh.EvannoDelta[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.spline.posteriorLlh.EvannoDelta)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplinedPosteriorLlh",ifelse(all_posterior_samples,"_allSamples",""),"_EvannoDelta_vs_K_Gibbs",nb_real,"r",topic_range,"_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noDinophyceae.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.posteriorLlh.EvannoDelta[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.posteriorLlh.EvannoDelta)], 
                (seq_along(plot.posteriorLlh.EvannoDelta[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.posteriorLlh.EvannoDelta)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/PosteriorLlh",ifelse(all_posterior_samples,"_allSamples",""),"_EvannoDelta_vs_K_Gibbs",nb_real,"r",topic_range,"_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noDinophyceae.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    # spl = split(plot.spline.posteriorLlh.derivative3[!(taxo_groups %in% groups_to_remove) & diversity > 100][-1], (seq_along(plot.spline.posteriorLlh.derivative3[!(taxo_groups %in% groups_to_remove) & diversity > 100][-1])-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/",spline_df,"dfSplinedPosteriorLlh_derivative3_vs_K_Gibbs100r",topic_range,"_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noDinophyceae.pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
    # 
    # spl = split(plot.spline.posteriorLlh.derivative4[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.spline.posteriorLlh.derivative4)], 
    #             (seq_along(plot.spline.posteriorLlh.derivative4[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.spline.posteriorLlh.derivative4)])-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/",spline_df,"dfSplinedPosteriorLlh_derivative4_vs_K_Gibbs100r",topic_range,"_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1_noDinophyceae.pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
  }
  
  if (optimalK_mpar_perplexity)
  {
    if (is.null(reals))
    {
      saveRDS(optimalK_min.crossValid[,1],
              paste0(results_folder,"/",short_marker,
                     if (!is.null(raref) && raref == "random.group.div") paste0(raref,"_")
                     else if (!is.null(raref)) paste0(paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)],collapse=""),"_") 
                     else "",
                     "optimalK_min.crossValid_Gibbs",fold_size,"sampleFolds",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin_mpar1,
                     "_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"),
              version=2)
    } else
      saveRDS(optimalK_min.crossValid,
              paste0(results_folder,"/",short_marker,
                     if (!is.null(raref)) paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)],collapse="") else "",
                     if (!is.null(reals)) paste0(".1-",reals) else "", 
                     "_optimalK_min.crossValid_Gibbs",fold_size,"sampleFolds",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin_mpar1,
                     "_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"),
              version=2)
    
    # saveRDS(optimalK_min.crossValid,paste0(results_folder,"/optimalK_min.crossValid_Gibbs",fold_size,"sampleFolds",topic_range,"t_iter",nb_iter,"thin",thin,"burnin",burnin,"_averageOverSamples_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    # spl = split(plot.perplexity.cor.optimalK, (seq_along(plot.perplexity.cor.optimalK)-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/Perplexity_cumCorr_vs_K_Gibbs_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
    
    # spl = split(plot.perplexity[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.perplexity)],
    #             (seq_along(plot.perplexity[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(plot.perplexity)])-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/Perplexity_vs_K_Gibbs_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
    
    spl = split(plot.spline.perplexity[!is.na(plot.spline.perplexity)],
                (seq_along(plot.spline.perplexity[!is.na(plot.spline.perplexity)])-1) %/% 20)
    # spl = split(plot.spline.perplexity[c(T,selected_groups) & !is.na(plot.spline.perplexity)],
                # (seq_along(plot.spline.perplexity[c(T,selected_groups) & !is.na(plot.spline.perplexity)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplined",fold_size,"sampleFoldPerplexity_errbar_vs_K_Gibbs",topic_range,"t_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.spline.perplexity.corrCumul[!is.na(plot.spline.perplexity.corrCumul)],
                (seq_along(plot.spline.perplexity.corrCumul[!is.na(plot.spline.perplexity.corrCumul)])-1) %/% 20)
    # spl = split(plot.spline.perplexity.corrCumul[c(T,selected_groups) & !is.na(plot.spline.perplexity.corrCumul)],
                # (seq_along(plot.spline.perplexity.corrCumul[c(T,selected_groups) & !is.na(plot.spline.perplexity.corrCumul)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplined",fold_size,"sampleFoldPerplexity_errbar_vs_K_corrCumul_Gibbs",topic_range,"t_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.spline.perplexity.derivative[selected_groups & !is.na(plot.spline.perplexity.derivative)],
                (seq_along(plot.spline.perplexity.derivative[selected_groups & diversity > 100 & !is.na(plot.spline.perplexity.derivative)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplined",fold_size,"sampleFoldPerplexity_derivative_vs_K_Gibbs100r",topic_range,"t_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.spline.perplexity.derivative2[selected_groups & !is.na(plot.spline.perplexity.derivative2)],
                (seq_along(plot.spline.perplexity.derivative2[selected_groups & !is.na(plot.spline.perplexity.derivative2)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/",spline_df,"dfSplined",fold_size,"sampleFoldPerplexity_derivative2_vs_K_Gibbs100r",topic_range,"t_alpha0.1delta0.1_iter",nb_iter,"thin",thin,"burnin",burnin,"_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
  }
  
  spl = split(plot.mean.sim.vs.K, (seq_along(plot.mean.sim.vs.K)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf(paste0("Stability_vs_K_occ",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.sim.intercept.vs.K, (seq_along(plot.sim.intercept.vs.K)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf(paste0("Stability_intercept_vs_K_occ",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.llh.derivative, (seq_along(plot.llh.derivative)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("llh.derivative_vs_K_ggplot.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.llh.derivative.100r, (seq_along(plot.llh.derivative.100r)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("llh.derivative.100r_vs_K_ggplot.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.max.llh.derivative.100r, (seq_along(plot.max.llh.derivative.100r)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("max.llh.derivative.100r_vs_K_ggplot.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  ############
  spl = split(plot.llh, (seq_along(plot.llh)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  # pdf("llh_vs_K_ggplot_errbar.pdf",height = 1.5*10, width = 1.5*10)
  pdf("llh_vs_K_ggplot_optimalK.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.llh.allpoints, (seq_along(plot.llh.allpoints)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("llh_vs_K_ggplot_allpoints_optimalK.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  ############
  
  spl = split(plot.llh.100r, (seq_along(plot.llh.100r)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("llh.100r_vs_K_ggplot_optimalK.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.max.llh.100r, (seq_along(plot.max.llh.100r)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("max.llh.100r_vs_K_ggplot_optimalK.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  # spl = split(plot.llh.allpoints.movmean, (seq_along(plot.llh.allpoints.movmean)-1) %/% 20)
  # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  # pdf("llh_vs_K_ggplot_allpoints_selected_movmean.pdf",height = 1.5*10, width = 1.5*10)
  # print(ppl)
  # dev.off()
  
  spl = split(plot.K, (seq_along(plot.K)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("llh.derivative2_vs_K_ggplot.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.K.100r, (seq_along(plot.K.100r)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("llh.derivative2.100r_vs_K_ggplot.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.K.100r.max, (seq_along(plot.K.100r.max)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("llh.derivative2.100r.max_vs_K_ggplot.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  spl = split(plot.llh.diff.ratio, (seq_along(plot.llh.diff.ratio)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf("llh.diff.ratio_vs_K_ggplot.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  
  # Comparing optimalK Arctic vs. noArctic:
  #################
  if (!noArcticNoBiomark)
  {
    taxo_groups_noArctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs_noArcticNoBiomark_noLagoon.rds"))
    optimalK_noArctic = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs_noArcticNoBiomark_noLagoon.rds"))
    names(optimalK_noArctic) = taxo_groups_noArctic
    plot.K.vs.K.arctic = ggplot(data = data.frame(x = optimalK[selected_groups], y = optimalK_noArctic[taxo_groups[selected_groups][taxo_groups[selected_groups] %in% taxo_groups_noArctic]])) + 
      geom_point(aes(x,y)) + geom_abline(slope = 1, intercept = 0) +
      ylab("Optimal K no Arctic") + xlab("Optimal K Arctic")
    pdf("OptimalK_vs_OptimalK_Arctic_selected.pdf")
    print(plot.K.vs.K.arctic)
    dev.off()
    
    optimalK_ratio = optimalK[selected_groups]/optimalK_noArctic[taxo_groups[selected_groups][taxo_groups[selected_groups] %in% taxo_groups_noArctic]]
    pdf("OptimalK_vs_OptimalK_Arctic_hist_selected.pdf")
    hist(optimalK_ratio,breaks = 10,xlab="Arctic to no Arctic optimal K ratio")
    dev.off()
    
    pdf("OptimalK_vs_OptimalK_Arctic_hist_20first.pdf")
    hist(optimalK_ratio[1:20],xlab="Arctic to no Arctic optimal K ratio")
    dev.off()
    
    pdf("OptimalK_Arctic_hist_selected.pdf")
    hist(optimalK,breaks = 10,xlab="Arctic optimal K")
    dev.off()
  }
  #######################
  
  # Computing optimal K for AllTaxa:
  ################
  data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
  nb_topics_range100r = 3:14
  mean_sim = vector(length = length(nb_topics_range100r), mode = "numeric")
  sim_intercept = vector(length = length(nb_topics_range100r), mode = "numeric")
  llh_allpoints100r = list()
  max_llh100r = vector(length = length(nb_topics_range100r), mode = "numeric")
  llh100r = vector(length = length(nb_topics_range100r), mode = "numeric")
  sd_llh100r = vector(length = length(nb_topics_range100r), mode = "numeric")
  for (K in nb_topics_range100r)
  {
    # K.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",K,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/")
    # K.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",K,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence_seededInit/")
    # K.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_topics",K,"_nb_iter2000_nb_real100_best_keep_occurrence/")
    # K.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha50:K_delta0.1_topics",K,"_nb_iter2000_nb_real100_best_keep_occurrence/")
    K.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta0.1_nb_topics",K,"_nb_iter2000_nb_real100_occurrence/")
    # K.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha50:K_delta0.1_nb_topics",K,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/")
    # K.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",K,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/")
    setwd(K.folder_name)
    
    stability_file = "Stability_assessment_samplewise_maxmatching/Stability_samplewise.rds"
    if (file.exists(stability_file))
    {
      stability_data.frame = readRDS(stability_file)
      mean_sim[K-2] = stability_data.frame$`Normalized ES`[1]
      sim_intercept[K-2] = stability_data.frame$`Normalized ES=f(llh) intercept`[1]
    } else 
    {
      mean_sim[K-2] = NA
      sim_intercept[K-2] = NA
    }
    
    ordered_real = readRDS("Ordered_realizations.rds")
    max_llh100r[K-2] = ordered_real$x[1]
    llh100r[K-2] = mean(ordered_real$x)
    sd_llh100r[K-2] = sd(ordered_real$x)
    llh_allpoints100r[[K-2]] = ordered_real$x
  }
  
  derivative100r = vector(length = length(nb_topics_range100r)-1, mode="numeric")
  derivative100r_max = vector(length = length(nb_topics_range100r)-1, mode="numeric")
  # llh_ratio100r = vector(length = length(nb_topics_range100r)-1, mode="numeric")
  # derivative_movmean = vector(length = length(nb_topics_range)-1, mode="numeric")
  coor_derivative100r = vector(length = length(nb_topics_range100r)-1, mode="numeric")
  for (i in 2:length(nb_topics_range100r))
  {
    derivative100r[i-1] = (llh100r[i] - llh100r[i-1])/(nb_topics_range100r[i] - nb_topics_range100r[i-1])
    derivative100r_max[i-1] = (max_llh100r[i] - max_llh100r[i-1])/(nb_topics_range100r[i] - nb_topics_range100r[i-1])
    # if (i > 2)
    #   llh_ratio100r[i-1] = derivative100r[i-1]/derivative100r[i-2]
    # derivative_movmean[i-1] = (llh_movmean[i] - llh_movmean[i-1])/(nb_topics_range[i] - nb_topics_range[i-1])
    coor_derivative100r[i-1] = (nb_topics_range100r[i] + nb_topics_range100r[i-1])/2
  }
  
  derivative100r2 = vector(length = length(derivative100r)-1, mode="numeric")
  derivative100r2_max = vector(length = length(derivative100r)-1, mode="numeric")
  # derivative2_movmean = vector(length = length(derivative)-1, mode="numeric")
  coor_derivative100r2 = vector(length = length(derivative100r)-1, mode="numeric")
  for (i in 2:length(derivative100r))
  {
    derivative100r2[i-1] = (derivative100r[i] - derivative100r[i-1])/(coor_derivative100r[i] - coor_derivative100r[i-1])
    derivative100r2_max[i-1] = (derivative100r_max[i] - derivative100r_max[i-1])/(coor_derivative100r[i] - coor_derivative100r[i-1])
    # derivative2_movmean[i-1] = (derivative_movmean[i] - derivative_movmean[i-1])/(coor_derivative[i] - coor_derivative[i-1])
    coor_derivative100r2[i-1] = (coor_derivative100r[i] + coor_derivative100r[i-1])/2
  }
  
  i = 1
  while (derivative100r2[i] < 0 && i < length(derivative100r2)+1)
    i = i+1
  if (i < length(derivative100r2)+1)
  {
    optimalK100r = coor_derivative100r2[i]
  } else
    optimalK100r = NA
  
  i = 1
  while (derivative100r2_max[i] < 0 && i < length(derivative100r2_max)+1)
    i = i+1
  if (i < length(derivative100r2_max)+1)
  {
    optimalK100r_max = coor_derivative100r2[i]
  } else
    optimalK100r_max = NA

  # pdf(paste0("Stability_vs_K_AllTaxa_occ",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  #pdf(paste0("Stability_vs_K_AllTaxa_occ",noArcticNoBiomark_insert,noLagoon_insert,"_seededInit.pdf"))
  # pdf(paste0("Stability_vs_K_AllTaxa_occ_Gibbs_comparison",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  # print(plot.mean.sim.vs.K)
  # print(plot.sim.intercept.vs.K)
  # dev.off()
  
  # plot.llh.100r = ggplot(data = data.frame(K = as.factor(unlist(lapply(nb_topics_range100r,rep,100))), llh = unlist(llh_allpoints100r), mean_llh = unlist(lapply(llh100r,rep,100)))) + 
  #   geom_boxplot(aes(K,llh)) + geom_line(aes(K,mean_llh)) + geom_vline(xintercept = optimalK100r, linetype = "dashed") + 
  plot.llh.100r = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range100r,rep,100)), llh = unlist(llh_allpoints100r), mean_llh = unlist(lapply(llh100r,rep,100)))) +
    geom_boxplot(aes(x=as.factor(K),y=llh)) + 
    # geom_line(aes(x=c(levels(as.factor(K)),rep(NA,length(K)-length(levels(as.factor(K))))),y=c(levels(as.factor(mean_llh)),rep(NA,length(K)-length(levels(as.factor(K))))))) + 
    # geom_line(aes(x=c(1:length(levels(as.factor(K))),rep(NA,length(K)-length(levels(as.factor(K))))),y=c(levels(as.factor(mean_llh)),rep(NA,length(K)-length(levels(as.factor(K))))))) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r), aes(x = K,y = llh)) +
    geom_vline(aes(xintercept = which(levels(as.factor(K)) == optimalK100r)), linetype = "dashed") +
    theme_bw() + ggtitle("Log-likelihood vs. K") +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="Log-likelihood 100 real.")
  plot.max.llh.100r = ggplot(data = data.frame(K = nb_topics_range100r, llh = max_llh100r)) + 
    geom_point(aes(K,llh)) + geom_line(aes(K,llh)) + geom_vline(xintercept = optimalK100r_max, linetype = "dashed") +
    theme_bw() + ggtitle("Max. log-likelihood vs. K") +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="Maximum log-likelihood across 100 real.")
  plot.llh.derivative.100r = ggplot(data = data.frame(K = coor_derivative100r, llh = derivative100r)) + 
    geom_point(aes(K,llh)) + geom_line(aes(K,llh)) + geom_vline(xintercept = optimalK100r, linetype = "dashed") +
    theme_bw() + ggtitle("Log-likelihood 1st derivative vs. K") +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="1st derivative of \nmean log-likelihood across 100 real.")
  plot.max.llh.derivative.100r = ggplot(data = data.frame(K = coor_derivative100r, llh = derivative100r_max)) + 
    geom_point(aes(K,llh)) + geom_line(aes(K,llh)) + geom_vline(xintercept = optimalK100r_max, linetype = "dashed") +
    theme_bw() + ggtitle("Max. log-likelihood 1st derivative vs. K") +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="1st derivative of \nmaximum log-likelihood across 100 real.")
  plot.K.100r = ggplot(data = data.frame(K = coor_derivative100r2, llh = derivative100r2)) + 
    geom_point(aes(K,llh)) + geom_line(aes(K,llh)) + geom_vline(xintercept = optimalK100r, linetype = "dashed") + 
    theme_bw() + ggtitle("Log-likelihood 2nd derivative vs. K") +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="2nd derivative of \nmean log-likelihood across 100 real.")
  plot.K.100r.max = ggplot(data = data.frame(K = coor_derivative100r2, llh = derivative100r2_max)) + 
    geom_point(aes(K,llh)) + geom_line(aes(K,llh)) + geom_vline(xintercept = optimalK100r_max, linetype = "dashed") +
    theme_bw() + ggtitle("Max. log-likelihood 2nd derivative vs. K") +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="2nd derivative of \nmaximum log-likelihood across 100 real.")
    
  # setwd(figure_folder)
  
  # ggsave(filename = paste0("llh.100r_vs_K_AllTaxa_occ",noArcticNoBiomark_insert,noLagoon_insert,".pdf"), 
  # ggsave(filename = paste0("llh.100r_vs_K_AllTaxa_occ",noArcticNoBiomark_insert,noLagoon_insert,"_seededInit.pdf"), 
  # ggsave(filename = paste0("llh.100r_vs_K_AllTaxa_occ_Gibbs_best",noArcticNoBiomark_insert,noLagoon_insert,".pdf"), 
  # ggsave(filename = paste0("llh.100r_vs_K_AllTaxa_occ_Gibbs_chain.end_alpha0.05/K",noArcticNoBiomark_insert,noLagoon_insert,".pdf"), 
  ggsave(filename = "/test.pdf", 
         do.call("arrangeGrob", c(list(plot.llh.100r,plot.max.llh.100r,plot.llh.derivative.100r,plot.max.llh.derivative.100r,plot.K.100r,plot.K.100r.max), nrow = 3, ncol = 2)),
         height = 1.5*10/4*3, width = 1.5*10/2)
  
  # pdf(paste0("llh.100r_vs_K_AllTaxa_occ",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10/4*3, width = 1.5*10/2)
  # ppl = marrangeGrob(grobs = list(plot.llh.100r,plot.max.llh.100r,plot.llh.derivative.100r,plot.max.llh.derivative.100r,plot.K.100r,plot.K.100r.max), nrow = 3, ncol = 2)
  # print(ppl)
  # dev.off()
  
  # print(plot.llh.100r)
  # print(plot.max.llh.100r)
  # print(plot.llh.derivative.100r)
  # print(plot.max.llh.derivative.100r)
  # print(plot.K.100r)
  # print(plot.K.100r.max)
  # dev.off()
  ########################
  
  # Comparing different inference approaches:
  #################
  library(sirt)
  library(ggplot2)
  library(gridExtra)
  data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
  # data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_Bacillariophyta",noArcticNoBiomark_insert,noLagoon_insert)
  nb_topics_range100r = 3:20
  K.folder_name_cases = c(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics_range100r,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha50:K_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter2000_nb_real100_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter2000_nb_real100_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter2000_nb_real100_occurrence/"),
                          # paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta",9.4-nb_topics_range100r/5,"_nb_topics",nb_topics_range100r,"_nb_iter2000_nb_real100_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta0.5_nb_topics",nb_topics_range100r,"_nb_iter2000_nb_real100_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha1_delta1_nb_topics",nb_topics_range100r,"_nb_iter2000_nb_real100_occurrence/"))
                          # paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha50:K_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/"),
                          # paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/"),
                          # paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/"))
  inference_method = c("VEM","Gibbs\n chain end sample\ndelta = 0.1, alpha = 50/K","Gibbs\n chain end sample\ndelta = 0.1, alpha = 0.1",
                       # "Gibbs\n chain end sample\ndelta = 0.1, alpha = 0.05/K","Gibbs\n chain end sample\ndelta = 9.4-K/5, alpha = 0.05/K","Gibbs\n chain end sample\ndelta = 1, alpha = 1")
                       "Gibbs\n chain end sample\ndelta = 0.1, alpha = 0.05/K","Gibbs\n chain end sample\ndelta = 0.5, alpha = 0.05/K","Gibbs\n chain end sample\ndelta = 1, alpha = 1")
                                        # "Gibbs\n best sample\n alpha = 50/K","Gibbs\n best sample\n alpha = 0.1","Gibbs\n best sample\n alpha = 0.05/K")
  mean_sim = matrix(nrow = length(nb_topics_range100r), ncol = 6, dimnames = list(nb_topics_range100r,inference_method), data=0)
  sim_intercept = matrix(nrow = length(nb_topics_range100r), ncol = 6, dimnames = list(nb_topics_range100r,inference_method), data=0)
  max_llh100r = matrix(nrow = length(nb_topics_range100r), ncol = 6, dimnames = list(nb_topics_range100r,inference_method), data=0)
  llh100r = matrix(nrow = length(nb_topics_range100r), ncol = 6, dimnames = list(nb_topics_range100r,inference_method), data=0)
  AIC100r = matrix(nrow = length(nb_topics_range100r), ncol = 6, dimnames = list(nb_topics_range100r,inference_method), data=0)
  sd_llh100r = matrix(nrow = length(nb_topics_range100r), ncol = 6, dimnames = list(nb_topics_range100r,inference_method), data=0)
  est_delta = list()
  load(paste0(data.folder_name,"/data2m.Rdata")) 
  data2m[data2m > 0] = 1
  sum_data2m = sum(data2m)
  llh_allpoints100r = list()
  AIC_allpoints100r = list()
  for (i_case in 1:6)
  {
    llh_allpoints100r[[i_case]] = list()
    AIC_allpoints100r[[i_case]] = list()
    for (K in nb_topics_range100r)
    {
      K.folder_name = K.folder_name_cases[which(nb_topics_range100r == K) + (i_case-1)*length(nb_topics_range100r)]
      if (file.exists(K.folder_name))
      {
        if (i_case == 1)
        {
          if (file.exists(paste0(K.folder_name,"1st_best_realization/assemblage_composition.rds")))
          {
            assemblage_composition = readRDS(paste0(K.folder_name,"1st_best_realization/assemblage_composition.rds"))
            # assemblage_composition[,1:K][assemblage_composition[,1:K] < 1/sum_data2m] = 0
            # assemblage_composition = assemblage_composition[1:max(apply(assemblage_composition,2,function(g) length(which(g > 0))))]
            # est_delta[K-2,1:K] = Compositional::diri.est(as.matrix(assemblage_composition[,1:K]), type = "mle")
            est_delta[[K-2]] = sirt::dirichlet.mle(assemblage_composition[,1:K])$alpha
          } else 
            est_delta[[K-2]] = NA
        }
        
        stability_file = paste0(K.folder_name,"Stability_assessment_samplewise_maxmatching/Stability_samplewise.rds")
        if (file.exists(stability_file))
        {
          stability_data.frame = readRDS(stability_file)
          mean_sim[K-2,i_case] = stability_data.frame$`Normalized ES`[1]
          sim_intercept[K-2,i_case] = stability_data.frame$`Normalized ES=f(llh) intercept`[1]
        } else 
        {
          mean_sim[K-2,i_case] = NA
          sim_intercept[K-2,i_case] = NA
        }
        
        ordered_real_file = paste0(K.folder_name,"Ordered_realizations.rds")
        if (file.exists(ordered_real_file))
        {
          ordered_real = readRDS(ordered_real_file)
          max_llh100r[K-2,i_case] = ordered_real$x[1]
          llh100r[K-2,i_case] = mean(ordered_real$x)
          sd_llh100r[K-2,i_case] = sd(ordered_real$x)
          llh_allpoints100r[[i_case]][[K-2]] = ordered_real$x
          if (i_case == 1)
          {
            AIC_allpoints100r[[i_case]][[K-2]] = 2*(K*(nrow(data2m)-1) + 1 - ordered_real$x)
          } else
            AIC_allpoints100r[[i_case]][[K-2]] = -2*ordered_real$x
          AIC100r[K-2,i_case] = mean(AIC_allpoints100r[[i_case]][[K-2]])
        } else
        {
          max_llh100r[K-2,i_case] = NA
          llh100r[K-2,i_case] = NA
          sd_llh100r[K-2,i_case] = NA
          llh_allpoints100r[[i_case]][[K-2]] = rep(NA,100)
        }
      } else
      {
        mean_sim[K-2,i_case] = NA
        sim_intercept[K-2,i_case] = NA
        max_llh100r[K-2,i_case] = NA
        llh100r[K-2,i_case] = NA
        sd_llh100r[K-2,i_case] = NA
        AIC100r[K-2,i_case] = NA
        llh_allpoints100r[[i_case]][[K-2]] = rep(NA,100)
        AIC_allpoints100r[[i_case]][[K-2]] = rep(NA,100)
      }
    }
  }
  
  plot.mean.sim.vs.K = ggplot(data = data.frame(K = nb_topics_range100r, mean_sim)) +
    geom_point(aes(K,mean_sim[,1],colour=inference_method[1])) + geom_line(aes(K,mean_sim[,1],colour=inference_method[1])) +
    geom_point(aes(K,mean_sim[,2],colour=inference_method[2])) + geom_line(aes(K,mean_sim[,2],colour=inference_method[2])) +
    geom_point(aes(K,mean_sim[,3],colour=inference_method[3])) + geom_line(aes(K,mean_sim[,3],colour=inference_method[3])) +
    geom_point(aes(K,mean_sim[,4],colour=inference_method[4])) + geom_line(aes(K,mean_sim[,4],colour=inference_method[4])) +
    geom_point(aes(K,mean_sim[,5],colour=inference_method[5])) + geom_line(aes(K,mean_sim[,5],colour=inference_method[5])) +
    geom_point(aes(K,mean_sim[,6],colour=inference_method[6])) + geom_line(aes(K,mean_sim[,6],colour=inference_method[6])) +
    # geom_point(aes(K,mean_sim[,7],colour=inference_method[7])) + geom_line(aes(K,mean_sim[,7],colour=inference_method[7])) +
    theme_bw() +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of community types", y="Stability across 100 real.")
  
  plot.sim.intercept.vs.K = ggplot(data = data.frame(K = nb_topics_range100r,sim_intercept)) +
    geom_point(aes(K,sim_intercept[,1],colour=inference_method[1])) + geom_line(aes(K,sim_intercept[,1],colour=inference_method[1])) +
    geom_point(aes(K,sim_intercept[,2],colour=inference_method[2])) + geom_line(aes(K,sim_intercept[,2],colour=inference_method[2])) +
    geom_point(aes(K,sim_intercept[,3],colour=inference_method[3])) + geom_line(aes(K,sim_intercept[,3],colour=inference_method[3])) +
    geom_point(aes(K,sim_intercept[,4],colour=inference_method[4])) + geom_line(aes(K,sim_intercept[,4],colour=inference_method[4])) +
    geom_point(aes(K,sim_intercept[,5],colour=inference_method[5])) + geom_line(aes(K,sim_intercept[,5],colour=inference_method[5])) +
    geom_point(aes(K,sim_intercept[,6],colour=inference_method[6])) + geom_line(aes(K,sim_intercept[,6],colour=inference_method[6])) +
    # geom_point(aes(K,sim_intercept[,7],colour=inference_method[7])) + geom_line(aes(K,sim_intercept[,7],colour=inference_method[7])) +
    theme_bw() +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of community types", y="Stability intercept across 100 real.")
  
  plot.llh.100r = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range100r,rep,100)), 
                                           llh.1 = unlist(llh_allpoints100r[[1]]), 
                                           llh.2 = unlist(llh_allpoints100r[[2]]), 
                                           llh.3 = unlist(llh_allpoints100r[[3]]), 
                                           llh.4 = unlist(llh_allpoints100r[[4]]), 
                                           llh.5 = unlist(llh_allpoints100r[[5]]),
                                           llh.6 = unlist(llh_allpoints100r[[6]]))) +
                                           # llh.7 = unlist(llh_allpoints100r[[7]]))) +
    geom_boxplot(aes(x=as.factor(K),y=llh.1, colour=inference_method[1])) + 
    geom_boxplot(aes(x=as.factor(K),y=llh.2, colour=inference_method[2])) + 
    geom_boxplot(aes(x=as.factor(K),y=llh.3, colour=inference_method[3])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.4, colour=inference_method[4])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.5, colour=inference_method[5])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.6, colour=inference_method[6])) +
    # geom_boxplot(aes(x=as.factor(K),y=llh.7, colour=inference_method[7])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,1]), aes(x = K, y = llh, colour=inference_method[1])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,2]), aes(x = K, y = llh, colour=inference_method[2])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,3]), aes(x = K, y = llh, colour=inference_method[3])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,4]), aes(x = K, y = llh, colour=inference_method[4])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,5]), aes(x = K, y = llh, colour=inference_method[5])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,6]), aes(x = K, y = llh, colour=inference_method[6])) +
    # geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,7]), aes(x = K, y = llh, colour=inference_method[7])) +
    theme_bw() + 
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="Log-likelihood 100 real.")
  
  plot.max.llh.100r = ggplot(data = data.frame(K = nb_topics_range100r, max_llh100r)) + 
    geom_point(aes(K,max_llh100r[,1],colour=inference_method[1]),inherit.aes = T) + geom_line(aes(K,max_llh100r[,1],colour=inference_method[1]),inherit.aes = T) +
    geom_point(aes(K,max_llh100r[,2],colour=inference_method[2]),inherit.aes = T) + geom_line(aes(K,max_llh100r[,2],colour=inference_method[2]),inherit.aes = T) +
    geom_point(aes(K,max_llh100r[,3],colour=inference_method[3]),inherit.aes = T) + geom_line(aes(K,max_llh100r[,3],colour=inference_method[3]),inherit.aes = T) +
    geom_point(aes(K,max_llh100r[,4],colour=inference_method[4]),inherit.aes = T) + geom_line(aes(K,max_llh100r[,4],colour=inference_method[4]),inherit.aes = T) +
    geom_point(aes(K,max_llh100r[,5],colour=inference_method[5]),inherit.aes = T) + geom_line(aes(K,max_llh100r[,5],colour=inference_method[5]),inherit.aes = T) +
    geom_point(aes(K,max_llh100r[,6],colour=inference_method[6]),inherit.aes = T) + geom_line(aes(K,max_llh100r[,6],colour=inference_method[6]),inherit.aes = T) +
    # geom_point(aes(K,max_llh100r[,7],colour=inference_method[7]),inherit.aes = T) + geom_line(aes(K,max_llh100r[,7],colour=inference_method[7]),inherit.aes = T) +
    theme_bw() + 
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of community types", y="Maximum log-likelihood across 100 real.")
  
  plot.AIC.100r = ggplot(data = data.frame(K = unlist(lapply(nb_topics_range100r,rep,100)), 
                                           llh.1 = unlist(AIC_allpoints100r[[1]]), 
                                           llh.2 = unlist(AIC_allpoints100r[[2]]), 
                                           llh.3 = unlist(AIC_allpoints100r[[3]]), 
                                           llh.4 = unlist(AIC_allpoints100r[[4]]), 
                                           llh.5 = unlist(AIC_allpoints100r[[5]]),
                                           llh.6 = unlist(AIC_allpoints100r[[6]]))) +
    # llh.7 = unlist(llh_allpoints100r[[7]]))) +
    geom_boxplot(aes(x=as.factor(K),y=llh.1, colour=inference_method[1])) + 
    geom_boxplot(aes(x=as.factor(K),y=llh.2, colour=inference_method[2])) + 
    geom_boxplot(aes(x=as.factor(K),y=llh.3, colour=inference_method[3])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.4, colour=inference_method[4])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.5, colour=inference_method[5])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.6, colour=inference_method[6])) +
    # geom_boxplot(aes(x=as.factor(K),y=llh.7, colour=inference_method[7])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = AIC100r[,1]), aes(x = K, y = llh, colour=inference_method[1])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = AIC100r[,2]), aes(x = K, y = llh, colour=inference_method[2])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = AIC100r[,3]), aes(x = K, y = llh, colour=inference_method[3])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = AIC100r[,4]), aes(x = K, y = llh, colour=inference_method[4])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = AIC100r[,5]), aes(x = K, y = llh, colour=inference_method[5])) +
    geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = AIC100r[,6]), aes(x = K, y = llh, colour=inference_method[6])) +
    # geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,7]), aes(x = K, y = llh, colour=inference_method[7])) +
    theme_bw() + 
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="AIC 100 real.")
  
  # pdf(paste0(figure_folder,"/Stability-llh_vs_K_AllTaxa_occ_Gibbs_comparison_woBest_deltaVariation",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  pdf(paste0(figure_folder,"/Stability-llh_vs_K_Bacillariophyta_occ_Gibbs_comparison_woBest_deltaVariation",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  print(plot.mean.sim.vs.K)
  print(plot.sim.intercept.vs.K)
  print(plot.llh.100r)
  print(plot.max.llh.100r)
  print(plot.AIC.100r)
  dev.off()
  ##########################
  
  # Comparing different inference approaches - perplexity:
  ###############
  library(sirt)
  library(ggplot2)
  data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
  # data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_Bacillariophyta",noArcticNoBiomark_insert,noLagoon_insert)
  K.folder_name_cases = c(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_alpha0.1_nb_topics2-18_post-predictive-cross-valid_fold_size10_em_tol1e-06_var_tol1e-08_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha50:K_delta0.1_nb_topics2-20_post-predictive-cross-valid_nb_iter1000_fold_size10_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics2-20_post-predictive-cross-valid_nb_iter2000_fold_size10_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta0.1_nb_topics2-20_post-predictive-cross-valid_nb_iter1000_fold_size10_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha1_delta1_nb_topics2-20_post-predictive-cross-valid_nb_iter1000_fold_size10_occurrence/"),
                          paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta1_nb_topics2-20_post-predictive-cross-valid_nb_iter1000_fold_size10_occurrence/"))
  # paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha50:K_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/"),
  # paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/"),
  # paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta0.1_nb_topics",nb_topics_range100r,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/"))
  inference_method = c("VEM","Gibbs\n chain end sample\ndelta = 0.1, alpha = 50/K","Gibbs\n chain end sample\ndelta = 0.1, alpha = 0.1",
                       # "Gibbs\n chain end sample\ndelta = 0.1, alpha = 0.05/K","Gibbs\n chain end sample\ndelta = 9.4-K/5, alpha = 0.05/K","Gibbs\n chain end sample\ndelta = 1, alpha = 1")
                       "Gibbs\n chain end sample\ndelta = 0.1, alpha = 0.05/K","Gibbs\n chain end sample\ndelta = 1, alpha = 1","Gibbs\n chain end sample\ndelta = 1, alpha = 0.1")
  perplexity = matrix(nrow = 20, ncol = 6, data=NA)
  perplexity_allpoints = list()
  for (i_case in 1:6)
  {
    perplexity_allpoints[[i_case]] = matrix(nrow = 17, ncol = 20, data=NA)
    K.folder_name = K.folder_name_cases[i_case]
    if (file.exists(K.folder_name) && i_case != 1)
    {
      perplexity_file = paste0(K.folder_name,"perplexity.Rdata")
      if (file.exists(perplexity_file))
      {
        load(perplexity_file)
        i_K = 0
        for (K in nb_topics_range)
        {
          i_K = i_K+1
          perplexity_allpoints[[i_case]][,K] = perplexity_mpar[,i_K]
          perplexity[K,i_case] = median(perplexity_mpar[,i_K])
        }
      }
    }
  }
  
  plot.perplexity = ggplot(data = data.frame(K = unlist(lapply(1:20,rep,17)), 
                                           llh.1 = as.vector(perplexity_allpoints[[1]]), 
                                           llh.2 = as.vector(perplexity_allpoints[[2]]), 
                                           llh.3 = as.vector(perplexity_allpoints[[3]]), 
                                           llh.4 = as.vector(perplexity_allpoints[[4]]),
                                           llh.5 = as.vector(perplexity_allpoints[[5]]),
                                           llh.6 = as.vector(perplexity_allpoints[[6]]))) +
    # llh.7 = unlist(llh_allpoints100r[[7]]))) +
    geom_boxplot(aes(x=as.factor(K),y=llh.1, colour=inference_method[1])) + 
    geom_boxplot(aes(x=as.factor(K),y=llh.2, colour=inference_method[2])) + 
    geom_boxplot(aes(x=as.factor(K),y=llh.3, colour=inference_method[3])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.4, colour=inference_method[4])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.5, colour=inference_method[5])) +
    geom_boxplot(aes(x=as.factor(K),y=llh.6, colour=inference_method[6])) +
    # geom_boxplot(aes(x=as.factor(K),y=llh.7, colour=inference_method[7])) +
    geom_line(data = data.frame(K = 1:20, llh = perplexity[,1]), aes(x = K, y = llh, colour=inference_method[1])) +
    geom_line(data = data.frame(K = 1:20, llh = perplexity[,2]), aes(x = K, y = llh, colour=inference_method[2])) +
    geom_line(data = data.frame(K = 1:20, llh = perplexity[,3]), aes(x = K, y = llh, colour=inference_method[3])) +
    geom_line(data = data.frame(K = 1:20, llh = perplexity[,4]), aes(x = K, y = llh, colour=inference_method[4])) +
    geom_line(data = data.frame(K = 1:20, llh = perplexity[,5]), aes(x = K, y = llh, colour=inference_method[5])) +
    geom_line(data = data.frame(K = 1:20, llh = perplexity[,6]), aes(x = K, y = llh, colour=inference_method[6])) +
    # geom_line(data = data.frame(K = 1:length(nb_topics_range100r), llh = llh100r[,7]), aes(x = K, y = llh, colour=inference_method[7])) +
    theme_bw() + 
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="Perplexity 10-sample fold")
  
  # pdf(paste0("figure_folder,"/Perplexity_vs_K_Bacillariophyta_occ_Gibbs_comparison_woBest_noVEM_deltaVariation",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  pdf(paste0(figure_folder,"/Perplexity_vs_K_AllTaxa_occ_Gibbs_comparison_woBest_noVEM_deltaVariation",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  print(plot.perplexity)
  dev.off()
  ########################
  
  # Optimal K Gibbs All Taxa perplexity:
  ############################################
  data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
  crossValid_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics2-20_post-predictive-cross-valid_nb_iter2000_fold_size10_occurrence/")
  
  perplexity_file = paste0(crossValid_folder_name,"perplexity.Rdata")
  load(perplexity_file)
  cor_cumul = vector(length = length(nb_topics_range)-1, mode = "numeric")
  cor_cumul_median = vector(length = length(nb_topics_range)-1, mode = "numeric")
  for (i_K in 1:(length(nb_topics_range)-1))
  {
    range_K = (length(nb_topics_range)-i_K):length(nb_topics_range)
    cor_cumul[i_K] = cor(nb_topics_range[range_K],colMeans(perplexity_mpar[,range_K]))
    cor_cumul_median[i_K] = cor(nb_topics_range[range_K],apply(perplexity_mpar[,range_K],2,median))
  }
  optimaK_crossValid = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)])[which(abs(cor_cumul[-1]) == max(abs(cor_cumul[-1])))]
  optimaK_crossValid_median = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)])[which(abs(cor_cumul_median[-1]) == max(abs(cor_cumul_median[-1])))]
  
  plot.perplex.optimalK = ggplot(data = data.frame(K = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)]), cor = abs(cor_cumul[-1]), cor_median = abs(cor_cumul_median[-1]))) +
    geom_line(aes(x = K, y = cor), size = 0.4) +
    geom_line(aes(x = K, y = cor_median), size = 0.4, col = "blue") +
    geom_vline(xintercept=optimaK_crossValid, linetype= 2, size = 0.4) +
    geom_vline(xintercept=optimaK_crossValid_median, linetype= 2, size = 0.4, col = "blue") +
    theme_bw() + 
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="Perplexity cumulative correlation")
  plot.perplex = ggplot(data = data.frame(K = unlist(lapply(2:20,rep,17)), llh = as.vector(perplexity_mpar))) +
    geom_boxplot(aes(x=as.factor(K),y=llh), size = 0.4) + 
    geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = colMeans(perplexity_mpar)), aes(x = K, y = llh), size = 0.4) +
    geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = apply(perplexity_mpar,2,median)), aes(x = K, y = llh), size = 0.4, col = "blue") +
    geom_vline(xintercept=optimaK_crossValid-1, linetype = 2, size = 0.4) +
    geom_vline(xintercept=optimaK_crossValid_median-1, linetype = 2, size = 0.4, col = "blue") +
    theme_bw() + 
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="Perplexity 10-sample fold")
  
  ggsave(filename = paste0(figure_folder,"/Perplexity_vs_K_AllTaxa_occ_Gibbs_delta0.1alpha0.1",noArcticNoBiomark_insert,noLagoon_insert,".pdf"), 
         do.call("arrangeGrob", c(list(plot.perplex,plot.perplex.optimalK), nrow = 1, ncol = 2)),
         height = 1.5*10/4, width = 1.5*10/2)
  
  # Optimal K Gibbs All Taxa posterior-distributed llh:
  # A FINIR
  data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
  posteriorLlh_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics2-20_elbow-AIC_nb_iter1000_meanPosteriorDistributedLlh_thin25_burnin500_nb_real100_occurrence/")
  
  perplexity_file = paste0(crossValid_folder_name,"perplexity.Rdata")
  load(perplexity_file)
  cor_cumul = vector(length = length(nb_topics_range)-1, mode = "numeric")
  cor_cumul_median = vector(length = length(nb_topics_range)-1, mode = "numeric")
  for (i_K in 1:(length(nb_topics_range)-1))
  {
    range_K = (length(nb_topics_range)-i_K):length(nb_topics_range)
    cor_cumul[i_K] = cor(nb_topics_range[range_K],colMeans(perplexity_mpar[,range_K]))
    cor_cumul_median[i_K] = cor(nb_topics_range[range_K],apply(perplexity_mpar[,range_K],2,median))
  }
  optimaK_crossValid = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)])[which(abs(cor_cumul[-1]) == max(abs(cor_cumul[-1])))]
  optimaK_crossValid_median = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)])[which(abs(cor_cumul_median[-1]) == max(abs(cor_cumul_median[-1])))]
  
  plot.perplex.optimalK = ggplot(data = data.frame(K = rev(nb_topics_range[-c(length(nb_topics_range),length(nb_topics_range)-1)]), cor = abs(cor_cumul[-1]), cor_median = abs(cor_cumul_median[-1]))) +
    geom_line(aes(x = K, y = cor), size = 0.4) +
    geom_line(aes(x = K, y = cor_median), size = 0.4, col = "blue") +
    geom_vline(xintercept=optimaK_crossValid, linetype= 2, size = 0.4) +
    geom_vline(xintercept=optimaK_crossValid_median, linetype= 2, size = 0.4, col = "blue") +
    theme_bw() + 
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="Perplexity cumulative correlation")
  plot.perplex = ggplot(data = data.frame(K = unlist(lapply(2:20,rep,17)), llh = as.vector(perplexity_mpar))) +
    geom_boxplot(aes(x=as.factor(K),y=llh), size = 0.4) + 
    geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = colMeans(perplexity_mpar)), aes(x = K, y = llh), size = 0.4) +
    geom_line(data = data.frame(K = seq_along(nb_topics_range), llh = apply(perplexity_mpar,2,median)), aes(x = K, y = llh), size = 0.4, col = "blue") +
    geom_vline(xintercept=optimaK_crossValid-1, linetype = 2, size = 0.4) +
    geom_vline(xintercept=optimaK_crossValid_median-1, linetype = 2, size = 0.4, col = "blue") +
    theme_bw() + 
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number K of assemblages", y="Perplexity 10-sample fold")
  
  ggsave(filename = paste0(figure_folder,"/Perplexity_vs_K_AllTaxa_occ_Gibbs_delta0.1alpha0.1",noArcticNoBiomark_insert,noLagoon_insert,".pdf"), 
         do.call("arrangeGrob", c(list(plot.perplex,plot.perplex.optimalK), nrow = 1, ncol = 2)),
         height = 1.5*10/4, width = 1.5*10/2)
  ###################
  
  # Histograms of optimalK ratios:
  ####################
  optimalK_ratio = (optimalK_max.llh[,1]/optimalK_min.crossValid[,1])[!(taxo_groups %in% groups_to_remove) & diversity > 100]
  pdf(paste0(figure_folder,"/Gibbs100r2-35_max.meanPosteriorLhh_vs_min.crossValid_ratio_hist_selected100+1.pdf"))
  hist(optimalK_ratio, xlab = "Max[mean post.-distrib. llh]/min[perplexity cross-valid]")
  dev.off()
  
  optimalK_ratio = (optimalK_sd.max.llh[,1]/optimalK_min.crossValid[,1])[!(taxo_groups %in% groups_to_remove) & diversity > 100]
  pdf(paste0(figure_folder,"/Gibbs100r2-35_sd.max.meanPosteriorLhh_vs_min.crossValid_ratio_hist_selected100+1.pdf"))
  hist(optimalK_ratio, xlab = "sd-corrected Max[mean post.-distrib. llh]/min[perplexity cross-valid]")
  dev.off()
  
  optimalK_ratio = optimalK100r_max[selected_groups]/optimalK[selected_groups]
  pdf(paste0(figure_folder,"/OptimalK100rBest_vs_OptimalK_ratio_hist_selected.pdf"))
  hist(optimalK_ratio, breaks = 20, xlab = "Optimal K best 100r to optimal K mean 10r")
  dev.off()
  
  optimalK_ratio = optimalK100r_max[selected_groups]/optimalK100r[selected_groups]
  pdf(paste0(figure_folder,"/OptimalK100rBest_vs_OptimalK100r_ratio_hist_selected.pdf"))
  hist(optimalK_ratio, breaks = 20, xlab = "Optimal K best 100r to optimal K mean 100r")
  dev.off()
  
  optimalK_ratio = optimalK2[selected_groups]/optimalK[selected_groups]
  pdf(paste0(figure_folder,"/OptimalK_vs_OptimalK2_ratio_hist_selected.pdf"))
  hist(optimalK_ratio, breaks = 10, xlab = "Optimal K threshold to optimal K 2nd derivative")
  dev.off()
  
  pdf(paste0(figure_folder,"/Hist_optimalK2_selected.pdf"))
  hist(optimalK2[selected_groups], breaks = 10, xlab = "Optimal K threshold")
  dev.off()
  
  pdf(paste0(figure_folder,"/Hist_optimalK_selected.pdf"))
  hist(optimalK[selected_groups], breaks = 10, xlab = "Optimal K 2nd derivative")
  dev.off()
  
  # pdf("Hist_optimalK_3panels.pdf",height = 7/3*2, weight = 7*2)
  # par(mfrow = c(1,3))
  # hist(optimalK)
  # hist(optimalK[1:61])
  # hist(optimalK[1:38])
  # dev.off()
  
  # pdf("OptimalK_vs_diversity.pdf")
  # #par(mar = c(5, 4, 4, 2) + 0.1)
  # par(mar = c(5, 5, 4, 2) + 0.1)
  # par(cex.lab=1.5, cex.axis=1.5)
  # plot(as.vector(diversity),optimalK,ann=F)
  # title(xlab="OTU richness",ylab="Optimal number K of assemblages")
  # dev.off()
  # 
  # pdf("OptimalK_vs_log_diversity.pdf")
  # #par(mar = c(5, 4, 4, 2) + 0.1)
  # par(mar = c(5, 5, 4, 2) + 0.1)
  # par(cex.lab=1.5, cex.axis=1.5)
  # plot(as.vector(diversity),optimalK,ann=F,log = "x")
  # title(xlab="OTU richness",ylab="Optimal number K of assemblages")
  # dev.off()
  ###############
  
  # Gibbs optimal K ratios vs. Gibbs optimal K:
  ###############################
  plot.optimalK.ratio_vs_optimalK = ggplot(data=data.frame(y=(optimalK_max.llh[,1]/optimalK_min.crossValid[,1])[!(taxo_groups %in% groups_to_remove) & diversity > 100],
                                          x=optimalK_max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1])) +
    theme_bw() +
    geom_point(aes(x = x, y = y), size = 0.4) +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Max[mean post.-distrib. llh]", y="Max[mean post.-distrib. llh]\n/min[perplexity cross-valid]") +
    geom_smooth(aes(x = x, y = y), method='lm')
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_max.meanPosteriorLhh_over_min.crossValid_ratio_vs_max.meanPosteriorLhh_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.ratio_vs_optimalK), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)

  plot.optimalK.ratio_vs_optimalK = ggplot(data=data.frame(y=(optimalK_sd.max.llh[,1]/optimalK_max.llh[,1])[!(taxo_groups %in% groups_to_remove) & diversity > 100],
                                                           x=optimalK_max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1])) +
    theme_bw() +
    geom_point(aes(x = x, y = y), size = 0.4) +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Max[mean post.-distrib. llh]", y="sd-corrected Max[mean post.-distrib. llh]\n/Max[mean post.-distrib. llh]") +
    geom_smooth(aes(x = x, y = y), method='lm')
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_sd.max.meanPosteriorLhh_over_max.meanPosteriorLhh_ratio_vs_max.meanPosteriorLhh_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.ratio_vs_optimalK), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  ##############
  
  # Comparing Gibbs optimal K: max.llh vs. sd.max.llh vs. min.cross.valid:
  ##############################
  library(MASS)
  library(viridis)
  get_density <- function(x, y, n = 100) {
    dens <- MASS::kde2d(x = x, y = y, n = n)
    ix <- findInterval(x, dens$x)
    iy <- findInterval(y, dens$y)
    ii <- cbind(ix, iy)
    return(dens$z[ii])
  }

  dat = data.frame(y=optimalK_sd.max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK_max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.sd.llh_vs_optimalK.llh = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Max[mean post.-distrib. llh]", y="sd-corrected Max[mean post.-distrib. llh]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_sd.max.meanPosteriorLhh_vs_max.meanPosteriorLhh_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.sd.llh_vs_optimalK.llh), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_sd.max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK_min.crossValid[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.sd.llh_vs_optimalK.perplexity = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Min[perplexity cross-valid]", y="sd-corrected Max[mean post.-distrib. llh]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_sd.max.meanPosteriorLhh_vs_min.crossValid_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.sd.llh_vs_optimalK.perplexity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK_min.crossValid[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.llh_vs_optimalK.perplexity = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Min[perplexity cross-valid]", y="Max[mean post.-distrib. llh]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_max.meanPosteriorLhh_vs_min.crossValid_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.llh_vs_optimalK.perplexity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_Evanno[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK_min.crossValid[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.Evanno_vs_optimalK.perplexity = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Min[perplexity cross-valid]", y="Largest_peak[Evanno delta]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_peak.Evanno_vs_min.crossValid_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.Evanno_vs_optimalK.perplexity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_Evanno[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK_max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.Evanno_vs_optimalK.llh = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Max[mean post.-distrib. llh]", y="Largest_peak[Evanno delta]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_peak.Evanno_vs_max.meanPosteriorLhh_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.Evanno_vs_optimalK.llh), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_Evanno[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK_sd.max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.Evanno_vs_optimalK.sd.llh = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="sd-corrected Max[mean post.-distrib. llh]", y="Largest_peak[Evanno delta]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_peak.Evanno_vs_sd.max.meanPosteriorLhh_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.Evanno_vs_optimalK.sd.llh), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_min.crossValid_2fold[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(optimalK_min.crossValid_2fold[,1]),1],
                   x=optimalK_min.crossValid_10fold[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(optimalK_min.crossValid_2fold[,1]),1])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.perplexity2fold_vs_optimalK.perplexity = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="10-sample-fold Min[perplexity cross-valid]", y="2-sample-fold Min[perplexity cross-valid]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_min.crossValid2fold_vs_min.crossValid10fold_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.perplexity2fold_vs_optimalK.perplexity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_max.llh_Structure[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(optimalK_max.llh_Structure[,1]),1],
                   x=optimalK_max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(optimalK_max.llh_Structure[,1]),1])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.max.llh.allsamples_vs_optimalK.max.llh = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Max[mean post.-distrib. llh]", y="All samples Max[mean post.-distrib. llh]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_max.meanPosteriorLhh_allSamples_vs_max.meanPosteriorLhh_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.max.llh.allsamples_vs_optimalK.max.llh), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  ##################
  
  # Comparing Gibbs optimal K: fold size and chain length:
  ######################################################
  library(MASS)
  library(viridis)
  get_density <- function(x, y, n = 100) {
    dens <- MASS::kde2d(x = x, y = y, n = n)
    ix <- findInterval(x, dens$x)
    iy <- findInterval(y, dens$y)
    ii <- cbind(ix, iy)
    return(dens$z[ii])
  }
  
  optimalK_min.crossValid_10fold = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
  optimalK_min.crossValid_2fold = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs2sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
  optimalK_min.crossValid_2fold_longchain = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs2sampleFolds2-25t_iter10000thin50burnin2000_2plusOTUs_noLagoon.rds"))[,1]
  optimalK_min.crossValid_10fold_longchain_average = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs10sampleFolds2-30t_iter1000thin25burnin2000_averageOverSamples_2plusOTUs_noLagoon.rds"))[,1]
  
  optimalK_max.llh = readRDS(paste0(results_folder,"/optimalK_max.llh_Gibbs100r2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
  optimalK_max.llh_longchain = readRDS(paste0(results_folder,"/optimalK_max.llh_Gibbs20r2-25t_iter10000thin50burnin2000_2plusOTUs_noLagoon.rds"))[,1]
  
  optimalK_sd.max.llh_longchain = readRDS(paste0(results_folder,"/optimalK_sd.max.llh_Gibbs20r2-25t_iter10000thin50burnin2000_2plusOTUs_noLagoon.rds"))[,1]
  optimalK_sd.max.llh = readRDS(paste0(results_folder,"/optimalK_sd.max.llh_Gibbs100r2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
  
  dat = data.frame(y=optimalK_min.crossValid_10fold_longchain_average[!is.na(optimalK_min.crossValid_10fold_longchain_average) & !is.na(optimalK_min.crossValid_10fold) & !(taxo_groups %in% groups_to_remove) & diversity > 100],
                   x=optimalK_min.crossValid_10fold[!is.na(optimalK_min.crossValid_10fold_longchain_average) & !is.na(optimalK_min.crossValid_10fold) & !(taxo_groups %in% groups_to_remove) & diversity > 100])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.perplexity.10fold.short_vs_long.chains.average = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Min[perplexity cross-valid] \n 10-sample folds, short chains", y="Min[perplexity cross-valid] \n 10-sample folds, long chains, average over samples")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r_optimalK_min.crossValid_10sampleFolds_averageOverSamples_longChains.2-30t.vs.shortChains.2-35t_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.perplexity.10fold.short_vs_long.chains.average), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_max.llh_longchain[!is.na(optimalK_max.llh_longchain) & !is.na(optimalK_max.llh) & !(taxo_groups %in% groups_to_remove) & diversity > 100],
                   x=optimalK_max.llh[!is.na(optimalK_max.llh_longchain) & !is.na(optimalK_max.llh) & !(taxo_groups %in% groups_to_remove) & diversity > 100])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.max.llh_vs_longchain = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="max[mean post.-distrib. llh] short chains", y="max[mean post.-distrib. llh] long chains")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_max.llh_shortChains_vs_longChains_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.max.llh_vs_longchain), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_sd.max.llh_longchain[!is.na(optimalK_sd.max.llh_longchain) & !is.na(optimalK_sd.max.llh) & !(taxo_groups %in% groups_to_remove) & diversity > 100],
                   x=optimalK_sd.max.llh[!is.na(optimalK_sd.max.llh_longchain) & !is.na(optimalK_sd.max.llh) & !(taxo_groups %in% groups_to_remove) & diversity > 100])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.sd.max.llh_vs_longchain = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="sd.max[mean post.-distrib. llh] short chains", y="sd.max[mean post.-distrib. llh] long chains")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_sd.max.llh_shortChains_vs_longChains_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.sd.max.llh_vs_longchain), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_min.crossValid_2fold[!is.na(optimalK_min.crossValid_2fold) & !is.na(optimalK_min.crossValid_10fold) & !(taxo_groups %in% groups_to_remove) & diversity > 100],
                   x=optimalK_min.crossValid_10fold[!is.na(optimalK_min.crossValid_2fold) & !is.na(optimalK_min.crossValid_10fold) & !(taxo_groups %in% groups_to_remove) & diversity > 100])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.perplexity.2fold_vs_10fold = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Min[perplexity cross-valid] 10-sample folds", y="Min[perplexity cross-valid] 2-sample folds")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_min.crossValid_2.vs.10sampleFolds_shortChains_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.perplexity.2fold_vs_10fold), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_min.crossValid_2fold_longchain[!is.na(optimalK_min.crossValid_2fold_longchain) & !is.na(optimalK_min.crossValid_2fold) & !(taxo_groups %in% groups_to_remove) & diversity > 100],
                   x=optimalK_min.crossValid_2fold[!is.na(optimalK_min.crossValid_2fold_longchain) & !is.na(optimalK_min.crossValid_2fold) & !(taxo_groups %in% groups_to_remove) & diversity > 100])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.perplexity.2fold.short_vs_long.chains = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Min[perplexity cross-valid] \n 2-sample folds, short chains", y="Min[perplexity cross-valid] \n 2-sample folds, long chains")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r_optimalK_min.crossValid_2sampleFolds_longChains.2-25t.vs.shortChains.2-35t_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.perplexity.2fold.short_vs_long.chains), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  ###############################
  
  # Gibbs optimal K vs. VEM optimal K:
  ##############################
  optimalK = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  dat = data.frame(y=optimalK_sd.max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK[!(taxo_groups %in% groups_to_remove) & diversity > 100][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.sd.llh_vs_optimalK.VEM = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="VEM optimalK", y="sd-corrected Max[mean post.-distrib. llh]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_sd.max.meanPosteriorLhh_vs_VEM.optimalK_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.sd.llh_vs_optimalK.VEM), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_min.crossValid[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK[!(taxo_groups %in% groups_to_remove) & diversity > 100][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.perplexity_vs_optimalK.VEM = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="VEM optimalK", y="Min[perplexity cross-valid]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_min.crossValid_vs_VEM.optimalK_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.perplexity_vs_optimalK.VEM), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_max.llh[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK[!(taxo_groups %in% groups_to_remove) & diversity > 100][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.llh_vs_optimalK.VEM = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="VEM optimalK", y="Max[mean post.-distrib. llh]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_max.meanPosteriorLhh_vs_VEM.optimalK_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.llh_vs_optimalK.VEM), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  dat = data.frame(y=optimalK_Evanno[!(taxo_groups %in% groups_to_remove) & diversity > 100,1][-c(1,2,3,7)],
                   x=optimalK[!(taxo_groups %in% groups_to_remove) & diversity > 100][-c(1,2,3,7)])
  dat$density = get_density(dat$x, dat$y)
  plot.optimalK.Evanno_vs_optimalK.VEM = ggplot(data=dat) +
    theme_bw() +
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    # geom_smooth(aes(x = x, y = y), method='lm') +
    geom_point(aes(x = x, y = y,color=density), size = 0.4) +
    scale_color_viridis() +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="VEM optimalK", y="Largest_peak[Evanno delta]")
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_peak.Evanno_vs_VEM.optimalK_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.Evanno_vs_optimalK.VEM), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  ############################
  
  # Gibbs Optimal K vs. diversity:
  ##########################
  
  plot.optimalK_vs_log_diversity = ggplot(data=data.frame(y=optimalK_prevalence.min.crossValid[selected_groups],
                                                                     x=as.vector(diversity)[selected_groups])) +
    theme_bw() +
    scale_x_log10() +
    geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 2), se = F, col = "black") +
    # geom_smooth(aes(x,y), method = "lm", col="black") +
    geom_point(aes(x = x, y = y)) +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_blank(),
          plot.margin=unit(c(1,10,1,0.5),"mm")) +
    # labs(x="Diversity (log10)", y="Mean Moran's I square weights")
    labs(x="Number of OTUs", y="Nb. of community types")
  pdf(paste0(figure_folder,"/OptimalK.prevalence.min.crossValid_vs_log.diversity_selected100+1.pdf"))
  print(plot.optimalK_vs_log_diversity)
  dev.off()
  
  ##########
  plot.optimalK.crossvalid_vs_log_diversity = ggplot(data=data.frame(y=optimalK_min.crossValid_10fold[selected_groups],
                                                                x=log10(as.vector(diversity))[selected_groups])) +
    theme_bw() +
    geom_point(aes(x = x, y = y), size = 0.4) +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Diversity (log10)", y="min[perplexity cross-valid]") +
    geom_smooth(aes(x = x, y = y), method='lm')
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_min.crossValid_vs_diversity_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.crossvalid_vs_log_diversity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  plot.optimalK.max.llh_vs_log_diversity = ggplot(data=data.frame(y=optimalK_max.llh[selected_groups],
                                                                     x=log10(as.vector(diversity))[selected_groups])) +
    theme_bw() +
    geom_point(aes(x = x, y = y), size = 0.4) +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Diversity (log10)", y="max[mean post.-distrib. llh]") +
    geom_smooth(aes(x = x, y = y), method='lm')
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_max.llh_vs_diversity_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.max.llh_vs_log_diversity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  plot.optimalK.sd.max.llh_vs_log_diversity = ggplot(data=data.frame(y=optimalK_sd.max.llh[selected_groups],
                                                                  x=log10(as.vector(diversity))[selected_groups])) +
    theme_bw() +
    geom_point(aes(x = x, y = y), size = 0.4) +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Diversity (log10)", y="sd.max[mean post.-distrib. llh]") +
    geom_smooth(aes(x = x, y = y), method='lm')
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_sd.max.llh_vs_diversity_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.sd.max.llh_vs_log_diversity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  plot.optimalK.ratio_vs_log_diversity = ggplot(data=data.frame(y=(optimalK_max.llh[,1]/optimalK_min.crossValid[,1])[!(taxo_groups %in% groups_to_remove) & diversity > 100],
                                                           x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & diversity > 100])) +
    theme_bw() +
    geom_point(aes(x = x, y = y), size = 0.4) +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Diversity (log10)", y="Max[mean post.-distrib. llh]\n/min[perplexity cross-valid]") +
    geom_smooth(aes(x = x, y = y), method='lm')
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_max.meanPosteriorLhh_over_min.crossValid_ratio_vs_diversity_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.ratio_vs_log_diversity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  plot.optimalK.ratio_vs_log_diversity = ggplot(data=data.frame(y=(optimalK_sd.max.llh[,1]/optimalK_min.crossValid[,1])[!(taxo_groups %in% groups_to_remove) & diversity > 100],
                                                                x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & diversity > 100])) +
    theme_bw() +
    geom_point(aes(x = x, y = y), size = 0.4) +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Diversity (log10)", y="sd-corrected Max[mean post.-distrib. llh]\n/min[perplexity cross-valid]") +
    geom_smooth(aes(x = x, y = y), method='lm')
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_sd.max.meanPosteriorLhh_over_min.crossValid_ratio_vs_diversity_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.ratio_vs_log_diversity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  plot.optimalK.ratio_vs_log_diversity = ggplot(data=data.frame(y=(optimalK_sd.max.llh[,1]/optimalK_max.llh[,1])[!(taxo_groups %in% groups_to_remove) & diversity > 100],
                                                                x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & diversity > 100])) +
    theme_bw() +
    geom_point(aes(x = x, y = y), size = 0.4) +
    theme(axis.title=element_text(size=9),
          axis.text = element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Diversity (log10)", y="sd-corrected Max[mean post.-distrib. llh]\n/Max[mean post.-distrib. llh]") +
    geom_smooth(aes(x = x, y = y), method='lm')
  ggsave(filename = paste0(figure_folder,"/Gibbs100r2-35_optimalK_sd.max.meanPosteriorLhh_over_max.meanPosteriorLhh_ratio_vs_diversity_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.optimalK.ratio_vs_log_diversity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  ##########################
  
  # VEM Optimal K vs. diversity:
  #####################
  plot.optimalK_log_diversity = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)),y=optimalK), label=taxo_groups, geom="point") +
    theme_bw() +
    #ggtitle("Mean similarity across real. vs. size") +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(7,1,1,0.5),"mm")) +
    labs(x="OTU richness (log10)", y="Optimal number K of assemblages") +
    #ylim(min(optimalK),10) +
    geom_smooth(method='lm')
  # geom_text(mapping = NULL, stat = "identity",size=3,
  #           #hjust=0, nudge_x = 0.2,
  #           nudge_y = 0,
  #           nudge_x = 0.1,
  #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
  #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
  #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
  #           hjust=0, 
  #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
  
  ggsave(filename = paste0(figure_folder,"/OptimalK_vs_log_diversity_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.optimalK_log_diversity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  plot.optimalK_log_diversity = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]),
                                                                    y=optimalK[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]), geom="point") +
    theme_bw() +
    #ggtitle("Mean similarity across real. vs. size") +
    theme(axis.title=element_text(size=12),
          plot.title=element_text(hjust=0, size=12),
          plot.margin=unit(c(7,1,1,0.5),"mm")) +
    labs(x="OTU richness (log10)", y="Optimal number K of assemblages") +
    # ylim(min(optimalK[1:61]),10) +
    #xlim(range(optimalK)) +
    geom_smooth(method='lm')
  # geom_text(mapping = NULL, stat = "identity",size=3,
  #           #hjust=0, nudge_x = 0.2,
  #           nudge_y = 0,
  #           nudge_x = 0.1,
  #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
  #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
  #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
  #           hjust=0, 
  #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
  
  ggsave(filename = paste0(figure_folder,"/OptimalK_vs_log10_diversity_ggplot_selected.pdf"), do.call("arrangeGrob", c(list(plot.optimalK_log_diversity), nrow=1)),
         height = 1.5*10/4, width = 1.5*10/4)
  
  # summary(lm(optimalK[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh] ~ log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]))
  #########################
  
  # Gibbs optimal K: functional boxplot
  #######################
  div_threshold = 100
  
  dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  dominant_function0 = dominant_function[selected_groups & diversity>div_threshold]
  # dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
  # dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
  dominant_function0[dominant_function0 == "unknown"] = NA
  dominant_function0[dominant_function0 == "photohost"] = "Collodaria"
  dominant_function0[dominant_function0 == "pteropoda"] = "Pteropoda"
  dominant_function0[dominant_function0 == "copepoda"] = "Copepoda"
  dominant_function0[dominant_function0 == "gelatineous_carnivores_filterers"] = "Gel. carn. filterers"
  dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Dinophyceae"] = "Dinophyceae"
  dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Bacillariophyta"] = "Bacillariophyta"
  dominant_function0[dominant_function0 == "phototroph"] = "Other phototrophs"
  dominant_function0[dominant_function0 == "phagotroph"] = "Phagotrophs"
  dominant_function0[dominant_function0 == "other metazoa"] = "Other metazoa"
  dominant_function0[dominant_function0 == "parasite"] = "Parasites"
  # alpha = rep(1,length(taxo_groups[selected_groups]))
  # alpha[dominant_function0 %in% c("copepoda","pteropoda")] = 0 
  # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them by deceasing number of groups:
  # dominant_function0 = factor(dominant_function0,names(sort(table(as.factor(dominant_function0)),decreasing = T)))
  # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them in the specified order:
  if (div_threshold == 100)
  {
    dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Pteropoda","Copepoda","Other metazoa","Parasites"))
    point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")
  } else if (div_threshold == 1000)
  {
    dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Copepoda","Parasites"))
    point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta")
  } 
  
  boxplot.optimalK = list()
  for (i_case in 1:3)
  {
    boxplot.optimalK[[i_case]] = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                          y = (if (i_case == 1) optimalK_prevalence.min.crossValid else if (i_case == 2) prevalence.corrected_K[,1] else prevalence.corrected_K[,2])
                                                          [selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
      scale_x_discrete(limits=levels(dominant_function0)) +
      geom_boxplot(aes(x,y)) +
      geom_point(data = data.frame(x = factor(point_groups),
                                   y = (if (i_case == 1) optimalK_prevalence.min.crossValid else if (i_case == 2) prevalence.corrected_K[,1] else prevalence.corrected_K[,2])
                                   [selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                 aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=22),
            axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
            plot.margin=unit(c(2,1,1,8),"mm")) +
      labs(x="", y=paste(if (i_case == 1) "Nb." else if (i_case == 2) "Surface nb." else if (i_case == 3) "DCM nb.","of community types"))
  }
  pdf(paste0(figure_folder,"/OptimalK.prevalence.min.crossValid_boxplot_allFunctionalGroups_selected",if (div_threshold == 1000) "1000" else if (div_threshold == 100) "100+1",".pdf"))
  print(boxplot.optimalK[[1]])
  print(boxplot.optimalK[[2]])
  print(boxplot.optimalK[[3]])
  dev.off()
  #######################
  
  if (optimalK_vs_size)
  {
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata"))
    
    # size_absoluteAbund_selected_groups = vector(length = length(taxo_groups), mode = "numeric")
    # size_relativeAbund_selected_groups = vector(length = length(taxo_groups), mode = "numeric")
    # sd_size_absoluteAbund_selected_groups = vector(length = length(taxo_groups), mode = "numeric")
    # sd_size_relativeAbund_selected_groups = vector(length = length(taxo_groups), mode = "numeric")
    # i_taxon = 0
    # for (taxon in taxo_groups)
    # {  
    #   i_taxon = i_taxon+1
    #   size_absoluteAbund_selected_groups[i_taxon] = size_absoluteAbund[which(taxo_groups == taxon)]
    #   size_relativeAbund_selected_groups[i_taxon] = size_relativeAbund[which(taxo_groups == taxon)]
    #   sd_size_absoluteAbund_selected_groups[i_taxon] = sd_size_absoluteAbund[which(taxo_groups == taxon)]
    #   sd_size_relativeAbund_selected_groups[i_taxon] = sd_size_absoluteAbund[which(taxo_groups == taxon)]
    # }
    
    # pdf("OptimalK_vs_size.pdf")
    # par(cex.lab=1.5, cex.axis=1.5)
    # plot(size_absoluteAbund,optimalK,ann=F)
    # title(xlab="Mean size using absolute read abundances",ylab="Optimal number K of assemblages")
    # dev.off()
    
    
    plot.optimalK_size = qplot(x = x, y = y, data=data.frame(x=size_absoluteAbund,y=optimalK), label=taxo_groups, geom="point") +
      # geom_errorbar(aes(ymax = y + sd_size_absoluteAbund[1:61],
      #                   ymin = y - sd_size_absoluteAbund[1:61]), size = 0.3, width = 0.5) +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=14),
            plot.title=element_text(hjust=0, size=14),
            plot.margin=unit(c(10,1,1,0.5),"mm")) +
      labs(x="Mean size (micron)", y="Optimal number K of assemblages") +
      ylim(min(optimalK),10) +
      # xlim(range(optimalK)) +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/OptimalK_vs_size_ggplot_truncated.pdf"), do.call("arrangeGrob", c(list(plot.optimalK_size), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    plot.optimalK_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]),
                                                                 y=optimalK[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]), geom="point") +
      # geom_errorbar(aes(ymax = y + sd_size_absoluteAbund[1:61],
      #                   ymin = y - sd_size_absoluteAbund[1:61]), size = 0.3, width = 0.5) +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=14),
            plot.title=element_text(hjust=0, size=14),
            plot.margin=unit(c(10,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Optimal number K of assemblages") +
      # ylim(min(optimalK),10) +
      # xlim(range(optimalK)) +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/OptimalK_vs_log10_size_ggplot_selected.pdf"), do.call("arrangeGrob", c(list(plot.optimalK_log_size), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    # summary(lm(optimalK[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh] ~ log10(size_absoluteAbund)[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]))
  }
  
  if (optimalK_vs_travel_time_perOTU)
  {
    prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_2yearTminProportion_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    plot.optimalK_tt_perOTU = qplot(x = x, y = y, data=data.frame(x=prop_within_OTU_vect,y=optimalK), label=taxo_groups, geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean travel time connectivity within OTUs", y="Optimal number K of assemblages") +
      xlim(range(prop_within_OTU_vect[!is.na(prop_within_OTU_vect) & !is.na(optimalK)])) +
      ylim(range(optimalK[!is.na(optimalK) & !is.na(prop_within_OTU_vect)])) +
      geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
      geom_smooth(method='lm') 
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/OptimalK_vs_OTU_travel_time_prop2y_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.optimalK_tt_perOTU), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    plot.tt_perOTU_optimalK = qplot(x = x, y = y, data=data.frame(x=optimalK,y=prop_within_OTU_vect), label=taxo_groups, geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Optimal number K of assemblages", y="Mean travel time connectivity within OTUs") +
      ylim(range(prop_within_OTU_vect[!is.na(prop_within_OTU_vect) & !is.na(optimalK)])) +
      xlim(range(optimalK[!is.na(optimalK) & !is.na(prop_within_OTU_vect)])) +
      geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed") +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0(figure_folder,"/OTU_travel_time_prop2y_vs_optimalK_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.tt_perOTU_optimalK), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
  }
}

if (convergence)
{
  optimalK_max.llh = readRDS(paste0(results_folder,"/optimalK_max.llh_Gibbs100r_2plusOTUs_noLagoon.rds"))
  optimalK_min.crossValid = readRDS(paste0(results_folder,"/optimalK_min.crossValid_10sampleFolds_Gibbs100r_2plusOTUs_noLagoon.rds"))
  
  optimalK_mpar_posteriorLlh = 1
  optimalK_mpar_perplexity = 0
  
  if (optimalK_mpar_perplexity)
  {
    optimalK_insert = "optimalK_min.crossValid10sampleFolds"
  } else if (optimalK_mpar_posteriorLlh)
    optimalK_insert = "optimalK_max.llh"
  
  convergence_plot = list()
  ii_taxon = 0
  for (taxon in taxo_groups)
  {
    i_taxon = which(taxo_groups == taxon)
    cat("\n",ifelse(taxon=="AllTaxa","AllTaxa",paste(i_taxon,"/",length(taxo_groups))))
    ii_taxon = ii_taxon+1
    data.folder_name = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    Gibbs_folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",
                               ifelse(optimalK_mpar_posteriorLlh,optimalK_max.llh[i_taxon,1],optimalK_min.crossValid[i_taxon,1]),"_nb_iter1000_nb_real100_meanPosteriorDistributedLlh_thin25_burnin500_occurrence/")
    filename = paste0("Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",
                      ifelse(optimalK_mpar_posteriorLlh,optimalK_max.llh[i_taxon,1],optimalK_min.crossValid[i_taxon,1]),"_nb_iter1000_nb_real100_meanPosteriorDistributedLlh_thin25_burnin500_occurrence.Rdata")
    
    if (!dir.exists(Gibbs_folder_name))
    {
      cat(" Non-existing directory.")
      convergence_plot[[ii_taxon]] = NA
    } else if (!file.exists(paste0(Gibbs_folder_name,filename)))
    {
      cat(" Non-existing result file.")
      convergence_plot[[ii_taxon]] = NA
    } else
    {
      load(paste0(Gibbs_folder_name,filename))
      Ordered_realizations = readRDS(paste0(Gibbs_folder_name,"Ordered_realizations.rds"))
      sampled_logLiks = readRDS(paste0(Gibbs_folder_name,"1st_closestToMean_realization/sampled_logLiks.rds"))
      
      llh_iterations = Result[[Ordered_realizations$ix[1]]]@logLiks
      llh_interpreted = Result[[Ordered_realizations$ix[1]]]@loglikelihood
      convergence_plot[[ii_taxon]] = ggplot(data = data.frame(x=seq_along(llh_iterations),y=llh_iterations)) +
        geom_point(aes(x,y), size = 0.4) +
        geom_vline(xintercept = 500, size = 0.4) +
        geom_vline(xintercept = 500 + 25*which(sampled_logLiks[Ordered_realizations$ix[1],] == llh_interpreted), linetype = "dotted", size = 0.4, col = "red") +
        theme_bw() +
        ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Iteration", y=paste0("Log-likelihood"))
    }
  }

  spl = split(convergence_plot[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(convergence_plot)], 
              (seq_along(convergence_plot[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(convergence_plot)])-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
  pdf(paste0(figure_folder,"/Convergence_closestToMeanReal_Gibbs100r_",optimalK_insert,"_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
}

if (stability)
{
  # taxo_groups = taxo_groupsNew
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  # Loading stability results from cluster:
  # for (taxon in taxo_groups)
  # {
  #   cluster.data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
  #                                     taxon,noArcticNoBiomark_insert,noLagoon_insert,"/Rtopicmodels_LDA_VEM_nb_topics8_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence")
  #   local.data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
  #                                   taxon,noArcticNoBiomark_insert,noLagoon_insert,"/Rtopicmodels_LDA_VEM_nb_topics8_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence")
  #   command = paste0("cp -r ",cluster.data.folder_name,"/Stability_assessment_samplewise_maxmatching ",
  #                    local.data.folder_name,"/")
  #   system(command, intern=TRUE)
  #   command = paste0("cp -r ",cluster.data.folder_name,"/Assemblage_comparison_within_best_realization ",
  #                    local.data.folder_name,"/")
  #   system(command, intern=TRUE)
  #   command = paste0("cp ",cluster.data.folder_name,"/Ordered_realizations.rds ",
  #                    local.data.folder_name,"/")
  #   system(command, intern=TRUE)
  # }
  
  # for (taxon in taxo_groups)
  # {
  #   # nb_topics = optimalK[taxo_groups == taxon]
  #   nb_topics = 2
  #   cluster.data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
  #                                     taxon,noArcticNoBiomark_insert,noLagoon_insert,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real10_em_tol1e-06_var_tol1e-08_best_keep_occurrence")
  #   # local.data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
  #   #                                 taxon,noArcticNoBiomark_insert,noLagoon_insert,"/")
  #   # command = paste0("cp -r ",cluster.data.folder_name," ",
  #   #                  local.data.folder_name)
  #   command = paste0("rm -r ",cluster.data.folder_name)
  #   system(command, intern=TRUE)
  # }
  
  # for (taxon in c("Porifera","Bryozoa"))
  # {
  #   for (nb_topics in c(5,6,7,8,9,10,12,14,16,20,25,30,35))
  #   {
  #     cluster.data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
  #                                       taxon,noArcticNoBiomark_insert,noLagoon_insert,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence")
  #     local.data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
  #                                     taxon,noArcticNoBiomark_insert,noLagoon_insert,"/")
  #     command = paste0("cp -r ",cluster.data.folder_name," ",
  #                      local.data.folder_name)
  #     system(command, intern=TRUE)
  #   }
  # }
  
  # for (no_rare_factor in c(0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9))
  # for (no_rare_factor in c(0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39))
  # for (no_rare_factor in c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9))
  # for (no_rare_factor in c(0.41,0.42,0.43,0.44,0.45,0.46,0.47,0.48,0.49))
  # {
  #   cluster.data.folder_name = paste0("/Users/guilhemsommeria-klein/Desktop/Serveur_Bioclust.data/Donnees_PetitPlateau/Protistes_18S/Rtopicmodels_LDA_VEM_nb_topics3_nb_real100_em_tol1e-07_var_tol1e-08_best_keep_occurrence_noRareOTU_",no_rare_factor,"factor")
  #   local.data.folder_name = paste0("/Users/guilhemsommeria-klein/Desktop/These/Donnees_PetitPlateau/Protistes_18S/")
  #   command = paste0("cp -r ",cluster.data.folder_name," ",
  #                    local.data.folder_name)
  #   system(command, intern=TRUE)
  # }
  
  ###############################
  Gibbs = 1
  VEM = 0
  
  if (Gibbs)
  {
    figure_folder_Gibbs.VEM = paste0(figure_path,"/Gibbs/All_stations")
    
    optimalK_max.llh = readRDS(paste0(results_folder,"/optimalK_max.llh_Gibbs100r2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
    optimalK_sd.max.llh = readRDS(paste0(results_folder,"/optimalK_sd.max.llh_Gibbs100r2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
    optimalK_min.crossValid = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
    optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
    optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
    optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]] 
    
    optimalK_mpar_posteriorLlh = 0
    optimalK_mpar_perplexity = 1
    
    if (optimalK_mpar_perplexity)
    {
      # optimalK_insert = "optimalK_min.crossValid10sampleFolds"
      optimalK_insert = "optimalK_Gibbs.prevalence.min.crossValid10sampleFolds"
    } else if (optimalK_mpar_posteriorLlh)
      optimalK_insert = "optimalK_max.llh"
  } else if (VEM)
  {
    figure_folder_Gibbs.VEM = paste0(figure_path,"/VEM/All_stations")
    optimalK = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  }
    
  mean_sim = vector(length = length(taxo_groups), mode = "numeric")
  sim_intercept = vector(length = length(taxo_groups), mode = "numeric")
  if (VEM)
    alpha_best_real = vector(length = length(taxo_groups), mode = "numeric")
  stability.plot.llh.diff = list()
  stability.plot.rank = list()
  ii_taxon = 0
  for (taxon in taxo_groups)
  {  
    ii_taxon = ii_taxon+1
    i_taxon = which(taxo_groups == taxon)
    if (Gibbs)
    {
      if (optimalK_mpar_posteriorLlh)
        nb_topics = optimalK_sd.max.llh[i_taxon]
      else if (optimalK_mpar_perplexity)
        # nb_topics = optimalK_min.crossValid[i_taxon]
        nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
      data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      # data.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter1000_nb_real100_meanPosteriorDistributedLlh_thin25_burnin500_occurrence/")
      data.folder_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter1000_nb_real100_meanPosteriorDistributedLlh_thin25_burnin2000_occurrence/")
    } else if (VEM)
    {
      nb_topics = round(optimalK)[i_taxon]
      # data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
      data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",
                                taxon,noArcticNoBiomark_insert,noLagoon_insert,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence")
    }
    stability_file = paste0(data.folder_name,"/Stability_assessment_samplewise_maxmatching/Stability_samplewise.rds")
    if (file.exists(stability_file))
    {
      stability_data.frame = readRDS(stability_file)
      mean_sim[i_taxon] = stability_data.frame$`Normalized ES`[1]
      sim_intercept[i_taxon] = stability_data.frame$`Normalized ES=f(llh) intercept`[1]
      
      Ordered_realizations = readRDS(paste0(data.folder_name,"/Ordered_realizations.rds"))
      load(paste0(data.folder_name,"/Stability_assessment_samplewise_maxmatching/Similarity_allRealPairs_samplewise.Rdata"))
      nES = t(DKL100_allRealPairs)[lower.tri(DKL100_allRealPairs,diag=F)]/KL_allRealPairs_w_rndzations[lower.tri(KL_allRealPairs_w_rndzations,diag=F)]
      
      stability.plot.llh.diff[[ii_taxon]] = ggplot(data = data.frame(x = abs(Ordered_realizations$x[1]-Ordered_realizations$x[2:100]),
                                                                     y = nES[1:(100-1)])) +
        geom_smooth(aes(x,y),method='lm') +
        geom_point(aes(x,y), size = 0.4) +
        theme_bw() +
        ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Llh difference with mean-llh realization", y="Similarity to mean-llh realization")
      
      stability.plot.rank[[ii_taxon]] = ggplot(data = data.frame(x = 2:100, y = nES[1:(100-1)])) +
        geom_smooth(aes(x,y),method='lm') +
        geom_point(aes(x,y), size = 0.4) +
        theme_bw() +
        ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Realizations sorted by decreasing llh", y="Similarity to mean-llh realization")
    } else
    {
      cat("No stability file found:",taxon,"\n")
      mean_sim[i_taxon] = NA
      sim_intercept[i_taxon] = NA
      stability.plot.llh.diff[[ii_taxon]] = NA
      stability.plot.rank[[ii_taxon]] = NA
    }
    if (VEM)
      alpha_best_real[i_taxon] = read.table(file = paste0(data.folder_name,"/1st_best_realization/estimated_alpha.txt"))
  }
  if (VEM)
    alpha_best_real = unlist(alpha_best_real)
  
  if (VEM)
  {
    saveRDS(alpha_best_real,paste0(results_folder,"/alpha_best_real_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    saveRDS(mean_sim,paste0(results_folder,"/mean_sim_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  } else if (Gibbs)
  {
    saveRDS(mean_sim,paste0(results_folder,"/mean_sim_Gibbs_",optimalK_insert,"_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  }
  
  if (Gibbs)
  {
    spl = split(stability.plot.llh.diff[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(stability.plot.llh.diff)], 
                (seq_along(stability.plot.llh.diff[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(stability.plot.llh.diff)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder_Gibbs.VEM,"/Stability_taxoGroups_llh.diff_Gibbs100r_",optimalK_insert,"_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(stability.plot.rank[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(stability.plot.rank)], 
                (seq_along(stability.plot.rank[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(stability.plot.rank)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder_Gibbs.VEM,"/Stability_taxoGroups_rank_Gibbs100r_",optimalK_insert,"_alpha0.1delta0.1_occ",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
  }
  
  # fit = lm(size_absoluteAbund_selected_groups ~ sim_intercept)
  # plot(sim_intercept,size_absoluteAbund_selected_groups)
  # lines(sim_intercept,fit$coefficient[1] + fit$coefficient[2]*sim_intercept)
  # fit = lm(size_absoluteAbund_selected_groups ~ optimalK)
  # plot(optimalK,size_absoluteAbund_selected_groups)
  # lines(optimalK,fit$coefficient[1] + fit$coefficient[2]*optimalK)
  # summary(fit)$r.squared
  # summary(fit)$coefficients[2,4]
  # 
  
  pdf(paste0(figure_folder_Gibbs.VEM,"/Hist_mean_sim_",optimalK_insert,"_selected100+1.pdf"),height = 7/3*2, width = 7*2)
  # par(mfrow = c(1,3), cex = 1.2)
  hist(mean_sim[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(mean_sim)],ann=F)
  title(xlab="Mean similarity across real.",ylab="Number of groups")
  dev.off()
  
  pdf("Alpha_best_real_diversity.pdf")
  par(mar = c(5.1,5.1,4.1,2.1))
  plot(log10(as.vector(diversity)),log10(alpha_best_real), ann = F)
  title(ylab = "Alpha best realization (log10)", xlab = "OTU richness (log10)", cex.lab = 1.4)
  dev.off()
  
  pdf("Alpha_best_real_diversity_rank.pdf")
  par(mar = c(5.1,5.1,4.1,2.1))
  plot(1:length(alpha_best_real),log10(alpha_best_real), xlim = c(length(alpha_best_real),1), ann = F)
  title(ylab = "Alpha best realization (log10)", xlab = "Rank in OTU richness", cex.lab = 1.4)
  dev.off()
  
  mean_sim_VEM = readRDS(paste0(results_folder,"/mean_sim_2plusOTUs_noLagoon.rds"))
  
  plot.mean.sim_log_diversity = ggplot(data=data.frame(x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(mean_sim)],
                                                                    y=mean_sim[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(mean_sim)])) +
    # geom_smooth(aes(x,y),method='lm') +
    # geom_point(data=data.frame(x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(mean_sim) & !is.na(mean_sim_VEM)],
    #                            y=mean_sim_VEM[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(mean_sim) & !is.na(mean_sim_VEM)]), aes(x,y), size = 0.4, col = "blue") +
    geom_point(aes(x,y), size = 0.4, ylim = c(0,1)) +
    ylim(0,1) +
    theme_bw() +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=9),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Diversity (log10)", y="Mean similarity across 100 real.")
  plot.mean.sim.VEM_log_diversity = ggplot(data=data.frame(x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(mean_sim_VEM)],
                                                       y=mean_sim_VEM[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(mean_sim_VEM)])) +
    geom_point(aes(x,y), size = 0.4) +
    ylim(0,1) +
    theme_bw() +
    theme(axis.title=element_text(size=9),
          plot.title=element_text(hjust=0, size=9),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Diversity (log10)", y="Mean similarity across 100 real.")
  # plot.intercept_log_diversity = ggplot(data=data.frame(x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(sim_intercept)],
  #                                                                    y=sim_intercept[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(sim_intercept)])) +
  #   geom_point(data=data.frame(x=log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(mean_sim) & !is.na(mean_sim_VEM)],
  #                              y=sim_intercept_VEM[!(taxo_groups %in% groups_to_remove) & diversity > 100 & !is.na(sim_intercept) & !is.na(sim_intercept_VEM)]), aes(x,y), size = 0.4, col = "blue") +
  #   # geom_smooth(aes(x,y),method='lm') +
  #   geom_point(aes(x,y), size = 0.4) +
  #   theme_bw() +
  #   theme(axis.title=element_text(size=9),
  #         plot.title=element_text(hjust=0, size=9),
  #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
  #   labs(x="Diversity (log10)", y="Similarity intercept across 100 real.")
  ggsave(filename = paste0(figure_folder_Gibbs.VEM,"/Stability_",optimalK_insert,"_VEM_vs_log10_diversity_selected100+1_2missing.pdf"), do.call("arrangeGrob", c(list(plot.mean.sim_log_diversity,plot.mean.sim.VEM_log_diversity), nrow=1)),
         height = 10/4, width = 2*10/4)
  
  # summary(lm(log10(as.vector(diversity))[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh] ~ mean_sim[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]))
  
  if (stability_vs_size)
  {
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata"))
    
    # size_absoluteAbund_selected_groups = vector(length = length(taxo_groups), mode = "numeric")
    # size_relativeAbund_selected_groups = vector(length = length(taxo_groups), mode = "numeric")
    # sd_size_absoluteAbund_selected_groups = vector(length = length(taxo_groups), mode = "numeric")
    # sd_size_relativeAbund_selected_groups = vector(length = length(taxo_groups), mode = "numeric")
    # i_taxon = 0
    # for (taxon in taxo_groups)
    # {  
    #   i_taxon = i_taxon+1
    #   size_absoluteAbund_selected_groups[i_taxon] = size_absoluteAbund[which(taxo_groups == taxon)]
    #   size_relativeAbund_selected_groups[i_taxon] = size_relativeAbund[which(taxo_groups == taxon)]
    #   sd_size_absoluteAbund_selected_groups[i_taxon] = sd_size_absoluteAbund[which(taxo_groups == taxon)]
    #   sd_size_relativeAbund_selected_groups[i_taxon] = sd_size_absoluteAbund[which(taxo_groups == taxon)]
    # }
    
    # pdf("Mean_Sim_vs_size.pdf")
    # #par(mar = c(5, 4, 4, 2) + 0.1)
    # par(mar = c(5, 5, 4, 2) + 0.1)
    # par(cex.lab=1.5, cex.axis=1.5)
    # plot(size_absoluteAbund,mean_sim,ann=F)
    # title(xlab="Mean size using absolute read abundances",ylab="Mean similarity across 100 real.")
    # dev.off()
    # 
    # pdf("Sim_intercept_vs_size.pdf")
    # #par(mar = c(5, 4, 4, 2) + 0.1)
    # par(mar = c(5, 5, 4, 2) + 0.1)
    # par(cex.lab=1.5, cex.axis=1.5)
    # plot(size_absoluteAbund,sim_intercept,ann=F)
    # title(xlab="Mean size using absolute read abundances",ylab="Similarity intercept across 100 real.")
    # dev.off()
    
    # summary(lm(log10(size_absoluteAbund) ~ mean_sim))
    # summary(lm(log10(size_absoluteAbund)[1:61] ~ mean_sim[1:61]))
    
    plot.mean.sim_size = qplot(x = x, y = y, data=data.frame(x=size_absoluteAbund,y=mean_sim), label=taxo_groups, geom="point") +
      # geom_errorbar(aes(ymax = y + sd_size_absoluteAbund,
      #                   ymin = y - sd_size_absoluteAbund), size = 0.2) +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=9),
            plot.title=element_text(hjust=0, size=9),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron)", y="Mean similarity across 100 real.") +
      ylim(min(min(mean_sim[!is.na(mean_sim)]),0),1) +
      xlim(range(size_absoluteAbund[!is.na(mean_sim)])) +
      geom_smooth(method='lm') 
    # geom_text(mapping = NULL, stat = "identity",size=2,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.01,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    plot.intercept_size = qplot(x = x, y = y, data=data.frame(x=size_absoluteAbund,y=sim_intercept), label=taxo_groups, geom="point") +
      # geom_errorbar(aes(ymax = y + sd_size_absoluteAbund,
      #                   ymin = y - sd_size_absoluteAbund), size = 0.2) +
      theme_bw() +
      #ggtitle("Similarity intercept vs. size") +
      theme(axis.title=element_text(size=9),
            plot.title=element_text(hjust=0, size=9),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron)", y="Similarity intercept across 100 real.") +
      ylim(min(min(sim_intercept[!is.na(sim_intercept)]),0),1) +
      xlim(range(size_absoluteAbund[!is.na(sim_intercept)])) +
      geom_smooth(method='lm') 
    # geom_text(mapping = NULL, stat = "identity",size=2,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0, 
    #           nudge_x = 0.01,
    #           #nudge_y = c(rep(0,2),10,0,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,2),0.05,0,-0.04,rep(0,length(size_relativeAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0("Stability_vs_mean_size_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.mean.sim_size, plot.intercept_size), nrow=1)),
           height = 10/4, width = 2*10/4)
    
    plot.mean.sim_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund),y=mean_sim), label=taxo_groups, geom="point") +
      # geom_errorbar(aes(ymax = y + sd_size_absoluteAbund,
      #                   ymin = y - sd_size_absoluteAbund), size = 0.2) +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=9),
            plot.title=element_text(hjust=0, size=9),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Mean similarity across 100 real.") +
      ylim(min(0,min(mean_sim[!is.na(mean_sim)])),1) +
      xlim(range(log10(size_absoluteAbund[!is.na(sim_intercept)]))) +
      geom_smooth(method='lm') 
    # geom_text(mapping = NULL, stat = "identity",size=2,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.01,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    plot.intercept_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund),y=sim_intercept), label=taxo_groups, geom="point") +
      # geom_errorbar(aes(ymax = y + sd_size_absoluteAbund,
      #                   ymin = y - sd_size_absoluteAbund), size = 0.2) +
      theme_bw() +
      #ggtitle("Similarity intercept vs. size") +
      theme(axis.title=element_text(size=9),
            plot.title=element_text(hjust=0, size=9),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Similarity intercept across 100 real.") +
      ylim(min(0,min(sim_intercept[!is.na(sim_intercept)])),1) +
      xlim(range(log10(size_absoluteAbund[!is.na(sim_intercept)]))) +
      geom_smooth(method='lm') 
    # geom_text(mapping = NULL, stat = "identity",size=2,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0, 
    #           nudge_x = 0.01,
    #           #nudge_y = c(rep(0,2),10,0,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,2),0.05,0,-0.04,rep(0,length(size_relativeAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = paste0("Stability_vs_log10_mean_size_ggplot.pdf"), do.call("arrangeGrob", c(list(plot.mean.sim_log_size, plot.intercept_log_size), nrow=1)),
           height = 10/4, width = 2*10/4)
    
    plot.mean.sim_log_size = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund)[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh],
                                                                 y=mean_sim[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]), geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(7,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Mean similarity across 100 real.") +
      ylim(min(0,min(mean_sim[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh])),1) +
      xlim(range(log10(size_absoluteAbund[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]))) +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = "Stability_vs_log10_mean_size_ggplot_selected.pdf", do.call("arrangeGrob", c(list(plot.mean.sim_log_size), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    # summary(lm(log10(size_absoluteAbund)[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh] ~ mean_sim[!(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh]))
  }
  
  if (stability_vs_optimalK)
  {
    plot.stability_optimalK = qplot(x = x, y = y, data=data.frame(x=optimalK,y=mean_sim), label=taxo_groups, geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Optimal number K of assemblages", y="Mean similarity across 100 real.") +
      xlim(min(optimalK[!is.na(mean_sim)]),10) +
      ylim(range(mean_sim[!is.na(mean_sim)])) +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = "Mean_sim_vs_optimalK_ggplot.pdf", do.call("arrangeGrob", c(list(plot.stability_optimalK), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
  }
  
  if (stability_vs_travel_time_perOTU)
  {
    prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_2yearTminProportion_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    plot.stability_tt_perOTU = qplot(x = x, y = y, data=data.frame(x=prop_within_OTU_vect,y=mean_sim), label=taxo_groups, geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean travel time connectivity within OTUs", y="Mean similarity across 100 real.") +
      xlim(range(prop_within_OTU_vect[!is.na(prop_within_OTU_vect) & !is.na(mean_sim)])) +
      ylim(range(mean_sim[!is.na(mean_sim) & !is.na(prop_within_OTU_vect)])) +
      geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = "Mean_sim_vs_OTU_travel_time_prop2y_ggplot.pdf", do.call("arrangeGrob", c(list(plot.stability_tt_perOTU), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
    
    plot.tt_perOTU_stability = qplot(x = x, y = y, data=data.frame(x=mean_sim,y=prop_within_OTU_vect), label=taxo_groups, geom="point") +
      theme_bw() +
      #ggtitle("Mean similarity across real. vs. size") +
      theme(axis.title=element_text(size=12),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean similarity across 100 real.", y="Mean travel time connectivity within OTUs") +
      ylim(range(prop_within_OTU_vect[!is.na(prop_within_OTU_vect) & !is.na(mean_sim)])) +
      xlim(range(mean_sim[!is.na(mean_sim) & !is.na(prop_within_OTU_vect)])) +
      geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed") +
      geom_smooth(method='lm')
    # geom_text(mapping = NULL, stat = "identity",size=3,
    #           #hjust=0, nudge_x = 0.2,
    #           nudge_y = 0,
    #           nudge_x = 0.1,
    #           #nudge_x = c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1),
    #           #nudge_y = c(rep(0,3),10,-10,rep(0,length(size_relativeAbund)-5)),
    #           #nudge_y = c(rep(0,4),-0.05,rep(0,length(size_absoluteAbund)-5)),
    #           hjust=0, 
    #           parse = FALSE, check_overlap = F, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
    
    ggsave(filename = "OTU_travel_time_prop2y_vs_mean_sim_ggplot.pdf", do.call("arrangeGrob", c(list(plot.tt_perOTU_stability), nrow=1)),
           height = 1.5*10/4, width = 1.5*10/4)
  }
}

if (posterior_distrib)
{
  if (data_Federico)
  {
    taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100
    optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
    optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
    optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]] 
  }
  
  ###############
  # Computing Rhat for every group, for different burnin values:
  burnin = 0
  R.hat = vector(length=length(taxo_groups),mode="numeric")
  # for (taxon in c("AllTaxa",taxo_groups[selected_groups]))
  for (taxon in "AllTaxa")
  {
    if (taxon != "AllTaxa")
    {
      i_taxon = which(taxo_groups == taxon)
      cat(i_taxon,"/",length(taxo_groups),"\n")
      nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
    } else
    {
      cat("AllTaxa\n")
      nb_topics = optimalK_prevalence.min.crossValid.allTaxa
    }
    data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    param.folder_name = paste0("Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter1000_nb_real100_meanPosteriorDistributedLlh_thin25_burnin2000_occurrence")
    param.save.file_name = paste0("Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter1000_nb_real100_meanPosteriorDistributedLlh_thin25_burnin2000_occurrence.Rdata")
    tot.file.name = paste0(data.folder_name,"/",param.folder_name,"/",param.save.file_name)
    load(tot.file.name)
    chains = matrix(nrow = 3000 - burnin, ncol = 100, data=0)
    split.chains = matrix(nrow = (3000 - burnin)/2, ncol = 200, data=0)
    for (i_chain in 1:100)
    {
      # Result[[i]]@gamma
      chains[,i_chain] = as.vector(Result[[i_chain]]@logLiks[burnin+(1:(3000-burnin))])
      split.chains[,i_chain] = chains[1:((3000 - burnin)/2), i_chain]
      split.chains[,100+i_chain] = chains[(3000 - burnin)/2 + (1:((3000 - burnin)/2)), i_chain]
    }
    within.variance = mean(apply(split.chains,2,var))
    between.variance = var(apply(split.chains,2,mean))
    post.var.est = ((3000 - burnin)/2 - 1)/((3000 - burnin)/2)*within.variance + between.variance
    if (taxon != "AllTaxa")
      R.hat[i_taxon] = sqrt(post.var.est/within.variance)
    else
      R.hat.allTaxa = sqrt(post.var.est/within.variance)
  }
  # saveRDS(chains,
  #         paste0(results_folder,"/Chains.allTaxa_nb_iter3000_nb_real100_occurrence.rds"),
  #         version=2)
  saveRDS(list(R.hat.500.allTaxa,R.hat.500),
          paste0(results_folder,"/",short_marker,
                 "Rhat.burnin.",burnin,"_nb_iter3000_nb_real100_occurrence.rds"),
          version=2)
  saveRDS(list(R.hat.1000.allTaxa,R.hat.1000),
          paste0(results_folder,"/",short_marker,
                 "Rhat.burnin.",burnin,"_nb_iter3000_nb_real100_occurrence.rds"),
          version=2)
  saveRDS(list(R.hat.2000.allTaxa,R.hat.2000),
          paste0(results_folder,"/",short_marker,
                 "Rhat.burnin.",burnin,"_nb_iter3000_nb_real100_occurrence.rds"),
          version=2)
  
  ##################
  # Loading 10 random reals for each group:
  nb.reals = 99
  documents.reals = list()
  documents.best.real = list()
  nrow.matrix = matrix(nrow = length(taxo_groups), ncol = nb.reals+1, data=0)
  # for (taxon in taxo_groups[selected_groups])
  for (taxon in "AllTaxa")
  {
    if (taxon != "AllTaxa")
    {
      i_taxon = which(taxo_groups == taxon)
      cat(i_taxon,"/",length(taxo_groups),"\n")
      nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
    } else
    {
      cat("AllTaxa\n")
      nb_topics = optimalK_prevalence.min.crossValid.allTaxa
    }
    data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    param.folder_name = paste0("Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter1000_nb_real100_meanPosteriorDistributedLlh_thin25_burnin2000_occurrence")
    param.save.file_name = paste0("Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter1000_nb_real100_meanPosteriorDistributedLlh_thin25_burnin2000_occurrence.Rdata")
    
    tot.file.name = paste0(data.folder_name,"/",param.folder_name,"/",param.save.file_name)
    load(tot.file.name)
    Ordered_realizations = readRDS(paste0(data.folder_name,"/",param.folder_name,"/Ordered_realizations.rds"))
    
    spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/",param.folder_name,"/1st_closestToMean_realization/Spatial_topicmix_kriged.rds"))
    # selecting the z.pred columns in all topics:
    documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
    # setting one topic per column
    if (taxon != "AllTaxa")
    {
      documents.best.real[[i_taxon]] = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics)))
      nrow.matrix[i_taxon,1] = nrow(documents.best.real[[i_taxon]])
    } else
    {
      documents.best.real.allTaxa = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics)))
    }
    
    real.sample = sample(1:99,nb.reals)
    if (taxon != "AllTaxa")
    {
      documents.reals[[i_taxon]] = list()
      for (i_real in 1:nb.reals)
      {
        documents.reals[[i_taxon]][[i_real]] = Result[[Ordered_realizations$ix[2:100][real.sample[i_real]]]]@gamma
        rownames(documents.reals[[i_taxon]][[i_real]]) = rownames(documents.best.real[[i_taxon]])
        nrow.matrix[i_taxon,i_real+1] = nrow(documents.reals[[i_taxon]][[i_real]])
      }
    } else
    {
      documents.reals.allTaxa = list()
      for (i_real in 1:nb.reals)
      {
        documents.reals.allTaxa[[i_real]] = Result[[Ordered_realizations$ix[2:100][real.sample[i_real]]]]@gamma
        rownames(documents.reals.allTaxa[[i_real]]) = rownames(documents.best.real.allTaxa)
      }
    }
  }
  
  # Similarity between groups across 10 random reals.
  normalized.VI = list()
  for (i_real in 1:(nb.reals+1))
  {
    cat(i_real,"/",(nb.reals+1),"\n")
    if (i_real < nb.reals+1)
      normalized.VI[[i_real]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data=0)
    else 
      normalized.VI.best.real = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data=0)
    for (i in 1:length(taxo_groups[selected_groups]))
    {
      ii = which(taxo_groups[selected_groups][i] == taxo_groups)
      for (j in 1:length(taxo_groups[selected_groups]))
      {
        if (j != i)
        {
          jj = which(taxo_groups[selected_groups][j] == taxo_groups)
          if (i_real < nb.reals+1)
          {
            normalized.VI[[i_real]][ii,jj] = normalized_VI_fun(documents.best.real[[ii]],documents.reals[[jj]][[i_real]],stations.means="different",SUR.DCM.all="all",stations_depths,coord)
          } else
          {
            normalized.VI.best.real[ii,jj] = normalized_VI_fun(documents.best.real[[ii]],documents.best.real[[jj]],stations.means="different",SUR.DCM.all="all",stations_depths,coord)
          }
        }
      }
    }
  }
  diag(normalized.VI.best.real) = NA
  for (i_real in 1:10)
    diag(normalized.VI[[i_real]]) = NA
  # saveRDS(list(normalized.VI.best.real,normalized.VI),
  #         paste0(results_folder,"/",short_marker,
  #                "Normalized_VI_10reals_different.stations.means.rds"),
  #         version=2)
  # saveRDS(list(normalized.VI.best.real,normalized.VI),
  #         paste0(results_folder,"/",short_marker,
  #                "Normalized_VI_10reals_different.stations.means_old.code.rds"),
  #         version=2)
  # saveRDS(list(normalized.VI.best.real,normalized.VI),
  #         paste0(results_folder,"/",short_marker,
  #                "Normalized_VI_10reals_different.stations.means_cluster.data.rds"),
  #         version=2)
  saveRDS(list(normalized.VI.best.real,normalized.VI),
          paste0(results_folder,"/",short_marker,
                 "Normalized_VI_10reals_different.stations.means.rds"),
          version=2)
  
  #########
  normalized.VI.within.group = list()
  mean.normalized.VI.within.group = vector(length = length(taxo_groups), mode = "numeric")
  # for (taxon in taxo_groups[selected_groups])
  for (taxon in "AllTaxa")
  {
    if (taxon != "AllTaxa")
    {
      i_taxon = which(taxo_groups == taxon)
      cat(i_taxon,"/",length(taxo_groups),"\n")
    } else
    {
      cat("AllTaxa\n")
    }
    if (taxon != "AllTaxa")
    {
      normalized.VI.within.group[[i_taxon]] = matrix(nrow = nb.reals+1, ncol = nb.reals+1, dimnames = list(c(1:nb.reals,"best"),c(1:nb.reals,"best")), data=NA)
      for (i in 2:(nb.reals+1))
      {
        for (j in 1:i)
        {
          if (i == nb.reals+1)
            documents1 = documents.best.real[[i_taxon]]
          else
            documents1 = documents.reals[[i_taxon]][[i]]
          if (j == nb.reals+1)
            documents2 = documents.best.real[[i_taxon]]
          else
            documents2 = documents.reals[[i_taxon]][[j]]
          normalized.VI.within.group[[i_taxon]][i,j] = normalized_VI_fun(documents1,documents2,stations.means="different",SUR.DCM.all="all",stations_depths,coord)
        }
      }
      mean.normalized.VI.within.group[i_taxon] = mean(normalized.VI.within.group[[i_taxon]][lower.tri(normalized.VI.within.group[[i_taxon]])])
    } else
    {
      normalized.VI.within.group.allTaxa = matrix(nrow = nb.reals+1, ncol = nb.reals+1, dimnames = list(c(1:nb.reals,"best"),c(1:nb.reals,"best")), data=NA)
      for (i in 2:(nb.reals+1))
      {
        for (j in 1:i)
        {
          if (i == nb.reals+1)
            documents1 = documents.best.real.allTaxa
          else
            documents1 = documents.reals.allTaxa[[i]]
          if (j == nb.reals+1)
            documents2 = documents.best.real.allTaxa
          else
            documents2 = documents.reals.allTaxa[[j]]
          normalized.VI.within.group.allTaxa[i,j] = normalized_VI_fun(documents1,documents2,stations.means="different",SUR.DCM.all="all",stations_depths,coord)
        }
      }
      mean.normalized.VI.allTaxa = mean(normalized.VI.within.group.allTaxa[lower.tri(normalized.VI.within.group.allTaxa)])
    }
  }
  saveRDS(normalized.VI.within.group,
          paste0(results_folder,"/",short_marker,
                 "Normalized_VI_within.groups_100reals_different.stations.means.rds"),
          version=2)
  saveRDS(mean.normalized.VI.within.group,
          paste0(results_folder,"/",short_marker,
                 "Normalized_VI_mean.within.groups_100reals_different.stations.means.rds"),
          version=2)
}
  
if (environmental_data)
{
  library(vegan)
  
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # taxo_groups = "AllTaxa"
  # selected_groups = T
  
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100
  
  target_groups = taxo_groups
  # target_groups = "AllTaxa"
  if (all(target_groups == "AllTaxa"))
  {
    target_groups_insert = "_AllTaxa"
  } else if (all(target_groups == taxo_groups))
    target_groups_insert = ""
  
  # If var_select = 1, variable selection is performed:
  var_select = 0
  # If existing_var_selection = 1, a preexisting variable selection is used (applies only for var_select=1):
  existing_var_selection = 0
  # If preliminary_global_test = 1, a global test is performed on each set of explanatory variable before performing variable selection,
  # and variable selection is only performed when the global test is significant (applies only for var_select=1):
  preliminary_global_test = 0
  # If indiv_signif_axes_selection = 1, individually significant axes are selected,
  # in addition to those selected by variable selection if var_select=1:
  indiv_signif_axes_selection = 1
  # If BH_correction = 1, axes are selected following the Benjamini-Hochberg procedure
  # for multiple comparisons (applies only for indiv_signif_axes_selection = 1): 
  BH_correction = 1
  # Standardization of biotic PCA axes:
  stdzation_biotic_pca = 1
  
  Gibbs = 1
  VEM = 0
  Functional = 0
  
  nb_real = 100
  fold_size = 10
  nb_iter = 1000
  thin = 25
  burnin = 2000
  
  if (stdzation_biotic_pca)
  {
    stdzation_insert = ""
  } else
  {
    stdzation_insert = "_noStdzation"
  }
  
  if (var_select)
  {
    var.select_insert = "_both.directions.independent.selection"
  } else
  {
    var.select_insert = ""
  }
  
  if (indiv_signif_axes_selection)
  {
    indiv.signif.axes_insert = ""
  } else
  {
    indiv.signif.axes_insert = "_no.indiv.signif.axes"
  }
  
  if (BH_correction && indiv_signif_axes_selection)
  {
    BH_correction_insert = "_BH.correction"  
  } else
  {
    BH_correction_insert = ""
  }
  
  if (preliminary_global_test || !var_select)
  {
    preliminary_global_test_insert = ""
  } else
  {
    preliminary_global_test_insert = "_no.prelim.global.test"
  }
  
  if (Gibbs)
  {
    figure_folder_Gibbs.VEM = paste0(figure_path,"/Gibbs/All_stations")
    # optimalK_max.llh = readRDS(paste0(results_folder,"/optimalK_max.llh_Gibbs100r_2plusOTUs_noLagoon.rds"))
    # optimalK_min.crossValid = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs",fold_size,"sampleFolds2-35t_iter",nb_iter,"thin",thin,"burnin",burnin,"_2plusOTUs_noLagoon.rds"))[,1]
    optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs",fold_size,"sampleFolds2-35t_iter",nb_iter,"thin",thin,"burnin500_2plusOTUs_noLagoon.rds"))
    optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
    optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]]
    
    if (fold_size == 10 && nb_iter == 1000 && thin == 25 && burnin == 2000)
      # Gibbs_VEM_insert = "_GibbsShortChainNoAverage10sampleFold"
      Gibbs_VEM_insert = "_Gibbs.prevalence.min.crossValid10sampleFolds"
    else
      stop("Non-existing Gibbs computation.")
    
    # optimalK_mpar_posteriorLlh = 0
    # optimalK_mpar_perplexity = 1
    # 
    # if (optimalK_mpar_perplexity)
    # {
    #   optimalK_insert = "optimalK_min.crossValid10sampleFolds"
    # } else if (optimalK_mpar_posteriorLlh)
    #   optimalK_insert = "optimalK_max.llh"
  } else if (VEM)
  {
    figure_folder_Gibbs.VEM = paste0(figure_path,"/VEM/All_stations")
    optimalK = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    Gibbs_VEM_insert = ""
  } else if (Functional)
  {
    figure_folder_Gibbs.VEM = figure_path
    Gibbs_VEM_insert = "_Functional"
  }
    
  # Looking at the abundance (number of OTUs or number of reads) of each taxonomic group across the stations as a biotic explanatory variable
  ######################
  # read_abundance_per_group = matrix(nrow = nrow(coord), ncol = length(taxo_groups), dimnames = list(rownames(coord),taxo_groups), data = 0)
  # for (taxon in taxo_groups)
  # {
  #   i_taxon = which(taxo_groups == taxon)
  #   
  #   # Using the raw read abundance per group and per station:
  #   data.folder_name_taxon = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
  #   load(paste0(data.folder_name_taxon,"/data2m.Rdata"))
  #   read_abundance_per_group[,i_taxon] = colSums(data2m)
  # }
  
  data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTAxa",noArcticNoBiomark_insert,noLagoon_insert)
  load(paste0(data.folder_name,"/coord.Rdata"))
  
  load(paste0(data.folder_name,"/data2m_unmerged.Rdata"))
  data2m = data2m0
  samples_data2m = colnames(data2m)
  
  load(paste0(data.folder_name,"/taxo_ref.Rdata"))
  taxo_groups_OTUs = taxo_ref$taxogroup2
  taxo_groups_unmodified = levels(as.factor(taxo_groups_OTUs))[sort.int(table(as.factor(taxo_groups_OTUs)),index.return = T,decreasing = T)$ix]
  OTU_indices_all_selected = which(taxo_groups_OTUs %in% taxo_groups_unmodified[selected_groups])
  
  functions_OTUs = taxo_ref$Function
  functions = levels(as.factor(functions_OTUs))[sort.int(table(as.factor(functions_OTUs)),index.return = T,decreasing = T)$ix]
  
  # # Looking for stations-depths with a 0.8-inf size fraction but not a complete range of size fractions
  # i_missing_stations_depths = 0
  # missing_stations_depths = list()
  # # for (station in stations_names[stations_names %in% Arctic_stations])
  # for (station in stations_names)
  # {
  #   cat("\nStation",which(stations_names == station),"of",length(stations_names))
  #   for (depth in c("SUR","DCM"))
  #   {
  #     # Looking for the samples corresponding to the current station in sample_ref:
  #     samples_indices = which(samples_stations == station)
  #     samples_indices = samples_indices[which(samples_depths[samples_indices] == depth)]
  #     #samples_indices = samples_indices[which(samples_templates[samples_indices] == "DNA")]
  # 
  #     if (!(
  #       (any(samples_fractions[samples_indices]=="0.8-3") || any(samples_fractions[samples_indices]=="0.8-5") || any(samples_fractions[samples_indices]=="0.8-inf"))
  #       &&
  #       (any(samples_fractions[samples_indices]=="3-20") || any(samples_fractions[samples_indices]=="5-20"))
  #       &&
  #       any(samples_fractions[samples_indices]=="20-180") && any(samples_fractions[samples_indices]=="180-2000"))
  #       && length(samples_indices) != 0)
  #     {
  #       i_missing_stations_depths = i_missing_stations_depths+1
  #       missing_stations_depths[[i_missing_stations_depths]] = c(station,depth)
  #       cat("\n",station,depth)
  #     }
  #   }
  # }
  # missing_stations_depths = matrix(unlist(missing_stations_depths), nrow = 2)
  
  # if (rda_all || rda_lda)
  # {
  #   read_abundance_per_group_trans = sweep(sweep(read_abundance_per_group,2,colMeans(read_abundance_per_group, na.rm = T),"-"),2,apply(read_abundance_per_group,2,sd,na.rm=T),"/")
  #   # absoluteAbund_trans = sweep(sweep(absoluteAbund,2,colMeans(absoluteAbund, na.rm = T),"-"),2,apply(absoluteAbund,2,sd,na.rm=T),"/")
  #   relativeAbund_trans = sweep(sweep(relativeAbund,2,colMeans(relativeAbund, na.rm = T),"-"),2,apply(relativeAbund,2,sd,na.rm=T),"/")
  #   # functions_absoluteAbund_trans = sweep(sweep(functions_absoluteAbund,2,colMeans(functions_absoluteAbund, na.rm = T),"-"),2,apply(functions_absoluteAbund,2,sd,na.rm=T),"/")
  #   functions_relativeAbund_trans = sweep(sweep(functions_relativeAbund,2,colMeans(functions_relativeAbund, na.rm = T),"-"),2,apply(functions_relativeAbund,2,sd,na.rm=T),"/")
  #   # functions_absoluteAbund_selected_trans = sweep(sweep(functions_absoluteAbund_selected,2,colMeans(functions_absoluteAbund_selected, na.rm = T),"-"),2,apply(functions_absoluteAbund_selected,2,sd,na.rm=T),"/")
  #   functions_relativeAbund_selected_trans = sweep(sweep(functions_relativeAbund_selected,2,colMeans(functions_relativeAbund_selected, na.rm = T),"-"),2,apply(functions_relativeAbund_selected,2,sd,na.rm=T),"/")
  # } else
  # {
  #   read_abundance_per_group_trans = read_abundance_per_group
  #   # absoluteAbund_trans = absoluteAbund
  #   relativeAbund_trans = relativeAbund
  #   # functions_absoluteAbund_trans = functions_absoluteAbund
  #   functions_relativeAbund_trans = functions_relativeAbund
  #   # functions_absoluteAbund_selected_trans = functions_absoluteAbund_selected
  #   functions_relativeAbund_selected_trans = functions_relativeAbund_selected
  # }
  # read_abundance_per_group = read_abundance_per_group/rowSums(read_abundance_per_group)
  
  # Loading the data used by Federico (mixed of measured and simulated data):
  load(paste0(data.folder_name,"/sample_ref.Rdata"))
  samples_stations = sample_ref$Station.label
  samples_depths = sample_ref$Depth
  samples_fractions = sample_ref$Fraction.size
  samples_templates = sample_ref$Template
  stations_names = levels(as.factor(sample_ref$Station.label))
  colnames(sample_ref)[colnames(sample_ref) == "Temperature"] = "Temperature_fed"
  # Taking the absolute value of Latitude:
  # sample_ref$Latitude = abs(sample_ref$Latitude)
  
  # Adding seasonality_index:
  # seasonality_index = read.table(paste0(data_folder,"/Abiotic_data/seasonality_index_t_n.csv"),sep=",",header=T,row.names=1)
  # # Selecting the samples available in sample_ref:
  # seasonality_index = seasonality_index[sample_ref$Sample.id,c("Seasonality_index.Temperature","Seasonality_index.Nitrates")]
  # sample_ref = cbind(sample_ref,seasonality_index)
  
  # Loading the WOA13 averaged-interpolated abiotic data (data used by Watteaux-Iudicone):
  # station_ref = read.table(paste0(data_folder,"/Abiotic_data/WOA13_AMODIS_data.csv"),sep=",",header=T,row.names=1)
  
  # Loading the WOA13 averaged-interpolated abiotic data (data sent by Paul Frmont and Olivier Jaillon):
  # station_ref_Arctic = read.table(paste0(data_folder,"/Abiotic_data/Env_arctic_woa13.csv"),sep=";",header=T,row.names=1)
  # Reordering station_ref_Arctic according to watteaux_selected_variables
  # station_ref_Arctic = station_ref_Arctic[,c("Temperature..degree.C.","Nitrate..micromol.L.","O2.dissolved..ml.L.","O2.Saturation....","Apparent.O2.utilization..ml.L.","Phosphate..micromol.L.","Silicate..micromol.L.","Distance.to.coast..kms.")]
  
  # Loading the WOA13 averaged-interpolated abiotic data (data sent by Paul Frmont and Olivier Jaillon):
  station_ref_all = read.table(paste0(data_folder,"/Abiotic_data/woa13_env_tara_all.csv"),sep=";",header=T,row.names=1)
  # Reordering the variables as in watteaux_selected_variables
  station_ref_all = station_ref_all[,c("T","no3","O2","o2s","aou","po4","si")]
  
  stations_depths = as.data.frame(matrix(nrow=nrow(coord),ncol=4))
  colnames(stations_depths) = c("Station","Depth","Station_depth","Station_number")
  for (station_depth_index in 1:nrow(coord))
  {
    stations_depths[station_depth_index,1:2] = c(strsplit(rownames(coord)[station_depth_index],split=" ",fixed=T)[[1]][1],
                                                 strsplit(rownames(coord)[station_depth_index],split=" ",fixed=T)[[1]][2])
    station_number = strsplit(stations_depths[station_depth_index,1],split="_",fixed=T)[[1]][2]
    # Removing the "0"s in front of the station number to conform to the rownames in sample_ref_indices  
    while (substr(station_number,1,1) == "0")
      station_number = substr(station_number,2,nchar(station_number))
    stations_depths[station_depth_index,3] = paste(c(station_number,stations_depths[station_depth_index,2]),collapse = "_")
    stations_depths[station_depth_index,4] = station_number
  }
  stations_names = levels(as.factor(stations_depths$Station))
  
  relativeAbund_file = paste0(results_folder,"/groups_relativeAbund",noArcticNoBiomark_insert,noLagoon_insert,".rds")
  functions_relativeAbund_file = paste0(results_folder,"/functions_relativeAbund",noArcticNoBiomark_insert,noLagoon_insert,".rds")
  if (file.exists(relativeAbund_file) && file.exists(functions_relativeAbund_file))
  {
    relativeAbund = readRDS(relativeAbund_file)
    functions_relativeAbund = readRDS(functions_relativeAbund_file)[[1]]
    functions_relativeAbund0 = readRDS(functions_relativeAbund_file)[[2]]
  } else
  {
    OTU_relativeAbund = matrix(nrow = nrow(coord), ncol = nrow(taxo_ref), dimnames = list(rownames(coord),1:nrow(taxo_ref)), data=NA)
    # absoluteAbund = matrix(nrow = nrow(coord), ncol = length(taxo_groups), dimnames = list(rownames(coord),taxo_groups), data = 0)
    relativeAbund = matrix(nrow = nrow(coord), ncol = length(taxo_groups), dimnames = list(rownames(coord),taxo_groups), data = NA)
    # functions_absoluteAbund = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = 0)
    functions_relativeAbund0 = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = NA)
    # functions_absoluteAbund_selected = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = 0)
    functions_relativeAbund_selected0 = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = NA)
    functions_relativeAbund = list()
    # functions_absoluteAbund_selected = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = 0)
    functions_relativeAbund_selected = list()
    # for (station in stations_names[stations_names %in% Arctic_stations])
    for (station_depth_index in 1:nrow(coord))
    {
      cat("\nStation-depth",station_depth_index,"of",nrow(coord))
      station = stations_depths$Station[station_depth_index]
      depth = stations_depths$Depth[station_depth_index]
      # Looking for the samples corresponding to the current station in sample_ref:
      samples_indices = which(samples_stations == station)
      samples_indices = samples_indices[which(samples_depths[samples_indices] == depth)]
      #samples_indices = samples_indices[which(samples_templates[samples_indices] == "DNA")]
      
      # The filtering below differs from the one performed during the merging byStationbyDepth step: 
      # fraction "0.8-inf" is considered as roughly equivalent to the "0.8-5" fraction, instead of covering the whole range of body sizes
      if (
        (any(samples_fractions[samples_indices]=="0.8-3") || any(samples_fractions[samples_indices]=="0.8-5") || any(samples_fractions[samples_indices]=="0.8-inf"))
        &&
        (any(samples_fractions[samples_indices]=="3-20") || any(samples_fractions[samples_indices]=="5-20"))  
        &&
        any(samples_fractions[samples_indices]=="20-180") && any(samples_fractions[samples_indices]=="180-2000")
      )
      {
        # Choosing only one size fraction among overlapping size fractions (it occurs rarely)
        if (any(samples_fractions[samples_indices]=="0.8-5") && any(samples_fractions[samples_indices]=="0.8-inf"))
          samples_indices = samples_indices[-which(samples_fractions[samples_indices] == "0.8-inf")]
        if (any(samples_fractions[samples_indices]=="3-20") && any(samples_fractions[samples_indices]=="5-20"))
          samples_indices = samples_indices[-which(samples_fractions[samples_indices] == "3-20")]
        
        # Choosing in priority the sample with "DNA", then "WGA/DNA", then "RNA"
        for (size_fraction in c("0.8-inf","0.8-3","0.8-5","3-20","5-20","20-180","180-2000"))
        {
          if (length(which(samples_fractions[samples_indices]==size_fraction))>1)
          {
            matching_fraction_indices = which(samples_fractions[samples_indices]==size_fraction)
            if (length(which(samples_templates[samples_indices[matching_fraction_indices]]=="DNA"))>0)
            {
              nonMatching_template_indices = which(samples_templates[samples_indices[matching_fraction_indices]]!="DNA")
              samples_indices = samples_indices[-which(samples_indices == samples_indices[matching_fraction_indices[nonMatching_template_indices]])]
            } else
            {
              nonMatching_template_indices = which(samples_templates[samples_indices[matching_fraction_indices]]!="WGA/DNA")
              samples_indices = samples_indices[-which(samples_indices == samples_indices[matching_fraction_indices[nonMatching_template_indices]])]
            }
          } 
        }
        
        if (length(c(samples_indices[which(samples_fractions[samples_indices]=="0.8-3")],samples_indices[which(samples_fractions[samples_indices]=="0.8-5")],samples_indices[which(samples_fractions[samples_indices]=="0.8-inf")]))!=1
            || length(c(samples_indices[which(samples_fractions[samples_indices]=="3-20")],samples_indices[which(samples_fractions[samples_indices]=="5-20")]))!=1)
          stop(paste("Wrong number of size fractions:",group,station,depth))
        
        sample_index = vector(length=4,mode="numeric")
        # Storing the names of the samples corresponding to the current station, so as to look for them in data2m:
        sample_index[1] = c(samples_indices[which(samples_fractions[samples_indices]=="0.8-3")],samples_indices[which(samples_fractions[samples_indices]=="0.8-5")],samples_indices[which(samples_fractions[samples_indices]=="0.8-inf")])
        sample_index[2] = c(samples_indices[which(samples_fractions[samples_indices]=="3-20")],samples_indices[which(samples_fractions[samples_indices]=="5-20")])
        sample_index[3] = samples_indices[which(samples_fractions[samples_indices]=="20-180")]
        sample_index[4] = samples_indices[which(samples_fractions[samples_indices]=="180-2000")]
        
        OTU_relativeAbund[station_depth_index,] = 0
        for (i in 1:nrow(taxo_ref))
        {
          for (fraction in 1:4)
          {
            sample = sample_ref$Sample.id[sample_index[fraction]]
            sample_index_data2m = which(samples_data2m==sample)
            
            term1 = sum(data2m[i,sample_index_data2m])
            term2 = sum(data2m[,sample_index_data2m])
            
            # absoluteAbund[station_depth_index,i_taxon] = absoluteAbund[station_depth_index,i_taxon] + term1
            # denom_absoluteAbund = denom_absoluteAbund + term2
            OTU_relativeAbund[station_depth_index,i] = OTU_relativeAbund[station_depth_index,i] + term1/term2/4
          }
        }
        
        functions_relativeAbund0[station_depth_index,] = 0 
        functions_relativeAbund_selected0[station_depth_index,] = 0
        for (func in functions)
        {
          i_func = which(functions == func)
          OTU_indices = which(functions_OTUs == func)
          OTU_indices_selected = which(functions_OTUs == func & taxo_groups_OTUs %in% taxo_groups_unmodified[selected_groups])
          
          # denom_absoluteAbund = 0
          # denom_absoluteAbund_selected = 0
          for (fraction in 1:4)
          {
            sample = sample_ref$Sample.id[sample_index[fraction]]
            sample_index_data2m = which(samples_data2m==sample)
            
            term1 = sum(data2m[OTU_indices,sample_index_data2m])
            term1_selected = sum(data2m[OTU_indices_selected,sample_index_data2m])
            term2 = sum(data2m[,sample_index_data2m])
            term2_selected = sum(data2m[OTU_indices_all_selected,sample_index_data2m])
            
            # denom_absoluteAbund = denom_absoluteAbund + term2
            # denom_absoluteAbund_selected = denom_absoluteAbund_selected + term2_selected
            # functions_absoluteAbund[station_depth_index,i_func] = functions_absoluteAbund[station_depth_index,i_func] + term1
            functions_relativeAbund0[station_depth_index,i_func] = functions_relativeAbund0[station_depth_index,i_func] + term1/term2/4
            # functions_absoluteAbund_selected[station_depth_index,i_func] = functions_absoluteAbund_selected[station_depth_index,i_func] + term1_selected
            functions_relativeAbund_selected0[station_depth_index,i_func] = functions_relativeAbund_selected0[station_depth_index,i_func] + term1_selected/term2_selected/4
          }
          # functions_absoluteAbund[station_depth_index,i_func] = functions_absoluteAbund[station_depth_index,i_func]/denom_absoluteAbund
          # functions_absoluteAbund_selected[station_depth_index,i_func] = functions_absoluteAbund_selected[station_depth_index,i_func]/denom_absoluteAbund_selected
        }
        
        relativeAbund[station_depth_index,] = 0
        for (taxon in taxo_groups)
        {
          i_taxon = which(taxo_groups == taxon)
          # Using read abundance data after normalizing per station (and per sample for relativeAbund):
          group = taxo_groups_unmodified[i_taxon]
          #cat(paste0("\n",group," ",i_taxon,"/",length(taxo_groups)))
          OTU_indices = which(taxo_groups_OTUs == group)
          
          # denom_absoluteAbund = 0
          for (fraction in 1:4)
          {
            sample = sample_ref$Sample.id[sample_index[fraction]]
            sample_index_data2m = which(samples_data2m==sample)
            
            term1 = sum(data2m[OTU_indices,sample_index_data2m])
            term2 = sum(data2m[,sample_index_data2m])
            
            # absoluteAbund[station_depth_index,i_taxon] = absoluteAbund[station_depth_index,i_taxon] + term1
            # denom_absoluteAbund = denom_absoluteAbund + term2
            relativeAbund[station_depth_index,i_taxon] = relativeAbund[station_depth_index,i_taxon] + term1/term2/4
          }
          # absoluteAbund[station_depth_index,i_taxon] = absoluteAbund[station_depth_index,i_taxon]/denom_absoluteAbund
          
          if (station_depth_index == 1)
          {
            # functions_absoluteAbund = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = 0)
            functions_relativeAbund[[i_taxon]] = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = NA)
            # functions_absoluteAbund_selected = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = 0)
            functions_relativeAbund_selected[[i_taxon]] = matrix(nrow = nrow(coord), ncol = length(functions), dimnames = list(rownames(coord),functions), data = NA)
          }
          
          functions_relativeAbund[[i_taxon]][station_depth_index,] = 0 
          functions_relativeAbund_selected[[i_taxon]][station_depth_index,] = 0
          for (func in functions)
          {
            i_func = which(functions == func)
            OTU_indices = which(functions_OTUs == func & taxo_groups_OTUs != group)
            OTU_indices_selected = which(functions_OTUs == func & taxo_groups_OTUs %in% taxo_groups_unmodified[selected_groups] & taxo_groups_OTUs != group)
            
            # denom_absoluteAbund = 0
            # denom_absoluteAbund_selected = 0
            for (fraction in 1:4)
            {
              sample = sample_ref$Sample.id[sample_index[fraction]]
              sample_index_data2m = which(samples_data2m==sample)
              
              term1 = sum(data2m[OTU_indices,sample_index_data2m])
              term1_selected = sum(data2m[OTU_indices_selected,sample_index_data2m])
              term2 = sum(data2m[,sample_index_data2m])
              term2_selected = sum(data2m[OTU_indices_all_selected,sample_index_data2m])
              
              # denom_absoluteAbund = denom_absoluteAbund + term2
              # denom_absoluteAbund_selected = denom_absoluteAbund_selected + term2_selected
              # functions_absoluteAbund[station_depth_index,i_func] = functions_absoluteAbund[station_depth_index,i_func] + term1
              functions_relativeAbund[[i_taxon]][station_depth_index,i_func] = functions_relativeAbund[[i_taxon]][station_depth_index,i_func] + term1/term2/4
              # functions_absoluteAbund_selected[station_depth_index,i_func] = functions_absoluteAbund_selected[station_depth_index,i_func] + term1_selected
              functions_relativeAbund_selected[[i_taxon]][station_depth_index,i_func] = functions_relativeAbund_selected[[i_taxon]][station_depth_index,i_func] + term1_selected/term2_selected/4
            }
            # functions_absoluteAbund[station_depth_index,i_func] = functions_absoluteAbund[station_depth_index,i_func]/denom_absoluteAbund
            # functions_absoluteAbund_selected[station_depth_index,i_func] = functions_absoluteAbund_selected[station_depth_index,i_func]/denom_absoluteAbund_selected
          }
        }
      } else
        warning("\n! Missing fraction in",station,depth)
    }
    
    # saveRDS(relativeAbund,paste0(results_folder,"/groups_relativeAbund",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # saveRDS(list(functions_relativeAbund,functions_relativeAbund0),paste0(results_folder,"/functions_relativeAbund",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  }
  
  # selected_variables = c("Temperature","Salinity","ChlorophyllA","Oxygen")
  # selected_variables = colnames(sample_ref)[36:86]
  # selected_variables = c("Temperature","Conductivity","Salinity","Density","ChlorophyllA","Moon.phase.prop","Sunshine.duration","Iron.5m","Ammonium.5m","NO2.5m","NO3.5m")
  # selected_variables = "Temperature"
  # selected_variables = c("Temperature","Salinity","Density","ChlorophyllA","Sunshine.duration","Iron.5m","Ammonium.5m","NO2.5m","NO3.5m")
  #selected_variables = c("Temperature","Salinity","Density","ChlorophyllA","Seasonality_index.Temperature","Seasonality_index.Nitrates","Iron.5m","Ammonium.5m","NO2.5m","NO3.5m","Latitude")
  # federico_selected_variables = c("Iron.5m","Ammonium.5m","NO2.5m","NO3.5m")
  # federico_selected_variables = c("Iron.5m","Ammonium.5m","NO2.5m")
  federico_selected_variables = c("Iron.5m","Depth.nominal")
  # federico_selected_variables = "Iron.5m"
  # watteaux_selected_variables = c("Temperature","Latitude_woa13","Longitude_woa13","Nitrate","OxygenDissolved","OxygenSaturation","OxygenUtilization","Phosphate","Silicate","Distance_to_coast")
  watteaux_selected_variables = c("Temperature","Nitrate","OxygenDissolved","OxygenSaturation","OxygenUtilization","Phosphate","Silicate")
  # watteaux_selected_variables = c("Temperature","OxygenDissolved","OxygenSaturation","OxygenUtilization","Phosphate","Silicate","Distance_to_coast")
  colnames(station_ref_all) = watteaux_selected_variables
  
  # abiotic_data is defined with all selected_variables for plotting the spatial distribution maps
  abiotic_data = matrix(nrow = nrow(coord), ncol = length(federico_selected_variables),
                                      dimnames = list(rownames(coord), federico_selected_variables), data = 0)
  for (i in 1:nrow(coord))
  {
    sample_ref_indices = sample_ref$Station.label == stations_depths[i,1] & sample_ref$Depth == stations_depths[i,2]
    if (length(which(sample_ref_indices)) > 1)
    {
      abiotic_data[i,] = colMeans(apply(sample_ref[sample_ref_indices,federico_selected_variables],2,as.numeric),na.rm=T)
    } else
      abiotic_data[i,] = as.numeric(as.vector(sample_ref[sample_ref_indices,federico_selected_variables]))
  }
  # colnames(station_ref_Arctic) = watteaux_selected_variables
  # abiotic_data[,(length(federico_selected_variables)+1):(length(federico_selected_variables)+length(watteaux_selected_variables))] = rbind(station_ref[stations_depths[1:(which(stations_depths[,3] == "155_SUR")-1),3],watteaux_selected_variables],
  #                                                                                                                                          station_ref_Arctic[stations_depths[which(stations_depths[,4] == "155")[1]:nrow(stations_depths),4],])
  abiotic_data = cbind(abiotic_data,station_ref_all[stations_depths[,3],watteaux_selected_variables])
  abiotic_data = abiotic_data[,colnames(abiotic_data) != "Depth.nominal"]
  
  ##############################################################
  travel.folder_name = paste0(data_folder,"/Abiotic_data")
  travel_time_matrix_SUR = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_10.csv"),sep="\t",header=T,row.names=1)
  # travel_time_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_1000.csv"),sep="\t",header=T,row.names=1)
  travel_time_matrix_SUR = travel_time_matrix_SUR[,-ncol(travel_time_matrix_SUR)]
  travel_time_matrix_DCM = read.table(paste0(travel.folder_name,"/tarrive_min_75m_10.csv"),sep=";",header=T,row.names=1)
  for (i in 2:nrow(travel_time_matrix_DCM))
  {
    for (j in 1:(i-1))
    {
      travel_time_matrix_DCM[i,j] = travel_time_matrix_DCM[j,i] = min(travel_time_matrix_DCM[i,j],travel_time_matrix_DCM[j,i])
    }
  }
  # travel_time_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_1000.csv"),sep="\t",header=T,row.names=1)
  # travel_time_matrix_asym = read.table(paste0(travel.folder_name,"/tarrive_min_surface_10_asym.csv"),sep="\t",header=T,row.names=1)
  # travel_time_matrix_asym = travel_time_matrix_asym[,-ncol(travel_time_matrix_asym)]
  
  # nb_part_matrix_SUR = read.table(paste0(travel.folder_name,"/minAijji_tarrive_num_points_surface_10.csv"),sep="\t",header=T,row.names=1)
  # nb_part_matrix_SUR = nb_part_matrix_SUR[,-ncol(nb_part_matrix_SUR)]
  # nb_part_matrix_DCM = read.table(paste0(travel.folder_name,"/tarrive_num_points_75m_10.csv"),sep="\t",header=T,row.names=1)
  # nb_part_matrix_DCM = nb_part_matrix_DCM[,-ncol(nb_part_matrix_DCM)]
  
  # travel_time_matrix1000 = travel_time_matrix_SUR
  # travel_time_matrix1000[nb_part_matrix_SUR<1000] = NaN
  # travel_time_matrix_asym1000 = travel_time_matrix_asym
  # travel_time_matrix_asym1000[nb_part_matrix<1000] = NaN
  
  selected_travel_time_matrix_SUR = travel_time_matrix_SUR[selected_stations,paste0("X",selected_stations)]
  selected_travel_time_matrix_SUR = selected_travel_time_matrix_SUR[stations_depths[,2] == "SUR",stations_depths[,2] == "SUR"]
  selected_travel_time_matrix_DCM = travel_time_matrix_DCM[selected_stations,paste0("X",selected_stations)]
  selected_travel_time_matrix_DCM = selected_travel_time_matrix_DCM[stations_depths[,2] == "DCM",stations_depths[,2] == "DCM"]
  # selected_travel_time_matrix1000 = travel_time_matrix1000[selected_stations,paste0("X",selected_stations)]
  # selected_travel_time_matrix_asym1000 = travel_time_matrix_asym1000[selected_stations,paste0("X",selected_stations)]
  
  coord_SUR = coord[stations_depths[,2] == "SUR",]
  coord_DCM = coord[stations_depths[,2] == "DCM",]
  
  #######################################
  # Building t_min-based MEMs
  ###########################
  tmin_thres_SUR = 2.1
  tmin_thres_DCM = 3.15
  
  truncated_Tmin_SUR = as.matrix(selected_travel_time_matrix_SUR)
  truncated_Tmin_SUR[is.nan(truncated_Tmin_SUR)] = 4*tmin_thres_SUR
  truncated_Tmin_SUR[truncated_Tmin_SUR > tmin_thres_SUR] = 4*tmin_thres_SUR
  diag(truncated_Tmin_SUR) = 4*tmin_thres_SUR
  
  truncated_Tmin_DCM = as.matrix(selected_travel_time_matrix_DCM)
  truncated_Tmin_DCM[is.nan(truncated_Tmin_DCM)] = 4*tmin_thres_DCM
  truncated_Tmin_DCM[truncated_Tmin_DCM > tmin_thres_DCM] = 4*tmin_thres_DCM
  diag(truncated_Tmin_DCM) = 4*tmin_thres_DCM
  
  devtools::source_url("https://github.com/guilhemSK/Useful_functions/raw/main/pcoa.all_fun.R")
  truncated_Tmin_SUR_pcoa = pcoa.all(as.dist(truncated_Tmin_SUR), rn = rownames(coord_SUR))
  truncated_Tmin_DCM_pcoa = pcoa.all(as.dist(truncated_Tmin_DCM), rn = rownames(coord_DCM))
  
  SUR_MEM = matrix(nrow = nrow(coord), ncol = ncol(truncated_Tmin_SUR_pcoa$vectors), dimnames = list(rownames(coord),1:ncol(truncated_Tmin_SUR_pcoa$vectors)), data = 0)
  SUR_MEM[rownames(truncated_Tmin_SUR_pcoa$vectors),] = truncated_Tmin_SUR_pcoa$vectors
  SUR_MEM_restricted = truncated_Tmin_SUR_pcoa$vectors
  colnames(SUR_MEM_restricted) = paste("SUR.MEM",1:ncol(SUR_MEM_restricted))
  
  DCM_MEM = matrix(nrow = nrow(coord), ncol = ncol(truncated_Tmin_DCM_pcoa$vectors), dimnames = list(rownames(coord),1:ncol(truncated_Tmin_DCM_pcoa$vectors)), data = 0)
  DCM_MEM[rownames(truncated_Tmin_DCM_pcoa$vectors),] = truncated_Tmin_DCM_pcoa$vectors
  DCM_MEM_restricted = truncated_Tmin_DCM_pcoa$vectors
  colnames(DCM_MEM_restricted) = paste("DCM.MEM",1:ncol(DCM_MEM_restricted))
  
  #######################################
  # Building distance-based MEMs
  ##############################
  geographic_distances = as.matrix(read.table(paste0(data_folder,"/Abiotic_data/Geographic_distances.csv"),sep="\t",header=T,row.names=1))
  geographic_distances = geographic_distances[,-ncol(geographic_distances)]
  selected_geographic_distances = geographic_distances[selected_stations,paste0("X",selected_stations)]
  diag(selected_geographic_distances) = NA
  selected_geographic_distances_SUR = selected_geographic_distances[stations_depths[,2] == "SUR",stations_depths[,2] == "SUR"]
  selected_geographic_distances_DCM = selected_geographic_distances[stations_depths[,2] == "DCM",stations_depths[,2] == "DCM"]
  
  dis_thres_SUR = 4778
  truncated_dis_SUR = selected_geographic_distances_SUR
  truncated_dis_SUR[is.nan(truncated_dis_SUR)] = 4*dis_thres_SUR
  truncated_dis_SUR[truncated_dis_SUR 
                    > dis_thres_SUR] = 4*dis_thres_SUR
  diag(truncated_dis_SUR) = 4*dis_thres_SUR
  
  dis_thres_DCM = 4778
  truncated_dis_DCM = selected_geographic_distances_DCM
  truncated_dis_DCM[is.nan(truncated_dis_DCM)] = 4*dis_thres_DCM
  truncated_dis_DCM[truncated_dis_DCM > dis_thres_DCM] = 4*dis_thres_DCM
  diag(truncated_dis_DCM) = 4*dis_thres_DCM
  
  devtools::source_url("https://github.com/guilhemSK/Useful_functions/raw/main/pcoa.all_fun.R")
  truncated_dis_SUR_pcoa = pcoa.all(as.dist(truncated_dis_SUR), rn = rownames(coord_SUR))
  truncated_dis_DCM_pcoa = pcoa.all(as.dist(truncated_dis_DCM), rn = rownames(coord_DCM))
  
  SUR_dis_MEM = matrix(nrow = nrow(coord), ncol = ncol(truncated_dis_SUR_pcoa$vectors), 
                       dimnames = list(rownames(coord),1:ncol(truncated_dis_SUR_pcoa$vectors)), data = 0)
  SUR_dis_MEM[rownames(truncated_dis_SUR_pcoa$vectors),] = truncated_dis_SUR_pcoa$vectors
  SUR_dis_MEM_restricted = truncated_dis_SUR_pcoa$vectors
  colnames(SUR_dis_MEM_restricted) = paste("SUR.dis.MEM",1:ncol(SUR_dis_MEM_restricted))
  # SUR_dis_MEM_restricted[,c(1,2,5,6)] = -SUR_dis_MEM_restricted[,c(1,2,5,6)]
  # SUR_dis_MEM_restricted.ev = truncated_dis_SUR_pcoa$values

  DCM_dis_MEM = matrix(nrow = nrow(coord), ncol = ncol(truncated_dis_DCM_pcoa$vectors), 
                       dimnames = list(rownames(coord),1:ncol(truncated_dis_DCM_pcoa$vectors)), data = 0)
  DCM_dis_MEM[rownames(truncated_dis_DCM_pcoa$vectors),] = truncated_dis_DCM_pcoa$vectors
  DCM_dis_MEM_restricted = truncated_dis_DCM_pcoa$vectors
  colnames(DCM_dis_MEM_restricted) = paste("DCM.dis.MEM",1:ncol(DCM_dis_MEM_restricted))
  
  # mixed_layer = vector(length = nrow(coord), mode = "numeric")
  # names(mixed_layer) = rownames(coord)
  # for (i in 1:nrow(coord))
  # {
  #   sampling_depth = mean(as.numeric(sample_ref$Depth.nominal[sample_ref$Station.label == stations_depths[i,1] & sample_ref$Depth == stations_depths[i,2]]),na.rm=T)
  #   ML_depth = mean(sample_ref$Depth.Mixed.Layer[sample_ref$Station.label == stations_depths[i,1] & sample_ref$Depth == stations_depths[i,2]],na.rm=T)
  #   # Since all Sur samples are above the Mixed Layer Depth, we assume it as well for the only "NA" Mixed Layer Depth:
  #   if (is.na(ML_depth))
  #   {
  #     mixed_layer[i] = 1
  #   } else if (sampling_depth < ML_depth)
  #     mixed_layer[i] = 1
  # }
  
  # SUR_DCM_distance = matrix(nrow = nrow(coord), ncol = nrow(coord), dimnames = list(rownames(coord),rownames(coord)), data = 1)
  # for (i in 2:nrow(coord))
  # {
  #   for (j in 1:(i-1))
  #   {
  #     station_i = stations_depths[i,1]
  #     station_j = stations_depths[j,1]
  #     # If station label is different
  #     if (station_i == station_j && stations_depths[i,2] != stations_depths[j,2] && mixed_layer[i] == mixed_layer[j])
  #     {
  #       SUR_DCM_distance[i,j] = 0
  #     }
  #   }
  # }
  # SUR_DCM_distance_pcoa = pcoa(as.dist(SUR_DCM_distance))
  
  #############################################
  #Variation partitioning latitude vs. depth  #
  #############################################
  if (VEM)
  {
    varpart.latitude.depth = list()
    varpart.latitude.depth.pval = list()
    rda_available_groups = vector(length = length(taxo_groups), mode = "logical")
    rda_available_groups[1:(length(taxo_groups)-2)] = T
    for (taxon in taxo_groups)
    {
      i_taxon = which(taxon == taxo_groups)
      # taxon = "AllTaxa"
      if (taxon %in% taxo_groups[rda_available_groups])
      {
        cat("\n",taxon)
        
        # data.folder_name = paste0(data_folder,"/Old_data/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
        data.folder_name_taxon = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
        nb_topics = optimalK[i_taxon]
        spatial_topicmix_kriged = readRDS(paste0(data.folder_name_taxon,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
        # selecting the z.pred columns in all topics:
        documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
        # setting one topic per column and centering-standardizing:
        documents = scale(matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics))))
        latitude = scale(abs(coord$y[rownames(coord) %in% rownames(documents)]))
        stations_depths_dummy = vector(length = length(stations_depths$Depth), mode = "numeric")
        stations_depths_dummy[stations_depths$Depth == "SUR"] = 1
        stations_depths_dummy = scale(stations_depths_dummy[rownames(coord) %in% rownames(documents)])
        
        varpart.latitude.depth[[i_taxon]] = varpart(documents,latitude,stations_depths_dummy)$part$indfract$Adj.R.squared[-4]
        varpart.latitude.depth.pval[[i_taxon]] = c(anova(rda(documents,latitude,stations_depths_dummy))$'Pr(>F)'[1],
                                                   anova(rda(documents,stations_depths_dummy,latitude))$'Pr(>F)'[1],
                                                   anova(rda(documents,cbind(latitude,stations_depths_dummy)))$'Pr(>F)'[1])
      } else
      {
        varpart.latitude.depth[[i_taxon]] = rep(NA,3)
        varpart.latitude.depth.pval[[i_taxon]] = rep(NA,3)
      }
    }
    varpart.latitude.depth =  matrix(ncol = length(taxo_groups), nrow = 3, dimnames = list(c("Latitude only","Latitude and depth","Depth only"), taxo_groups), data = unlist(varpart.latitude.depth))
    varpart.latitude.depth.pval =  matrix(ncol = length(taxo_groups), nrow = 3, dimnames = list(c("Latitude only","Latitude and depth","Depth only"), taxo_groups), data = unlist(varpart.latitude.depth))
    
    #Figures:
    varpart.latitude.depth0 = varpart.latitude.depth
    varpart.latitude.depth0[varpart.latitude.depth0 < 0] = 0
    env_sorting = sort.int(colSums(varpart.latitude.depth0[,selected_groups]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
    
    shading_density = rbind(varpart.latitude.depth.pval[1,selected_groups][env_sorting],rep(0,length(taxo_groups[selected_groups])),varpart.latitude.depth.pval[2,selected_groups][env_sorting])
    shading_density[shading_density<0.05] = 0
    shading_density[shading_density>0] = 10
    
    pdf(paste0(figure_folder,"/varpart_lda_latitude_vs_depth_decreasingTotalVariance.pdf"))
    par(mar=c(7.1,4.1,4.1,2.1))
    #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
    x = barplot(varpart.latitude.depth0[,selected_groups][,env_sorting],col=terrain.colors(3),legend.text = T, xaxt="n", space = rep(1,ncol(shading_density)), args.legend = list(bty = "n"))
    for (i in 1:ncol(shading_density))
    {
      subbarplot = varpart.latitude.depth0[,selected_groups][,env_sorting]
      subbarplot[,-i] = 0
      barplot(subbarplot, col = "black", density = shading_density[,i], xaxt="n", yaxt="n", space = rep(1,ncol(shading_density)), add = T)
    }
    title(ylab="Explained variance (RDA)",cex.lab=1.3)
    labs = taxo_groups[selected_groups][env_sorting]
    text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
    dev.off()
    
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
    plot(log10(size_relativeAbund[selected_groups]),varpart.latitude.depth0[1,selected_groups])
    plot(log10(size_relativeAbund[selected_groups]),varpart.latitude.depth0[3,selected_groups])
    
    relativeAbund = readRDS(paste0(results_folder,"/groups_relativeAbund",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    plot(log10(colMeans(relativeAbund,na.rm = T)[selected_groups]),varpart.latitude.depth0[1,selected_groups])
    summary(lm(log10(colMeans(relativeAbund,na.rm = T)[selected_groups]) ~ varpart.latitude.depth0[1,selected_groups]))
    plot(log10(colMeans(relativeAbund,na.rm = T)[selected_groups]),varpart.latitude.depth0[3,selected_groups])
    
    plot(optimalK[selected_groups],varpart.latitude.depth0[1,selected_groups])
    plot(optimalK[selected_groups],varpart.latitude.depth0[3,selected_groups])
    
    prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_expTmin_1.5yearTminThres_10particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    plot(1-prop_within_OTU_vect[selected_groups],varpart.latitude.depth0[1,selected_groups])
    plot(1-prop_within_OTU_vect[selected_groups],varpart.latitude.depth0[3,selected_groups])
    
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    dominant_function0 = dominant_function[selected_groups]
    dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
    dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
    # Changes how the factors are stored so that geom_boxplot plots them by deceasing number of groups:
    dominant_function0 = factor(dominant_function0,names(sort(table(as.factor(dominant_function0)),decreasing = T)))
    boxplot.depth.fraction.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = varpart.latitude.depth0[3,selected_groups][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Variance explained by depth")
    pdf(paste0(figure_folder,"/varpart_depth_boxplot_functionalGroups_selected.pdf"))
    print(boxplot.depth.fraction.functions)
    dev.off()
    t.test(varpart.latitude.depth0[1,selected_groups][dominant_function0 == "phagotroph"],
           varpart.latitude.depth0[1,selected_groups][dominant_function0 == "parasite"])
    boxplot.latitude.fraction.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = varpart.latitude.depth0[1,selected_groups][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Variance explained by latitude")
    pdf(paste0(figure_folder,"/varpart_surface_boxplot_functionalGroups_selected.pdf"))
    print(boxplot.latitude.fraction.functions)
    dev.off()
    
  }
  ###################################
  
  ###################################
  # Old MEM decompositions          #
  ###################################     
  
  # tau = 1.5
  # # In expTmin_distance and Tmin_distance, Surface and DCM samples of the same station are perfectly connected (distance = 0)
  # expTmin_distance = matrix(nrow = nrow(coord), ncol = nrow(coord), dimnames = list(rownames(coord),rownames(coord)), data = 1)
  # Tmin_distance = matrix(nrow = nrow(coord), ncol = nrow(coord), dimnames = list(rownames(coord),rownames(coord)), data = 4*max(selected_travel_time_matrix,na.rm=T))
  # # In expTmin_distance1 and Tmin_distance1, Surface and DCM samples of the same station are well connected (1 day t_min) only if they belong to the same layer
  # expTmin_distance1 = matrix(nrow = nrow(coord), ncol = nrow(coord), dimnames = list(rownames(coord),rownames(coord)), data = 1)
  # Tmin_distance1 = matrix(nrow = nrow(coord), ncol = nrow(coord), dimnames = list(rownames(coord),rownames(coord)), data = 4*max(selected_travel_time_matrix,na.rm=T))
  # Tmin_distance2 = matrix(nrow = nrow(coord), ncol = nrow(coord), dimnames = list(rownames(coord),rownames(coord)), data = 4*max(selected_travel_time_matrix1000,na.rm=T))
  # for (i in 2:nrow(coord))
  # {
  #   for (j in 1:(i-1))
  #   {
  #     station_i = stations_depths[i,1]
  #     station_j = stations_depths[j,1]
  #     # If station label is different
  #     if (station_i != station_j)
  #     {
  #       if (!is.nan(selected_travel_time_matrix[i,j]))
  #       {
  #         expTmin_distance[i,j] = 1-exp(-selected_travel_time_matrix[i,j]/tau)
  #         Tmin_distance[i,j] = selected_travel_time_matrix[i,j]
  #         if (mixed_layer[i] == mixed_layer[j])
  #         {
  #           expTmin_distance1[i,j] = 1-exp(-selected_travel_time_matrix[i,j]/tau)
  #           Tmin_distance1[i,j] = selected_travel_time_matrix[i,j]
  #         }
  #       }
  #       if (!is.nan(selected_travel_time_matrix1000[i,j]))
  #       {
  #         if (mixed_layer[i] == mixed_layer[j])
  #         {
  #           if (selected_travel_time_matrix1000[i,j] < 10)
  #             Tmin_distance2[i,j] = selected_travel_time_matrix1000[i,j]
  #         }
  #       }
  #     } else if (station_i == station_j)
  #     {
  #       expTmin_distance[i,j] = 0
  #       Tmin_distance[i,j] = 0
  #       if (mixed_layer[i] == mixed_layer[j])
  #       {
  #         expTmin_distance1[i,j] = 1-exp(-min(selected_travel_time_matrix,na.rm=T)/tau)
  #         Tmin_distance1[i,j] = min(selected_travel_time_matrix,na.rm=T)
  #         Tmin_distance2[i,j] = min(selected_travel_time_matrix,na.rm=T)
  #       }
  #     }
  #   }
  # }
  # library(ape)
  # expTmin_distance_pcoa = pcoa(as.dist(expTmin_distance))
  # Tmin_distance_pcoa = pcoa(as.dist(Tmin_distance))
  # expTmin_distance_pcoa_vectors = expTmin_distance_pcoa$vectors
  # expTmin_distance1_pcoa = pcoa(as.dist(expTmin_distance1))
  # Tmin_distance1_pcoa = pcoa(as.dist(Tmin_distance1))
  # Tmin_distance2_pcoa = pcoa(as.dist(Tmin_distance2))
  # 
  # Tmin_connectivity = matrix(nrow = nrow(coord), ncol = nrow(coord), dimnames = list(1:nrow(coord),1:nrow(coord)), data = 0)
  # for (i in 1:nrow(coord))
  # {
  #   for (j in 1:nrow(coord))
  #   {
  #     station_i = stations_depths[i,1]
  #     station_j = stations_depths[j,1]
  #     # If station label is different
  #     if (station_i != station_j && !is.nan(selected_travel_time_matrix_asym1000[i,j]))
  #     {
  #       if (mixed_layer[i] == mixed_layer[j])
  #       {
  #         if (selected_travel_time_matrix_asym1000[i,j] < 10)
  #           Tmin_connectivity[i,j] = selected_travel_time_matrix_asym1000[i,j]
  #           # Tmin_connectivity[i,j] = 1
  #       }
  #     } else if (station_i == station_j && mixed_layer[i] == mixed_layer[j])
  #     {
  #       Tmin_connectivity[i,j] = min(selected_travel_time_matrix_asym1000,na.rm=T)
  #       # Tmin_connectivity[i,j] = 1
  #     }
  #   }
  # }
  # library(igraph)
  # # Getting a list of edges "link" form the connectivity matrix ("adjacency" matrix), along with a vector of weights "weight",
  # # to use in aem.build.binary:
  # # g = igraph::graph.adjacency(adjmatrix = Tmin_connectivity)
  # g = igraph::graph.adjacency(adjmatrix = Tmin_connectivity, mode = "directed", weighted = T)
  # link = apply(get.edgelist(g),2,as.numeric)
  # weights = edge_attr(g, "weight")
  # original_edge_names = apply(link,1,paste0,collapse="-")
  # names(weights) = original_edge_names
  # library(adespatial)
  # aem.build = adespatial::aem.build.binary(coords = cbind(site = 1:nrow(coord),coord[,c(2,1)]), link = link, rm.same.y = F)
  # aem_edge_names = as.vector(apply(aem.build$edges,1,paste0,collapse="-"))
  # weights = weights[original_edge_names %in% aem_edge_names]
  # # Tmin_1000p10y_aem = adespatial::aem(aem.build.binary = aem.build, weight = 1-weights/max(weights), rm.link0 = T)
  # Tmin_1000p10y_aem = adespatial::aem(aem.build.binary = aem.build, rm.link0 = T)
  # # Computing Moran's I (spatial autocorrelation) for each AEM vector and comparing it to its expected null value:
  # library(ape)
  # weight_matrix = 1-Tmin_connectivity/10
  # diag(weight_matrix) = 0
  # I = list()
  # pval = vector(length = ncol(Tmin_1000p10y_aem$vectors), mode = "numeric")
  # for (k in 1:ncol(Tmin_1000p10y_aem$vectors))
  # {
  #   I[[k]] = ape::Moran.I(Tmin_1000p10y_aem$vectors[,k],weight_matrix)
  #   pval[k] = I[[k]]$p.value
  # }
  # 
  # coord_SUR = coord[stations_depths[,2] == "SUR",]
  # expTmin_distance_SUR = matrix(nrow = nrow(coord_SUR), ncol = nrow(coord_SUR), dimnames = list(rownames(coord_SUR),rownames(coord_SUR)), data = 1)
  # Tmin_distance2_SUR = matrix(nrow = nrow(coord_SUR), ncol = nrow(coord_SUR), dimnames = list(rownames(coord_SUR),rownames(coord_SUR)), data = 4*max(selected_travel_time_matrix1000,na.rm=T))
  # selected_travel_time_matrix_SUR = selected_travel_time_matrix[stations_depths[,2] == "SUR",stations_depths[,2] == "SUR"]
  # selected_travel_time_matrix1000_SUR = selected_travel_time_matrix1000[stations_depths[,2] == "SUR",stations_depths[,2] == "SUR"]
  # for (i in 2:nrow(coord_SUR))
  # {
  #   for (j in 1:(i-1))
  #   {
  #     if (!is.nan(selected_travel_time_matrix_SUR[i,j]))
  #     {
  #       expTmin_distance_SUR[i,j] = 1-exp(-selected_travel_time_matrix_SUR[i,j]/tau)
  #     }
  #     if (!is.nan(selected_travel_time_matrix1000_SUR[i,j]) && selected_travel_time_matrix1000_SUR[i,j]<10)
  #     {
  #       Tmin_distance2_SUR[i,j] = selected_travel_time_matrix1000_SUR[i,j]
  #     }
  #   }
  # }
  # expTmin_distance_SUR_pcoa = pcoa(as.dist(expTmin_distance_SUR))
  # Tmin_distance2_SUR_pcoa = pcoa(as.dist(Tmin_distance2_SUR))
  # 
  # coord_DCM = coord[stations_depths[,2] == "DCM",]
  # expTmin_distance_DCM = matrix(nrow = nrow(coord_DCM), ncol = nrow(coord_DCM), dimnames = list(rownames(coord_DCM),rownames(coord_DCM)), data = 1)
  # selected_travel_time_matrix_DCM = selected_travel_time_matrix[stations_depths[,2] == "DCM",stations_depths[,2] == "DCM"]
  # for (i in 2:nrow(coord_DCM))
  # {
  #   for (j in 1:(i-1))
  #   {
  #     if (!is.nan(selected_travel_time_matrix_DCM[i,j]))
  #     {
  #       expTmin_distance_DCM[i,j] = 1-exp(-selected_travel_time_matrix_DCM[i,j]/tau)
  #     }
  #   }
  # }
  # expTmin_distance_DCM_pcoa = pcoa(as.dist(expTmin_distance_DCM))
  # 
  # library(vegan)
  # expTmin_distance_nmds = metaMDS(as.dist(expTmin_distance),autotransform = F,try=20,trymax=200,k=2)
  
  ###############################################################
  
  # Saving abiotic and biotic matrices for the whole dataset:
  abiotic_data_all = abiotic_data
  relativeAbund_all = relativeAbund
  functions_relativeAbund0_all = functions_relativeAbund0
  functions_relativeAbund_all = functions_relativeAbund
  
  nb_sites = matrix(nrow = length(target_groups), ncol = 2, dimnames = list(target_groups,c("SUR","DCM")), data=0)
  if (rda_all || rda_lda)
  {
    adjr2_individualAxes_abiotic = list(SUR=list(),DCM=list())
    pval_individualAxes_abiotic = list(SUR=list(),DCM=list())
    adjr2_individualAxes_relativeAbund = list(SUR=list(),DCM=list())
    pval_individualAxes_relativeAbund = list(SUR=list(),DCM=list())
    # adjr2_individualAxes_functions = list(SUR=list(),DCM=list())
    # pval_individualAxes_functions = list(SUR=list(),DCM=list())
    adjr2_individualAxes_MEM = list(SUR=list(),DCM=list())
    pval_individualAxes_MEM = list(SUR=list(),DCM=list())
    
    adjr2_lumpedAxes_abiotic = list(SUR=list(),DCM=list())
    pval_lumpedAxes_abiotic = list(SUR=list(),DCM=list())
    adjr2_lumpedAxes_relativeAbund = list(SUR=list(),DCM=list())
    pval_lumpedAxes_relativeAbund = list(SUR=list(),DCM=list())
    # adjr2_lumpedAxes_functions = list(SUR=list(),DCM=list())
    # pval_lumpedAxes_functions = list(SUR=list(),DCM=list())
    adjr2_lumpedAxes_MEM = list(SUR=list(),DCM=list())
    pval_lumpedAxes_MEM = list(SUR=list(),DCM=list())
    
    adjr2_orderedLumpedAxes_abiotic = list(SUR=list(),DCM=list())
    pval_orderedLumpedAxes_abiotic = list(SUR=list(),DCM=list())
    adjr2_orderedLumpedAxes_relativeAbund = list(SUR=list(),DCM=list())
    pval_orderedLumpedAxes_relativeAbund = list(SUR=list(),DCM=list())
    # adjr2_orderedLumpedAxes_functions = list(SUR=list(),DCM=list())
    # pval_orderedLumpedAxes_functions = list(SUR=list(),DCM=list())
    adjr2_orderedLumpedAxes_MEM = list(SUR=list(),DCM=list())
    pval_orderedLumpedAxes_MEM = list(SUR=list(),DCM=list())
    
    if (global_selection)
    {
      adjr2_orderedLumpedAxes_all = list(SUR=list(),DCM=list())
      pval_orderedLumpedAxes_all = list(SUR=list(),DCM=list())
    }
  }
  if (varpart_lda)
  {
    # varpart.groups = list()
    # varpart.groups.pval = list()
    
    # varpart.functions = list()
    # varpart.functions.pval = list()
    
    # varpart.groups.expTmin = list()
    # varpart.groups.expTmin.pval = list()
    
    varpart.env.spatial = list(SUR=list(),DCM=list())
    varpart.env.spatial.pval = list(SUR=list(),DCM=list())
    
    sub.varpart.biotic.abiotic = list(SUR=list(),DCM=list())
    sub.varpart.biotic.abiotic.pval = list(SUR=list(),DCM=list())
    
    # sub.varpart.SUR.DCM = list()
    # sub.varpart.SUR.DCM.pval = list()
    
    varpart.biotic.abiotic = list(SUR=list(),DCM=list())
    varpart.biotic.abiotic.pval = list(SUR=list(),DCM=list())
    
    # varpart.SUR.DCM = list()
    # varpart.SUR.DCM.pval = list()
  }
  if ((var_select || indiv_signif_axes_selection) && (rda_lda || varpart_lda))
  {
    no_selected_axes = list(SUR=matrix(nrow = length(target_groups), ncol = 3, data = NA),
                            DCM=matrix(nrow = length(target_groups), ncol = 3, data = NA))
    if (!var_select || !existing_var_selection)
    {
      env_selected = list(SUR=list(),DCM=list())
    } else
    {
      var_select_result = readRDS(paste0(results_folder,"/RDA",
                                         Gibbs_VEM_insert,target_groups_insert,
                                         "_separate.SUR.DCM_noSelectedAxes-envSelected-significantGlobalModel-nbSites",
                                         var.select_insert,preliminary_global_test_insert,indiv.signif.axes_insert,
                                         abiotic_pca_insert,biotic_pca_insert,dis_MEM_insert,stdzation_insert,noArcticNoBiomark_insert,
                                         "_eigenvalueThres0.8.rds"))
      env_selected = var_select_result[[2]]
      significant_global_model = var_select_result[[3]]
      # list(no_selected_axes,env_selected,significant_global_model,nb_sites)
    }
    
    if (var_select && !existing_var_selection)
    {
      if (!global_selection)
      {
        significant_global_model= list(SUR=list(),DCM=list())
      } else
      {
        significant_global_model = list(SUR=vector(length = length(target_groups), mode = "logical"),
                                        DCM=vector(length = length(target_groups), mode = "logical"))
      }
    }
  }
  ################################
  # Start of Surf. DCM dichotomy #
  ################################
  for (case in c("SUR","DCM"))
  {
    cat(paste0("\n",case,":"))
    i_case = which(c("SUR","DCM") == case)
    abiotic_data = abiotic_data_all[stations_depths[,2] == case,]
    relativeAbund = relativeAbund_all[stations_depths[,2] == case,]
    functions_relativeAbund0 = functions_relativeAbund0_all[stations_depths[,2] == case,]
    
    rownames_done = 0
    if (rda_all || rda_lda)
    {
      rownames_lumpedAxes = list()
      rownames_orderedLumpedAxes = list()
    }
    
    # Ice.free.period is always equal to 365 days if we remove the Arctic
    # Residence.time is not an abiotic variable strictly speaking (?):
    # abiotic_data_trans = abiotic_data[,colnames(abiotic_data) != "Ice.free.period" & colnames(abiotic_data) != "Residence.time"]
    # Removing abiotic variable with more than a certain number of NA stations-detphs (out of 143 without Arctic, 172 with Arctic):
    if (any(apply(abiotic_data,2,is.na)))
    {
      abiotic_data_trans = abiotic_data[,!(as.vector(unlist(lapply(apply(apply(abiotic_data,2,is.na),2,which),length))) > 3)]
    } else 
      abiotic_data_trans = abiotic_data
    if (rda_all || rda_lda)
    {
      # Centering and standardizing the abiotic data:
      # abiotic_data_trans = sweep(sweep(abiotic_data_trans,2,colMeans(abiotic_data_trans, na.rm = T),"-"),2,apply(abiotic_data_trans,2,sd,na.rm=T),"/")
      abiotic_data_trans = scale(abiotic_data_trans)
    }
    
    # lost_stations = vector(length = 143, mode = "numeric")
    # for (k in 1:143)
    #   lost_stations[k] = length(colnames(abiotic_data)[which(as.vector(unlist(lapply(apply(apply(abiotic_data,2,is.na),2,which),length))) > k)])
    # plot(1:143,lost_stations)
    
    if (abiotic_pca)
    {
      ######################
      if (VEM)
      {
        if (old_data)
        {
          data.folder_name = paste0(data_folder,"/Old_data/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
          nb_topics = 10
          spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
          coord0 = coord
          # Need to load again coord only for old_data, for which coord differ
          load(paste0(data.folder_name,"/coord.Rdata"))
          
          AllTaxa_topics = c("Upwelling","Indian Ocean","Medit.","Temp. Atlantic","Tropical DCM","Tropical Surf.","C. Pacific","E. Pacific","W. Atlantic","Red Sea")
          topicmix = matrix(nrow = nrow(coord), ncol = nb_topics, dimnames = list(rownames(coord),AllTaxa_topics), data = 0)
          for (k in 1:nb_topics)
            topicmix[,k] = spatial_topicmix_kriged[[k]]$z.pred
          topicmix = topicmix[rownames(coord0),]
          coord = coord0
        }
        
        # data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
        # data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
        nb_topics = 7
        spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
        
        # spatial_topicmix_kriged doesn't necessarily have the same number of rows as coord, but for AllTaxa it does. 
        # spatial_topicmix_kriged and coord follow the same row names.
        AllTaxa_topics = 1:nb_topics
        topicmix = matrix(nrow = nrow(coord), ncol = nb_topics, dimnames = list(rownames(coord),AllTaxa_topics), data = 0)
        for (k in 1:nb_topics)
          topicmix[,k] = spatial_topicmix_kriged[[k]]$z.pred
        
        dominant_topic = vector(length = nrow(topicmix), mode = "numeric")
        for (i in 1:length(dominant_topic))
        {
          if (length(which(topicmix[i,] == max(topicmix[i,]))) == 1)
            dominant_topic[i] = which(topicmix[i,] == max(topicmix[i,]))
          else
            dominant_topic[i] = sample(which(topicmix[i,] == max(topicmix[i,])),1)
        }
        
        # Taking the first sample belonging to the right station and depth, for station-depth in coord, so as to access its abiotic measurements (all equal for the same station-depth)
        sample_ref_indices = vector(length = nrow(coord), mode = "numeric")
        for (i in 1:nrow(coord))
          sample_ref_indices[i] = which(sample_ref$Station.label == stations_depths[i,1] & sample_ref$Depth == stations_depths[i,2])[1]
        
        geographic_classes = matrix(nrow = nrow(coord), ncol = 4, 
                                    dimnames = list(rownames(coord), c("Marine.biome","Ocean.region","Biogeographical.province","LDA.AllTaxa.topics")) , data = 0)
        for (k in 1:3)
        {
          geographic_classes[,k] = sample_ref[sample_ref_indices,c("Marine.biome","Ocean.region","Biogeographical.province")[k]]
          if (k == 2 || k == 3)
          {
            # for Ocean.region and Biogeographical.province, keeping only the abbreviation so as not to overload the figure:
            l = lapply(geographic_classes[,k],strsplit," ")
            for (i in 1:nrow(coord))
            {
              geographic_classes[i,k] = unlist(l[[i]])[1]
            }
          }
        }
        geographic_classes[,4] = AllTaxa_topics[dominant_topic]
      }
      ######################
      
      library(ade4)
      
      # PCA on standardized ("normed") data, ie centered and divided by std. dev. for each column 
      # Removing stations where one abiotic value is missing:
      stations_to_remove = apply(apply(abiotic_data_trans,2,is.na),1,any)
      # Removing Latitude from the abiotic variables on which PCA is applied
      abiotic_PCA = dudi.pca(as.data.frame(abiotic_data_trans[!stations_to_remove,colnames(abiotic_data_trans)!="Distance_to_coast"]), row.w = rep(1, nrow(abiotic_data_trans[!stations_to_remove,]))/nrow(abiotic_data_trans[!stations_to_remove,]), 
                             # col.w = rep(1, ncol(abiotic_data_trans) - 1),
                             # col.w = c(1,1/3,1/3,1/3,1,1/3,1/3,1/3,1,1),
                             col.w = rep(1,ncol(abiotic_data_trans)),
                             # col.w = c(1,1,1,1/3,1/3,1/3,1,1),
                             center = TRUE, scale = TRUE, scannf = F, nf = ncol(abiotic_data_trans))
    }
    
    if (biotic_pca)
    {
      library(ade4)
      # PCA on standardized ("normed") data, ie centered and divided by std. dev. for each column 
      # read_abundance_PCA = dudi.pca(as.data.frame(read_abundance_per_group[,selected_groups]), row.w = rep(1, nrow(read_abundance_per_group))/nrow(read_abundance_per_group), 
      #                               col.w = rep(1, ncol(read_abundance_per_group[,selected_groups])),
      #                               center = TRUE, scale = FALSE, scannf = F, nf = ncol(read_abundance_per_group[,selected_groups]))
      
      # absoluteAbund_PCA = dudi.pca(as.data.frame(absoluteAbund_trans[,selected_groups]), row.w = rep(1, nrow(absoluteAbund_trans))/nrow(absoluteAbund_trans), 
      #                              col.w = rep(1, ncol(absoluteAbund_trans[,selected_groups])),
      #                              center = TRUE, scale = TRUE, scannf = F, nf = ncol(absoluteAbund_trans[,selected_groups]))
      
      stations_to_remove = apply(apply(relativeAbund,2,is.na),1,any)
      # pca_selected_groups = sort.int(colMeans(relativeAbund[!stations_to_remove,selected_groups]), decreasing = T, index.return = T)$ix[1:69]
      relativeAbund_PCA0 = dudi.pca(as.data.frame(relativeAbund[!stations_to_remove,selected_groups]), row.w = rep(1, nrow(relativeAbund[!stations_to_remove,]))/nrow(relativeAbund[!stations_to_remove,]), 
                                    col.w = rep(1, ncol(relativeAbund[,selected_groups])),
                                    center = T, scale = stdzation_biotic_pca, scannf = F, nf = ncol(relativeAbund[,selected_groups]))
      
      # functions_absoluteAbund_PCA = dudi.pca(as.data.frame(functions_absoluteAbund_trans), row.w = rep(1, nrow(functions_absoluteAbund_trans))/nrow(functions_absoluteAbund_trans),
      #                                        col.w = rep(1, ncol(functions_absoluteAbund_trans)),
      #                                        center = TRUE, scale = TRUE, scannf = F, nf = ncol(functions_absoluteAbund_trans))
      
      # stations_to_remove = apply(apply(functions_relativeAbund,2,is.na),1,any)
      functions_relativeAbund_PCA0 = dudi.pca(as.data.frame(functions_relativeAbund0[!stations_to_remove,colnames(functions_relativeAbund0)!="unknown"]), row.w = rep(1, nrow(relativeAbund[!stations_to_remove,]))/nrow(relativeAbund[!stations_to_remove,]),
                                              col.w = rep(1, ncol(functions_relativeAbund0[,colnames(functions_relativeAbund0)!="unknown"])),
                                              center = T, scale = stdzation_biotic_pca, scannf = F, nf = ncol(functions_relativeAbund0[,colnames(functions_relativeAbund0)!="unknown"]))
      
      # functions_absoluteAbund_selected_PCA = dudi.pca(as.data.frame(functions_absoluteAbund_selected_trans), row.w = rep(1, nrow(functions_absoluteAbund_selected_trans))/nrow(functions_absoluteAbund_selected_trans), 
      #                                        col.w = rep(1, ncol(functions_absoluteAbund_selected_trans)),
      #                                        center = TRUE, scale = TRUE, scannf = F, nf = ncol(functions_absoluteAbund_selected_trans))
      
      # stations_to_remove = apply(apply(functions_relativeAbund_selected,2,is.na),1,any)
      # functions_relativeAbund_selected_PCA0 = dudi.pca(as.data.frame(functions_relativeAbund_selected0[!stations_to_remove,colnames(functions_relativeAbund0)!="unknown"]), row.w = rep(1, nrow(relativeAbund[!stations_to_remove,]))/nrow(relativeAbund[!stations_to_remove,]), 
      #                                        col.w = rep(1, ncol(functions_relativeAbund0[,colnames(functions_relativeAbund0)!="unknown"])),
      #                                        center = TRUE, scale = stdzation_biotic_pca, scannf = F, nf = ncol(functions_relativeAbund0[,colnames(functions_relativeAbund0)!="unknown"]))
      
      functions_relativeAbund_PCA = list()
      functions_relativeAbund = list()
      # functions_relativeAbund_selected_PCA = list()
      relativeAbund_PCA = list()
      for (taxon in taxo_groups)
      {
        i_taxon = which(taxo_groups == taxon)
        functions_relativeAbund[[i_taxon]] = functions_relativeAbund_all[[i_taxon]][stations_depths[,2] == case,]
        functions_relativeAbund_PCA[[i_taxon]] = dudi.pca(as.data.frame(functions_relativeAbund[[i_taxon]][!stations_to_remove,colnames(functions_relativeAbund0)!="unknown"]), row.w = rep(1, nrow(relativeAbund[!stations_to_remove,]))/nrow(relativeAbund[!stations_to_remove,]),
                                                          col.w = rep(1, ncol(functions_relativeAbund0[,colnames(functions_relativeAbund0)!="unknown"])),
                                                          center = T, scale = stdzation_biotic_pca, scannf = F, nf = ncol(functions_relativeAbund0[,colnames(functions_relativeAbund0)!="unknown"]))
        
        # functions_absoluteAbund_selected_PCA = dudi.pca(as.data.frame(functions_absoluteAbund_selected_trans), row.w = rep(1, nrow(functions_absoluteAbund_selected_trans))/nrow(functions_absoluteAbund_selected_trans), 
        #                                        col.w = rep(1, ncol(functions_absoluteAbund_selected_trans)),
        #                                        center = TRUE, scale = TRUE, scannf = F, nf = ncol(functions_absoluteAbund_selected_trans))
        
        # functions_relativeAbund_selected_PCA[[i_taxon]] = dudi.pca(as.data.frame(functions_relativeAbund_selected[[i_taxon]][!stations_to_remove,colnames(functions_relativeAbund0)!="unknown"]), row.w = rep(1, nrow(relativeAbund[!stations_to_remove,]))/nrow(relativeAbund[!stations_to_remove,]), 
        #                                                            col.w = rep(1, ncol(functions_relativeAbund0[,colnames(functions_relativeAbund0)!="unknown"])),
        #                                                            center = TRUE, scale = stdzation_biotic_pca, scannf = F, nf = ncol(functions_relativeAbund0[,colnames(functions_relativeAbund0)!="unknown"]))
        
        relativeAbund_PCA[[i_taxon]] = dudi.pca(as.data.frame(relativeAbund[!stations_to_remove, selected_groups & colnames(relativeAbund) != taxon]), row.w = rep(1, nrow(relativeAbund[!stations_to_remove,]))/nrow(relativeAbund[!stations_to_remove,]), 
                                                col.w = rep(1, ncol(relativeAbund[,selected_groups & colnames(relativeAbund) != taxon])),
                                                center = T, scale = stdzation_biotic_pca, scannf = F, nf = ncol(relativeAbund[,selected_groups & colnames(relativeAbund) != taxon]))
      }
    }
    
    # Variance_Inflation_Factor = diag(solve(cor(relativeAbund[!stations_to_remove,selected_groups])))
    # 
    # stations_to_remove = apply(apply(functions_relativeAbund,2,is.na),1,any)
    # cor_i = vector(length = ncol(functions_relativeAbund), mode = "numeric")
    # for (i in 1:ncol(functions_relativeAbund))
    # {
    #   cor_i[i] = cor(rowSums(functions_relativeAbund[!stations_to_remove,-i]),functions_relativeAbund[!stations_to_remove,i])
    # }
    
    # increasing_llh = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # alpha_best_real = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # 
    # selected_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
    # selected_groups = rep(T,length(taxo_groups))
    
    # varpart.groups.variable.nb.of.axes = list()
    # varpart.groups.pval.variable.nb.of.axes = list()
    # for (i_axis in 2:30)
    # {
    
    if (abiotic_dissimilarity_all)
    {
      Mantel_out = list()
      mantelslope = list()
      mantelr2 = list()
      mantelpval = list()
      # mantelslope_allvariables = vector(length = length(taxo_groups), mode = "numeric")
      # mantelr2_allvariables = vector(length = length(taxo_groups), mode = "numeric")
      # mantelpval_allvariables = vector(length = length(taxo_groups), mode = "numeric")
      # !!!! Length to be defined manually !!!!!
      plot.abiotic.dis = vector(length = 4+1, mode = "list")
    }
    if (relative_abiotic_sd_per_OTU)
    {
      OTU_abiotic_dispersion_allOTUs = list()
      mean_OTU_abiotic_dispersion = list()
    }
    if (relative_abiotic_dissimilarity_per_OTU)
    {
      dissimilarity_within_OTU_allOTUs = list()
      mean_dissimilarity_within_OTU = list()
    }
    # rda_available_groups = vector(length = length(taxo_groups), mode = "logical")
    rda_available_groups = selected_groups
    # rda_available_groups[1:133] = T
    # rda_available_groups[1:(length(taxo_groups)-2)] = T
    # rda_available_groups[1:length(taxo_groups)] = T
    ii_taxon = 0
    for (taxon in target_groups)
    {
      if (taxon == "AllTaxa")
      {
        ii_taxon = 1
      } else
      {
        i_taxon = which(taxon == target_groups)
        ii_taxon = ii_taxon+1
      }
      # i_taxon = 1
      # taxon = "AllTaxa"
      
      if (rda_lda || varpart_lda)
      {
        if (abiotic_pca)
        {
          abiotic_data_trans_taxon = abiotic_PCA$li[,abiotic_PCA$eig > 0.8]
          # abiotic_data_trans_taxon = cbind(abiotic_PCA$li[,1:3],'Distance to coast' = abiotic_data_trans[!stations_to_remove,"Distance_to_coast"])
          # abiotic_data_trans_taxon = abiotic_PCA$li[,1:3]
          # abiotic_data_trans_taxon = abiotic_PCA$li[,1:2]
        } else
          abiotic_data_trans_taxon = abiotic_data_trans
        
        if (taxon == "AllTaxa")
        {
          if (biotic_pca)
          {
            # Selecting the same number of columns for every group (based on the PCA performed on all groups, instead of all groups minus the one considered):
            relativeAbund_taxon = relativeAbund_PCA0$li[,which(relativeAbund_PCA0$eig > 0.8)]
            functions_relativeAbund_taxon = functions_relativeAbund_PCA0$li[,which(functions_relativeAbund_PCA0$eig > 0.9)]
          } else
          {
            relativeAbund_taxon = relativeAbund
            functions_relativeAbund_taxon = functions_relativeAbund0
          }
        } else
        {
          if (biotic_pca)
          {
            # read_abundance_per_group_trans_taxon = read_abundance_PCA$li[,1:3]
            # absoluteAbund_trans_taxon = absoluteAbund_PCA$li
            # if (rda_lda)
            # {
            # Selecting the same number of columns for every group (based on the PCA performed on all groups, instead of all groups minus the one considered):
            relativeAbund_taxon = relativeAbund_PCA[[i_taxon]]$li[,which(relativeAbund_PCA0$eig > 0.8)]
            functions_relativeAbund_taxon = functions_relativeAbund_PCA[[i_taxon]]$li[,which(functions_relativeAbund_PCA0$eig > 0.9)]
            # } else
            # {
            #   relativeAbund_taxon = relativeAbund_PCA[[i_taxon]]$li[,which(relativeAbund_PCA[[i_taxon]]$eig/sum(relativeAbund_PCA[[i_taxon]]$eig) > 1/nrow(relativeAbund_PCA[[i_taxon]]$co)*0.9)]
            #   functions_relativeAbund_taxon = functions_relativeAbund_PCA[[i_taxon]]$li[,which(functions_relativeAbund_PCA[[i_taxon]]$eig/sum(functions_relativeAbund_PCA[[i_taxon]]$eig) > 1/nrow(functions_relativeAbund_PCA[[i_taxon]]$co)*0.9)]
            # }
            # relativeAbund_taxon = relativeAbund_PCA[[i_taxon]]$li[,1:i_axis]
            # functions_absoluteAbund_trans_taxon = functions_absoluteAbund_PCA$li
            # functions_relativeAbund_taxon = functions_relativeAbund_PCA[[i_taxon]]$li[,1:2]
            # functions_absoluteAbund_selected_trans_taxon = functions_absoluteAbund_selected_PCA$li
            # functions_relativeAbund_selected_trans_taxon = functions_relativeAbund_selected_PCA$li
          } else
          {
            # read_abundance_per_group_trans_taxon = read_abundance_per_group_trans
            # absoluteAbund_trans_taxon = absoluteAbund_trans
            relativeAbund_taxon = relativeAbund
            # functions_absoluteAbund_trans_taxon = functions_absoluteAbund_trans
            functions_relativeAbund_taxon = functions_relativeAbund[[i_taxon]]
            # functions_absoluteAbund_selected_trans_taxon = functions_absoluteAbund_selected_trans
            # functions_relativeAbund_selected_trans_taxon = functions_relativeAbund_selected_trans
          }
        }
      }
      
      if (taxon %in% taxo_groups[rda_available_groups] || taxon == "AllTaxa")
      {
        cat("\n",taxon)
        
        # data.folder_name = paste0(data_folder,"/Old_data/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
        # data.folder_name_taxon = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
        data.folder_name_taxon = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
        
        if (rda_all || abiotic_dissimilarity_all || relative_abiotic_sd_per_OTU || relative_abiotic_dissimilarity_per_OTU)
        {
          load(paste0(data.folder_name_taxon,"/data2m.Rdata"))
          
          documents = t(data2m)
          rownames(documents) = rownames(coord)
          # Removing missing stations-depths in data2m (there are no missing OTUs by construction)
          documents = documents[rowMeans(documents, na.rm = T) != 0,]
          
          if (abiotic_pca)
          {
            # abiotic_data_trans_taxon = abiotic_PCA$li[,abiotic_PCA$eig/sum(abiotic_PCA$eig) > 1/ncol(abiotic_data_trans)]
            # abiotic_data_trans_taxon = cbind(abiotic_PCA$li[,1:3],'Distance to coast' = abiotic_data_trans[!stations_to_remove,"Distance_to_coast"])
            abiotic_data_trans_taxon = abiotic_PCA$li[,1:3]
          } else
            abiotic_data_trans_taxon = abiotic_data_trans
          
          # Removing missing stations-depths in documents to match abiotic_data_trans_taxon:
          documents = documents[rownames(documents) %in% rownames(abiotic_data_trans_taxon),]
          # Removing missing stations-depths in the abiotic data to match documents:
          abiotic_data_trans_taxon = abiotic_data_trans_taxon[rownames(documents),]
          
          if (rda_all)
          {
            # Centering and standardazing the data by column (i.e. by OTU for rda_all and by topic for rda_lda)
            # documents = sweep(sweep(documents,2,colMeans(documents, na.rm = T),"-"),2,apply(documents,2,sd,na.rm=T),"/")
            documents = scale(documents)
          } else if (abiotic_dissimilarity_all)
          {
            # Computing dissimilarity between rows (stations-detphs)
            hellinger_documents = 1/sqrt(2)*dist(sqrt(documents), method = "euclidean", diag = FALSE, upper = FALSE)
            sorensen_documents = vegan::designdist(documents, "(b+c)/(2*a+b+c)", abcd=TRUE)
          }
          
          if (abiotic_dissimilarity_all || relative_abiotic_dissimilarity_per_OTU)
          {
            abiotic_dissimilarity = list()
            rownames_Mantel_out = vector(length = 2*ncol(abiotic_data_trans_taxon)-1, mode = "character")
            # Computing abiotic dissimilarities as the norm of the differences between stations-depths for individual variables, and then based on all variables
            for (k in 1:ncol(abiotic_data_trans_taxon))
            {
              if (k == 1)
              {
                rownames_Mantel_out[1] = rownames(abiotic_data_trans_taxon)[1]
                abiotic_dissimilarity[[1]] = dist(abiotic_data_trans_taxon[,1], method = "euclidean", diag = FALSE, upper = FALSE)
              } else
              {
                rownames_Mantel_out[2*(k-1)] = rownames(abiotic_data_trans_taxon)[k]
                abiotic_dissimilarity[[2*(k-1)]] = dist(abiotic_data_trans_taxon[,k], method = "euclidean", diag = FALSE, upper = FALSE)
                rownames_Mantel_out[2*(k-1)+1] = paste(rownames(abiotic_data_trans_taxon)[1:k],collapse="-")
                abiotic_dissimilarity[[2*(k-1)+1]] = dist(abiotic_data_trans_taxon[,1:k], method = "euclidean", diag = FALSE, upper = FALSE)
              }
            }
            # abiotic_dissimilarity[[ncol(abiotic_data_trans_taxon) + 1]] = dist(abiotic_data_trans_taxon, method = "euclidean", diag = FALSE, upper = FALSE)
          }
        }
        
        # if rda_lda, the documents and abiotic_data_trans variables of abiotic_dissimilarity_all are overloaded
        if (rda_lda || varpart_lda)
        {
          if (VEM)
          {
            nb_topics = optimalK[i_taxon]
            spatial_topicmix_kriged = readRDS(paste0(data.folder_name_taxon,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
            # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/2nd_best_realization_maxmatching/Spatial_topicmix_kriged.rds"))
            # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/3rd_best_realization_maxmatching/Spatial_topicmix_kriged.rds"))
            # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/1st_best_realization/Spatial_topicmix_kriged.rds"))
          
            # selecting the z.pred columns in all topics:
            documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
            # setting one topic per column
            documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics)))
          } else if (Gibbs)
          {
            # nb_topics = optimalK_min.crossValid[i_taxon]
            if (taxon == "AllTaxa")
              nb_topics = optimalK_prevalence.min.crossValid.allTaxa
            else   
              nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
            spatial_topicmix_kriged = readRDS(paste0(data.folder_name_taxon,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds"))
          
            # selecting the z.pred columns in all topics:
            documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
            # setting one topic per column
            documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics)))
          } else if (Functional)
          {
            if (length(target_groups) > 1 || target_groups != "AllTaxa")
              stop("Functional analysis only applies for AllTaxa")
            
            load(paste0(data.folder_name_taxon,"/coord.Rdata"))
            
            load(paste0(data.folder_name_taxon,"/data2m.Rdata"))
            # load(paste0(data.folder_name,"/data2m_unmerged.Rdata"))
            # data2m = data2m0
            # samples_data2m = colnames(data2m)
            load(paste0(data.folder_name_taxon,"/taxo_ref.Rdata"))
            functions_OTUs = taxo_ref$Function
            #functions = levels(as.factor(functions_OTUs))[sort.int(table(as.factor(functions_OTUs)),index.return = T,decreasing = T)$ix]
            functions = c("phototroph","photohost","endophotosymbiont","phagotroph","copepoda","pteropoda","gelatineous_carnivores_filterers","other metazoa","parasite","unknown")
            function_names = c("Phototroph","Photohost","Endophotosymbiont","Phagotroph","Copepoda","Pteropoda","Gel. carn. filterers","Other metazoa","Parasite","Unknown")
            # function_colors = c("darkgreen","chartreuse2","orange","firebrick2","cadetblue","darkblue","darkturquoise","dodgerblue1","darkgoldenrod1","grey")
            
            documents = matrix(nrow = ncol(data2m), ncol = length(functions), data = 0, dimnames = list(rownames(coord),function_names))
            for (j in 1:length(functions))
            {
              for (i in 1:ncol(data2m))
                documents[i,j] = length(which(data2m[,i] > 0 & functions_OTUs == functions[j]))
            }
            documents = t(scale(t(documents),center=F,scale=rowSums(documents)))
          }
          
          # Selecting a subset of stations-depths for each ocean:
          documents = documents[stations_depths[rownames(coord) %in% rownames(documents),2] == case,]
          # Hellinger transformation (aimed at making the distribution of assemblage proportions across samples closer to normal but does not make much of a difference):
          # documents = sqrt(documents)
          
          # Removing missing stations-depths in documents to match abiotic and biotic data:
          # - in practice, for most selected groups, it is "relativeAbund" that is limiting for the number of stations, because 14 stations are removed in which not all size fractions are available,
          # while those fractions were not removed in the LDA input data (because the 0.8-inf size fraction was considered as making up for missing size fractions), and therefore are present in the LDA output ("documents").
          documents = documents[rownames(documents) %in% rownames(abiotic_data_trans_taxon) & rownames(documents) %in% rownames(relativeAbund_taxon),]
          # Removing missing stations-depths in the abiotic and biotic data to match documents:
          abiotic_data_trans_taxon = abiotic_data_trans_taxon[rownames(documents),]
          # read_abundance_per_group_trans_taxon = read_abundance_per_group_trans_taxon[rownames(documents),]
          # absoluteAbund_trans_taxon = absoluteAbund_trans_taxon[rownames(documents),]
          relativeAbund_taxon = relativeAbund_taxon[rownames(documents),]
          # functions_absoluteAbund_trans_taxon = functions_absoluteAbund_trans_taxon[rownames(documents),]
          functions_relativeAbund_taxon = functions_relativeAbund_taxon[rownames(documents),]
          # functions_absoluteAbund_selected_trans_taxon = functions_absoluteAbund_selected_trans_taxon[rownames(documents),]
          # functions_relativeAbund_selected_trans_taxon = functions_relativeAbund_selected_trans_taxon[rownames(documents),]
          # expTmin_distance_pcoa_vectors_taxon = expTmin_distance_pcoa_vectors[rownames(documents),]
          if (case == "SUR")
          {
            if (dis_MEM)
            {
              MEM_taxon = SUR_dis_MEM_restricted[rownames(documents),]
            } else
              MEM_taxon = SUR_MEM_restricted[rownames(documents),]
          } else if (case == "DCM")
          {
            if (dis_MEM)
            {
              MEM_taxon = DCM_dis_MEM_restricted[rownames(documents),]
            } else
              MEM_taxon = DCM_MEM_restricted[rownames(documents),]
          }
          # mixed_layer_taxon = mixed_layer[rownames(documents)]
          
          nb_sites[ii_taxon,i_case] = nrow(documents)
          
          # Centering and standardazing the data by column (i.e. by OTU for rda_all and by topic for rda_lda) 
          # - standardizing not mandatory but required for using the F-statistic_based test
          # documents = sweep(sweep(documents,2,colMeans(documents, na.rm = T),"-"),2,apply(documents,2,sd,na.rm=T),"/")
          # Equivalent to using sweep: scale(data.frame)
          documents = scale(documents)
          
          # expTmin_distance_pcoa_vectors_taxon = expTmin_distance_pcoa_vectors
          # PCA and PCoA axes are already centered, but not standardized (sd set to 1).
          # They have to be centered again due to the removal of some stations.
          # Standardization does not change anything from a mathematical perspective but is preferable from a computational one (Legendre and Legendre).
          # expTmin_distance_pcoa_vectors_taxon = scale(expTmin_distance_pcoa_vectors_taxon)
          MEM_taxon = scale(MEM_taxon)
          relativeAbund_taxon = scale(relativeAbund_taxon)
          functions_relativeAbund_taxon = scale(functions_relativeAbund_taxon)
          abiotic_data_trans_taxon = scale(abiotic_data_trans_taxon)
          
          # Distinguishing between the names of the different sets of axes:
          colnames(abiotic_data_trans_taxon) = paste0("abiotic.",colnames(abiotic_data_trans_taxon))
          colnames(relativeAbund_taxon) = paste0("biotic.",colnames(relativeAbund_taxon))
          colnames(functions_relativeAbund_taxon) = paste0("functions.",colnames(functions_relativeAbund_taxon))
          # colnames(expTmin_distance_pcoa_vectors_taxon) = paste0("expTmin.",colnames(expTmin_distance_pcoa_vectors_taxon))
          if (case == "SUR")
          {
            colnames(MEM_taxon) = paste0("MEM.SUR.",1:ncol(MEM_taxon))
          } else if (case == "DCM")
          {
            colnames(MEM_taxon) = paste0("MEM.DCM.",1:ncol(MEM_taxon))
          }
          # names(mixed_layer_taxon) = paste0("Mixed.layer.",names(mixed_layer_taxon))
          
          env_descriptor_list = list(abiotic_data_trans_taxon,relativeAbund_taxon,MEM_taxon)
          # Performing variable selection:
          if (var_select && !existing_var_selection || indiv_signif_axes_selection)
          {
            if (!var_select || !global_selection)
            {
              descriptor_case_vect = c(1,2,3)
              if (var_select)
                significant_global_model[[i_case]][[ii_taxon]] = vector(length = 3, mode = "logical")
            } else
              # case 4 corresponds to global selection across all explanatory variables:
              descriptor_case_vect = 4
            env_selected[[i_case]][[ii_taxon]] = list()
            for (descriptor_case in descriptor_case_vect)
            {
              if (descriptor_case != 4)
              {
                env_descriptor = env_descriptor_list[[descriptor_case]]
              } else
              {
                env_descriptor = cbind(env_descriptor_list[[1]],env_descriptor_list[[2]],env_descriptor_list[[3]])
                cor_all_env_descriptors[[i_case]][[ii_taxon]] = cor(env_descriptor)
              }
              
              env_selected[[i_case]][[ii_taxon]][[descriptor_case]] = vector(length = ncol(env_descriptor), mode = "logical")
              
              # Selecting at least the axes that are individually significant 
              if (indiv_signif_axes_selection)
              {
                if (BH_correction)
                  pval_vec = vector(length = ncol(env_descriptor), mode = "numeric")
                for (i in 1:ncol(env_descriptor))
                {
                  # Performing RDA on individual axes:
                  RDA = rda(documents ~ as.vector(env_descriptor[,i]), na.action = na.exclude)
                  pval = as.numeric(anova(RDA)$'Pr(>F)'[1])
                  if (!is.na(pval))
                  {
                    if (BH_correction)
                    {
                      # Saving pval for Benjamini-Hochberg procedure:
                      pval_vec[i] = pval 
                    } else
                      # Applying a 0.05 significance threshold without correction:
                      env_selected[[i_case]][[ii_taxon]][[descriptor_case]][i] = pval < 0.05
                  } else
                    pval_vec[i] = NA
                }
                
                # Moran.labs.cols <- function(Moran.obs,Moran.pval)
                # {
                #   x.labs = paste("I =",round(as.vector(do.call(c,Moran.obs),mode="numeric"),digits=3))
                #   x.labs[is.na(as.vector(do.call(c,Moran.obs),mode="numeric"))] = ""
                #   pval.vec = as.vector(do.call(c,Moran.pval),mode="numeric")
                #   high.cols = rep("red",length(pval.vec))
                #   # No correction - setting in magenta the samples with pval < 0.05,
                #   # i.e. plots with a significant spatial structure:
                #   high.cols[pval.vec < 0.05 & !is.na(pval.vec)] = "mediumvioletred" #magenta
                #   # Applying the Benjamini-Hochberg multiple comparison correction procedure:
                #   BH_criterium = 1:length(pval.vec[!is.na(pval.vec)])*0.05/length(pval.vec[!is.na(pval.vec)])
                #   sorted.pval.vec = sort.int(pval.vec[!is.na(pval.vec)], decreasing = F, index.return = T)
                #   true_vec = which(sorted.pval.vec$x < BH_criterium)
                #   # Setting in purple the plots with pval lower than the largest pval satisfying the criterium: 
                #   if (length(true_vec) > 0)
                #     high.cols[!is.na(pval.vec)][sorted.pval.vec$ix[1:true_vec[length(true_vec)]]] = "blueviolet" #purple
                #   # Applying the Bonferoni multiple comparison correction procedure
                #   # - setting in blue the samples satisfying the cirterium:
                #   high.cols[pval.vec < 0.05/length(pval.vec[!is.na(pval.vec)]) & !is.na(pval.vec)] = "blue"
                #   
                #   return(list(x.labs,high.cols))
                # }
                
                if (BH_correction)
                {
                  # Benjamini-Hochberg procedure:
                  BH_criterium = 1:length(pval_vec[!is.na(pval_vec)])*0.05/length(pval_vec[!is.na(pval_vec)])
                  sorted_pval_vec = sort.int(pval_vec[!is.na(pval_vec)], decreasing = F, index.return = T)
                  # Axes satisfying the criterium:
                  true_vec = which(sorted_pval_vec$x < BH_criterium)
                  # Keeping all axes with pval lower than the largest pval satisfying the criterium:
                  if (length(true_vec) > 0)
                    env_selected[[i_case]][[ii_taxon]][[descriptor_case]][!is.na(pval.vec)][sorted_pval_vec$ix[1:true_vec[length(true_vec)]]] = T
                }
              }
              
              if (var_select)
              {
                # Performing a global test on the set of axes:
                RDA0 = rda(documents ~ 1, data = as.data.frame(env_descriptor), na.action = na.exclude)
                RDA_global_test = rda(documents ~ as.matrix(env_descriptor), na.action = na.exclude)
                positive_global_test = length(anova(RDA_global_test)$'Pr(>F)'[1]) > 0 && !is.na(anova(RDA_global_test)$'Pr(>F)'[1]) && anova(RDA_global_test)$'Pr(>F)'[1] < 0.05
                # env_selected[[i_taxon]][[case]] = rep(F,ncol(env_descriptor))
                # Performing a variable selection (if preliminary_global_test=1: only if the global test is positive):
                if (!preliminary_global_test && !is.na(anova(RDA_global_test)$'Pr(>F)'[1]) || positive_global_test)
                {
                  RDA_selected = ordiR2step(RDA0, scope = as.formula(paste("documents ~", paste(colnames(env_descriptor), collapse = " + "))), 
                                            # direction = "forward", trace = F)
                                            direction = "both", trace = F)
                  # If indiv_signif_axes_selection=1, the axes are selected if they are either individually significant or selected by the variable selection procedure:
                  if (length(rownames(RDA_selected$CCA$biplot)) > 0 && !is.na(rownames(RDA_selected$CCA$biplot)))
                    env_selected[[i_case]][[ii_taxon]][[descriptor_case]] = env_selected[[i_case]][[ii_taxon]][[descriptor_case]] | colnames(env_descriptor) %in% rownames(RDA_selected$CCA$biplot)
                }
                if (positive_global_test)
                {
                  if (!global_selection)
                    significant_global_model[[i_case]][[ii_taxon]][descriptor_case] = T
                  else
                    significant_global_model[[i_case]][ii_taxon] = T
                }
              }
              
              # Keeping only the selected axes for each set of variables:
              if (descriptor_case == 4)
              {
                env_selected[[i_case]][[ii_taxon]][[4]] = as.factor(env_selected[[i_case]][[ii_taxon]][[4]])
                names(env_selected[[i_case]][[ii_taxon]][[4]]) = colnames(env_descriptor)
                env_selected[[i_case]][[ii_taxon]][[1]] = as.vector(env_selected[[i_case]][[ii_taxon]][[4]][colnames(abiotic_data_trans_taxon)], mode = "logical")
                env_selected[[i_case]][[ii_taxon]][[2]] = as.vector(env_selected[[i_case]][[ii_taxon]][[4]][colnames(relativeAbund_taxon)], mode = "logical")
                env_selected[[i_case]][[ii_taxon]][[3]] = as.vector(env_selected[[i_case]][[ii_taxon]][[4]][colnames(MEM_taxon)], mode = "logical")
                env_selected[[i_case]][[ii_taxon]][[4]] = as.vector(env_selected[[i_case]][[ii_taxon]][[4]], mode = "logical")
              }
            }
          }
        }
        
        # for (i_taxon in 1:length(taxo_groups))
        #   env_selected[[i_taxon]][[5]] = as.vector(env_selected[[i_taxon]][[5]], mode = "logical")
        
        #############
        if (rda_all || rda_lda)
        {
          if (!global_selection)
            descriptor_case_vect = c(1,2,3)
          else
            descriptor_case_vect = c(1,2,3,4)
          for (descriptor_case in descriptor_case_vect)
          {
            if (descriptor_case != 4)
            {
              env_descriptor = env_descriptor_list[[descriptor_case]]
            } else
            {
              env_descriptor = cbind(env_descriptor_list[[1]],env_descriptor_list[[2]],env_descriptor_list[[3]])
            }
            
            if (descriptor_case != 4)
            {
              RDA_out_lda_individualAxes = matrix(nrow = ncol(env_descriptor), ncol = 3, data = 0)
              # colnames(RDA_out_lda_individualAxes) = c("R2.fraction","Adjusted.R2.fraction","p.value")
              # rownames(RDA_out_lda_individualAxes) = colnames(env_descriptor)
              RDA_out_lda_lumpedAxes = matrix(nrow = ncol(env_descriptor), ncol = 3, data = 0)
              # colnames(RDA_out_lda_lumpedAxes) = c("R2.fraction","Adjusted.R2.fraction","p.value")
              # rownames(RDA_out_lda_lumpedAxes) = rep(NA,nrow(RDA_out_lda_lumpedAxes))
              if (!rownames_done)
                rownames_lumpedAxes[[descriptor_case]] = rep(NA,ncol(env_descriptor))
              # Computing RDA significance for all individual variables, as well as for combinations of variables, 
              # either in their original order (lumpedAxes), or ranked by the variance they explain individually in the data (orderedLumpedAxes)
              for (i in 1:ncol(env_descriptor))
              {
                # Performing RDA on individual axes:
                RDA = rda(documents ~ as.vector(env_descriptor[,i]), na.action = na.exclude)
                Rsquare = RDA$CCA$eig/RDA$tot.chi
                if (length(Rsquare)==0)
                  Rsquare = 0
                pval = anova(RDA)$'Pr(>F)'[1]
                if (is.na(pval))
                  pval = 1
                RDA_out_lda_individualAxes[i,] = as.numeric(unlist(c(Rsquare,RsquareAdj(RDA)[2],pval)))
                
                # Performing RDA on lumped axes:
                RDA = rda(documents ~ as.matrix(env_descriptor[,1:i]), na.action = na.exclude)
                if (!rownames_done)
                {
                  if (i == 1)
                    rownames_lumpedAxes[[descriptor_case]][1] = colnames(env_descriptor)[1]
                  else
                    rownames_lumpedAxes[[descriptor_case]][i] = paste(c(colnames(env_descriptor)[1],colnames(env_descriptor)[i]),collapse="-")
                }
                # rownames(RDA_out_lda_lumpedAxes)[i-1] = rownames_lumpedAxes[[case]][i-1]
                RDA_out_lda_lumpedAxes[i,] = as.numeric(unlist(c(sum(RDA$CCA$eig)/RDA$tot.chi,RsquareAdj(RDA)[2],anova(RDA)$'Pr(>F)'[1])))
                # sum(RDA$CA$eig/RDA$tot.chi) + RDA$CCA$eig/RDA$tot.chi = 1 :
                # [sum of the eigenvalues of the unconstrained Canonical Axes (CA)]/Trace + [eigenvalue of the contrained CA]/Trace = 1 
              }
            }
            
            # Performing RDA on lumped axes, adding lumped axes by increasing order of contribution to explained variance:
            if (!rownames_done)
              rownames_orderedLumpedAxes[[descriptor_case]] = rep(NA,ncol(env_descriptor))
            RDA_out_lda_orderedLumpedAxes = matrix(nrow = ncol(env_descriptor), ncol = 3, data = 0)
            for (i in 1:ncol(env_descriptor))
            {
              if (descriptor_case != 4)
              {
                RDA = rda(documents ~ as.matrix(env_descriptor[,sort.int(RDA_out_lda_individualAxes[,2],index.return = T, decreasing = T)$ix[1:i]]), na.action = na.exclude)
              } else
              {
                adjr2_all_individualAxes = c(adjr2_individualAxes_abiotic[[i_case]][[ii_taxon]],adjr2_individualAxes_relativeAbund[[i_case]][[ii_taxon]],adjr2_individualAxes_MEM[[i_case]][[ii_taxon]])
                RDA = rda(documents ~ as.matrix(env_descriptor[,sort.int(adjr2_all_individualAxes,index.return = T, decreasing = T)$ix[1:i]]), na.action = na.exclude)
              }
              if (!rownames_done)
              {
                if (i == 1)
                  rownames_orderedLumpedAxes[[descriptor_case]][1] = paste("Ordered",colnames(env_descriptor)[1])
                else
                  rownames_orderedLumpedAxes[[descriptor_case]][i] = paste(c(paste("Ordered",colnames(env_descriptor)[1]),paste("Ordered",colnames(env_descriptor)[i])),collapse="-")
              }
              RDA_out_lda_orderedLumpedAxes[i,] = as.numeric(unlist(c(sum(RDA$CCA$eig)/RDA$tot.chi,RsquareAdj(RDA)[2],anova(RDA)$'Pr(>F)'[1])))
            }
            
            if (descriptor_case == 1)
            {
              adjr2_individualAxes_abiotic[[i_case]][[ii_taxon]] = RDA_out_lda_individualAxes[,2]
              pval_individualAxes_abiotic[[i_case]][[ii_taxon]] = RDA_out_lda_individualAxes[,3]
              adjr2_lumpedAxes_abiotic[[i_case]][[ii_taxon]] = RDA_out_lda_lumpedAxes[,2]
              pval_lumpedAxes_abiotic[[i_case]][[ii_taxon]] = RDA_out_lda_lumpedAxes[,3]
              adjr2_orderedLumpedAxes_abiotic[[i_case]][[ii_taxon]] = RDA_out_lda_orderedLumpedAxes[,2]
              pval_orderedLumpedAxes_abiotic[[i_case]][[ii_taxon]] = RDA_out_lda_orderedLumpedAxes[,3]
            } else if (descriptor_case == 2)
            {
              adjr2_individualAxes_relativeAbund[[i_case]][[ii_taxon]] = RDA_out_lda_individualAxes[,2]
              pval_individualAxes_relativeAbund[[i_case]][[ii_taxon]] = RDA_out_lda_individualAxes[,3]
              adjr2_lumpedAxes_relativeAbund[[i_case]][[ii_taxon]] = RDA_out_lda_lumpedAxes[,2]
              pval_lumpedAxes_relativeAbund[[i_case]][[ii_taxon]] = RDA_out_lda_lumpedAxes[,3]
              adjr2_orderedLumpedAxes_relativeAbund[[i_case]][[ii_taxon]] = RDA_out_lda_orderedLumpedAxes[,2]
              pval_orderedLumpedAxes_relativeAbund[[i_case]][[ii_taxon]] = RDA_out_lda_orderedLumpedAxes[,3]
            } else if (descriptor_case == 3)
            {
              adjr2_individualAxes_MEM[[i_case]][[ii_taxon]] = RDA_out_lda_individualAxes[,2]
              pval_individualAxes_MEM[[i_case]][[ii_taxon]] = RDA_out_lda_individualAxes[,3]
              adjr2_lumpedAxes_MEM[[i_case]][[ii_taxon]] = RDA_out_lda_lumpedAxes[,2]
              pval_lumpedAxes_MEM[[i_case]][[ii_taxon]] = RDA_out_lda_lumpedAxes[,3]
              adjr2_orderedLumpedAxes_MEM[[i_case]][[ii_taxon]] = RDA_out_lda_orderedLumpedAxes[,2]
              pval_orderedLumpedAxes_MEM[[i_case]][[ii_taxon]] = RDA_out_lda_orderedLumpedAxes[,3]
            } else if (descriptor_case == 4)
            {
              adjr2_orderedLumpedAxes_all[[i_case]][[ii_taxon]] = RDA_out_lda_orderedLumpedAxes[,2]
              pval_orderedLumpedAxes_all[[i_case]][[ii_taxon]] = RDA_out_lda_orderedLumpedAxes[,3]
            }
          }
          rownames_done = 1
        }
        
        if (varpart_lda)
        {
          if (var_select || indiv_signif_axes_selection)
          {
            if (length(env_selected[[i_case]][[ii_taxon]][[1]]) > 0 && any(env_selected[[i_case]][[ii_taxon]][[1]]))
            {
              abiotic_data_trans_taxon = as.matrix(abiotic_data_trans_taxon)[,env_selected[[i_case]][[ii_taxon]][[1]]]
              no_selected_axes[[i_case]][ii_taxon,1] = F
            } else
              no_selected_axes[[i_case]][ii_taxon,1] = T
            
            if (length(env_selected[[i_case]][[ii_taxon]][[2]]) > 0 && any(env_selected[[i_case]][[ii_taxon]][[2]]))
            {
              relativeAbund_taxon = as.matrix(relativeAbund_taxon)[,env_selected[[i_case]][[ii_taxon]][[2]]]
              no_selected_axes[[i_case]][ii_taxon,2] = F
            } else 
              no_selected_axes[[i_case]][ii_taxon,2] = T
            
            if (length(env_selected[[i_case]][[ii_taxon]][[3]]) > 0 && any(env_selected[[i_case]][[ii_taxon]][[3]]))
            {
              MEM_taxon = as.matrix(MEM_taxon)[,env_selected[[i_case]][[ii_taxon]][[3]]]
              no_selected_axes[[i_case]][ii_taxon,3] = F
            } else
              no_selected_axes[[i_case]][ii_taxon,3] = T
          } else
          {
            abiotic_data_trans_taxon = as.matrix(abiotic_data_trans_taxon)
            relativeAbund_taxon = as.matrix(relativeAbund_taxon)
            MEM_taxon = as.matrix(MEM_taxon)
          }
            
          # if (!no_selected_axes[1] && !no_selected_axes[2])
          # {
          #   varpart.groups[[i_taxon]] = varpart(documents,abiotic_data_trans_taxon,relativeAbund_taxon)$part$indfract$Adj.R.squared[-4]
          #   varpart.groups.pval[[i_taxon]] = c(anova(rda(documents,abiotic_data_trans_taxon,relativeAbund_taxon))$'Pr(>F)'[1],
          #                                      anova(rda(documents,relativeAbund_taxon,abiotic_data_trans_taxon))$'Pr(>F)'[1],
          #                                      anova(rda(documents,cbind(abiotic_data_trans_taxon,relativeAbund_taxon)))$'Pr(>F)'[1])
          # } else
          # {
          #   varpart.groups[[i_taxon]] = rep(NA,3)
          #   varpart.groups.pval[[i_taxon]] = rep(NA,3)
          # }
          
          # if (!no_selected_axes[1] && !no_selected_axes[3])
          # {
          #   varpart.functions[[i_taxon]] = varpart(documents,abiotic_data_trans_taxon,functions_relativeAbund_taxon)$part$indfract$Adj.R.squared[-4]
          #   varpart.functions.pval[[i_taxon]] = c(anova(rda(documents,abiotic_data_trans_taxon,functions_relativeAbund_taxon))$'Pr(>F)'[1],
          #                                       anova(rda(documents,functions_relativeAbund_taxon,abiotic_data_trans_taxon))$'Pr(>F)'[1],
          #                                       anova(rda(documents,cbind(abiotic_data_trans_taxon,functions_relativeAbund_taxon)))$'Pr(>F)'[1])
          # } else
          # {
          #   varpart.functions[[i_taxon]] = rep(NA,3)
          #   varpart.functions.pval[[i_taxon]] = rep(NA,3)
          # }
          
          # ("Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents")
          
          # if (!no_selected_axes[1] && !no_selected_axes[2] && !no_selected_axes[4])
          # {
          #   varpart.groups.expTmin[[i_taxon]] = varpart(documents,abiotic_data_trans_taxon,relativeAbund_taxon,expTmin_distance_pcoa_vectors_taxon)$part$indfract$Adj.R.square[-8][c(2,4,5,7,1,6,3)]
          #   varpart.groups.expTmin.pval[[i_taxon]] = c(anova(rda(documents,abiotic_data_trans_taxon,cbind(relativeAbund_taxon,expTmin_distance_pcoa_vectors_taxon)))$'Pr(>F)'[1],
          #                                              anova(rda(documents,relativeAbund_taxon,cbind(abiotic_data_trans_taxon,expTmin_distance_pcoa_vectors_taxon)))$'Pr(>F)'[1],
          #                                              anova(rda(documents,expTmin_distance_pcoa_vectors_taxon,cbind(abiotic_data_trans_taxon,relativeAbund_taxon)))$'Pr(>F)'[1],
          #                                              anova(rda(documents,cbind(abiotic_data_trans_taxon,relativeAbund_taxon,expTmin_distance_pcoa_vectors_taxon)))$'Pr(>F)'[1])
          # } else
          # {
          #   varpart.groups.expTmin[[i_taxon]] = rep(NA,7)
          #   varpart.groups.expTmin.pval[[i_taxon]] = rep(NA,4)
          # }
          
          if (!var_select || all(!no_selected_axes[[i_case]][ii_taxon,]))
          {
            # if (!no_selected_axes[i_taxon,6])
            #   currents_MEM = cbind(SUR_MEM_taxon,DCM_MEM_taxon,mixed_layer_taxon)
            # else
            #   currents_MEM = cbind(SUR_MEM_taxon,DCM_MEM_taxon)
            
            global_pval = anova(rda(documents,cbind(MEM_taxon,abiotic_data_trans_taxon,relativeAbund_taxon)))$'Pr(>F)'[1]
            
            #################
            # ("Pure environment","Mixed env. currents","Pure currents")
            varpart.env.spatial[[i_case]][[ii_taxon]] = varpart(documents,cbind(abiotic_data_trans_taxon,relativeAbund_taxon),MEM_taxon)$part$indfract$Adj.R.square[-4]
            varpart.env.spatial.pval[[i_case]][[ii_taxon]] = c(anova(rda(documents,cbind(abiotic_data_trans_taxon,relativeAbund_taxon),MEM_taxon))$'Pr(>F)'[1],
                                                            anova(rda(documents,MEM_taxon,cbind(abiotic_data_trans_taxon,relativeAbund_taxon)))$'Pr(>F)'[1],
                                                            global_pval)
            
            #################
            # (a             ,  b           ,  c             , d                     , e                      , f                       , g                             )
            # ("Pure abiotic", "Pure biotic", "Pure currents", "Mixed biotic-abiotic", "Mixed biotic-currents", "Mixed abiotic-currents", Mixed biotic-abiotic-currents")
            sub.varpart.biotic.abiotic[[i_case]][[ii_taxon]] = varpart(documents,abiotic_data_trans_taxon,relativeAbund_taxon,MEM_taxon)$part$indfract$Adj.R.square[-8]
            sub.varpart.biotic.abiotic.pval[[i_case]][[ii_taxon]] = c(anova(rda(documents,abiotic_data_trans_taxon,cbind(relativeAbund_taxon,MEM_taxon)))$'Pr(>F)'[1],
                                                                   anova(rda(documents,relativeAbund_taxon,cbind(abiotic_data_trans_taxon,MEM_taxon)))$'Pr(>F)'[1],
                                                                   anova(rda(documents,MEM_taxon,cbind(relativeAbund_taxon,abiotic_data_trans_taxon)))$'Pr(>F)'[1],
                                                                   global_pval)
            
            #################
            # (a                  , b                 , c                 , d                 , e              , f                     , g                    , h              , i              , j                ,
            # ("Pure SUR currents","Pure DCM currents", "Pure Mixed Layer", "Pure environment", "Mixed SUR-DCM", "Mixed DCM-MixedLayer", 'Mixed SUR-MixedLayer", "Mixed SUR-env., Mixed DCM-env.", "MixedLayer-env.",
            # k                   , l                         , m                    , n                    , o                              ) 
            # "Mixed SUR-DCM-env.", "Mixed SUR-DCM-MixedLayer", "DCM-MixedLayer-env.", "SUR-MixedLayer-env.", "Mixed SUR-DCM-MixedLayer-env.")
            # if (!no_selected_axes[i_taxon,6])
            # {
            #   sub.varpart.SUR.DCM[[i_taxon]] = varpart(documents,SUR_MEM_taxon,DCM_MEM_taxon,mixed_layer_taxon,cbind(abiotic_data_trans_taxon,relativeAbund_taxon))$part$indfract$Adj.R.square[-16]
            #   sub.varpart.SUR.DCM.pval[[i_taxon]] = c(anova(rda(documents,SUR_MEM_taxon,cbind(DCM_MEM_taxon,mixed_layer_taxon,abiotic_data_trans_taxon,relativeAbund_taxon)))$'Pr(>F)'[1],
            #                                           anova(rda(documents,DCM_MEM_taxon,cbind(SUR_MEM_taxon,mixed_layer_taxon,relativeAbund_taxon,abiotic_data_trans_taxon)))$'Pr(>F)'[1],
            #                                           anova(rda(documents,mixed_layer_taxon,cbind(SUR_MEM_taxon,DCM_MEM_taxon,relativeAbund_taxon,abiotic_data_trans_taxon)))$'Pr(>F)'[1],
            #                                           anova(rda(documents,cbind(relativeAbund_taxon,abiotic_data_trans_taxon),cbind(mixed_layer_taxon,SUR_MEM_taxon,DCM_MEM_taxon)))$'Pr(>F)'[1],
            #                                           global_pval)
            # } else
            # {
            #   # (a                  ,  b                 ,  c                , d              , e                     , f                     , g                        )
            #   # ("Pure SUR currents", "Pure DCM currents", "Pure environment", "Mixed SUR-DCM", "Mixed DCM-environment", "Mixed SUR-environment", Mixed SUR-DCM-environment")
            #   sub.varpart.SUR.DCM.taxon = varpart(documents,SUR_MEM_taxon,DCM_MEM_taxon,cbind(abiotic_data_trans_taxon,relativeAbund_taxon))$part$indfract$Adj.R.square[-8]
            #   sub.varpart.SUR.DCM[[i_taxon]] = c(sub.varpart.SUR.DCM.taxon[1:2],0,sub.varpart.SUR.DCM.taxon[3:4],0,0,sub.varpart.SUR.DCM.taxon[c(6,5)],0,sub.varpart.SUR.DCM.taxon[7],0,0,0,0)
            #   sub.varpart.SUR.DCM.pval[[i_taxon]] = c(anova(rda(documents,SUR_MEM_taxon,cbind(DCM_MEM_taxon,abiotic_data_trans_taxon,relativeAbund_taxon)))$'Pr(>F)'[1],
            #                                           anova(rda(documents,DCM_MEM_taxon,cbind(SUR_MEM_taxon,relativeAbund_taxon,abiotic_data_trans_taxon)))$'Pr(>F)'[1],
            #                                           1,
            #                                           anova(rda(documents,cbind(relativeAbund_taxon,abiotic_data_trans_taxon),cbind(SUR_MEM_taxon,DCM_MEM_taxon)))$'Pr(>F)'[1],
            #                                           global_pval)
            # }
            
            ################
            # ("Pure abiotic","Mixed abiotic-biotic","Pure biotic")
            varpart.biotic.abiotic[[i_case]][[ii_taxon]] = varpart(documents,abiotic_data_trans_taxon,relativeAbund_taxon)$part$indfract$Adj.R.square[-4]
            varpart.biotic.abiotic.pval[[i_case]][[ii_taxon]] = c(anova(rda(documents,abiotic_data_trans_taxon,relativeAbund_taxon))$'Pr(>F)'[1],
                                                               anova(rda(documents,relativeAbund_taxon,abiotic_data_trans_taxon))$'Pr(>F)'[1],
                                                               anova(rda(documents,cbind(relativeAbund_taxon,abiotic_data_trans_taxon)))$'Pr(>F)'[1])
            
            ###############
            # (a                  ,  b                 ,  c                , d              , e                     , f                     , g                        )
            # ("Pure SUR currents", "Pure DCM currents", "Pure Mixed layer", "Mixed SUR-DCM", "Mixed DCM-MixedLayer", "Mixed SUR-MixedLayer", Mixed SUR-DCM-MixedLayer")
            # if (!no_selected_axes[i_taxon,6])
            # {
            #   varpart.SUR.DCM[[i_taxon]] = varpart(documents,SUR_MEM_taxon,DCM_MEM_taxon,mixed_layer_taxon)$part$indfract$Adj.R.square[-8]
            #   varpart.SUR.DCM.pval[[i_taxon]] = c(anova(rda(documents,SUR_MEM_taxon,cbind(DCM_MEM_taxon,mixed_layer_taxon)))$'Pr(>F)'[1],
            #                                       anova(rda(documents,DCM_MEM_taxon,cbind(SUR_MEM_taxon,mixed_layer_taxon)))$'Pr(>F)'[1],
            #                                       anova(rda(documents,mixed_layer_taxon,cbind(SUR_MEM_taxon,DCM_MEM_taxon)))$'Pr(>F)'[1],
            #                                       anova(rda(documents,cbind(mixed_layer_taxon,SUR_MEM_taxon,DCM_MEM_taxon)))$'Pr(>F)'[1])
            # } else
            # {
            #   #("Pure SUR currents", "Mixed SUR-DCM", "Pure DCM currents")
            #   varpar.SUR.DCM.taxon = varpart(documents,SUR_MEM_taxon,DCM_MEM_taxon)$part$indfract$Adj.R.square[-4]
            #   varpart.SUR.DCM[[i_taxon]] = c(varpar.SUR.DCM.taxon[c(1,3)],0,varpar.SUR.DCM.taxon[2],0,0,0)
            #   varpart.SUR.DCM.pval[[i_taxon]] = c(anova(rda(documents,SUR_MEM_taxon,DCM_MEM_taxon))$'Pr(>F)'[1],
            #                                       anova(rda(documents,DCM_MEM_taxon,SUR_MEM_taxon))$'Pr(>F)'[1],
            #                                       1,
            #                                       anova(rda(documents,cbind(SUR_MEM_taxon,DCM_MEM_taxon)))$'Pr(>F)'[1])
            # }
          } else
          {
            # varpart.groups.expTmin[[i_taxon]] = rep(NA,7)
            # varpart.groups.expTmin.pval[[i_taxon]] = rep(NA,4)
            
            varpart.env.spatial[[i_case]][[ii_taxon]] = rep(NA,3)
            varpart.env.spatial.pval[[i_case]][[ii_taxon]] = rep(NA,3)
            
            sub.varpart.biotic.abiotic[[i_case]][[ii_taxon]] = rep(NA,7)
            sub.varpart.biotic.abiotic.pval[[i_case]][[ii_taxon]] = rep(NA,4)
            
            # sub.varpart.SUR.DCM[[i_case]][[i_taxon]] = rep(NA,15)
            # sub.varpart.SUR.DCM.pval[[i_case]][[i_taxon]] = rep(NA,5)
            
            varpart.biotic.abiotic[[i_case]][[ii_taxon]] = rep(NA,3)
            varpart.biotic.abiotic.pval[[i_case]][[ii_taxon]] = rep(NA,3)
            
            # varpart.SUR.DCM[[i_case]][[i_taxon]] = rep(NA,7) 
            # varpart.SUR.DCM.pval[[i_case]][[i_taxon]] = rep(NA,4)
          }
        }
        
        if (abiotic_dissimilarity_all)
        {
          # Mantel_out[[i_taxon]] = matrix(nrow = ncol(abiotic_data_trans_taxon)+1, ncol = 4, dimnames = list(c(colnames(abiotic_data_trans_taxon),"All_variables"),c("intercept","slope","Mantel.R2","Mantel.p.value")), data = 0)
          Mantel_out[[ii_taxon]] = matrix(nrow = 2*ncol(abiotic_data_trans_taxon)-1, ncol = 4, dimnames = list(rownames_Mantel_out,c("intercept","slope","Mantel.R2","Mantel.p.value")), data = 0)
          for (k in 1:(2*ncol(abiotic_data_trans_taxon)-1))
          {
            LM = lm(sorensen_documents ~ abiotic_dissimilarity[[k]])
            test = vegan::mantel(abiotic_dissimilarity[[k]],sorensen_documents,permutations = 1000)
            Mantel_out[[ii_taxon]][k,] = c(LM$coefficients[2],LM$coefficients[1],test$statistic,test$signif)
            
            lower_tri_matrix = lower.tri(as.matrix(sorensen_documents))
            plot.abiotic.dis[[k]][[ii_taxon]] = ggplot(data=data.frame(x=as.matrix(abiotic_dissimilarity[[k]])[lower_tri_matrix],y=as.matrix(sorensen_documents)[lower_tri_matrix])) +
              geom_point(aes(x,y)) +
              geom_smooth(method='lm', aes(x,y)) +
              ylim(c(0,1)) +
              theme_bw() +
              ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
              theme(axis.title=element_text(size=9),
                    plot.title=element_text(hjust=0, size=15),
                    plot.margin=unit(c(1,1,1,0.5),"mm")) +
              labs(x=paste(rownames(Mantel_out[[ii_taxon]])[k],"dissimilarity"), y="Sorensen dissimilarity")
          }
          mantelslope[[ii_taxon]] = Mantel_out[[ii_taxon]][,2]
          mantelr2[[ii_taxon]] = Mantel_out[[ii_taxon]][,3]
          mantelpval[[ii_taxon]] = Mantel_out[[ii_taxon]][,4]
          # mantelslope[[i_taxon]] = Mantel_out[[i_taxon]][1:ncol(abiotic_data_trans_taxon),2]
          # mantelr2[[i_taxon]] = Mantel_out[[i_taxon]][1:ncol(abiotic_data_trans_taxon),3]
          # mantelpval[[i_taxon]] = Mantel_out[[i_taxon]][1:ncol(abiotic_data_trans_taxon),4]
          # mantelslope_allvariables[i_taxon] = Mantel_out[[i_taxon]][ncol(abiotic_data_trans_taxon)+1,2]
          # mantelr2_allvariables[i_taxon] = Mantel_out[[i_taxon]][ncol(abiotic_data_trans_taxon)+1,3]
          # mantelpval_allvariables[i_taxon] = Mantel_out[[i_taxon]][ncol(abiotic_data_trans_taxon)+1,4]
        }
        
        if (relative_abiotic_sd_per_OTU)
        {
          cat("\nComputing abiotic dispersion per OTU ...")
          OTU_locations = apply(documents,2,function(x) x>0)
          OTU_abiotic_dispersion = matrix(nrow = ncol(documents), ncol = 2*ncol(abiotic_data_trans_taxon)-1, data = NA)
          colnames(OTU_abiotic_dispersion) = rep(NA,ncol(OTU_abiotic_dispersion))
          if (ii_taxon == 1)
            sd_abiotic = vector(length = 2*ncol(abiotic_data_trans_taxon)-1, mode = "numeric")
          for (k in 1:ncol(abiotic_data_trans_taxon))
          {
            cat("\n",k)
            if (k ==1)
            {
              colnames(OTU_abiotic_dispersion)[k] = colnames(abiotic_data_trans_taxon)[k]
              for (i_OTU in 1:ncol(documents))
              {
                OTU_abiotic_dispersion[i_OTU,k] = sd(abiotic_data_trans_taxon[OTU_locations[,i_OTU],k])
              }
              if (ii_taxon == 1)
                sd_abiotic[k] = sd(abiotic_data_trans_taxon[,k])
            } else
            {
              colnames(OTU_abiotic_dispersion)[2*(k-1)] = paste(colnames(abiotic_data_trans_taxon)[k],collapse="-")
              colnames(OTU_abiotic_dispersion)[2*(k-1)+1] = paste(colnames(abiotic_data_trans_taxon)[1:k],collapse="-")
              abiotic_data_trans_taxon[OTU_locations[,i_OTU],k]
              for (i_OTU in 1:ncol(documents))
              {
                OTU_abiotic_dispersion[i_OTU,2*(k-1)] = sd(abiotic_data_trans_taxon[OTU_locations[,i_OTU],k])
                OTU_abiotic_dispersion[i_OTU,2*(k-1)+1] = mean(apply(abiotic_data_trans_taxon[OTU_locations[,i_OTU],1:k],2,sd))
              }
              if (ii_taxon == 1)
              {
                sd_abiotic[2*(k-1)] = sd(abiotic_data_trans_taxon[,k])
                sd_abiotic[2*(k-1)+1] = mean(apply(abiotic_data_trans_taxon[,1:k],2,sd))
              }
            }
          }
          OTU_abiotic_dispersion_allOTUs[[ii_taxon]] = sweep(OTU_abiotic_dispersion,2,sd_abiotic,"/")
          mean_OTU_abiotic_dispersion[[ii_taxon]] = colMeans(OTU_abiotic_dispersion_allOTUs[[ii_taxon]],na.rm=T)
        }
        
        if (relative_abiotic_dissimilarity_per_OTU)
        {
          cat("\nComputing relative abiotic dissimilarity per OTU ...")
          tot_nb = 0
          no_common_otu_nb = 0
          # ik and prop_within_OTU are vectors of length the number of OTUs in the taxonomic groups
          # They record the number of pairs of stations-depths (belonging to different stations) where the OTU is observed, 
          # and the subset of those where the travel time is below travel_time_threshold, respectively
          # For particle_thres = 0, prop_within_OTU records the sum of exchanged particles among stations-depths where the OTU is observed
          dissimilarity_within_OTU = matrix(nrow = ncol(documents), ncol = 2*ncol(abiotic_data_trans_taxon)-1, data = NA)
          colnames(dissimilarity_within_OTU) = rownames_Mantel_out
          ik = vector(length = ncol(documents), mode = "numeric")
          if (ii_taxon == 1)
            mean_abiotic_dissimilarity = vector(length = 2*ncol(abiotic_data_trans_taxon)-1, mode = "numeric")
          for (i in 2:nrow(documents))
          {
            cat("\ni = ",i,"out of",nrow(documents),"stations")
            for (j in 1:(i-1))
            {
              # cat("\nj = ",j)
              tot_nb = tot_nb+1
              ii_vect = which(documents[j,] !=0 & documents[i,] !=0)
              if (length(ii_vect) > 0)
              {
                for (ii in ii_vect)
                {
                  ik[ii] = ik[ii]+1
                  for (k in 1:(2*ncol(abiotic_data_trans_taxon)-1))
                  {
                    dissimilarity_within_OTU[ii,k] = dissimilarity_within_OTU[ii,k] + as.matrix(abiotic_dissimilarity[[k]])[i,j]
                  }
                }
              } else
                no_common_otu_nb = no_common_otu_nb+1
              if (ii_taxon == 1)
              {
                for (k in 1:(2*ncol(abiotic_data_trans_taxon)-1))
                  mean_abiotic_dissimilarity[k] = mean_abiotic_dissimilarity[k] + as.matrix(abiotic_dissimilarity[[k]])[i,j]
              }
            }
          }
          cat("\n",no_common_otu_nb,"no common OTU out of",tot_nb,"travel times (",no_common_otu_nb/tot_nb*100,"% )")
          
          if (length(which(ik>0)) > 0)
          {
            # The OTUs that are only present in a single station-depth or in the two depths of a single station are removed from the count when computing the proportion:
            dissimilarity_within_OTU = dissimilarity_within_OTU[ik > 0,]/ik[ik > 0]
            dissimilarity_within_OTU_allOTUs[[ii_taxon]] = sweep(dissimilarity_within_OTU,2,mean_abiotic_dissimilarity,"/")
            mean_dissimilarity_within_OTU[[ii_taxon]] = colMeans(dissimilarity_within_OTU)
          } else
          {
            dissimilarity_within_OTU_allOTUs[[ii_taxon]] = NA
            mean_dissimilarity_within_OTU[[ii_taxon]] = NA
          }
        }
      } else
      {
        if (rda_lda || varpart_lda)
        {
          if (dis_MEM)
            env_descriptor_list = list(abiotic_data_trans_taxon,relativeAbund_taxon,if (case == "SUR") SUR_dis_MEM_restricted else if (case == "DCM") DCM_dis_MEM_restricted)
          else
            env_descriptor_list = list(abiotic_data_trans_taxon,relativeAbund_taxon,if (case == "SUR") SUR_MEM_restricted else if (case == "DCM") DCM_MEM_restricted)
          
          if (var_select && !existing_var_selection)
          {
            env_selected[[ii_taxon]] = list(rep(NA,ncol(env_descriptor_list[[1]])),
                                            rep(NA,ncol(env_descriptor_list[[2]])),
                                            rep(NA,ncol(env_descriptor_list[[3]])),
                                            rep(NA,ncol(env_descriptor_list[[1]])+ncol(env_descriptor_list[[2]])+ncol(env_descriptor_list[[3]])+1))
            
            if (global_selection)
              significant_global_model[[i_case]][ii_taxon] = NA
            else
              significant_global_model[[i_case]][[ii_taxon]] = rep(NA,3)
          }
        }  
        
        if (rda_all || rda_lda)
        {
          adjr2_individualAxes_abiotic[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[1]]))
          pval_individualAxes_abiotic[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[1]]))
          adjr2_individualAxes_relativeAbund[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[2]]))
          pval_individualAxes_relativeAbund[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[2]]))
          adjr2_individualAxes_MEM[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[3]]))
          pval_individualAxes_MEM[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[3]]))
          
          adjr2_lumpedAxes_abiotic[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[1]]))
          pval_lumpedAxes_abiotic[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[1]]))
          adjr2_lumpedAxes_relativeAbund[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[2]]))
          pval_lumpedAxes_relativeAbund[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[2]]))
          adjr2_lumpedAxes_MEM[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[3]]))
          pval_lumpedAxes_MEM[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[3]]))
          
          adjr2_orderedLumpedAxes_abiotic[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[1]]))
          pval_orderedLumpedAxes_abiotic[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[1]]))
          adjr2_orderedLumpedAxes_relativeAbund[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[2]]))
          pval_orderedLumpedAxes_relativeAbund[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[2]]))
          adjr2_orderedLumpedAxes_MEM[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[3]]))
          pval_orderedLumpedAxes_MEM[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[3]]))
          
          if (global_selection)
          {
            adjr2_orderedLumpedAxes_all[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[1]]) + ncol(env_descriptor_list[[2]]) + ncol(env_descriptor_list[[3]]))
            pval_orderedLumpedAxes_all[[i_case]][[ii_taxon]] = rep(NA,ncol(env_descriptor_list[[1]]) + ncol(env_descriptor_list[[2]]) + ncol(env_descriptor_list[[3]]))
          }
        }
        
        if (varpart_lda)
        {
          # varpart.groups[[i_taxon]] = rep(NA,3)
          # varpart.groups.pval[[i_taxon]] = rep(NA,3)
          
          # varpart.functions[[i_taxon]] = rep(NA,3)
          # varpart.functions.pval[[i_taxon]] = rep(NA,3)
          
          # varpart.groups.expTmin[[i_taxon]] = rep(NA,7)
          # varpart.groups.expTmin.pval[[i_taxon]] = rep(NA,4)
          
          varpart.env.spatial[[i_case]][[ii_taxon]] = rep(NA,3)
          varpart.env.spatial.pval[[i_case]][[ii_taxon]] = rep(NA,3)
          
          sub.varpart.biotic.abiotic[[i_case]][[ii_taxon]] = rep(NA,7)
          sub.varpart.biotic.abiotic.pval[[i_case]][[ii_taxon]] = rep(NA,4)
          
          # sub.varpart.SUR.DCM[[i_taxon]] = rep(NA,15)
          # sub.varpart.SUR.DCM.pval[[i_taxon]] = rep(NA,5)
          
          varpart.biotic.abiotic[[i_case]][[ii_taxon]] = rep(NA,3)
          varpart.biotic.abiotic.pval[[i_case]][[ii_taxon]] = rep(NA,3)
          
          # varpart.SUR.DCM[[i_taxon]] = rep(NA,7) 
          # varpart.SUR.DCM.pval[[i_taxon]] = rep(NA,4)
        }
        
        if (abiotic_dissimilarity_all)
        {
          mantelslope[[ii_taxon]] = rep(NA,2*ncol(abiotic_data_trans_taxon)-1)
          mantelr2[[ii_taxon]] = rep(NA,2*ncol(abiotic_data_trans_taxon)-1)
          mantelpval[[ii_taxon]] = rep(NA,2*ncol(abiotic_data_trans_taxon)-1)
          # mantelslope[[i_taxon]] = rep(NA,ncol(abiotic_data_trans_taxon))
          # mantelr2[[i_taxon]] = rep(NA,ncol(abiotic_data_trans_taxon))
          # mantelpval[[i_taxon]] = rep(NA,ncol(abiotic_data_trans_taxon))
          # mantelslope_allvariables[i_taxon] = NA
          # mantelr2_allvariables[i_taxon] = NA
          # mantelpval_allvariables[i_taxon] = NA
        }
        
        if (relative_abiotic_sd_per_OTU)
        {
          OTU_abiotic_dispersion_allOTUs[[ii_taxon]] = NA
          mean_OTU_abiotic_dispersion[[ii_taxon]] = NA
        }
        
        if (relative_abiotic_dissimilarity_per_OTU)
        {
          dissimilarity_within_OTU_allOTUs[[ii_taxon]] = NA
          mean_dissimilarity_within_OTU[[ii_taxon]] = NA
        }
      }
      
      # setwd(figure_folder)
      # write.table(RDA_out_lda,
      #             file = "RDA_optimalK100r.csv",
      #             quote = F, append = F, sep = ";",
      #             col.names = T, row.names = T)
      
      # pdf("RDA_optimalK100r.pdf")
      # par(mar=c(7.1,4.1,4.1,2.1))
      # #barplot(RDA_soil_data.frame_reordered,col=c(terrain.colors(6),"blue"),ann=F,names.arg=colnames(RDA_soil_data.frame_reordered),las=3,legend.text = T, space = c(1,0),args.legend = list(bty = "n"))
      # x = barplot(RDA_out_lda[,2],legend.text = F, space = c(1,0), xaxt="n", args.legend = list(bty = "n"))
      # title(ylab="Proportion of explained variance (RDA)",cex.lab=1.3)
      # labs = rownames(RDA_out_lda)
      # text(cex=1, x=x+0.7, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
      # dev.off()
      # }   
    }
    # End of loop over taxo_groups
    
    if (rda_all || rda_lda)
    {
      adjr2_individualAxes_abiotic[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[1]]), dimnames = list(colnames(env_descriptor_list[[1]]), target_groups), data = unlist(adjr2_individualAxes_abiotic[[i_case]])))
      pval_individualAxes_abiotic[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[1]]), dimnames = list(colnames(env_descriptor_list[[1]]), target_groups), data = unlist(pval_individualAxes_abiotic[[i_case]])))
      adjr2_individualAxes_relativeAbund[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[2]]), dimnames = list(colnames(env_descriptor_list[[2]]), target_groups), data = unlist(adjr2_individualAxes_relativeAbund[[i_case]])))
      pval_individualAxes_relativeAbund[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[2]]), dimnames = list(colnames(env_descriptor_list[[2]]), target_groups), data = unlist(pval_individualAxes_relativeAbund[[i_case]])))
      adjr2_individualAxes_MEM[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[3]]), dimnames = list(colnames(env_descriptor_list[[3]]), target_groups), data = unlist(adjr2_individualAxes_MEM[[i_case]])))
      pval_individualAxes_MEM[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[3]]), dimnames = list(colnames(env_descriptor_list[[3]]), target_groups), data = unlist(pval_individualAxes_MEM[[i_case]])))
      
      adjr2_lumpedAxes_abiotic[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[1]]), dimnames = list(rownames_lumpedAxes[[1]], target_groups), data = unlist(adjr2_lumpedAxes_abiotic[[i_case]])))
      pval_lumpedAxes_abiotic[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[1]]), dimnames = list(rownames_lumpedAxes[[1]], target_groups), data = unlist(pval_lumpedAxes_abiotic[[i_case]])))
      adjr2_lumpedAxes_relativeAbund[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[2]]), dimnames = list(rownames_lumpedAxes[[2]], target_groups), data = unlist(adjr2_lumpedAxes_relativeAbund[[i_case]])))
      pval_lumpedAxes_relativeAbund[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[2]]), dimnames = list(rownames_lumpedAxes[[2]], target_groups), data = unlist(pval_lumpedAxes_relativeAbund[[i_case]])))
      adjr2_lumpedAxes_MEM[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[3]]), dimnames = list(rownames_lumpedAxes[[3]], target_groups), data = unlist(adjr2_lumpedAxes_MEM[[i_case]])))
      pval_lumpedAxes_MEM[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[3]]), dimnames = list(rownames_lumpedAxes[[3]], target_groups), data = unlist(pval_lumpedAxes_MEM[[i_case]])))
      
      adjr2_orderedLumpedAxes_abiotic[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[1]]), dimnames = list(rownames_orderedLumpedAxes[[1]], target_groups), data = unlist(adjr2_orderedLumpedAxes_abiotic[[i_case]])))
      pval_orderedLumpedAxes_abiotic[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[1]]), dimnames = list(rownames_orderedLumpedAxes[[1]], target_groups), data = unlist(pval_orderedLumpedAxes_abiotic[[i_case]])))
      adjr2_orderedLumpedAxes_relativeAbund[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[2]]), dimnames = list(rownames_orderedLumpedAxes[[2]], target_groups), data = unlist(adjr2_orderedLumpedAxes_relativeAbund[[i_case]])))
      pval_orderedLumpedAxes_relativeAbund[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[2]]), dimnames = list(rownames_orderedLumpedAxes[[2]], target_groups), data = unlist(pval_orderedLumpedAxes_relativeAbund[[i_case]])))
      adjr2_orderedLumpedAxes_MEM[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[3]]), dimnames = list(rownames_orderedLumpedAxes[[3]], target_groups), data = unlist(adjr2_orderedLumpedAxes_MEM[[i_case]])))
      pval_orderedLumpedAxes_MEM[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[3]]), dimnames = list(rownames_orderedLumpedAxes[[3]], target_groups), data = unlist(pval_orderedLumpedAxes_MEM[[i_case]])))
      
      if (global_selection)
      {
        adjr2_orderedLumpedAxes_all[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[1]]) + ncol(env_descriptor_list[[2]]) + ncol(env_descriptor_list[[3]]) + 1, dimnames = list(rownames_orderedLumpedAxes[[4]], target_groups), data = unlist(adjr2_orderedLumpedAxes_all[[i_case]])))
        pval_orderedLumpedAxes_all[[i_case]] = t(matrix(ncol = length(target_groups), nrow = ncol(env_descriptor_list[[1]]) + ncol(env_descriptor_list[[2]]) + ncol(env_descriptor_list[[3]]) + 1, dimnames = list(rownames_orderedLumpedAxes[[4]], target_groups), data = unlist(pval_orderedLumpedAxes_all[[i_case]])))
        adjr2_individualAxes_all[[i_case]] = cbind(adjr2_individualAxes_abiotic[[i_case]],adjr2_individualAxes_relativeAbund[[i_case]],adjr2_individualAxes_MEM[[i_case]])
        pval_individualAxes_all[[i_case]] = cbind(pval_individualAxes_abiotic[[i_case]],pval_individualAxes_relativeAbund[[i_case]],pval_individualAxes_MEM[[i_case]])
      }
    }
    
    if (varpart_lda)
    {
      # varpart.groups =  matrix(ncol = length(taxo_groups), nrow = 3, dimnames = list(c("Pure abiotic","Mixed","Pure biotic"), taxo_groups), data = unlist(varpart.groups))
      # varpart.groups.pval =  matrix(ncol = length(taxo_groups), nrow = 3, dimnames = list(c("Pure abiotic","Pure biotic","Total"), taxo_groups), data = unlist(varpart.groups.pval))
      
      # varpart.functions =  matrix(ncol = length(taxo_groups), nrow = 3, dimnames = list(c("Pure abiotic","Mixed","Pure biotic"), taxo_groups), data = unlist(varpart.functions))
      # varpart.functions.pval =  matrix(ncol = length(taxo_groups), nrow = 3, dimnames = list(c("Pure abiotic","Pure biotic","Total"), taxo_groups), data = unlist(varpart.functions.pval))
      # 
      # varpart.groups.expTmin = matrix(ncol = length(taxo_groups), nrow = 7, dimnames = list(c("Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"), taxo_groups), data = unlist(varpart.groups.expTmin))
      # varpart.groups.expTmin.pval = matrix(ncol = length(taxo_groups), nrow = 4, dimnames = list(c("Pure abiotic","Pure biotic","Pure currents","Total"), taxo_groups), data = unlist(varpart.groups.expTmin.pval))
      
      varpart.env.spatial[[i_case]] = matrix(ncol = length(target_groups), nrow = 3, dimnames = list(c("Pure environment","Mixed environment-currents","Pure currents"), target_groups), data = unlist(varpart.env.spatial[[i_case]]))
      varpart.env.spatial.pval[[i_case]] = matrix(ncol = length(target_groups), nrow = 3, dimnames = list(c("Pure environment","Pure currents","All"), target_groups), data = unlist(varpart.env.spatial.pval[[i_case]]))
      
      sub.varpart.biotic.abiotic[[i_case]] = matrix(ncol = length(target_groups), nrow = 7, dimnames = list(c("Pure abiotic", "Pure biotic", "Pure currents", "Mixed biotic-abiotic", "Mixed biotic-currents",
                                                                                                  "Mixed abiotic-currents", "Mixed biotic-abiotic-currents"), target_groups), data = unlist(sub.varpart.biotic.abiotic[[i_case]]))
      sub.varpart.biotic.abiotic.pval[[i_case]] = matrix(ncol = length(target_groups), nrow = 4, dimnames = list(c("Pure abiotic","Pure biotic","Pure currents","All"), target_groups), data = unlist(sub.varpart.biotic.abiotic.pval[[i_case]]))
      
      # sub.varpart.SUR.DCM = matrix(ncol = length(taxo_groups), nrow = 15, dimnames = list(c("Pure SUR currents","Pure DCM currents", "Pure Mixed Layer", "Pure environment", "Mixed SUR-DCM",
      #                                                                                       "Mixed DCM-MixedLayer", "Mixed SUR-MixedLayer", "Mixed SUR-env.", "Mixed DCM-env.", "MixedLayer-env.","Mixed SUR-DCM-env.",
      #                                                                                       "Mixed SUR-DCM-MixedLayer", "Mixed DCM-MixedLayer-env.", "Mixed SUR-MixedLayer-env.", "Mixed SUR-DCM-MixedLayer-env."), taxo_groups), data = unlist(sub.varpart.SUR.DCM))
      # sub.varpart.SUR.DCM.pval = matrix(ncol = length(taxo_groups), nrow = 5, dimnames = list(c("Pure SUR currents","Pure DCM currents", "Pure Mixed Layer", "Pure environment","All"), taxo_groups), data = unlist(sub.varpart.SUR.DCM.pval))
      
      varpart.biotic.abiotic[[i_case]] = matrix(ncol = length(target_groups), nrow = 3, dimnames = list(c("Pure abiotic","Mixed abiotic-biotic","Pure biotic"), target_groups), data = unlist(varpart.biotic.abiotic[[i_case]]))
      varpart.biotic.abiotic.pval[[i_case]] = matrix(ncol = length(target_groups), nrow = 3, dimnames = list(c("Pure abiotic","Pure biotic","All"), target_groups), data = unlist(varpart.biotic.abiotic.pval[[i_case]]))
      
      # varpart.SUR.DCM = matrix(ncol = length(taxo_groups), nrow = 7, dimnames = list(c("Pure SUR currents", "Pure DCM currents", "Pure Mixed layer", "Mixed SUR-DCM", "Mixed DCM-MixedLayer",
      #                                                                                  "Mixed SUR-MixedLayer", "Mixed SUR-DCM-MixedLayer"), taxo_groups), data = unlist(varpart.SUR.DCM)) 
      # varpart.SUR.DCM.pval = matrix(ncol = length(taxo_groups), nrow = 4, dimnames = list(c("Pure SUR currents","Pure DCM currents", "Pure Mixed Layer","All"), taxo_groups), data = unlist(varpart.SUR.DCM.pval))
      
      # ("Pure SUR currents","Pure DCM currents", "Pure Mixed Layer", "Pure environment", "Mixed SUR-DCM", "Mixed DCM-MixedLayer", 'Mixed SUR-MixedLayer", "Mixed SUR-env., Mixed DCM-env.", "MixedLayer-env.",
      # k                   , l                         , m                    , n                    , o                              ) 
      # "Mixed SUR-DCM-env.", "Mixed SUR-DCM-MixedLayer", "DCM-MixedLayer-env.", "SUR-MixedLayer-env.", "Mixed SUR-DCM-MixedLayer-env.")
    }
  }
  #####################################
  # End of loop over SUR and DCM cases#
  #####################################
  
  if ((rda_lda || varpart_lda) && !existing_var_selection)
  {
    if (var_select)
    {
      saveRDS(list(no_selected_axes,env_selected,significant_global_model,nb_sites),
              paste0(results_folder,"/RDA",Gibbs_VEM_insert,target_groups_insert,
                     "_separate.SUR.DCM_noSelectedAxes-envSelected-significantGlobalModel-nbSites",
                     var.select_insert,preliminary_global_test_insert,indiv.signif.axes_insert,BH_correction_insert,
                     abiotic_pca_insert,biotic_pca_insert,dis_MEM_insert,stdzation_insert,noArcticNoBiomark_insert,
                     "_eigenvalueThres0.8.rds"))
    } else if (indiv_signif_axes_selection)
    {
      saveRDS(list(no_selected_axes,env_selected,nb_sites),
              paste0(results_folder,"/RDA",Gibbs_VEM_insert,target_groups_insert,
                     "_separate.SUR.DCM_noSelectedAxes-envSelected-nbSites",
                     var.select_insert,indiv.signif.axes_insert,BH_correction_insert,
                     abiotic_pca_insert,biotic_pca_insert,dis_MEM_insert,stdzation_insert,noArcticNoBiomark_insert,
                     "_eigenvalueThres0.8.rds"))
    }
  }
  
  if (rda_lda)
  {
    saveRDS(list(adjr2_individualAxes_abiotic,pval_individualAxes_abiotic,adjr2_individualAxes_relativeAbund,pval_individualAxes_relativeAbund,adjr2_individualAxes_MEM,pval_individualAxes_MEM),
            # paste0(results_folder,"/RDA_environment-currents_individualAxes_independentSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
            paste0(results_folder,"/RDA",Gibbs_VEM_insert,target_groups_insert,"_separate.SUR.DCM_individualAxes",
                   abiotic_pca_insert,biotic_pca_insert,dis_MEM_insert,stdzation_insert,noArcticNoBiomark_insert,"_eigenvalueThres0.8.rds"))
    saveRDS(list(adjr2_lumpedAxes_abiotic,pval_lumpedAxes_abiotic,adjr2_lumpedAxes_relativeAbund,pval_lumpedAxes_relativeAbund,adjr2_lumpedAxes_MEM,pval_lumpedAxes_MEM),
            # paste0(results_folder,"/RDA_environment-currents_lumpedAxes_independentSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
            paste0(results_folder,"/RDA",Gibbs_VEM_insert,target_groups_insert,"_separate.SUR.DCM_lumpedAxes",
                   abiotic_pca_insert,biotic_pca_insert,dis_MEM_insert,stdzation_insert,noArcticNoBiomark_insert,"_eigenvalueThres0.8.rds"))
    # saveRDS(list(adjr2_orderedLumpedAxes_abiotic,pval_orderedLumpedAxes_abiotic,adjr2_orderedLumpedAxes_relativeAbund,pval_orderedLumpedAxes_relativeAbund,adjr2_orderedLumpedAxes_expTmin_distance,pval_orderedLumpedAxes_expTmin_distance,adjr2_orderedLumpedAxes_all,pval_orderedLumpedAxes_all),
    saveRDS(list(adjr2_orderedLumpedAxes_abiotic,pval_orderedLumpedAxes_abiotic,adjr2_orderedLumpedAxes_relativeAbund,pval_orderedLumpedAxes_relativeAbund,adjr2_orderedLumpedAxes_MEM,pval_orderedLumpedAxes_MEM),
            # paste0(results_folder,"/RDA_environment-currents_orderedLumpedAxes_independentSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
            paste0(results_folder,"/RDA",Gibbs_VEM_insert,target_groups_insert,"_separate.SUR.DCM_orderedLumpedAxes",
                   abiotic_pca_insert,biotic_pca_insert,dis_MEM_insert,stdzation_insert,noArcticNoBiomark_insert,"_eigenvalueThres0.8.rds"))
    
    # saveRDS(list(adjr2_individualAxes_abiotic,pval_individualAxes_abiotic,adjr2_individualAxes_relativeAbund,pval_individualAxes_relativeAbund,adjr2_individualAxes_expTmin_distance,pval_individualAxes_expTmin_distance),
    #       paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_individualAxes_independentSelection1",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # saveRDS(list(adjr2_lumpedAxes_abiotic,pval_lumpedAxes_abiotic,adjr2_lumpedAxes_relativeAbund,pval_lumpedAxes_relativeAbund,adjr2_lumpedAxes_expTmin_distance,pval_lumpedAxes_expTmin_distance),
    #       paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_lumpedAxes_independentSelection1",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # # saveRDS(list(adjr2_orderedLumpedAxes_abiotic,pval_orderedLumpedAxes_abiotic,adjr2_orderedLumpedAxes_relativeAbund,pval_orderedLumpedAxes_relativeAbund,adjr2_orderedLumpedAxes_expTmin_distance,pval_orderedLumpedAxes_expTmin_distance,adjr2_orderedLumpedAxes_all,pval_orderedLumpedAxes_all),
    # saveRDS(list(adjr2_orderedLumpedAxes_abiotic,pval_orderedLumpedAxes_abiotic,adjr2_orderedLumpedAxes_relativeAbund,pval_orderedLumpedAxes_relativeAbund,adjr2_orderedLumpedAxes_expTmin_distance,pval_orderedLumpedAxes_expTmin_distance),
    #       paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_all_orderedLumpedAxes_independentSelection1",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  }
  
  if (varpart_lda)
  {
    # saveRDS(list(varpart.groups,varpart.groups.pval),paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # saveRDS(list(varpart.functions,varpart.functions.pval),paste0(results_folder,"/varpart_lda_abiotic_vs_functions",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # saveRDS(list(varpart.groups.expTmin,varpart.groups.expTmin.pval),paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # saveRDS(list(varpart.groups.expTmin,varpart.groups.expTmin.pval),paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # saveRDS(list(varpart.groups.expTmin,varpart.groups.expTmin.pval),paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # saveRDS(list(varpart.groups.expTmin,varpart.groups.expTmin.pval),paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_bothDirectionsGlobalSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))  
    saveRDS(list(varpart.env.spatial,varpart.env.spatial.pval,sub.varpart.biotic.abiotic,sub.varpart.biotic.abiotic.pval,varpart.biotic.abiotic,varpart.biotic.abiotic.pval),
            # paste0(results_folder,"/varpart_lda_environment-currents_bothDirectionsIndependentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
            paste0(results_folder,"/varpart_lda",
                   Gibbs_VEM_insert,target_groups_insert,"_separate.SUR.DCM",
                   var.select_insert,"_PCA0",preliminary_global_test_insert,indiv.signif.axes_insert,BH_correction_insert,
                   abiotic_pca_insert,biotic_pca_insert,dis_MEM_insert,stdzation_insert,noArcticNoBiomark_insert,
                   "_eigenvalueThres0.8.rds")) 
  }
  
  # varpart.groups.variable.nb.of.axes[[which(2:30 == i_axis)]] = varpart.groups
  # varpart.groups.pval.variable.nb.of.axes[[which(2:30 == i_axis)]] = varpart.groups.pval
  # }
  # 
  # saveRDS(list(varpart.groups.variable.nb.of.axes,varpart.groups.pval.variable.nb.of.axes),paste0(results_folder,"/varpart_abiotic_relativeAbund_varyingAxisNumber2-30",abiotic_pca_insert,biotic_pca_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  # if (relative_abiotic_sd_per_OTU)
  #   saveRDS(list(mean_OTU_abiotic_dispersion,OTU_abiotic_dispersion_allOTUs),paste0(results_folder,"/OTU_relative_abiotic_dispersion_",ncol(abiotic_data_trans_taxon),"variables",abiotic_pca_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  # setwd(figure_folder)
  library(ggplot2)
  library(gridExtra)
  
  # all_env_descriptors0 = cbind(abiotic_data_trans_taxon[rownames(relativeAbund_taxon),],relativeAbund_taxon,expTmin_distance_pcoa_vectors_taxon[rownames(relativeAbund_taxon),])
  # cor_all_env_descriptors = abs(cor(all_env_descriptors0))
  # # tmp.plot = ggplot(melt(abs(cor(abiotic_data_trans_taxon))), aes(x = Var2, y = Var1)) + geom_raster(aes(fill=value)) + scale_fill_gradient(low="grey90", high="red")
  # # tmp.plot = ggplot(melt(abs(cor(relativeAbund_taxon))), aes(x = Var2, y = Var1)) + geom_raster(aes(fill=value)) + scale_fill_gradient(low="grey90", high="red")
  # tmp.plot = ggplot(melt(cor_all_env_descriptors), aes(x = Var2, y = Var1)) + geom_raster(aes(fill=value)) + scale_fill_gradient(low="grey90", high="red")
  # print(tmp.plot)
  # # cor_all_env_descriptors_tri = cor_all_env_descriptors[lower.tri(cor_all_env_descriptors)]
  # melt(cor_all_env_descriptors)[sort.int(melt(cor_all_env_descriptors)$value,decreasing = T,index.return=T)$ix,]
  # hist(cor_all_env_descriptors[lower.tri(cor_all_env_descriptors) & cor_all_env_descriptors>0.25])
  
  if (rda_all || rda_lda)
  {
    # Transforming adr2 and pval into matrices for plotting
    # adjr2 = t(matrix(ncol = length(taxo_groups), nrow = 2*ncol(abiotic_data_trans_taxon)-1, dimnames = list(rownames(RDA_out_lda), taxo_groups), data = unlist(adjr2)))
    # pval = t(matrix(ncol = length(taxo_groups), nrow = 2*ncol(abiotic_data_trans_taxon)-1, dimnames = list(rownames(RDA_out_lda), taxo_groups), data = unlist(pval)))
    
    # rda_available_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
    
    ########################################
    plot.SUR.lumped.biotic.variance.vs.sum.axis.variance = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      sum_adjr2_individualAxes_relativeAbund = vector(length = ncol(adjr2_individualAxes_relativeAbund[[1]]), mode = "numeric")
      # sum_adjr2_individualAxes_relativeAbund[1] = adjr2_individualAxes_relativeAbund[i_taxon,1]
      sum_adjr2_individualAxes_relativeAbund[1] = adjr2_individualAxes_relativeAbund[[1]][i_taxon,sort.int(adjr2_individualAxes_relativeAbund[[1]][i_taxon,],index.return = T,decreasing = T)$ix[1]]
      for (i in 2:ncol(adjr2_individualAxes_relativeAbund[[1]]))
        # sum_adjr2_individualAxes_relativeAbund[i] = sum(adjr2_individualAxes_relativeAbund[i_taxon,1:i])
        sum_adjr2_individualAxes_relativeAbund[i] = sum(adjr2_individualAxes_relativeAbund[[1]][i_taxon,sort.int(adjr2_individualAxes_relativeAbund[[1]][i_taxon,],index.return = T,decreasing = T)$ix[1:i]])
      # plot.lumped.biotic.variance.vs.sum.axis.variance[[ii_taxon]] = ggplot(data=data.frame(x=sum_adjr2_individualAxes_relativeAbund,y=adjr2_lumpedAxes_relativeAbund[i_taxon,])) +
      plot.SUR.lumped.biotic.variance.vs.sum.axis.variance[[ii_taxon]] = ggplot(data=data.frame(x=sum_adjr2_individualAxes_relativeAbund,y=adjr2_orderedLumpedAxes_relativeAbund[[1]][i_taxon,])) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,]<0.05,"black","red")) +
        geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[[1]][i_taxon,sort.int(adjr2_individualAxes_relativeAbund[[1]][i_taxon,],index.return = T,decreasing = T)$ix]<0.05,"black","red")) +
        # geom_line(aes(x,y)) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Summed surf. variance explained by biotic axes", y="Surf. variance explained by lumped biotic axes")
    }
    
    plot.DCM.lumped.biotic.variance.vs.sum.axis.variance = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      sum_adjr2_individualAxes_relativeAbund = vector(length = ncol(adjr2_individualAxes_relativeAbund[[2]]), mode = "numeric")
      # sum_adjr2_individualAxes_relativeAbund[1] = adjr2_individualAxes_relativeAbund[i_taxon,1]
      sum_adjr2_individualAxes_relativeAbund[1] = adjr2_individualAxes_relativeAbund[[2]][i_taxon,sort.int(adjr2_individualAxes_relativeAbund[[2]][i_taxon,],index.return = T,decreasing = T)$ix[1]]
      for (i in 2:ncol(adjr2_individualAxes_relativeAbund[[2]]))
        # sum_adjr2_individualAxes_relativeAbund[i] = sum(adjr2_individualAxes_relativeAbund[i_taxon,1:i])
        sum_adjr2_individualAxes_relativeAbund[i] = sum(adjr2_individualAxes_relativeAbund[[2]][i_taxon,sort.int(adjr2_individualAxes_relativeAbund[[2]][i_taxon,],index.return = T,decreasing = T)$ix[1:i]])
      # plot.lumped.biotic.variance.vs.sum.axis.variance[[ii_taxon]] = ggplot(data=data.frame(x=sum_adjr2_individualAxes_relativeAbund,y=adjr2_lumpedAxes_relativeAbund[i_taxon,])) +
      plot.DCM.lumped.biotic.variance.vs.sum.axis.variance[[ii_taxon]] = ggplot(data=data.frame(x=sum_adjr2_individualAxes_relativeAbund,y=adjr2_orderedLumpedAxes_relativeAbund[[2]][i_taxon,])) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,]<0.05,"black","red")) +
        geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[[2]][i_taxon,sort.int(adjr2_individualAxes_relativeAbund[[2]][i_taxon,],index.return = T,decreasing = T)$ix]<0.05,"black","red")) +
        # geom_line(aes(x,y)) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Summed DCM variance explained by biotic axes", y="DCM variance explained by lumped biotic axes")
    }
    
    spl = split(plot.SUR.lumped.biotic.variance.vs.sum.axis.variance, (seq_along(plot.SUR.lumped.biotic.variance.vs.sum.axis.variance)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
    # pdf(paste0("AdjR2_relativeAbund_lumped_axes_vs_sum_of_axes_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_relativeAbund_SUR_orderedLumped_axes_vs_sum_of_axes_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.DCM.lumped.biotic.variance.vs.sum.axis.variance, (seq_along(plot.DCM.lumped.biotic.variance.vs.sum.axis.variance)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
    # pdf(paste0("AdjR2_relativeAbund_lumped_axes_vs_sum_of_axes_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_relativeAbund_DCM_orderedLumped_axes_vs_sum_of_axes_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    ########################################
    plot.SUR.biotic.variance.vs.axis.nb = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      colour_vect = vector(length = ncol(adjr2_lumpedAxes_relativeAbund[[1]]), mode = "numeric")
      for (i in 1:ncol(adjr2_lumpedAxes_relativeAbund[[1]]))
      {
        if (!is.na(pval_individualAxes_relativeAbund[[1]][i_taxon,i]) && pval_individualAxes_relativeAbund[[1]][i_taxon,i] < 0.05)
        {
          if (any(env_selected[[1]][[i_taxon]][[2]]) && i %in% which(as.logical(env_selected[[1]][[i_taxon]][[2]])))
            colour_vect[i] = "blue"
          else
            colour_vect[i] = "black"
        } else
        {
          if (any(env_selected[[1]][[i_taxon]][[2]]) && i %in% which(as.logical(env_selected[[1]][[i_taxon]][[2]])))
            colour_vect[i] = "darkgreen"
          else
            colour_vect[i] = "red"
        }
      }
      plot.SUR.biotic.variance.vs.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_lumpedAxes_relativeAbund[[1]]),y=adjr2_lumpedAxes_relativeAbund[[1]][i_taxon,])) +
        geom_line(aes(x,y)) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,]<0.05,"black","red")) +
        geom_point(aes(x,y),colour = colour_vect) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of biotic axes kept", y="Surf. variance explained by biotic environment")
    }
    
    plot.DCM.biotic.variance.vs.axis.nb = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      colour_vect = vector(length = ncol(adjr2_lumpedAxes_relativeAbund[[2]]), mode = "numeric")
      for (i in 1:ncol(adjr2_lumpedAxes_relativeAbund[[2]]))
      {
        if (!is.na(pval_individualAxes_relativeAbund[[2]][i_taxon,i]) && pval_individualAxes_relativeAbund[[2]][i_taxon,i] < 0.05)
        {
          if (any(env_selected[[2]][[i_taxon]][[2]]) && i %in% which(as.logical(env_selected[[2]][[i_taxon]][[2]])))
            colour_vect[i] = "blue"
          else
            colour_vect[i] = "black"
        } else
        {
          if (any(env_selected[[2]][[i_taxon]][[2]]) && i %in% which(as.logical(env_selected[[2]][[i_taxon]][[2]])))
            colour_vect[i] = "darkgreen"
          else
            colour_vect[i] = "red"
        }
      }
      plot.DCM.biotic.variance.vs.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_lumpedAxes_relativeAbund[[2]]),y=adjr2_lumpedAxes_relativeAbund[[2]][i_taxon,])) +
        geom_line(aes(x,y)) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,]<0.05,"black","red")) +
        geom_point(aes(x,y),colour = colour_vect) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of biotic axes kept", y="DCM variance explained by biotic environment")
    }
    
    spl = split(plot.SUR.biotic.variance.vs.axis.nb, (seq_along(plot.SUR.biotic.variance.vs.axis.nb)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_forwardVariableSelection_globalSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_relativeAbund_SUR_vs_axisNb_bothDirectionsVariableSelection_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,"_(1).pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_bothDirectionsVariableSelection_individuallySignif_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.DCM.biotic.variance.vs.axis.nb, (seq_along(plot.DCM.biotic.variance.vs.axis.nb)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_forwardVariableSelection_globalSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_relativeAbund_DCM_vs_axisNb_bothDirectionsVariableSelection_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_bothDirectionsVariableSelection_individuallySignif_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    ########################################
    plot.SUR.MEM.variance.vs.axis.nb = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      colour_vect = vector(length = ncol(adjr2_lumpedAxes_MEM[[1]]), mode = "numeric")
      for (i in 1:ncol(adjr2_lumpedAxes_MEM[[1]]))
      {
        if (!is.na(pval_individualAxes_MEM[[1]][i_taxon,i]) && pval_individualAxes_MEM[[1]][i_taxon,i] < 0.05)
        {
          if (any(env_selected[[1]][[i_taxon]][[3]]) && i %in% which(as.logical(env_selected[[1]][[i_taxon]][[3]])))
            colour_vect[i] = "blue"
          else
            colour_vect[i] = "black"
        } else
        {
          if (any(env_selected[[1]][[i_taxon]][[3]]) && i %in% which(as.logical(env_selected[[1]][[i_taxon]][[3]])))
            colour_vect[i] = "darkgreen"
          else
            colour_vect[i] = "red"
        }
      }
      plot.SUR.MEM.variance.vs.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_lumpedAxes_MEM[[1]]),y=adjr2_lumpedAxes_MEM[[1]][i_taxon,])) +
        geom_line(aes(x,y)) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,]<0.05,"black","red")) +
        geom_point(aes(x,y),colour = colour_vect) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of axes kept", y="Variance explained by surface currents connectivity")
    }
    
    plot.DCM.MEM.variance.vs.axis.nb = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      colour_vect = vector(length = ncol(adjr2_lumpedAxes_MEM[[2]]), mode = "numeric")
      for (i in 1:ncol(adjr2_lumpedAxes_MEM[[2]]))
      {
        if (!is.na(pval_individualAxes_MEM[[2]][i_taxon,i]) && pval_individualAxes_MEM[[2]][i_taxon,i] < 0.05)
        {
          if (any(env_selected[[2]][[i_taxon]][[3]]) && i %in% which(as.logical(env_selected[[2]][[i_taxon]][[3]])))
            colour_vect[i] = "blue"
          else
            colour_vect[i] = "black"
        } else
        {
          if (any(env_selected[[2]][[i_taxon]][[3]]) && i %in% which(as.logical(env_selected[[2]][[i_taxon]][[3]])))
            colour_vect[i] = "darkgreen"
          else
            colour_vect[i] = "red"
        }
      }
      plot.DCM.MEM.variance.vs.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_lumpedAxes_MEM[[2]]),y=adjr2_lumpedAxes_MEM[[2]][i_taxon,])) +
        geom_line(aes(x,y)) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,]<0.05,"black","red")) +
        geom_point(aes(x,y),colour = colour_vect) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of axes kept", y="Variance explained by DCM currents connectivity")
    }
    
    spl = split(plot.SUR.MEM.variance.vs.axis.nb, (seq_along(plot.SUR.MEM.variance.vs.axis.nb)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0("AdjR2_expTmin_distance_vs_axisNb_forwardVariableSelection_individuallySignif_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_SUR_MEM_vs_axisNb_bothDirectionsVariableSelection_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,"_(1).pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.DCM.MEM.variance.vs.axis.nb, (seq_along(plot.DCM.MEM.variance.vs.axis.nb)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0("AdjR2_expTmin_distance_vs_axisNb_forwardVariableSelection_individuallySignif_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_DCM_MEM_vs_axisNb_bothDirectionsVariableSelection_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_axisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    ########################################
    plot.SUR.biotic.variance.vs.ordered.axis.nb = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      colour_vect = vector(length = ncol(adjr2_orderedLumpedAxes_relativeAbund[[1]]), mode = "numeric")
      for (i in 1:ncol(adjr2_orderedLumpedAxes_relativeAbund[[1]]))
      {
        ii = sort.int(adjr2_individualAxes_relativeAbund[[1]][i_taxon,],index.return = T,decreasing = T)$ix[i]
        if (!is.na(pval_individualAxes_relativeAbund[[1]][i_taxon,i]) && pval_individualAxes_relativeAbund[[1]][i_taxon,ii] < 0.05)
        {
          if (any(env_selected[[1]][[i_taxon]][[2]]) && ii %in% which(as.logical(env_selected[[1]][[i_taxon]][[2]])))
            colour_vect[i] = "blue"
          else
            colour_vect[i] = "black"
        } else
        {
          if (any(env_selected[[1]][[i_taxon]][[2]]) && ii %in% which(as.logical(env_selected[[1]][[i_taxon]][[2]])))
            colour_vect[i] = "darkgreen"
          else 
            colour_vect[i] = "red"
        }
      }
      plot.SUR.biotic.variance.vs.ordered.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_orderedLumpedAxes_relativeAbund[[1]]),y=adjr2_orderedLumpedAxes_relativeAbund[[1]][i_taxon,])) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y),colour = colour_vect) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,sort.int(adjr2_individualAxes_relativeAbund[i_taxon,],index.return = T,decreasing = T)$ix]<0.05,"black","red")) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of ordered biotic axes kept", y="Surface variance explained by biotic environment")
    }
    
    plot.DCM.biotic.variance.vs.ordered.axis.nb = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      colour_vect = vector(length = ncol(adjr2_orderedLumpedAxes_relativeAbund[[2]]), mode = "numeric")
      for (i in 1:ncol(adjr2_orderedLumpedAxes_relativeAbund[[2]]))
      {
        ii = sort.int(adjr2_individualAxes_relativeAbund[[2]][i_taxon,],index.return = T,decreasing = T)$ix[i]
        if (!is.na(pval_individualAxes_relativeAbund[[2]][i_taxon,i]) && pval_individualAxes_relativeAbund[[2]][i_taxon,ii] < 0.05)
        {
          if (any(env_selected[[2]][[i_taxon]][[2]]) && ii %in% which(as.logical(env_selected[[2]][[i_taxon]][[2]])))
            colour_vect[i] = "blue"
          else
            colour_vect[i] = "black"
        } else
        {
          if (any(env_selected[[2]][[i_taxon]][[2]]) && ii %in% which(as.logical(env_selected[[2]][[i_taxon]][[2]])))
            colour_vect[i] = "darkgreen"
          else 
            colour_vect[i] = "red"
        }
      }
      plot.DCM.biotic.variance.vs.ordered.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_orderedLumpedAxes_relativeAbund[[2]]),y=adjr2_orderedLumpedAxes_relativeAbund[[2]][i_taxon,])) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y),colour = colour_vect) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,sort.int(adjr2_individualAxes_relativeAbund[i_taxon,],index.return = T,decreasing = T)$ix]<0.05,"black","red")) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of ordered biotic axes kept", y="DCM variance explained by biotic environment")
    }
    
    spl = split(plot.SUR.biotic.variance.vs.ordered.axis.nb, (seq_along(plot.SUR.biotic.variance.vs.ordered.axis.nb)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, ncol = 5, nrow = 4, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_forwardVariableSelection_globalSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_relativeAbund_SUR_vs_orderedAxisNb_bothDirectionsVariableSelection_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.DCM.biotic.variance.vs.ordered.axis.nb, (seq_along(plot.DCM.biotic.variance.vs.ordered.axis.nb)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, ncol = 5, nrow = 4, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_forwardVariableSelection_globalSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_relativeAbund_DCM_vs_orderedAxisNb_bothDirectionsVariableSelection_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    ########################################
    plot.SUR.MEM.variance.vs.ordered.axis.nb = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      colour_vect = vector(length = ncol(adjr2_orderedLumpedAxes_MEM[[1]]), mode = "numeric")
      for (i in 1:ncol(adjr2_orderedLumpedAxes_MEM[[1]]))
      {
        ii = sort.int(adjr2_individualAxes_MEM[[1]][i_taxon,],index.return = T,decreasing = T)$ix[i]
        if (!is.na(pval_individualAxes_MEM[[1]][i_taxon,i]) && pval_individualAxes_MEM[[1]][i_taxon,ii] < 0.05)
        {
          if (any(env_selected[[1]][[i_taxon]][[3]]) && ii %in% which(as.logical(env_selected[[1]][[i_taxon]][[3]])))
            colour_vect[i] = "blue"
          else
            colour_vect[i] = "black"
        } else
        {
          if (any(env_selected[[1]][[i_taxon]][[3]]) && ii %in% which(as.logical(env_selected[[1]][[i_taxon]][[3]])))
            colour_vect[i] = "darkgreen"
          else 
            colour_vect[i] = "red"
        }
      }
      plot.SUR.MEM.variance.vs.ordered.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_orderedLumpedAxes_MEM[[1]]),y=adjr2_orderedLumpedAxes_MEM[[1]][i_taxon,])) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y),colour = colour_vect) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,sort.int(adjr2_individualAxes_relativeAbund[i_taxon,],index.return = T,decreasing = T)$ix]<0.05,"black","red")) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of ordered connectivity axes kept", y="Variance explained by surface currents connectivity")
    }
    
    plot.DCM.MEM.variance.vs.ordered.axis.nb = list()
    ii_taxon = 0
    for (taxon in taxo_groups[selected_groups])
    {
      i_taxon = which(taxo_groups == taxon)
      ii_taxon = ii_taxon+1
      colour_vect = vector(length = ncol(adjr2_orderedLumpedAxes_MEM[[2]]), mode = "numeric")
      for (i in 1:ncol(adjr2_orderedLumpedAxes_MEM[[2]]))
      {
        ii = sort.int(adjr2_individualAxes_MEM[[2]][i_taxon,],index.return = T,decreasing = T)$ix[i]
        if (!is.na(pval_individualAxes_MEM[[2]][i_taxon,i]) && pval_individualAxes_MEM[[2]][i_taxon,ii] < 0.05)
        {
          if (any(env_selected[[2]][[i_taxon]][[3]]) && ii %in% which(as.logical(env_selected[[2]][[i_taxon]][[3]])))
            colour_vect[i] = "blue"
          else
            colour_vect[i] = "black"
        } else
        {
          if (any(env_selected[[2]][[i_taxon]][[3]]) && ii %in% which(as.logical(env_selected[[2]][[i_taxon]][[3]])))
            colour_vect[i] = "darkgreen"
          else 
            colour_vect[i] = "red"
        }
      }
      plot.DCM.MEM.variance.vs.ordered.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_orderedLumpedAxes_MEM[[2]]),y=adjr2_orderedLumpedAxes_MEM[[2]][i_taxon,])) +
        geom_line(aes(x,y)) +
        geom_point(aes(x,y),colour = colour_vect) +
        # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,sort.int(adjr2_individualAxes_relativeAbund[i_taxon,],index.return = T,decreasing = T)$ix]<0.05,"black","red")) +
        theme_bw() +
        ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
        theme(axis.title=element_text(size=9),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of ordered connectivity axes kept", y="Variance explained by DCM currents connectivity")
    }
    
    spl = split(plot.SUR.MEM.variance.vs.ordered.axis.nb, (seq_along(plot.SUR.MEM.variance.vs.ordered.axis.nb)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_SUR_MEM_vs_orderedAxisNb_bothDirectionsVariableSelection_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_expTmin_distance_vs_orderedAxisNb_forwardVariableSelection_individuallySignif_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(plot.DCM.MEM.variance.vs.ordered.axis.nb, (seq_along(plot.DCM.MEM.variance.vs.ordered.axis.nb)-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder_Gibbs.VEM,"/AdjR2_DCM_MEM_vs_orderedAxisNb_bothDirectionsVariableSelection_selected100+1",noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_expTmin_distance_vs_orderedAxisNb_forwardVariableSelection_individuallySignif_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    ########################################
    if (global_selection)
    {
      tmp.plot = list()
      ii_taxon = 0
      for (taxon in taxo_groups[selected_groups])
      {
        i_taxon = which(taxo_groups == taxon)
        ii_taxon = ii_taxon+1
        tmp.plot[[ii_taxon]] = ggplot(melt(abs(cor_all_env_descriptors[[i_taxon]])), aes(x = Var2, y = Var1)) + 
          geom_raster(aes(fill=value)) + 
          scale_fill_gradient(low="grey90", high="red") +
          theme_bw() +
          ggtitle(paste(taxon,"-",nb_sites[i_taxon],"station-depths")) +
          theme(axis.title=element_blank(),
                plot.title=element_text(hjust=0, size=10),
                plot.margin=unit(c(1,1,1,0.5),"mm"),
                axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size=3),
                axis.text.y = element_text(size = 3))
      }
      
      spl = split(tmp.plot, (seq_along(tmp.plot)-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
      pdf(paste0(figure_folder_Gibbs.VEM,"/Correlation_abiotic.biotic.MEM.axes_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
      
      ########################################
      plot.variance.all.axes.vs.ordered.axis.nb = list()
      ii_taxon = 0
      for (taxon in taxo_groups[selected_groups])
      {
        i_taxon = which(taxo_groups == taxon)
        ii_taxon = ii_taxon+1
        colour_vect = vector(length = ncol(adjr2_orderedLumpedAxes_all), mode = "numeric")
        for (i in 1:ncol(adjr2_orderedLumpedAxes_all))
        {
          ii = sort.int(adjr2_individualAxes_all[i_taxon,],index.return = T,decreasing = T)$ix[i]
          if (!is.na(pval_individualAxes_all[i_taxon,i]) && pval_individualAxes_all[i_taxon,ii] < 0.05)
          {
            if (any(env_selected[[i_taxon]][[5]]) && ii %in% which(env_selected[[i_taxon]][[5]]))
              colour_vect[i] = "blue"
            else
              colour_vect[i] = "black"
          } else
          {
            if (any(env_selected[[i_taxon]][[5]]) && ii %in% which(env_selected[[i_taxon]][[5]]))
              colour_vect[i] = "darkgreen"
            else 
              colour_vect[i] = "red"
          }
        }
        plot.variance.all.axes.vs.ordered.axis.nb[[ii_taxon]] = ggplot(data=data.frame(x=1:ncol(adjr2_orderedLumpedAxes_all),y=adjr2_orderedLumpedAxes_all[i_taxon,])) +
          geom_line(aes(x,y)) +
          geom_point(aes(x,y),colour = colour_vect) +
          # geom_point(aes(x,y),colour = ifelse(pval_individualAxes_relativeAbund[i_taxon,sort.int(adjr2_individualAxes_relativeAbund[i_taxon,],index.return = T,decreasing = T)$ix]<0.05,"black","red")) +
          theme_bw() +
          ggtitle(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Number of ordered connectivity axes kept", y="Variance explained by axes")
      }
      
      spl = split(plot.variance.all.axes.vs.ordered.axis.nb, (seq_along(plot.variance.all.axes.vs.ordered.axis.nb)-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
      pdf(paste0("AdjR2_all_axes_vs_orderedAxisNb_forwardVariableSelection_globalSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
      # pdf(paste0("AdjR2_expTmin_distance_vs_orderedAxisNb_forwardVariableSelection_individuallySignif_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
      # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_forwardVariableSelection_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
      # pdf(paste0("AdjR2_relativeAbund_vs_orderedAxisNb_selected",noArcticNoBiomark_insert,noLagoon_insert,".pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
      
    }
    
    ###########################
    # Adj. R2 plots           #  
    ###########################
    
    plot.rda.adjr2_diversity = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_diversity[[j]] = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)[rda_available_groups]),y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        theme(axis.title=element_text(size=16),
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="OTU richness (log10)", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(log10(as.vector(diversity))[rda_available_groups])) +
        geom_smooth(method='lm') 
      # scale_fill_gradientn(limits = range(pval[rda_available_groups,j]), colours = c("blue","goldenrod1","red"), 
      #                      values = rescale(min(pval[rda_available_groups,j]),0.05,max(pval[rda_available_groups,j])), na.value="cyan", guide = "colourbar")
    }
    
    plot.rda.adjr2_diversity[[ncol(adjr2)+1]] = qplot(x = x, y = y, data=data.frame(x=log10(as.vector(diversity)[rda_available_groups]),y=adjr2_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="OTU richness (log10)", y="RDA adjusted R2") +
      ylim(range(adjr2_allvariables[rda_available_groups])) +
      xlim(range(log10(as.vector(diversity))[rda_available_groups])) +
      geom_smooth(method='lm') 
    
    # ggsave(filename = paste0("RDA_adjR2_vs_diversity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(abiotic_data_trans),".pdf"),
    #        do.call("arrangeGrob", c(list(plot.rda.adjr2_diversity), nrow=1)),
    #        height = 1.5*10/4, width = 1.5*10/4)
    
    pdf(paste0("RDA_adjR2_vs_diversity_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected.pdf"))
    for (j in 1:(ncol(adjr2)+1))
      print(plot.rda.adjr2_diversity[[j]])
    dev.off()
    
    #########################
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
    
    # plot.margin=unit(c(7,1,1,0.5),"mm"))
    # height = 1.5*10/4, width = 1.5*10/4
    
    plot.rda.adjr2_size = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_size[[j]] = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund[rda_available_groups]),y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="Mean size (micron, log10)", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(log10(size_absoluteAbund)[rda_available_groups])) +
        geom_smooth(method='lm') 
      # scale_fill_gradientn(limits = range(pval[rda_available_groups,j]), colours = c("blue","goldenrod1","red"), 
      #                      values = rescale(min(pval[rda_available_groups,j]),0.05,max(pval[rda_available_groups,j])), na.value="cyan", guide = "colourbar")
    }
    
    # plot.rda.adjr2_size[[ncol(adjr2)+1]] = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund[rda_available_groups]),y=adjr2_allvariables[rda_available_groups]), geom="point") +
    #   theme_bw() +
    #   ggtitle("All variables") +
    #   theme(axis.text = element_text(size=16),
    #         axis.title=element_text(size=24),
    #         plot.title=element_text(hjust=0, size=24),
    #         plot.margin=unit(c(15,1,1,0.5),"mm")) +
    #   labs(x="Mean size (micron, log10)", y="RDA adjusted R2") +
    #   ylim(range(adjr2_allvariables[rda_available_groups])) +
    #   xlim(range(log10(size_absoluteAbund)[rda_available_groups])) +
    #   geom_smooth(method='lm') 
    
    pdf(paste0("RDA_adjR2_vs_size_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected1.pdf"))
    # for (j in 1:(ncol(adjr2)+1))
    for (j in 1:(ncol(adjr2)))
      print(plot.rda.adjr2_size[[j]])
    dev.off()
    
    #########################
    mean_sim = readRDS(paste0(results_folder,"/mean_sim_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    plot.rda.adjr2_stability = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_stability[[j]] = qplot(x = x, y = y, data=data.frame(x=mean_sim[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        theme(axis.title=element_text(size=16),
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="Mean similarity across 100 real.", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(mean_sim[rda_available_groups])) +
        geom_smooth(method='lm') 
      # scale_fill_gradientn(limits = range(pval[rda_available_groups,j]), colours = c("blue","goldenrod1","red"), 
      #                      values = rescale(min(pval[rda_available_groups,j]),0.05,max(pval[rda_available_groups,j])), na.value="cyan", guide = "colourbar")
    }
    
    plot.rda.adjr2_stability[[ncol(adjr2)+1]] = qplot(x = x, y = y, data=data.frame(x=mean_sim[rda_available_groups],y=adjr2_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean similarity across 100 real.", y="RDA adjusted R2") +
      ylim(range(adjr2_allvariables[rda_available_groups])) +
      xlim(range(mean_sim[rda_available_groups])) +
      geom_smooth(method='lm') 
    
    pdf(paste0("RDA_adjR2_vs_stability_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected.pdf"))
    for (j in 1:(ncol(adjr2)+1))
      print(plot.rda.adjr2_stability[[j]])
    dev.off()
    
    #########################
    plot.rda.adjr2_optimalK = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_optimalK[[j]] = qplot(x = x, y = y, data=data.frame(x=optimalK[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        theme(axis.title=element_text(size=16),
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="Optimal number K of assemblages", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(optimalK[rda_available_groups])) +
        geom_smooth(method='lm') 
      # scale_fill_gradientn(limits = range(pval[rda_available_groups,j]), colours = c("blue","goldenrod1","red"), 
      #                      values = rescale(min(pval[rda_available_groups,j]),0.05,max(pval[rda_available_groups,j])), na.value="cyan", guide = "colourbar")
    }
    
    plot.rda.adjr2_optimalK[[ncol(adjr2)+1]] = qplot(x = x, y = y, data=data.frame(x=optimalK[rda_available_groups],y=adjr2_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Optimal number K of assemblages", y="RDA adjusted R2") +
      ylim(range(adjr2_allvariables[rda_available_groups])) +
      xlim(range(optimalK[rda_available_groups])) +
      geom_smooth(method='lm') 
    
    pdf(paste0("RDA_adjR2_vs_optimalK_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected.pdf"))
    for (j in 1:(ncol(adjr2)+1))
      print(plot.rda.adjr2_optimalK[[j]])
    dev.off()
    
    #############################
    # prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_",travel_time_threshold,"yearTminProportion_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_",particle_thres,"particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    plot.rda.adjr2_OTU.connectivity = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_OTU.connectivity[[j]] = qplot(x = x, y = y, data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        theme(axis.title=element_text(size=16),
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="Mean travel time connectivity within OTUs", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(prop_within_OTU_vect[rda_available_groups])) +
        geom_smooth(method='lm') 
    }
    
    plot.rda.adjr2_OTU.connectivity[[ncol(adjr2)+1]] = qplot(x = x, y = y, data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=adjr2_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean travel time connectivity within OTUs", y="RDA adjusted R2") +
      ylim(range(adjr2_allvariables[rda_available_groups])) +
      xlim(range(prop_within_OTU_vect[rda_available_groups])) +
      geom_smooth(method='lm') 
    
    pdf(paste0("RDA_adjR2_vs_OTU_connectivity_",travel_time_threshold,"yearTminProportion_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected.pdf"))
    for (j in 1:(ncol(adjr2)+1))
      print(plot.rda.adjr2_OTU.connectivity[[j]])
    dev.off()
    
    ###############################
    # prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_",travel_time_threshold,"yearTminProportion_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
    prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_",particle_thres,"particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    rda_available_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
    # rda_available_groups = vector(length = length(taxo_groups), mode = "logical")
    # rda_available_groups[1:133] = T
    # rda_available_groups = as.vector(diversity) > 50 
    
    plot.rda.adjr2_OTU.connectivity = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        labs(x="Mean travel time connectivity within OTUs", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(prop_within_OTU_vect[rda_available_groups])) +
        scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15), 
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              legend.text=element_text(size=16),
              legend.title=element_text(size=16)) + 
        # axis.title=element_blank(),
        # axis.text = element_blank(), panel.background = element_blank(),
        # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
        guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    }
    
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_stabilityColors_selected.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_diversityColors_morethan50OTUs.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_sizeColors_2rdBestReal.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_",travel_time_threshold,"yearTminProportion_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_sizeColors_selected.pdf"))
    pdf(paste0("RDA_adjR2_vs_OTU_connectivity_",particle_thres,"particlesThres_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_sizeColors_selected.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_optimalKColors_selected.pdf"))
    # for (j in 1:(ncol(adjr2)+1))
    for (j in 1:ncol(adjr2))
      print(plot.rda.adjr2_OTU.connectivity[[j]])
    dev.off()
    
    ################################
    plot.rda.adjr2_OTU.connectivity = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = pval[rda_available_groups,j], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        labs(x="Mean OTU connectivity per group", y="Variance explained by the environment") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(prop_within_OTU_vect[rda_available_groups])) +
        scale_colour_gradientn(colours = c("red","blue","black"), values = rescale(c(0,0.05,1)), na.value = "grey50", guide = "colourbar", name = "Environmental RDA p-value") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15), 
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              legend.text=element_text(size=16),
              legend.title=element_text(size=16)) + 
        # axis.title=element_blank(),
        # axis.text = element_blank(), panel.background = element_blank(),
        # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
        guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    }
    
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_stabilityColors_selected.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_diversityColors_morethan50OTUs.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_sizeColors_2rdBestReal.pdf"))
    pdf(paste0("RDA_adjR2_vs_OTU_connectivity_",travel_time_threshold,"yearTminProportion_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_pvalColors_selected1.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_optimalKColors_selected.pdf"))
    # for (j in 1:(ncol(adjr2)+1))
    for (j in 1:ncol(adjr2))
      print(plot.rda.adjr2_OTU.connectivity[[j]])
    dev.off()
    
    ###############################
    # prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_",travel_time_threshold,"yearTminProportion_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_",particle_thres,"particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    rda_available_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
    # rda_available_groups = vector(length = length(taxo_groups), mode = "logical")
    # rda_available_groups[1:133] = T
    # rda_available_groups = as.vector(diversity) > 50 
    
    ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
    functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
    
    plot.rda.adjr2_OTU.connectivity = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = dominant_function[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        labs(x="Mean travel time connectivity within OTUs", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(prop_within_OTU_vect[rda_available_groups])) +
        scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15), 
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              legend.text=element_text(size=10),
              legend.title=element_text(size=16)) + 
        # axis.title=element_blank(),
        # axis.text = element_blank(), panel.background = element_blank(),
        # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
        guides(colour = guide_legend(title.position="bottom"))
    }
    
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_",travel_time_threshold,"yearTminProportion_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_functionColors_selected1.pdf"))
    pdf(paste0("RDA_adjR2_vs_OTU_connectivity_",particle_thres,"particlesThres_meanPerOTU_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_functionColors_selected1.pdf"))
    # for (j in 1:(ncol(adjr2)+1))
    for (j in 1:ncol(adjr2))
      print(plot.rda.adjr2_OTU.connectivity[[j]])
    dev.off()
    
    #############################
    plot_index = 0
    plot.rda.adjr2_axes.comparison = list()
    for (i in 2:ncol(adjr2))
    {
      for (j in 1:(i-1))
      {
        plot_index = plot_index+1
        plot.rda.adjr2_axes.comparison[[plot_index]] = qplot(x = x, y = y, colour = dominant_function[rda_available_groups], data=data.frame(x=adjr2[rda_available_groups,i],y=adjr2[rda_available_groups,j]), geom="point") +
          theme_bw() +
          ggtitle(paste(colnames(adjr2)[j],"vs.",colnames(adjr2)[i])) +
          labs(x = paste("Variance explained by", colnames(adjr2)[i]), y = paste("Variance explained by", colnames(adjr2)[j])) +
          ylim(range(adjr2[rda_available_groups,j])) +
          xlim(range(adjr2[rda_available_groups,i])) +
          scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
          theme(axis.title=element_text(size=16),
                text=element_text(size=15), 
                plot.title=element_text(hjust=0, size=16),
                plot.margin=unit(c(15,1,1,0.5),"mm"),
                legend.position="bottom",
                legend.text=element_text(size=10),
                legend.title=element_text(size=16)) + 
          # axis.title=element_blank(),
          # axis.text = element_blank(), panel.background = element_blank(),
          # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
          guides(colour = guide_legend(title.position="bottom"))
      }
    }
    
    pdf(paste0("RDA_adjR2_axes_camparison_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_functionColors_selected1.pdf"))
    for (j in 1:plot_index)
      print(plot.rda.adjr2_axes.comparison[[j]])
    dev.off()
    
    #############################
    prop_within_topic_vect = readRDS(paste0(results_folder,"/Connectivity_2yearTminProportion_meanPerAssemblage_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    # ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
    
    plot.rda.adjr2_topic.connectivity = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_topic.connectivity[[j]] = qplot(x = x, y = y, data=data.frame(x=prop_within_topic_vect[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        theme(axis.title=element_text(size=16),
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="Mean travel time connectivity within assemblages", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(prop_within_topic_vect[rda_available_groups])) +
        geom_smooth(method='lm') 
    }
    
    plot.rda.adjr2_topic.connectivity[[ncol(adjr2)+1]] = qplot(x = x, y = y, data=data.frame(x=prop_within_topic_vect[rda_available_groups],y=adjr2_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean travel time connectivity within assemblages", y="RDA adjusted R2") +
      ylim(range(adjr2_allvariables[rda_available_groups])) +
      xlim(range(prop_within_topic_vect[rda_available_groups])) +
      geom_smooth(method='lm') 
    
    pdf(paste0("RDA_adjR2_vs_topic_connectivity_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected.pdf"))
    for (j in 1:(ncol(adjr2)+1))
      print(plot.rda.adjr2_topic.connectivity[[j]])
    dev.off()
    
    #############################
    prop_within_topic_vect = readRDS(paste0(results_folder,"/Connectivity_2yearTminProportion_meanPerAssemblage_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    plot.rda.adjr2_topic.connectivity = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_topic.connectivity[[j]] = qplot(x = x, y = y, colour = size_absoluteAbund[rda_available_groups], data=data.frame(x=prop_within_topic_vect[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        labs(x="Mean travel time connectivity within assemblages", y="RDA adjusted R2") +
        ylim(range(adjr2[rda_available_groups,j])) +
        xlim(range(prop_within_topic_vect[rda_available_groups])) +
        scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15), 
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              legend.text=element_text(size=16),
              legend.title=element_text(size=16)) + 
        # axis.title=element_blank(),
        # axis.text = element_blank(), panel.background = element_blank(),
        # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
        guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    }
    
    plot.rda.adjr2_topic.connectivity[[ncol(adjr2)+1]] = qplot(x = x, y = y, colour = size_absoluteAbund[rda_available_groups], data=data.frame(x=prop_within_topic_vect[rda_available_groups],y=adjr2_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      labs(x="Mean travel time connectivity within assemblages", y="RDA adjusted R2") +
      ylim(range(adjr2_allvariables[rda_available_groups])) +
      xlim(range(prop_within_topic_vect[rda_available_groups])) +
      scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
      theme(axis.title=element_text(size=16),
            text=element_text(size=15), 
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm"),
            legend.position="bottom",
            legend.text=element_text(size=16),
            legend.title=element_text(size=16)) + 
      # axis.title=element_blank(),
      # axis.text = element_blank(), panel.background = element_blank(),
      # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
      guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    
    pdf(paste0("RDA_adjR2_vs_topic_connectivity_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_sizeColors_selected.pdf"))
    for (j in 1:(ncol(adjr2)+1))
      print(plot.rda.adjr2_topic.connectivity[[j]])
    dev.off()
    
    #########################
    
    rda_available_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
    
    plot.rda.adjr2_vs_adjr2_3rdBestReal = list()
    for (j in 1:ncol(adjr2))
    {
      plot.rda.adjr2_vs_adjr2_3rdBestReal[[j]] = qplot(x = x, y = y, colour = mean_sim[rda_available_groups], data=data.frame(x=adjr2_BestReal[rda_available_groups,j],y=adjr2_3rdBestReal[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(adjr2)[j]) +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15),
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              legend.text=element_text(size=16),
              legend.title=element_text(size=16)) + 
        labs(x="RDA adjusted R2 best real.", y="RDA adjusted R2 3rd best real.") +
        ylim(range(adjr2_3rdBestReal[rda_available_groups,j])) +
        xlim(range(adjr2_BestReal[rda_available_groups,j])) +
        scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean similarity across 100 real.") +
        geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
        # geom_smooth(method='lm') +
        guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    }
    
    plot.rda.adjr2_vs_adjr2_3rdBestReal[[ncol(adjr2)+1]] = qplot(x = x, y = y, colour = mean_sim[rda_available_groups], data=data.frame(x=adjr2_allvariables_BestReal[rda_available_groups],y=adjr2_allvariables_3rdBestReal[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            text=element_text(size=15),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm"),
            legend.position="bottom",
            legend.text=element_text(size=16),
            legend.title=element_text(size=16)) + 
      labs(x="RDA adjusted R2 best real.", y="RDA adjusted R2 3rd best real.") +
      ylim(range(adjr2_allvariables_3rdBestReal[rda_available_groups])) +
      xlim(range(adjr2_allvariables_BestReal[rda_available_groups])) +
      scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean similarity across 100 real.") +
      geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
      # geom_smooth(method='lm') +
      guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    
    pdf(paste0("RDA_adjR2_vs_adjr2_3rdBestReal_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_stabilityColors_selected.pdf"))
    for (j in 1:(ncol(adjr2)+1))
      print(plot.rda.adjr2_vs_adjr2_3rdBestReal[[j]])
    dev.off()
    
  }
  
  # Varpart-specific figures:
  if (varpart_lda)
  {
    # varpart.groups.expTmin.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    # varpart.groups.expTmin.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    # 
    varpart.groups.expTmin.indSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.indSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    varpart.indSelec = readRDS(paste0(results_folder,"/varpart_lda",Gibbs_VEM_insert,target_groups_insert,
                                      "_separate.SUR.DCM_both.directions.independent.selection_PCA0",
                                      abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".rds"))
    varpart.env.spatial = varpart.indSelec[[1]]
    varpart.env.spatial[[1]][varpart.env.spatial[[1]]<0] = 0
    varpart.env.spatial[[2]][varpart.env.spatial[[2]]<0] = 0
    varpart.env.spatial.pval = varpart.indSelec[[2]]
    
    sub.varpart.biotic.abiotic = varpart.indSelec[[3]]
    sub.varpart.biotic.abiotic[[1]][sub.varpart.biotic.abiotic[[1]]<0] = 0
    sub.varpart.biotic.abiotic[[2]][sub.varpart.biotic.abiotic[[2]]<0] = 0
    sub.varpart.biotic.abiotic.pval = varpart.indSelec[[4]]
    
    # sub.varpart.SUR.DCM = varpart.indSelec[[5]]
    # sub.varpart.SUR.DCM[sub.varpart.SUR.DCM<0] = 0
    # sub.varpart.SUR.DCM.pval = varpart.indSelec[[6]]
    
    varpart.biotic.abiotic = varpart.indSelec[[5]]
    varpart.biotic.abiotic[[1]][varpart.biotic.abiotic[[1]]<0] = 0
    varpart.biotic.abiotic[[2]][varpart.biotic.abiotic[[2]]<0] = 0
    varpart.biotic.abiotic.pval = varpart.indSelec[[6]]
    
    # varpart.SUR.DCM = varpart.indSelec[[9]] 
    # varpart.SUR.DCM[varpart.SUR.DCM<0] = 0
    # varpart.SUR.DCM.pval = varpart.indSelec[[10]] 
    
    # varpart.groups.expTmin.globalSelec0 = varpart.groups.expTmin.globalSelec
    # varpart.groups.expTmin.globalSelec0[varpart.groups.expTmin.globalSelec0<0] = 0
    varpart.groups.expTmin.indSelec0 = varpart.groups.expTmin.indSelec
    varpart.groups.expTmin.indSelec0[varpart.groups.expTmin.indSelec0<0] = 0
    
    # significant_global_model_globalSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    significant_global_model_old = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_independentSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    significant_global_model_indSelec_old = vector(length = length(taxo_groups), mode = "logical")
    for (i_taxon in 1:length(taxo_groups))
      significant_global_model_indSelec_old[i_taxon] = all(significant_global_model_old[[i_taxon]])
    
    significant_global_model = readRDS(paste0(results_folder,"/RDA",Gibbs_VEM_insert,
                                              "_separate.SUR.DCM_noSelectedAxes-envSelected-significantGlobalModel-nbSites_both.directions.independent.selection",
                                              abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".rds"))[[3]]
    significant_global_model_indSelec = list(SUR=vector(length = length(taxo_groups), mode = "logical"),
                                             DCM=vector(length = length(taxo_groups), mode = "logical"))
    for (i_taxon in 1:length(taxo_groups))
    {
      significant_global_model_indSelec[[1]][i_taxon] = all(significant_global_model[[1]][[i_taxon]])
      significant_global_model_indSelec[[2]][i_taxon] = all(significant_global_model[[2]][[i_taxon]])
    }
      
    ####################
    # barplot all taxa #
    ####################
    {
      ##### All fractions:
      # "Pure abiotic","Pure biotic", "Pure currents", "Mixed biotic-abiotic", "Mixed biotic-currents", "Mixed abiotic-currents", "Mixed biotic-abiotic-currents"
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_AllTaxa_SUR.DCM.allfractions.boxplot_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
      par(mar=c(2,4.1,6.1,1.1))
      barplot_matrix = cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(1,4,2,6,5,7,3),]
      dimnames(barplot_matrix) = list(c("Purely by abiotic conditions","Jointly by biotic and abiotic conditions","Purely by biotic conditions",
                                            "Jointly by currents and abiotic conditions","Jointly by currents and biotic conditions","Jointly by currents, abiotic and biotic conditions",
                                            "Purely by currents"), c("Surface","DCM"))
      #colors = c("deepskyblue4","cadetblue","chartreuse3")
      # colors = c(colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")(3),
      #            colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")(3),
      #            "#00007F")
      colors = c("chartreuse3",colorRampPalette(c("chartreuse3","red"),space = "Lab")(3)[2],"red",
                colorRampPalette(c("chartreuse3","#007FFF"),space = "Lab")(3)[2],colorRampPalette(c("#007FFF","red"),space = "Lab")(3)[2],
                "antiquewhite3",
                "#007FFF")
      barplot(barplot_matrix,col=colors, 
              # xaxt="n", 
              legend.text = T, args.legend = list(x="topleft",bty = "n",inset = c(0,-0.22)),
              space = c(1,1))
      title(ylab="Explained variance",cex.lab=1.3)
      dev.off()
      
      ##### All fractions - abiotic-currents only:
      # "Pure abiotic","Pure biotic", "Pure currents", "Mixed biotic-abiotic", "Mixed biotic-currents", "Mixed abiotic-currents", "Mixed biotic-abiotic-currents"
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_AllTaxa_SUR.DCM.abiotic.currents.boxplot_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
      par(mar=c(2,4.1,6.1,1.1))
      barplot_matrix = matrix(nrow=3,ncol=2,data=0,
                              dimnames = list(c("Purely by abiotic conditions",
                                                "Jointly by currents and abiotic conditions",
                                                "Purely by currents"), c("Surface","DCM")))
      barplot_matrix[1,] = colSums(cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(1,4),])
      barplot_matrix[2,] = colSums(cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(6,7),])
      barplot_matrix[3,] = colSums(cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(3,5),])
      #colors = c("deepskyblue4","cadetblue","chartreuse3")
      # colors = c(colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")(3),
      #            colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")(3),
      #            "#00007F")
      colors = c("chartreuse3",colorRampPalette(c("chartreuse3","#007FFF"),space = "Lab")(3)[2],"#007FFF")
      barplot(barplot_matrix,col=colors, 
              # xaxt="n", 
              legend.text = T, args.legend = list(x="topleft",bty = "n",inset = c(0,-0.22)),
              space = c(1,1))
      title(ylab="Explained variance",cex.lab=1.3)
      dev.off()
      
      ######### One mixed fraction:
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_AllTaxa_SUR.DCM.oneMixedFraction.boxplot_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
      par(mar=c(2,4.1,4.1,1.1))
      barplot_matrix = matrix(nrow=5,ncol=2,data=0,
                                         dimnames = list(c("Purely by abiotic conditions","Jointly by biotic and abiotic conditions","Purely by biotic conditions",
                                                                               "Jointly by currents and environmental conditions",
                                                                               "Purely by currents"), c("Surface","DCM")))
      barplot_matrix[c(1:3,5),] = cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(1,4,2,3),]
      barplot_matrix[4,] = colSums(cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[5:7,])
      
      #colors = c("deepskyblue4","cadetblue","chartreuse3")
      # colors = c(colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")(3),
      #            colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")(3),
      #            "#00007F")
      colors = c("chartreuse3",colorRampPalette(c("chartreuse3","red"),space = "Lab")(3)[2],"red",
                 "#A7848F",
                 "#007FFF")
      barplot(barplot_matrix,col=colors, 
              # xaxt="n", 
              legend.text = T, args.legend = list(x="topleft",bty = "n",inset = c(0,-0.12)),
              space = c(1,1))
      title(ylab="Explained variance",cex.lab=1.3)
      dev.off()
    }
    
    ######################
    # barplot Functional #
    ######################
    {
      ##### All fractions:
      # "Pure abiotic","Pure biotic", "Pure currents", "Mixed biotic-abiotic", "Mixed biotic-currents", "Mixed abiotic-currents", "Mixed biotic-abiotic-currents"
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_AllTaxa.Functional_SUR.DCM.allfractions.boxplot_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
      par(mar=c(2,4.1,6.1,1.1))
      barplot_matrix = cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(1,4,2,6,5,7,3),]
      dimnames(barplot_matrix) = list(c("Purely by abiotic conditions","Jointly by biotic and abiotic conditions","Purely by biotic conditions",
                                        "Jointly by currents and abiotic conditions","Jointly by currents and biotic conditions","Jointly by currents, abiotic and biotic conditions",
                                        "Purely by currents"), c("Surface","DCM"))
      #colors = c("deepskyblue4","cadetblue","chartreuse3")
      # colors = c(colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")(3),
      #            colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")(3),
      #            "#00007F")
      colors = c("chartreuse3",colorRampPalette(c("chartreuse3","red"),space = "Lab")(3)[2],"red",
                 colorRampPalette(c("chartreuse3","#007FFF"),space = "Lab")(3)[2],colorRampPalette(c("#007FFF","red"),space = "Lab")(3)[2],
                 "antiquewhite3",
                 "#007FFF")
      barplot(barplot_matrix,col=colors, 
              # xaxt="n", 
              legend.text = T, args.legend = list(x="topleft",bty = "n",inset = c(0,-0.22)),
              space = c(1,1))
      title(ylab="Explained variance - functional biogeography",cex.lab=1.3)
      dev.off()
      
      ##### All fractions - abiotic-currents only:
      # "Pure abiotic","Pure biotic", "Pure currents", "Mixed biotic-abiotic", "Mixed biotic-currents", "Mixed abiotic-currents", "Mixed biotic-abiotic-currents"
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_AllTaxa.Functional_SUR.DCM.abiotic.currents.boxplot_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
      par(mar=c(2,4.1,6.1,1.1))
      barplot_matrix = matrix(nrow=3,ncol=2,data=0,
                              dimnames = list(c("Purely by abiotic conditions",
                                                "Jointly by currents and abiotic conditions",
                                                "Purely by currents"), c("Surface","DCM")))
      barplot_matrix[1,] = colSums(cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(1,4),])
      barplot_matrix[2,] = colSums(cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(6,7),])
      barplot_matrix[3,] = colSums(cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(3,5),])
      #colors = c("deepskyblue4","cadetblue","chartreuse3")
      # colors = c(colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")(3),
      #            colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")(3),
      #            "#00007F")
      colors = c("chartreuse3",colorRampPalette(c("chartreuse3","#007FFF"),space = "Lab")(3)[2],"#007FFF")
      barplot(barplot_matrix,col=colors, 
              # xaxt="n", 
              legend.text = T, args.legend = list(x="topleft",bty = "n",inset = c(0,-0.22)),
              space = c(1,1))
      title(ylab="Explained variance - functional biogeography",cex.lab=1.3)
      dev.off()
      
      ######### One mixed fraction:
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_AllTaxa.Functional_SUR.DCM.oneMixedFraction.boxplot_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
      par(mar=c(2,4.1,4.1,1.1))
      barplot_matrix = matrix(nrow=5,ncol=2,data=0,
                              dimnames = list(c("Purely by abiotic conditions","Jointly by biotic and abiotic conditions","Purely by biotic conditions",
                                                "Jointly by currents and environmental conditions",
                                                "Purely by currents"), c("Surface","DCM")))
      barplot_matrix[c(1:3,5),] = cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[c(1,4,2,3),]
      barplot_matrix[4,] = colSums(cbind(sub.varpart.biotic.abiotic$SUR,sub.varpart.biotic.abiotic$DCM)[5:7,])
      
      #colors = c("deepskyblue4","cadetblue","chartreuse3")
      # colors = c(colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")(3),
      #            colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")(3),
      #            "#00007F")
      colors = c("chartreuse3",colorRampPalette(c("chartreuse3","red"),space = "Lab")(3)[2],"red",
                 "#A7848F",
                 "#007FFF")
      barplot(barplot_matrix,col=colors, 
              # xaxt="n", 
              legend.text = T, args.legend = list(x="topleft",bty = "n",inset = c(0,-0.12)),
              space = c(1,1))
      title(ylab="Explained variance - functional biogeography",cex.lab=1.3)
      dev.off()
    }
    
    ############
    # barplots #
    ############
    {
      varpart.groups0 = varpart.groups
      varpart.groups0[varpart.groups0 < 0] = 0
      env_sorting = sort.int(colSums(varpart.groups0[,selected_groups]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      
      shading_density = rbind(varpart.groups.pval[1,selected_groups][env_sorting],rep(0,length(taxo_groups[selected_groups])),varpart.groups.pval[2,selected_groups][env_sorting])
      shading_density[shading_density<0.05] = 0
      shading_density[shading_density>0] = 10
      
      pdf(paste0("varpart_lda_abiotic_vs_taxoGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_decreasingTotalVariance.pdf"))
      par(mar=c(7.1,4.1,4.1,2.1))
      #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
      x = barplot(varpart.groups0[,selected_groups][,env_sorting],col=terrain.colors(3),legend.text = T, xaxt="n", space = rep(1,ncol(shading_density)), args.legend = list(bty = "n"))
      for (i in 1:ncol(shading_density))
      {
        subbarplot = varpart.groups0[,selected_groups][,env_sorting]
        subbarplot[,-i] = 0
        barplot(subbarplot, col = "black", density = shading_density[,i], xaxt="n", yaxt="n", space = rep(1,ncol(shading_density)), add = T)
      }
      title(ylab="Explained variance (RDA)",cex.lab=1.3)
      labs = taxo_groups[selected_groups][env_sorting]
      text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      dev.off()
      
      ###################
      # Decreasing total env-spatial variance, all fractions:
      
      varpart.groups.expTmin0 = varpart.groups.expTmin
      varpart.groups.expTmin0[varpart.groups.expTmin0 < 0] = 0
      tot_sorting = sort.int(colSums(varpart.groups.expTmin0[,selected_groups]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      shading_density = rbind(varpart.groups.expTmin.pval[2,selected_groups][tot_sorting],rep(0,length(taxo_groups[selected_groups])),rep(0,length(taxo_groups[selected_groups])),rep(0,length(taxo_groups[selected_groups])),
                              varpart.groups.expTmin.pval[1,selected_groups][tot_sorting],rep(0,length(taxo_groups[selected_groups])),varpart.groups.expTmin.pval[3,selected_groups][tot_sorting])
      shading_density[shading_density<0.05] = 0
      shading_density[shading_density>0] = 10
      
      tot_sorting_indSelec = sort.int(colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      shading_density = rbind(varpart.groups.expTmin.indSelec.pval[2,selected_groups & significant_global_model_indSelec][tot_sorting_indSelec],rep(0,length(taxo_groups[selected_groups & significant_global_model_indSelec])),rep(0,length(taxo_groups[selected_groups & significant_global_model_indSelec])),rep(0,length(taxo_groups[selected_groups & significant_global_model_indSelec])),
                              varpart.groups.expTmin.indSelec.pval[1,selected_groups & significant_global_model_indSelec][tot_sorting_indSelec],rep(0,length(taxo_groups[selected_groups & significant_global_model_indSelec])),varpart.groups.expTmin.indSelec.pval[3,selected_groups & significant_global_model_indSelec][tot_sorting_indSelec])
      shading_density[shading_density<0.05] = 0
      shading_density[shading_density>0] = 10
      
      # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
      # pdf(paste0("varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_distance",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_decreasingTotalVariance.pdf"))
      # pdf(paste0("varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_distance_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_decreasingTotalVariance.pdf"))
      pdf(paste0("varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_distance_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_decreasingTotalVariance.pdf"))
      par(mar=c(7.1,4.1,4.1,2.1))
      #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
      x = barplot(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec][,tot_sorting_indSelec],col=terrain.colors(7),legend.text = T, xaxt="n", space = rep(1,ncol(shading_density)), args.legend = list(bty = "n"))
      for (i in 1:ncol(shading_density))
      {
        subbarplot = varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec][,tot_sorting_indSelec]
        subbarplot[,-i] = 0
        barplot(subbarplot, col = "black", density = shading_density[,i], xaxt="n", yaxt="n", space = rep(1,ncol(shading_density)), add = T)
      }
      title(ylab="Explained variance (RDA)",cex.lab=1.3)
      labs = taxo_groups[selected_groups][tot_sorting_indSelec]
      text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      dev.off()
      
      #########################
      # Decreasing total env_spatial variance, no fraction:
      
      sorting = sort.int(colSums(varpart.env.spatial[,selected_groups & diversity > 100]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_total_variance",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected100.pdf"))
      # par(mar=c(7.1,4.1,4.1,2.1))
      par(mar=c(4.4,4.1,0.5,0.5))
      #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
      x = barplot(colSums(varpart.env.spatial[,selected_groups & diversity > 100][,sorting]),col="gray", xaxt="n", space = rep(0,length(taxo_groups[selected_groups & diversity > 100])), args.legend = list(bty = "n"))
      title(ylab="Explained variance (RDA)",cex.lab=1.3)
      labs = taxo_groups_unmodified[selected_groups & diversity > 100][sorting]
      labs[!labs %in% c("Bacillariophyta","Arthropoda","Dinophyceae","Diplonemida","Collodaria","Acantharea")] = NA
      # text(cex=0.3, x=x+2.5, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
      text(cex=1, x=x+1.25, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
      dev.off()
      
      ##########################
      # Decreasing total env-spatial variance, environment and spatial fractions:
      
      div_threshold = 100
      for (i_case in 1:2)
      {
        # tot_sorting_indSelec = sort.int(colSums(varpart.env.spatial[,selected_groups]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        tot_sorting = sort.int(colSums(varpart.env.spatial[[i_case]][,selected_groups & diversity>div_threshold]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        
        # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
        # pdf(paste0("varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_distance",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_decreasingTotalVariance.pdf"))
        # pdf(paste0("varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_distance_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_decreasingTotalVariance.pdf"))
        # pdf(paste0("varpart_environment.currents_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected_decreasingTotalVariance.pdf"))
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_",if (i_case == 1) "SUR" else "DCM","_environment.currents_individualSelection",
                   abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected",if (div_threshold == 1000) "1000" else if (div_threshold == 100) "100+1","_eigenvalueThres0.8_decreasingTotalVariance.pdf"))
        # par(mar=c(7.1,4.1,4.1,2.1))
        par(mar=c(7,5.1,0.5,0.5))
        barplot_data.frame = rbind(varpart.env.spatial[[i_case]][1,],varpart.env.spatial[[i_case]][2,],varpart.env.spatial[[i_case]][3,])
        dimnames(barplot_data.frame) = list(c("Purely by environment","Jointly by currents and environment","Purely by currents"), taxo_groups_unmodified)
        barplot_data.frame = barplot_data.frame[,selected_groups & diversity > div_threshold][,tot_sorting]
        x = barplot(barplot_data.frame,col=terrain.colors(3), xaxt="n", legend.text = T, args.legend = list(x="topright",bty = "n", cex = 1.3),
                    space = rep(0,length(taxo_groups[selected_groups & diversity > div_threshold])), cex.axis=1.5)
        # for (i in 1:length(taxo_groups[selected_groups & diversity > div_threshold]))
        # {
        #   subbarplot = barplot_data.frame
        #   subbarplot[,-i] = 0
        #   # barplot(subbarplot, col = "black", density = shading_density[,i], xaxt="n", yaxt="n", space = rep(1,ncol(shading_density)), add = T)
        #   barplot(subbarplot, col = terrain.colors(3), xaxt="n", yaxt="n", space = rep(0,length(taxo_groups[selected_groups & diversity > div_threshold])), add = T)
        # }
        # legend(x="topright",legend=rownames(barplot_data.frame),bty = "n",col=terrain.colors(3))
        title(ylab=paste(if (i_case == 1) "Surface" else "DCM","explained variance"),cex.lab=1.7)
        labs = taxo_groups_unmodified[selected_groups & diversity > div_threshold][tot_sorting]
        labs[!labs %in% c("Bacillariophyta","Arthropoda","Dinophyceae","Diplonemida","Collodaria","Acantharea")] = NA
        text(cex=1.5, x=x+1.25*length(which(selected_groups & diversity > div_threshold))/70, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
        # text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
        dev.off()
      }
      
      ##########################
      # Decreasing total abiotic-biotic variance, abiotic and biotic fractions:
      tot_sorting = sort.int(colSums(varpart.biotic.abiotic[,selected_groups & diversity > div_threshold]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      
      # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
      # pdf(paste0("varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_distance",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_decreasingTotalVariance.pdf"))
      # pdf(paste0("varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_distance_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_decreasingTotalVariance.pdf"))
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_biotic.abiotic_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected",ifelse(div_threshold == 2,"",div_threshold),"_decreasingTotalVariance.pdf"))
      par(mar=c(7.1,4.1,4.1,2.1))
      barplot_data.frame = varpart.biotic.abiotic[c(3,2,1),]
      dimnames(barplot_data.frame) = list(c("Purely by biotic conditions","Jointly by biotic and abiotic conditions","Purely by abiotic conditions"), taxo_groups_unmodified)
      barplot_data.frame = barplot_data.frame[,selected_groups & diversity > div_threshold][,tot_sorting]
      colors = c("deepskyblue4","cadetblue","chartreuse3")
      barplot(barplot_data.frame,col=colors, xaxt="n", legend.text = T, args.legend = list(x="top",bty = "n"),
              space = rep(0,length(taxo_groups[selected_groups & diversity > div_threshold])))
      # for (i in 1:length(taxo_groups[selected_groups & diversity > div_threshold]))
      # {
      #   subbarplot = barplot_data.frame
      #   subbarplot[,-i] = 0
      #   # barplot(subbarplot, col = "black", density = shading_density[,i], xaxt="n", yaxt="n", space = rep(1,ncol(shading_density)), add = T)
      #   barplot(subbarplot, col = terrain.colors(9)[c(3,4,5)], xaxt="n", yaxt="n", space = rep(1,length(taxo_groups[selected_groups & diversity > div_threshold])), add = T)
      # }
      # legend(x="topright",legend=rownames(barplot_data.frame),bty = "n",col=terrain.colors(3))
      title(ylab="Explained variance",cex.lab=1.3)
      labs = taxo_groups_unmodified[selected_groups & diversity > div_threshold][tot_sorting]
      labs[!labs %in% c("Bacillariophyta","Arthropoda","Dinophyceae","Diplonemida","Collodaria","Acantharea")] = NA
      # text(cex=0.3, x=x+2.5, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
      text(cex=1, x=x+1.25, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
      # text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      dev.off()
      
      ##################
      # Sorting the groups according to decreasing relative abiotic/biotic fraction, within the biotic-abiotic partitioning:
      biotic_based = 1
      abiotic_based = 0
      
      for (i_case in 1:2)
      {
        if (abiotic_based)
        {
          env_sorting = sort.int(varpart.biotic.abiotic[[i_case]][1,selected_groups]/colSums(varpart.biotic.abiotic[[i_case]][,selected_groups]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        } else if (biotic_based)
          env_sorting = sort.int(varpart.biotic.abiotic[[i_case]][3,selected_groups]/colSums(varpart.biotic.abiotic[[i_case]][,selected_groups]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        
        # shading_density = rbind(varpart.groups.pval[1,selected_groups][env_sorting],rep(0,length(taxo_groups[selected_groups])),varpart.groups.pval[2,selected_groups][env_sorting])
        # shading_density[shading_density<0.05] = 0
        # shading_density[shading_density>0] = 10
        # To remove non-significant fractions from the plot:
        # if (abiotic_based)
        # {
        #   env_sorting = env_sorting[shading_density[1,] == 0]
        #   shading_density = shading_density[,shading_density[1,] == 0]
        # } else if (biotic_based)
        # { 
        #   env_sorting = env_sorting[shading_density[3,] == 0]
        #   shading_density = shading_density[,shading_density[3,] == 0]
        # }
        
        if (abiotic_based)
        {
          pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_",if (i_case == 1) "SUR" else "DCM","_abiotic.biotic",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected",ifelse(div_threshold == 2,"",div_threshold),"_eigenvalueThres0.8_decreasingAbioticOrder.pdf"))
          colors = c("deepskyblue4","cadetblue","chartreuse3")[c(3,2,1)]
          plot.data = varpart.biotic.abiotic[[i_case]][,selected_groups]
          dimnames(plot.data) = list(c("Purely by abiotic conditions","Jointly by biotic and abiotic conditions","Purely by biotic conditions"), taxo_groups_unmodified[selected_groups])
        } else if (biotic_based)
        {
          pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_",if (i_case == 1) "SUR" else "DCM","_abiotic.biotic",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected",ifelse(div_threshold == 2,"",div_threshold),"_eigenvalueThres0.8_decreasingBioticOrder.pdf"))
          plot.data = varpart.biotic.abiotic[[i_case]][c(3,2,1),selected_groups]
          # shading_density = shading_density[c(3,2,1),]
          colors = c("deepskyblue4","cadetblue","chartreuse3")
          dimnames(plot.data) = list(c("Purely by biotic conditions","Jointly by biotic and abiotic conditions","Purely by abiotic conditions"), taxo_groups_unmodified[selected_groups])
        }
        par(mar=c(4.5,4.1,4.1,2.1))
        #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
        x = barplot(t(apply(plot.data[,env_sorting],1,function(x) x/colSums(varpart.biotic.abiotic[[i_case]][,selected_groups][,env_sorting]))),
                    col=colors,legend.text = T, xaxt="n", space = rep(0,ncol(plot.data)), args.legend = list(bty = "n", x= "topright", inset = c(0,-0.15)))
        # normalization of varpart.groups[,selected_groups][,env_sorting]: colSums(t(apply(varpart.groups[,selected_groups][,env_sorting],1,function(x) x/colSums(varpart.groups[,selected_groups][,env_sorting])))) = c(1,1,...)
        # for (i in 1:ncol(shading_density))
        # {
        #   subbarplot = t(apply(varpart.groups0[,selected_groups][,env_sorting],1,function(x) x/colSums(varpart.groups0[,selected_groups][,env_sorting])))
        #   subbarplot[,-i] = 0
        #   barplot(subbarplot, col = "black", density = shading_density[,i], xaxt="n", yaxt="n", space = rep(1,ncol(shading_density)), add = T)
        # }
        title(ylab=paste("Proportion of",if (i_case == 1) "surface" else "DCM","explained variance"),cex.lab=1.3)
        labs = taxo_groups_unmodified[selected_groups][env_sorting]
        # if (biotic_based)
        # {
        labs[!labs %in% c("Bacillariophyta","Arthropoda","Dinophyceae","Diplonemida","Collodaria","Acantharea")] = NA
        # text(cex=0.3, x=x+2.5, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
        text(cex=1, x=x+1.25, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
        # text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
        # } else if (abiotic_based)
        #   text(cex=0.5, x=x+2, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
        dev.off()
      }
      
      ##################
      # Sorting the groups according to decreasing relative environment/currents fraction:
      env_based = 1
      currents_based = 0
      div_threshold = 2
      nb_sites_threshold = 0
      
      for (i_case in 1:2)
      {
        # c("Pure environment","Mixed environment-currents","Pure currents")
        if (env_based)
        {
          # sorting = sort.int(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec])/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
          sorting = sort.int(varpart.env.spatial[[i_case]][1,selected_groups]/colSums(varpart.env.spatial[[i_case]][,selected_groups]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        } else if (currents_based)
        {
          sorting = sort.int(varpart.env.spatial[[i_case]][3,selected_groups]/colSums(varpart.env.spatial[[i_case]][,selected_groups]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        }
        # shading_density = rbind(varpart.groups.expTmin.indSelec.pval[1,selected_groups][sorting],rep(0,length(taxo_groups[selected_groups])),varpart.groups.pval[2,selected_groups][env_sorting])
        # shading_density[shading_density<0.05] = 0
        # shading_density[shading_density>0] = 10
        # To remove non-significant fractions from the plot:
        # if (abiotic_based)
        # {
        #   env_sorting = env_sorting[shading_density[1,] == 0]
        #   shading_density = shading_density[,shading_density[1,] == 0]
        # } else if (biotic_based)
        # { 
        #   env_sorting = env_sorting[shading_density[3,] == 0]
        #   shading_density = shading_density[,shading_density[3,] == 0]
        # }
        
        if (env_based)
        {
          pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_",if (i_case == 1) "SUR" else "DCM","_environment.currents_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected100+1",
                     ifelse(nb_sites_threshold == 0,"",paste0(nb_sites_threshold,"sites")),"_eigenvalueThres0.8_decreasingEnvOrder.pdf"))
          plot.data = rbind(varpart.env.spatial[[i_case]][1,selected_groups],
                            varpart.env.spatial[[i_case]][2,selected_groups],
                            varpart.env.spatial[[i_case]][3,selected_groups])
          dimnames(plot.data) = list(c("Purely by environment","Jointly by currents and environment","Purely by currents"), taxo_groups_unmodified[selected_groups])
          colors = terrain.colors(3)
        } else if (currents_based)
        {
          pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_",if (i_case == 1) "SUR" else "DCM","_environment.currents_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected100+1",
                     ifelse(nb_sites_threshold == 0,"",paste0(nb_sites_threshold,"sites")),"_eigenvalueThres0.8_decreasingCurrentsOrder.pdf"))
          plot.data = rbind(varpart.env.spatial[[i_case]][3,selected_groups],
                            varpart.env.spatial[[i_case]][2,selected_groups],
                            varpart.env.spatial[[i_case]][1,selected_groups])
          dimnames(plot.data) = list(c("Purely by currents","Jointly by currents and environment","Purely by environment"), taxo_groups_unmodified[selected_groups])
          # shading_density = shading_density[c(3,2,1),]
          colors = terrain.colors(3)[c(3,2,1)]
        }
        par(mar=c(4.5,4.1,4.1,2.1))
        #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
        x = barplot(t(apply(plot.data[,sorting],1,function(x) x/colSums(varpart.env.spatial[[i_case]][,selected_groups][,sorting]))),
                    col=colors,legend.text = T, xaxt="n", space = rep(0,ncol(plot.data)), args.legend = list(bty = "n", x= "topright", inset = c(0,-0.15)))
        # normalization of varpart.groups[,selected_groups][,env_sorting]: colSums(t(apply(varpart.groups[,selected_groups][,env_sorting],1,function(x) x/colSums(varpart.groups[,selected_groups][,env_sorting])))) = c(1,1,...)
        # for (i in 1:ncol(plot.data))
        # {
        #   subbarplot = t(apply(plot.data[,sorting],1,function(x) x/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec][,sorting])))
        #   subbarplot[,-i] = 0
        #   barplot(subbarplot, col = "black", xaxt="n", yaxt="n", space = rep(1,ncol(plot.data)), add = T)
        # }
        title(ylab=paste("Proportion of",if (i_case == 1) "surface" else "DCM","explained variance"),cex.lab=1.3)
        labs = taxo_groups_unmodified[selected_groups][sorting]
        labs[!labs %in% c("Bacillariophyta","Arthropoda","Dinophyceae","Diplonemida","Collodaria","Acantharea")] = NA
        # if (biotic_based)
        # {
        # text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
        # } else if (abiotic_based)
        #   text(cex=0.5, x=x+2, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
        text(cex=1, x=x+1.25, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
        dev.off()
      }
      
      ##################
      # Sorting the groups according to decreasing relative SUR/DCM fraction:
      SUR_based = 1
      DCM_based = 0
      div_threshold = 100
      
      # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
      if (SUR_based)
      {
        # sorting = sort.int(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec])/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        sorting = sort.int(sub.varpart.SUR.DCM[1,selected_groups & diversity > div_threshold]/colSums(sub.varpart.SUR.DCM[c(1,2,3,5,6,7,12),selected_groups & diversity > div_threshold]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      } else if (DCM_based)
      {
        sorting = sort.int(sub.varpart.SUR.DCM[2,selected_groups & diversity > div_threshold]/colSums(sub.varpart.SUR.DCM[c(1,2,3,5,6,7,12),selected_groups & diversity > div_threshold]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      }
      
      # c("Pure SUR currents","Pure DCM currents", "Pure Mixed Layer", "Pure environment", "Mixed SUR-DCM",
      #   "Mixed DCM-MixedLayer", "Mixed SUR-MixedLayer", "Mixed SUR-env.", "Mixed DCM-env.", "MixedLayer-env.","Mixed SUR-DCM-env.",
      #   "Mixed SUR-DCM-MixedLayer", "Mixed DCM-MixedLayer-env.", "Mixed SUR-MixedLayer-env.", "Mixed SUR-DCM-MixedLayer-env.")
      
      if (SUR_based)
      {
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_sub.SUR.DCM.MixedLayer_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected",ifelse(div_threshold == 2,"",div_threshold),"_decreasingSUROrder.pdf"))
        plot.data = rbind(sub.varpart.SUR.DCM[1,selected_groups & diversity > div_threshold],
                          sub.varpart.SUR.DCM[2,selected_groups & diversity > div_threshold],
                          sub.varpart.SUR.DCM[3,selected_groups & diversity > div_threshold],
                          colSums(sub.varpart.SUR.DCM[c(6,7,12),selected_groups & diversity > div_threshold]))
        dimnames(plot.data) = list(c("Purely by surface currents","Purely by DCM currents","Purely by vert. mixing","By joint vert. mixing and currents"), taxo_groups_unmodified[selected_groups & diversity > div_threshold])
        colors = terrain.colors(4)[c(1,4,2,3)]
      } else if (DCM_based)
      {
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_sub.SUR.DCM.MixedLayer_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected",ifelse(div_threshold == 2,"",div_threshold),"_decreasingDCMOrder.pdf"))
        plot.data = rbind(colSums(sub.varpart.SUR.DCM[c(6,7,12),selected_groups & diversity > div_threshold]),
                          sub.varpart.SUR.DCM[3,selected_groups & diversity > div_threshold],
                          sub.varpart.SUR.DCM[2,selected_groups & diversity > div_threshold],
                          sub.varpart.SUR.DCM[1,selected_groups & diversity > div_threshold])
        dimnames(plot.data) = list(rev(c("Purely by surface currents","Purely by vert. mixing","Purely by DCM currents","By joint vert. mixing and currents")), taxo_groups_unmodified[selected_groups & diversity > div_threshold])
        # shading_density = shading_density[c(3,2,1),]
        colors = terrain.colors(4)[rev(c(1,4,2,3))]
      }
      par(mar=c(4.1,4.1,5.1,1.1))
      #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
      x = barplot(t(apply(plot.data[,sorting],1,function(x) x/colSums(sub.varpart.SUR.DCM[c(1,2,3,5,6,7,12),selected_groups & diversity > div_threshold][,sorting]))),
                  col=colors,legend.text = T, xaxt="n", space = rep(1,ncol(plot.data)), args.legend = list(bty = "n", x= "topright", inset = c(0,-0.19)))
      # normalization of varpart.groups[,selected_groups][,env_sorting]: colSums(t(apply(varpart.groups[,selected_groups][,env_sorting],1,function(x) x/colSums(varpart.groups[,selected_groups][,env_sorting])))) = c(1,1,...)
      # for (i in 1:ncol(plot.data))
      # {
      #   subbarplot = t(apply(plot.data[,sorting],1,function(x) x/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec][,sorting])))
      #   subbarplot[,-i] = 0
      #   barplot(subbarplot, col = "black", xaxt="n", yaxt="n", space = rep(1,ncol(plot.data)), add = T)
      # }
      title(ylab="Proportion of explained variance",cex.lab=1.3)
      labs = taxo_groups_unmodified[selected_groups & diversity > div_threshold][sorting]
      # if (biotic_based)
      # {
      text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      # } else if (abiotic_based)
      #   text(cex=0.5, x=x+2, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      dev.off()
      
      ##################
      # Sorting the groups according to decreasing relative abiotic/biotic fraction within the pure env. fraction:
      biotic_based = 1
      abiotic_based = 0
      div_threshold = 100
      
      # c("Pure abiotic", "Pure biotic", "Pure currents", "Mixed biotic-abiotic", "Mixed biotic-currents", "Mixed abiotic-currents", "Mixed biotic-abiotic-currents")
      if (biotic_based)
      {
        # sorting = sort.int(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec])/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        sorting = sort.int(sub.varpart.biotic.abiotic[2,selected_groups & diversity > div_threshold]/colSums(sub.varpart.biotic.abiotic[c(1,2,4),selected_groups & diversity > div_threshold]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      } else if (abiotic_based)
      {
        sorting = sort.int(sub.varpart.biotic.abiotic[1,selected_groups & diversity > div_threshold]/colSums(sub.varpart.biotic.abiotic[c(1,2,4),selected_groups & diversity > div_threshold]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      }
      
      if (biotic_based)
      {
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_sub.biotic.abiotic_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected",ifelse(div_threshold == 2,"",div_threshold),"_decreasingBioticOrder.pdf"))
        plot.data = rbind(sub.varpart.biotic.abiotic[2,selected_groups & diversity > div_threshold],
                          sub.varpart.biotic.abiotic[4,selected_groups & diversity > div_threshold],
                          sub.varpart.biotic.abiotic[1,selected_groups & diversity > div_threshold])
        dimnames(plot.data) = list(c("Purely by biotic conditions","Jointly by biotic and abiotic conditions","Purely by abiotic conditions"), taxo_groups_unmodified[selected_groups & diversity > div_threshold])
        # colors = terrain.colors(9)[c(3,4,5)]
        colors = c("deepskyblue4","cadetblue","chartreuse3")
        # colors = c("dodgerblue4","cadetblue","chartreuse3")
      } else if (abiotic_based)
      {
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_sub.biotic.abiotic_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected",ifelse(div_threshold == 2,"",div_threshold),"_decreasingAbioticOrder.pdf"))
        plot.data = rbind(sub.varpart.biotic.abiotic[1,selected_groups & diversity > div_threshold],
                          sub.varpart.biotic.abiotic[4,selected_groups & diversity > div_threshold],
                          sub.varpart.biotic.abiotic[2,selected_groups & diversity > div_threshold])
        dimnames(plot.data) = list(c("Purely by abiotic conditions","By joint biotic and biotic conditions","Purely by biotic conditions"), taxo_groups_unmodified[selected_groups & diversity > div_threshold])
        # shading_density = shading_density[c(3,2,1),]
        # colors = terrain.colors(9)[rev(c(3,4,5))]
        colors = rev(c("deepskyblue4","cadetblue","chartreuse3"))
      }
      par(mar=c(4.5,4.1,5.1,1.1))
      #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
      x = barplot(t(apply(plot.data[,sorting],1,function(x) x/colSums(sub.varpart.biotic.abiotic[c(1,2,4),selected_groups & diversity > div_threshold][,sorting]))),
                  col=colors,legend.text = T, xaxt="n", space = rep(0,ncol(plot.data)), args.legend = list(bty = "n", x= "topright", inset = c(0,-0.15)))
      # normalization of varpart.groups[,selected_groups][,env_sorting]: colSums(t(apply(varpart.groups[,selected_groups][,env_sorting],1,function(x) x/colSums(varpart.groups[,selected_groups][,env_sorting])))) = c(1,1,...)
      # for (i in 1:ncol(plot.data))
      # {
      #   subbarplot = t(apply(plot.data[,sorting],1,function(x) x/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec][,sorting])))
      #   subbarplot[,-i] = 0
      #   barplot(subbarplot, col = "black", xaxt="n", yaxt="n", space = rep(1,ncol(plot.data)), add = T)
      # }
      title(ylab="Proportion of explained variance",cex.lab=1.3)
      labs = taxo_groups_unmodified[selected_groups & diversity > div_threshold][sorting]
      labs[!labs %in% c("Bacillariophyta","Arthropoda","Dinophyceae","Diplonemida","Collodaria","Acantharea")] = NA
      # if (biotic_based)
      # {
      # text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      # text(cex=0.35, x=x+1.25, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      text(cex=1, x=x+1.25, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      # } else if (abiotic_based)
      #   text(cex=0.5, x=x+2, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      dev.off()
      
      ##################
      # Sorting the groups according to decreasing relative abiotic/biotic fraction within the env-spatial mixed fraction:
      biotic_based = 1
      abiotic_based = 0
      div_threshold = 100
      
      # c("Pure abiotic", "Pure biotic", "Pure currents", "Mixed biotic-abiotic", "Mixed biotic-currents", "Mixed abiotic-currents", "Mixed biotic-abiotic-currents")
      if (biotic_based)
      {
        # sorting = sort.int(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec])/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
        sorting = sort.int(sub.varpart.biotic.abiotic[5,selected_groups & diversity > div_threshold]/colSums(sub.varpart.biotic.abiotic[c(5,6,7),selected_groups & diversity > div_threshold]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      } else if (abiotic_based)
      {
        sorting = sort.int(sub.varpart.biotic.abiotic[6,selected_groups & diversity > div_threshold]/colSums(sub.varpart.biotic.abiotic[c(5,6,7),selected_groups & diversity > div_threshold]), index.return = T, decreasing = T, na.last = T, method = "radix")$ix
      }
      
      if (biotic_based)
      {
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_sub.biotic.abiotic.mixed.fraction_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected",ifelse(div_threshold == 2,"",div_threshold),"_decreasingBioticOrder.pdf"))
        plot.data = rbind(sub.varpart.biotic.abiotic[5,selected_groups & diversity > div_threshold],
                          sub.varpart.biotic.abiotic[7,selected_groups & diversity > div_threshold],
                          sub.varpart.biotic.abiotic[6,selected_groups & diversity > div_threshold])
        dimnames(plot.data) = list(c("Purely by biotic conditions","Jointly by biotic and abiotic conditions","Purely by abiotic conditions"), taxo_groups_unmodified[selected_groups & diversity > div_threshold])
        # colors = terrain.colors(9)[c(3,4,5)]
        colors = c("deepskyblue4","cadetblue","chartreuse3")
        # colors = c("dodgerblue4","cadetblue","chartreuse3")
      } else if (abiotic_based)
      {
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_lda_sub.biotic.abiotic.mixed.fraction_individualSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_relativeFraction_selected",ifelse(div_threshold == 2,"",div_threshold),"_decreasingAbioticOrder.pdf"))
        plot.data = rbind(sub.varpart.biotic.abiotic[6,selected_groups & diversity > div_threshold],
                          sub.varpart.biotic.abiotic[7,selected_groups & diversity > div_threshold],
                          sub.varpart.biotic.abiotic[5,selected_groups & diversity > div_threshold])
        dimnames(plot.data) = list(c("Purely by abiotic conditions","By joint biotic and biotic conditions","Purely by biotic conditions"), taxo_groups_unmodified[selected_groups & diversity > div_threshold])
        # shading_density = shading_density[c(3,2,1),]
        # colors = terrain.colors(9)[rev(c(3,4,5))]
        colors = rev(c("deepskyblue4","cadetblue","chartreuse3"))
      }
      par(mar=c(4.5,4.1,5.1,1.1))
      x = barplot(t(apply(plot.data[,sorting],1,function(x) x/colSums(sub.varpart.biotic.abiotic[c(5,6,7),selected_groups & diversity > div_threshold][,sorting]))),
                  col=colors,legend.text = T, xaxt="n", space = rep(0,ncol(plot.data)), args.legend = list(bty = "n", x= "topright", inset = c(0,-0.15)))
      title(ylab="Proportion of explained variance",cex.lab=1.3)
      labs = taxo_groups_unmodified[selected_groups & diversity > div_threshold][sorting]
      labs[!labs %in% c("Bacillariophyta","Arthropoda","Dinophyceae","Diplonemida","Collodaria","Acantharea")] = NA
      # if (biotic_based)
      # {
      # text(cex=0.35, x=x+3, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      # text(cex=0.35, x=x+1.25, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      text(cex=1, x=x+1.25, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      # } else if (abiotic_based)
      #   text(cex=0.5, x=x+2, y=-0.03, labels = labs, xpd=TRUE, srt=45, pos=2)
      dev.off()
      
      ##################
      # abiotic and functional fractions:
      
      shading_density = rbind(varpart.functions.pval[1,selected_groups],rep(0,length(taxo_groups[selected_groups])),varpart.functions.pval[2,selected_groups])
      shading_density[shading_density<0.05] = 0
      shading_density[shading_density>0] = 10
      
      # pdf(paste0("varpart_lda_abiotic_vs_functions",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
      pdf(paste0("varpart_lda_abiotic_vs_functions",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_2firstFunctionsAxes.pdf"))
      par(mar=c(7.1,4.1,4.1,2.1))
      #barplot(VarPart_data.frame_reordered,col=terrain.colors(3),ann=F,names.arg=colnames(VarPart_data.frame_reordered),las=3,legend.text = T, args.legend = list(bty = "n"))
      x = barplot(varpart.functions[,selected_groups],col=terrain.colors(3),legend.text = T, xaxt="n", space = rep(1,length(taxo_groups[selected_groups])), args.legend = list(bty = "n"))
      for (i in 1:ncol(shading_density))
      {
        subbarplot = varpart.functions[,selected_groups]
        subbarplot[,-i] = 0
        barplot(subbarplot, col = "black", density = shading_density[,i], xaxt="n", yaxt="n", space = rep(1,length(taxo_groups[selected_groups])), add = T)
      }
      title(ylab="Explained variance (RDA)",cex.lab=1.3)
      labs = taxo_groups[selected_groups]
      text(cex=0.5, x=x+3, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
      dev.off()
      
    }
    
    #############################
    # t-tests functional groups #
    #############################
    {
      #########################################
      ###   All functional groups plots     ###
      #########################################
      
      div_threshold = 100
      
      dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      dominant_function0 = dominant_function[selected_groups & diversity>div_threshold]
      # dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
      # dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
      dominant_function0[dominant_function0 == "unknown"] = NA
      dominant_function0[dominant_function0 == "photohost"] = "Collodaria"
      dominant_function0[dominant_function0 == "pteropoda"] = "Pteropoda"
      dominant_function0[dominant_function0 == "copepoda"] = "Copepoda"
      dominant_function0[dominant_function0 == "gelatineous_carnivores_filterers"] = "Gel. carn. filterers"
      dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Dinophyceae"] = "Dinophyceae"
      dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Bacillariophyta"] = "Bacillariophyta"
      dominant_function0[dominant_function0 == "phototroph"] = "Other phototrophs"
      dominant_function0[dominant_function0 == "phagotroph"] = "Phagotrophs"
      dominant_function0[dominant_function0 == "other metazoa"] = "Other metazoa"
      dominant_function0[dominant_function0 == "parasite"] = "Parasites"
      # alpha = rep(1,length(taxo_groups[selected_groups]))
      # alpha[dominant_function0 %in% c("copepoda","pteropoda")] = 0 
      # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them by deceasing number of groups:
      # dominant_function0 = factor(dominant_function0,names(sort(table(as.factor(dominant_function0)),decreasing = T)))
      # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them in the specified order:
      if (div_threshold == 100)
      {
        dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Pteropoda","Copepoda","Other metazoa","Parasites"))
        point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")
      } else if (div_threshold == 1000)
      {
        dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Copepoda","Parasites"))
        point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta")
      } 
        
      #log-ratio currents-env: 
      boxplot.ratio.currents.env.functions = list()
      for (i_case in 1:2)
      {
        boxplot.ratio.currents.env.functions[[i_case]] = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                  y = (varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,])
                                                                  [selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
          scale_x_discrete(limits=levels(dominant_function0)) +
          geom_boxplot(aes(x,y)) +
          geom_point(data = data.frame(x = factor(point_groups),
                                       y = (varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,])[selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                     aes(x,y)) +
          theme_bw() +
          scale_y_log10() +
          geom_hline(yintercept = 1, linetype = "dashed") +
          theme(axis.title=element_text(size=22),
                axis.text=element_text(size=22),
                axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
                plot.margin=unit(c(10,1,1,5),"mm")) +
          #labs(x="", y=paste("Ratio of",if (i_case == 1) "surface" else "DCM","variance\n purely explained by currents vs. envir."))
          labs(x="",y="")
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.ratio.pure.currents.env_boxplot_allFunctionalGroups_selected",
                 if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
      print(boxplot.ratio.currents.env.functions[[1]])
      print(boxplot.ratio.currents.env.functions[[2]])
      dev.off()
      
      #log-ratio biotic-abiotic: 
      boxplot.ratio.biotic.abiotic.functions = list()
      for (i_case in 1:2)
      {
        boxplot.ratio.biotic.abiotic.functions[[i_case]] = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                                  y = (varpart.biotic.abiotic[[i_case]][3,]/varpart.biotic.abiotic[[i_case]][1,])
                                                                                  [selected_groups & diversity>div_threshold & (varpart.biotic.abiotic[[i_case]][3,]/varpart.biotic.abiotic[[i_case]][1,]) < 30]
                                                                                  [!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
          scale_x_discrete(limits=levels(dominant_function0)) +
          geom_boxplot(aes(x,y)) +
          geom_point(data = data.frame(x = factor(point_groups),
                                       y = (varpart.biotic.abiotic[[i_case]][3,]/varpart.biotic.abiotic[[i_case]][1,])
                                       [selected_groups & diversity>div_threshold & (varpart.biotic.abiotic[[i_case]][3,]/varpart.biotic.abiotic[[i_case]][1,]) < 30]
                                       [dominant_function0 %in% point_groups]),
                     aes(x,y)) +
          theme_bw() +
          scale_y_log10() +
          geom_hline(yintercept = 1, linetype = "dashed") +
          theme(axis.title=element_text(size=22),
                axis.text=element_text(size=22),
                axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
                plot.margin=unit(c(10,1,1,10),"mm")) +
          #labs(x="", y=paste("Ratio of",if (i_case == 1) "surface" else "DCM","variance\n purely explained by currents vs. envir."))
          labs(x="",y="")
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.ratio.pure.biotic.abiotic_boxplot_allFunctionalGroups_selected",
                 if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
      print(boxplot.ratio.biotic.abiotic.functions[[1]])
      print(boxplot.ratio.biotic.abiotic.functions[[2]])
      dev.off()
      
      #log-ratio sub biotic-abiotic: 
      boxplot.ratio.sub.biotic.abiotic.functions = list()
      for (i_case in 1:2)
      {
        boxplot.ratio.sub.biotic.abiotic.functions[[i_case]] = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                                    y = (sub.varpart.biotic.abiotic[[i_case]][3,]/sub.varpart.biotic.abiotic[[i_case]][1,])
                                                                                    [selected_groups & diversity>div_threshold & (sub.varpart.biotic.abiotic[[i_case]][3,]/sub.varpart.biotic.abiotic[[i_case]][1,]) < 30]
                                                                                    [!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
          scale_x_discrete(limits=levels(dominant_function0)) +
          geom_boxplot(aes(x,y)) +
          geom_point(data = data.frame(x = factor(point_groups),
                                       y = (sub.varpart.biotic.abiotic[[i_case]][3,]/sub.varpart.biotic.abiotic[[i_case]][1,])
                                       [selected_groups & diversity>div_threshold & (sub.varpart.biotic.abiotic[[i_case]][3,]/sub.varpart.biotic.abiotic[[i_case]][1,]) < 30]
                                       [dominant_function0 %in% point_groups]),
                     aes(x,y)) +
          theme_bw() +
          scale_y_log10() +
          geom_hline(yintercept = 1, linetype = "dashed") +
          theme(axis.title=element_text(size=22),
                axis.text=element_text(size=22),
                axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
                plot.margin=unit(c(10,1,1,10),"mm")) +
          #labs(x="", y=paste("Ratio of",if (i_case == 1) "surface" else "DCM","variance\n purely explained by currents vs. envir."))
          labs(x="",y="")
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.ratio.pure.sub.biotic.abiotic_boxplot_allFunctionalGroups_selected",
                 if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
      print(boxplot.ratio.sub.biotic.abiotic.functions[[1]])
      print(boxplot.ratio.sub.biotic.abiotic.functions[[2]])
      dev.off()
      
      #############
      
      boxplot.biotic.functions = list()
      for (i_case in 1:2)
      {
        boxplot.biotic.functions[[i_case]] = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                                    y = sub.varpart.biotic.abiotic[[i_case]][1,]
                                                                                    [selected_groups & diversity>div_threshold]
                                                                                    [!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
          scale_x_discrete(limits=levels(dominant_function0)) +
          geom_boxplot(aes(x,y)) +
          geom_point(data = data.frame(x = factor(point_groups),
                                       y = sub.varpart.biotic.abiotic[[i_case]][1,]
                                       [selected_groups & diversity>div_threshold]
                                       [dominant_function0 %in% point_groups]),
                     aes(x,y)) +
          theme_bw() +
          scale_y_log10() +
          #geom_hline(yintercept = 1, linetype = "dashed") +
          theme(axis.title=element_text(size=22),
                axis.text=element_text(size=22),
                axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
                plot.margin=unit(c(10,1,1,10),"mm")) +
          labs(x="", y=paste(if (i_case == 1) "Surface" else "DCM","variance\n purely explained by abiotic envir."))
          labs(x="",y="")
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.sub.pure.abiotic_boxplot_allFunctionalGroups_selected",
                 if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
      print(boxplot.biotic.functions[[1]])
      print(boxplot.biotic.functions[[2]])
      dev.off()
      
      ############
      for (i_case in 1:2)
      {
        boxplot.relative.env.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                  y = (varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))
                                                                  [selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
          scale_x_discrete(limits=levels(dominant_function0)) +
          geom_boxplot(aes(x,y)) +
          geom_point(data = data.frame(x = factor(point_groups),
                                       y = (varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                     aes(x,y)) +
          theme_bw() +
          theme(axis.title=element_text(size=22),
                axis.text=element_text(size=22),
                axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
                plot.margin=unit(c(2,1,1,0.5),"mm")) +
          labs(x="", y=paste("Relative",if (i_case == 1) "surface" else "DCM","variance explained\n purely by the environment"))
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.rel.pure.env.",if (i_case == 1) "SUR" else "DCM","_boxplot_allFunctionalGroups_selected",
                   if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
        print(boxplot.relative.env.functions)
        dev.off()
        
        boxplot.relative.currents.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                       y = (varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
          scale_x_discrete(limits=levels(dominant_function0)) +
          geom_boxplot(aes(x,y)) +
          geom_point(data = data.frame(x = factor(point_groups),
                                       y = (varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                     aes(x,y)) +
          theme_bw() +
          theme(axis.title=element_text(size=22),
                axis.text=element_text(size=22),
                axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
                plot.margin=unit(c(2,1,1,0.5),"mm")) +
          labs(x="", y=paste("Relative",if (i_case == 1) "surface" else "DCM","variance explained\n purely by currents"))
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.rel.pure.currents",if (i_case == 1) "SUR" else "DCM","_boxplot_allFunctionalGroups_selected",
                   if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
        print(boxplot.relative.currents.functions)
        dev.off()
      }
      
      boxplot.relative.mixed.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")],
                                                                     y = (varpart.env.spatial[2,]/colSums(varpart.env.spatial))[selected_groups & diversity > 100][!is.na(dominant_function0) & !dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")),
                                     y = (varpart.env.spatial[2,]/colSums(varpart.env.spatial))[selected_groups & diversity > 100][dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=24),
              axis.text=element_text(size=17),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="", y="Relative variance explained\n jointly by currents and the environment")
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_rel_pure_mixed.env.currents_boxplot_allFunctionalGroups_selected",ifelse(div_threshold==2,"",div_threshold),".pdf"))
      print(boxplot.relative.mixed.functions)
      dev.off()
      
      boxplot.tot.variance.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")],
                                                                  y = colSums(varpart.env.spatial)[selected_groups & diversity > 100][!is.na(dominant_function0) & !dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")),
                                     y = colSums(varpart.env.spatial)[selected_groups & diversity > 100][dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=24),
              axis.text=element_text(size=17),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="", y="Total explained variance")
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_tot.variance.env.currents_boxplot_allFunctionalGroups_selected",ifelse(div_threshold==2,"",div_threshold),".pdf"))
      print(boxplot.tot.variance.functions)
      dev.off()
      
      boxplot.optimalK.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")],
                                                                y = optimalK[selected_groups & diversity > 100][!is.na(dominant_function0) & !dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")),
                                     y = optimalK[selected_groups & diversity > 100][dominant_function0 %in% c("Collodaria","Copepoda","Pteropoda","Dinophyceae","Bacillariophyta")]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=24),
              axis.text=element_text(size=17),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="", y="Number of community types")
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_optimalK_boxplot_allFunctionalGroups_selected",ifelse(div_threshold==2,"",div_threshold),".pdf"))
      print(boxplot.optimalK.functions)
      dev.off()
      
      env_mixed_currents_fractions = c((varpart.env.spatial[1,]/colSums(varpart.env.spatial))[selected_groups & diversity>100],
                                       (varpart.env.spatial[2,]/colSums(varpart.env.spatial))[selected_groups & diversity>100],
                                       (varpart.env.spatial[3,]/colSums(varpart.env.spatial))[selected_groups & diversity>100])
      
      boxplot.fractions = ggplot(data = data.frame(x = c(rep("Environment\n only",length(taxo_groups[selected_groups & diversity>100])),
                                                         rep("Currents\n and environment",length(taxo_groups[selected_groups & diversity>100])),
                                                         rep("Currents\n only",length(taxo_groups[selected_groups & diversity>100]))), 
                                                   y = env_mixed_currents_fractions)) +
        geom_boxplot(aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=24),
              axis.text=element_text(size=17),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="", y="Relative explained variance")
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_env.currents.fractions_boxplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,ifelse(div_threshold==2,"",div_threshold),".pdf"))
      print(boxplot.fractions)
      dev.off()
      
    ##########################################
    ###   Four functional groups plots     ###
    ##########################################
     
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
    # functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
    
    # varpart.groups0 = varpart.groups
    # varpart.groups0[varpart.groups0 < 0] = 0
    
    # dominant_function0 = dominant_function[selected_groups]
    dominant_function0 = dominant_function[selected_groups & diversity>100]
    # dominant_function0[dominant_function0 == "gelatineous_carnivores_filterers"] = "gel. carniv.\nfilterers"
    # dominant_function0[dominant_function0 == "other metazoa"] = "other\nmetazoa"
    dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
    dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
    # Changes how the factors are stored so that geom_boxplot plots them by deceasing number of groups:
    dominant_function0 = factor(dominant_function0,names(sort(table(as.factor(dominant_function0)),decreasing = T)))
    
    ######################################
    # Explanatory variables boxplots     #
    ######################################
    
    boxplot.size.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = log10(size_relativeAbund)[selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y=expression("Mean within-group body size ("*mu*"m)"))
    pdf(paste0("varpart_body.size_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.size.functions)
    dev.off()
    
    boxplot.abundance.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Mean group relative abundance")
    pdf(paste0("varpart_abundance_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.abundance.functions)
    dev.off()
    
    boxplot.diversity.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = log10(as.vector(diversity))[selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="OTU richness (log10)")
    pdf(paste0("varpart_diversity_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.diversity.functions)
    dev.off()
    
    boxplot.connectivity.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = 1-prop_within_OTU_vect[selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Mean within-group OTU connectivity")
    pdf(paste0("varpart_connectivity_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.connectivity.functions)
    dev.off()
    
    boxplot.optimalK.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = optimalK[selected_groups & diversity>100][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Number of community types")
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_optimalK_boxplot_4functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected",ifelse(div_threshold==2,"",div_threshold),".pdf"))
    print(boxplot.optimalK.functions)
    dev.off()
    
    boxplot.VI_over_K.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = VI_over_K[selected_groups & diversity>100][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Disimilarity between\n Surface and DCM communities")
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_VI_over_K_boxplot_4functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected",ifelse(div_threshold==2,"",div_threshold),".pdf"))
    print(boxplot.VI_over_K.functions)
    dev.off()
    
    boxplot.stability.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = mean_sim[selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Convergence")
    pdf(paste0("varpart_convergence_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.stability.functions)
    dev.off()
    
    #####################################
    # Raw fractions:                    #
    #####################################
    
    boxplot.pure.env.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec])[!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Variance explained\n purely by the environment")
    pdf(paste0("varpart_pure.environment_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.pure.env.functions)
    dev.off()
    
    t.test(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec])[dominant_function0 == "metazoa"],
           colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec])[dominant_function0 == "parasite"])
    
    boxplot.env.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = colSums(varpart.groups.expTmin.indSelec0[1:6,selected_groups & significant_global_model_indSelec])[!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Variance explained\n by the environment")
    pdf(paste0("varpart_tot.environment_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.env.functions)
    dev.off()
    
    boxplot.pure.currents.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Variance explained\n purely by currents")
    pdf(paste0("varpart_pure.currents_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.pure.currents.functions)
    dev.off()
    
    t.test(varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec][dominant_function0 == "metazoa"],
           varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec][dominant_function0 == "parasite"])
    
    t.test(varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec][dominant_function0 == "parasite"],
           varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec][dominant_function0 == "phagotroph"])
    
    t.test(varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec][dominant_function0 == "parasite"],
           varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec][dominant_function0 == "phototroph"])
    
    boxplot.mixed.currents.environment.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec])[!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Variance explained\n by both currents and the environment")
    pdf(paste0("varpart_mixed.environment.currents_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.mixed.currents.environment.functions)
    dev.off()
    
    boxplot.tot.variance.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = colSums(varpart.env.spatial)[selected_groups & diversity>100][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Total variance explained\n by currents and the environment")
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_tot.variance_boxplot_4functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected",ifelse(div_threshold==2,"",div_threshold),".pdf"))
    print(boxplot.tot.variance.functions)
    dev.off()
    
    # env_mixed_currents_fractions = c(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec])[!is.na(dominant_function0)],
    #                                 colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec])[!is.na(dominant_function0)],
    #                                 varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])
    # 
    # boxplot.fractions = ggplot(data = data.frame(x = c(rep("Purely\n environment",length(taxo_groups[selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])),
    #                                                    rep("Both\n environment\n and currents",length(taxo_groups[selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)])),
    #                                                    rep("Purely\n currents",length(taxo_groups[selected_groups & significant_global_model_indSelec][!is.na(dominant_function0)]))), 
    #                                              y = env_mixed_currents_fractions)) +
    #   geom_boxplot(aes(x,y)) +
    #   theme_bw() +
    #   theme(axis.title=element_text(size=24),
    #         axis.text=element_text(size=17),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="", y="Explained variance")
    # pdf(paste0("varpart_fractions_boxplot_noUnknownNoPhotohost",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    # print(boxplot.fractions)
    # dev.off()
    
    env_mixed_currents_fractions = c(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]),
                                     colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]),
                                     varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])
    
    boxplot.fractions = ggplot(data = data.frame(x = c(rep("Purely\n environment",length(taxo_groups[selected_groups & significant_global_model_indSelec])),
                                                       rep("Both\n environment\n and currents",length(taxo_groups[selected_groups & significant_global_model_indSelec])),
                                                       rep("Purely\n currents",length(taxo_groups[selected_groups & significant_global_model_indSelec]))), 
                                                 y = env_mixed_currents_fractions)) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=17),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Explained variance")
    pdf(paste0("varpart_fractions_boxplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected.pdf"))
    print(boxplot.fractions)
    dev.off()
    
    t.test(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]),
           colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]))
    
    t.test(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]),
           varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])
    
    t.test(colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]),
           varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])
    
    #####################################
    # Relative fractions:               #
    #####################################
    
    boxplot.rel.env.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = (varpart.env.spatial[1,]/colSums(varpart.env.spatial))[selected_groups & diversity>100][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=14),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Relative variance explained\n purely by the environment")
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_relative.pure.env_boxplot_4functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected",ifelse(div_threshold==2,"",div_threshold),"_noNegativeAdjR2.pdf"))
    print(boxplot.rel.env.functions)
    dev.off()
    
    boxplot.rel.currents.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = (varpart.env.spatial[3,]/colSums(varpart.env.spatial))[selected_groups & diversity>100][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=14),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Relative variance explained\n purely by currents")
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_relative.pure.currents_boxplot_4functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected",ifelse(div_threshold==2,"",div_threshold),"_noNegativeAdjR2.pdf"))
    print(boxplot.rel.currents.functions)
    dev.off()
    
    boxplot.rel.mixed.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)], y = (varpart.env.spatial[2,]/colSums(varpart.env.spatial))[selected_groups & diversity>100][!is.na(dominant_function0)])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=14),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Relative variance explained\n jointly by currents and the environment")
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_relative.mixed.env.currents_boxplot_4functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected",ifelse(div_threshold==2,"",div_threshold),"_noNegativeAdjR2.pdf"))
    print(boxplot.rel.mixed.functions)
    dev.off()
    
    t.test((varpart.groups0[1,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "phototroph"],
           (varpart.groups0[1,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "phagotroph"])
    t.test((varpart.groups0[1,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "phototroph"],
           (varpart.groups0[1,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "parasite"])
    
    # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
    boxplot.relative.abiotic.functions = ggplot(data = data.frame(x = dominant_function0, y = (varpart.groups.expTmin0[5,]/colSums(varpart.groups.expTmin0))[selected_groups])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=14),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Abiotic relative explained variance")
    pdf(paste0("varpart.groups.expTmin_relative.pure.abiotic_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(boxplot.relative.abiotic.functions)
    dev.off()
    
    t.test((varpart.groups.expTmin0[5,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "parasite"],
           (varpart.groups.expTmin0[5,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "metazoa"])
    
    boxplot.relative.biotic.functions = ggplot(data = data.frame(x = dominant_function0, y = (varpart.groups0[3,]/colSums(varpart.groups0))[selected_groups])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=14),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Biotic relative explained variance")
    pdf(paste0("varpart_relative_pure_biotic_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(boxplot.relative.biotic.functions)
    dev.off()
    
    t.test((varpart.groups0[3,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "phototroph"],
           (varpart.groups0[3,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "phagotroph"])
    t.test((varpart.groups0[3,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "phototroph"],
           (varpart.groups0[3,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "parasite"])
    t.test((varpart.groups0[3,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "parasite"],
           (varpart.groups0[3,]/colSums(varpart.groups0))[selected_groups][dominant_function0 == "metazoa"])
    
    boxplot.relative.biotic.functions = ggplot(data = data.frame(x = dominant_function0, y = (varpart.groups.expTmin0[1,]/colSums(varpart.groups.expTmin0))[selected_groups])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=14),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Biotic relative explained variance")
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(boxplot.relative.biotic.functions)
    dev.off()
    
    t.test((varpart.groups.expTmin0[1,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "parasite"],
           (varpart.groups.expTmin0[1,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "metazoa"])
    
    boxplot.relative.env.functions = ggplot(data = data.frame(x = dominant_function0, y = (colSums(varpart.groups.expTmin0[c(1,2,5),])/colSums(varpart.groups.expTmin0))[selected_groups])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=13),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Relative variance\n explained purely by the environment")
    pdf(paste0("varpart.groups.expTmin_relative.pure.environment_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(boxplot.relative.env.functions)
    dev.off()
    
    t.test((colSums(varpart.groups.expTmin0[c(1,2,5),])/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "parasite"],
           (colSums(varpart.groups.expTmin0[c(1,2,5),])/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "metazoa"])
    
    ######################################
    boxplot.tot.variance.functions = ggplot(data = data.frame(x = dominant_function0, y = colSums(varpart.groups0)[selected_groups])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=14),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Total variance explained by the environment")
    pdf(paste0("varpart_total_variance_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(boxplot.tot.variance.functions)
    dev.off()
    
    t.test(colSums(varpart.groups0)[selected_groups][dominant_function0 == "phototroph"],
           colSums(varpart.groups0)[selected_groups][dominant_function0 == "phagotroph"])
    t.test(colSums(varpart.groups0)[selected_groups][dominant_function0 == "phototroph"],
           colSums(varpart.groups0)[selected_groups][dominant_function0 == "parasite"])
    t.test(colSums(varpart.groups0)[selected_groups][dominant_function0 == "phagotroph"],
           colSums(varpart.groups0)[selected_groups][dominant_function0 == "metazoa"])
    t.test(colSums(varpart.groups0)[selected_groups][dominant_function0 == "phototroph"],
           colSums(varpart.groups0)[selected_groups][dominant_function0 == "metazoa"])
    t.test(colSums(varpart.groups0)[selected_groups][dominant_function0 == "parasite"],
           colSums(varpart.groups0)[selected_groups][dominant_function0 == "metazoa"])
    
    boxplot.tot.variance.functions = ggplot(data = data.frame(x = dominant_function0, y = colSums(varpart.groups.expTmin0)[selected_groups])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=13),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Total variance explained\n by currents and the environment")
    pdf(paste0("varpart.groups.expTmin_total.variance_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(boxplot.tot.variance.functions)
    dev.off()
    
    ######################################
    boxplot.connectivity.functions = ggplot(data = data.frame(x = dominant_function0, y = prop_within_OTU_vect[selected_groups])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=14),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Connectivity through currents")
    pdf(paste0("varpart_connectivity_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(boxplot.connectivity.functions)
    dev.off()
    
    t.test(prop_within_OTU_vect[selected_groups][dominant_function0 == "phototroph"],
           prop_within_OTU_vect[selected_groups][dominant_function0 == "phagotroph"])
    t.test(prop_within_OTU_vect[selected_groups][dominant_function0 == "phototroph"],
           prop_within_OTU_vect[selected_groups][dominant_function0 == "parasite"])
    t.test(prop_within_OTU_vect[selected_groups][dominant_function0 == "phagotroph"],
           prop_within_OTU_vect[selected_groups][dominant_function0 == "parasite"])
    t.test(prop_within_OTU_vect[selected_groups][dominant_function0 == "phototroph"],
           prop_within_OTU_vect[selected_groups][dominant_function0 == "metazoa"])
    t.test(prop_within_OTU_vect[selected_groups][dominant_function0 == "phagotroph"],
           prop_within_OTU_vect[selected_groups][dominant_function0 == "metazoa"])
    
    ######################################
    boxplot.expTmin.functions = ggplot(data = data.frame(x = dominant_function0, y = (varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups])) +
      geom_boxplot(aes(x,y)) +
      theme_bw() +
      theme(axis.title=element_text(size=24),
            axis.text=element_text(size=13),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="", y="Relative variance\n explained purely by currents")
    pdf(paste0("varpart.groups.expTmin_relative.pure.currents_boxplot_functionalGroups",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(boxplot.expTmin.functions)
    dev.off()
    
    t.test((varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "phototroph"],
           (varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "phagotroph"])
    t.test((varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "phototroph"],
           (varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "parasite"])
    t.test((varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "phagotroph"],
           (varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "parasite"])
    t.test((varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "phototroph"],
           (varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "metazoa"])
    t.test((varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "phagotroph"],
           (varpart.groups.expTmin0[7,]/colSums(varpart.groups.expTmin0))[selected_groups][dominant_function0 == "metazoa"])
    
    }
    
    ###############################################
    # expTmin partition vs. MEM.SUR.DCM partition #
    ###############################################
    {
      
    div_threshold = 100  
      
    plot.tot.variance.expTmin.MEM = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[,selected_groups & diversity>100]),y=colSums(varpart.env.spatial[,selected_groups & diversity>100]))) +
      geom_point(aes(x,y)) +
      geom_abline(slope = 1,intercept = 0, linetype = 2) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total variance expTmin", y="Total variance MEM.SUR.DCM") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_tot_var_MEM.SUR.DCM_vs_expTmin_ggplot_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
    print(plot.tot.variance.expTmin.MEM)
    dev.off()
    
    plot.rel.env.expTmin.MEM = ggplot(data=data.frame(y=varpart.env.spatial[1,selected_groups & diversity>100]/colSums(varpart.env.spatial[,selected_groups & diversity>100]), 
                                                      x=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & diversity>100])/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & diversity>100]))) +
      geom_point(aes(x,y)) +
      geom_abline(slope = 1,intercept = 0, linetype = 2) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance explained\n by the environment expTmin", y="Relative variance explained\n by the environment MEM.SUR.DCM") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_relative_env_MEM.SUR.DCM_vs_expTmin_ggplot_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
    print(plot.rel.env.expTmin.MEM)
    dev.off()
    
    plot.rel.currents.expTmin.MEM = ggplot(data=data.frame(y=varpart.env.spatial[3,selected_groups & diversity>100]/colSums(varpart.env.spatial[,selected_groups & diversity>100]), 
                                                      x=varpart.groups.expTmin.indSelec0[7,selected_groups & diversity>100]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & diversity>100]))) +
      geom_point(aes(x,y)) +
      geom_abline(slope = 1,intercept = 0, linetype = 2) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(y="Relative variance explained\n by currents MEM.SUR.DCM", x="Relative variance explained\n by currents expTmin") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_relative_currents_MEM.SUR.DCM_vs_expTmin_ggplot_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
    print(plot.rel.currents.expTmin.MEM)
    dev.off()
    
    plot.rel.mixed.expTmin.MEM = ggplot(data=data.frame(y=varpart.env.spatial[2,selected_groups & diversity>100]/colSums(varpart.env.spatial[,selected_groups & diversity>100]), 
                                                           x=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & diversity>100])/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & diversity>100]))) +
      geom_point(aes(x,y)) +
      geom_abline(slope = 1,intercept = 0, linetype = 2) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(y="Relative variance explained\n jointly by currents and env. MEM.SUR.DCM", x="Relative variance explained\n jointly by currents and env. expTmin") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart_relative_mixed_MEM.SUR.DCM_vs_expTmin_ggplot_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
    print(plot.rel.mixed.expTmin.MEM)
    dev.off()
    
    }
    
    ##################################################################
    # biotic-abiotic partition vs. currents-biotic-abiotic partition #
    ##################################################################
    {
    
    varpart.groups.expTmin0 = varpart.groups.expTmin
    varpart.groups.expTmin0[varpart.groups.expTmin0<0] = 0
    
    # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
    
    plot.relative.pure.biotic.with.without.currents = ggplot(data=data.frame(x=varpart.groups0[3,selected_groups]/colSums(varpart.groups0[,selected_groups]),
                                                                                y=varpart.groups.expTmin0[1,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative pure biotic fration\n without currents", y="Relative pure biotic fration\n with currents") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_vs_varpart.groups_relative.pure.biotic_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.with.without.currents)
    dev.off()
    
    ##################
    plot.relative.pure.abiotic.with.without.currents = ggplot(data=data.frame(x=varpart.groups0[1,selected_groups]/colSums(varpart.groups0[,selected_groups]),
                                                                             y=varpart.groups.expTmin0[5,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative pure abiotic fration\n without currents", y="Relative pure abiotic fration\n with currents") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_vs_varpart.groups_relative.pure.abiotic_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.with.without.currents)
    dev.off()
    
    ##################
    plot.relative.pure.env.with.currents.vs.tot.variance.without.currents = ggplot(data=data.frame(x=colSums(varpart.groups0[,selected_groups]),
                                                                              y=colSums(varpart.groups.expTmin0[c(1,2,5),selected_groups])/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total variance explained by the environment\n without currents", y="Relative pure environmental fration\n with currents") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_vs_varpart.groups_environmental.fraction_ggplot_forwardBothDirectionsVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.env.with.currents.vs.tot.variance.without.currents)
    dev.off()
    
    ##################
    plot.tot.variance.with.without.currents = ggplot(data=data.frame(x=colSums(varpart.groups0[,selected_groups]),
                                                                    y=colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total variance explained by the environment\n without currents", y="Total variance explained \nby currents and environment") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_vs_varpart.groups_environmental.fraction_ggplot_forwardBothDirectionsVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.tot.variance.with.without.currents)
    dev.off()
    
    }
    
    ##############################################
    # global selection vs. independent selection #
    ##############################################
    {
    
    varpart.groups.expTmin.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    varpart.groups.expTmin.indSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.indSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    varpart.groups.expTmin.indSelec0 = varpart.groups.expTmin.indSelec
    varpart.groups.expTmin.indSelec0[varpart.groups.expTmin.indSelec0<0] = 0
    varpart.groups.expTmin.globalSelec0 = varpart.groups.expTmin.globalSelec
    varpart.groups.expTmin.globalSelec0[varpart.groups.expTmin.globalSelec0<0] = 0
    
    significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    # plot.tot.variance.ind.vs.global.selection = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model]),
    #                                                                  y=colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model]))) +
    plot.tot.variance.ind.vs.global.selection = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[,selected_groups]),
                                                                     y=colSums(varpart.groups.expTmin.globalSelec0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total explained variance\n by independently selected axes", y="Total explained variance\n by globally selected axes") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_vs_tot.variance.independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_vs_tot.variance.independent.selection_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.tot.variance.ind.vs.global.selection)
    dev.off()
    
    # plot.rel.pure.abiotic.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model]),
    #                                                                 y=varpart.groups.expTmin.globalSelec0[5,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model]))) +
    plot.rel.pure.abiotic.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[5,selected_groups]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups]),
                                                                    y=varpart.groups.expTmin.globalSelec0[5,selected_groups]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected abiotic axes", y="Relative variance purely explained\n by globally selected abiotic axes") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_rel.pure.abiotic.global.selection_vs_rel.pure.abiotic.independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # pdf(paste0("varpart.groups.expTmin_rel.pure.abiotic.global.selection_vs_rel.pure.abiotic.independent.selection_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.rel.pure.abiotic.ind.vs.global.selection)
    dev.off()
    
    # plot.rel.pure.biotic.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model]),
    #                                                                        y=varpart.groups.expTmin.globalSelec0[1,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model]))) +
    plot.rel.pure.biotic.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[1,selected_groups]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups]),
                                                                           y=varpart.groups.expTmin.globalSelec0[1,selected_groups]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected biotic axes", y="Relative variance purely explained\n by globally selected biotic axes") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_rel.pure.biotic.global.selection_vs_rel.pure.biotic.independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # pdf(paste0("varpart.groups.expTmin_rel.pure.biotic.global.selection_vs_rel.pure.biotic.independent.selection_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.rel.pure.biotic.ind.vs.global.selection)
    dev.off()
    
    # plot.rel.pure.expTmin.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model]),
    #                                                                       y=varpart.groups.expTmin.globalSelec0[7,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model]))) +
    plot.rel.pure.expTmin.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[7,selected_groups]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups]),
                                                                          y=varpart.groups.expTmin.globalSelec0[7,selected_groups]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected currents axes", y="Relative variance purely explained\n by globally selected currents axes") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_rel.pure.currents.global.selection_vs_rel.pure.currents.independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # pdf(paste0("varpart.groups.expTmin_rel.pure.currents.global.selection_vs_rel.pure.currents.independent.selection_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.rel.pure.expTmin.ind.vs.global.selection)
    dev.off()
    
    }
    
    ##############################################################
    # number of selected axes - global vs. independent selection #
    ##############################################################
    {
    # varpart.groups.expTmin.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    # varpart.groups.expTmin.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    # varpart.groups.expTmin.indSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    # varpart.groups.expTmin.indSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    # 
    # varpart.groups.expTmin.indSelec0 = varpart.groups.expTmin.indSelec
    # varpart.groups.expTmin.indSelec0[varpart.groups.expTmin.indSelec0<0] = 0
    # varpart.groups.expTmin.globalSelec0 = varpart.groups.expTmin.globalSelec
    # varpart.groups.expTmin.globalSelec0[varpart.groups.expTmin.globalSelec0<0] = 0
    
    env_selected_indSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_independentSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    env_selected_globalSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    
    significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    test = vector(length = length(taxo_groups), mode = "logical")
    for (i_taxon in 1:(length(taxo_groups)-2))
    {
      test[i_taxon] = all(env_selected_indSelec[[i_taxon]][[1]] == env_selected_globalSelec[[i_taxon]][[1]])
    }
    
    indSelec_globalSelec_abiotic2_selection = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:(length(taxo_groups)-2))
    {
      if (env_selected_indSelec[[i_taxon]][[1]][2] && env_selected_globalSelec[[i_taxon]][[1]][2] || !env_selected_indSelec[[i_taxon]][[1]][2] && !env_selected_globalSelec[[i_taxon]][[1]][2])
      {
        indSelec_globalSelec_abiotic2_selection[i_taxon] = 0
      } else if (env_selected_indSelec[[i_taxon]][[1]][2] && !env_selected_globalSelec[[i_taxon]][[1]][2])
      {
        indSelec_globalSelec_abiotic2_selection[i_taxon] = 1
      } else if (!env_selected_indSelec[[i_taxon]][[1]][2] && env_selected_globalSelec[[i_taxon]][[1]][2])
        indSelec_globalSelec_abiotic2_selection[i_taxon] = -1
    }
    
    indSelec_globalSelec_abiotic1_selection = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:(length(taxo_groups)-2))
    {
      if (env_selected_indSelec[[i_taxon]][[1]][1] && env_selected_globalSelec[[i_taxon]][[1]][1] || !env_selected_indSelec[[i_taxon]][[1]][1] && !env_selected_globalSelec[[i_taxon]][[1]][1])
      {
        indSelec_globalSelec_abiotic1_selection[i_taxon] = 0
      } else if (env_selected_indSelec[[i_taxon]][[1]][1] && !env_selected_globalSelec[[i_taxon]][[1]][1])
      {
        indSelec_globalSelec_abiotic1_selection[i_taxon] = 1
      } else if (!env_selected_indSelec[[i_taxon]][[1]][1] && env_selected_globalSelec[[i_taxon]][[1]][1])
        indSelec_globalSelec_abiotic1_selection[i_taxon] = -1
    }
    
    indSelec_globalSelec_abiotic3_selection = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:(length(taxo_groups)-2))
    {
      if (env_selected_indSelec[[i_taxon]][[1]][3] && env_selected_globalSelec[[i_taxon]][[1]][3] || !env_selected_indSelec[[i_taxon]][[1]][3] && !env_selected_globalSelec[[i_taxon]][[1]][3])
      {
        indSelec_globalSelec_abiotic3_selection[i_taxon] = 0
      } else if (env_selected_indSelec[[i_taxon]][[1]][3] && !env_selected_globalSelec[[i_taxon]][[1]][3])
      {
        indSelec_globalSelec_abiotic3_selection[i_taxon] = 1
      } else if (!env_selected_indSelec[[i_taxon]][[1]][3] && env_selected_globalSelec[[i_taxon]][[1]][3])
        indSelec_globalSelec_abiotic3_selection[i_taxon] = -1
    }
    
    all_selected_indSelec = vector(length = length(taxo_groups), mode = "numeric")
    all_selected_globalSelec = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:length(taxo_groups))
    {
      all_selected_indSelec[i_taxon] = length(which(env_selected_indSelec[[i_taxon]][[1]])) + length(which(env_selected_indSelec[[i_taxon]][[2]])) + length(which(env_selected_indSelec[[i_taxon]][[4]]))
      all_selected_globalSelec[i_taxon] = length(which(env_selected_globalSelec[[i_taxon]][[1]])) + length(which(env_selected_globalSelec[[i_taxon]][[2]])) + length(which(env_selected_globalSelec[[i_taxon]][[4]]))
    }
    
    # plot.tot.variance.ind.vs.global.selection = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model]),
    #                                                                  y=colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model]))) +
    plot.tot.selected.axes.ind.vs.global.selection = ggplot(data=data.frame(x=all_selected_indSelec[selected_groups & significant_global_model],
                                                                     y=all_selected_globalSelec[selected_groups & significant_global_model])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total number of\n independently selected axes", y="Total number of\n globally selected axes") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_tot.nb.axes.global.selection_vs_independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_vs_tot.variance.independent.selection_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.tot.selected.axes.ind.vs.global.selection)
    dev.off()
    
    abiotic_selected_indSelec = vector(length = length(taxo_groups), mode = "numeric")
    abiotic_selected_globalSelec = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:length(taxo_groups))
    {
      abiotic_selected_indSelec[i_taxon] = length(which(env_selected_indSelec[[i_taxon]][[1]]))
      abiotic_selected_globalSelec[i_taxon] = length(which(env_selected_globalSelec[[i_taxon]][[1]]))
    }
    
    # plot.rel.pure.abiotic.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model]),
    #                                                                 y=varpart.groups.expTmin.globalSelec0[5,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model]))) +
    plot.abiotic.selected.axes.ind.vs.global.selection = ggplot(data=data.frame(x=abiotic_selected_indSelec[selected_groups & significant_global_model],
                                                                    y=abiotic_selected_globalSelec[selected_groups & significant_global_model])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Number of independently selected abiotic axes", y="Number of globally selected abiotic axes") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_nb.abiotic.axes.global.selection_vs_independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # pdf(paste0("varpart.groups.expTmin_rel.pure.abiotic.global.selection_vs_rel.pure.abiotic.independent.selection_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.abiotic.selected.axes.ind.vs.global.selection)
    dev.off()
    
    biotic_selected_indSelec = vector(length = length(taxo_groups), mode = "numeric")
    biotic_selected_globalSelec = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:length(taxo_groups))
    {
      biotic_selected_indSelec[i_taxon] = length(which(env_selected_indSelec[[i_taxon]][[2]]))
      biotic_selected_globalSelec[i_taxon] = length(which(env_selected_globalSelec[[i_taxon]][[2]]))
    }
    
    # plot.rel.pure.biotic.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model]),
    #                                                                        y=varpart.groups.expTmin.globalSelec0[1,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model]))) +
    plot.biotic.selected.axes.ind.vs.global.selection = ggplot(data=data.frame(x=biotic_selected_indSelec[selected_groups & significant_global_model],
                                                                           y=biotic_selected_globalSelec[selected_groups & significant_global_model])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Number of independently selected biotic axes", y="Number of globally selected biotic axes") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_nb.biotic.axes.global.selection_vs_independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # pdf(paste0("varpart.groups.expTmin_rel.pure.biotic.global.selection_vs_rel.pure.biotic.independent.selection_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.biotic.selected.axes.ind.vs.global.selection)
    dev.off()
    
    currents_selected_indSelec = vector(length = length(taxo_groups), mode = "numeric")
    currents_selected_globalSelec = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:length(taxo_groups))
    {
      currents_selected_indSelec[i_taxon] = length(which(env_selected_indSelec[[i_taxon]][[4]]))
      currents_selected_globalSelec[i_taxon] = length(which(env_selected_globalSelec[[i_taxon]][[4]]))
    }
    
    # plot.rel.pure.expTmin.ind.vs.global.selection = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model]),
    #                                                                       y=varpart.groups.expTmin.globalSelec0[7,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model]))) +
    plot.currents.selected.axes.ind.vs.global.selection = ggplot(data=data.frame(x=currents_selected_indSelec[selected_groups & significant_global_model],
                                                                          y=currents_selected_globalSelec[selected_groups & significant_global_model])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=24),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Number of independently selected currents axes", y="Number of globally selected currents axes") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_nb.currents.axes.global.selection_vs_independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # pdf(paste0("varpart.groups.expTmin_rel.pure.currents.global.selection_vs_rel.pure.currents.independent.selection_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.currents.selected.axes.ind.vs.global.selection)
    dev.off()
    
    }
    
    #########################################################
    # Former independent selection vs. properly normalized #
    ########################################################
    {
    
    varpart.groups.expTmin.indSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.indSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    varpart.groups.expTmin.indSelec.old = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.indSelec.old.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    varpart.groups.expTmin.indSelec0 = varpart.groups.expTmin.indSelec
    varpart.groups.expTmin.indSelec0[varpart.groups.expTmin.indSelec0<0] = 0
    varpart.groups.expTmin.indSelec.old0 = varpart.groups.expTmin.indSelec.old
    varpart.groups.expTmin.indSelec.old0[varpart.groups.expTmin.indSelec.old0<0] = 0
    
    plot.tot.variance.ind.selection.proper.normalized.vs.old = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec.old0[,selected_groups]),
                                                                     y=colSums(varpart.groups.expTmin.indSelec0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=20),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total explained variance\n by independently selected axes", y="Total explained variance\n by independently selected axes - proper normaliz.") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_vs_tot.variance.independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.variance.independent.selection.properly.normalized_vs_old_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.tot.variance.ind.selection.proper.normalized.vs.old)
    dev.off()
    
    plot.rel.pure.abiotic.ind.selection.proper.normalized.vs.old = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec.old0[5,selected_groups]/colSums(varpart.groups.expTmin.indSelec.old0[,selected_groups]),
                                                                    y=varpart.groups.expTmin.indSelec0[5,selected_groups]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=20),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected abiotic axes", y="Relative variance purely explained\n by independently selected abiotic axes - proper normaliz.") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_rel.pure.abiotic.global.selection_vs_rel.pure.abiotic.independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.abiotic.independent.selection.properly.normalized_vs_old_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.rel.pure.abiotic.ind.selection.proper.normalized.vs.old)
    dev.off()
    
    plot.rel.pure.biotic.ind.selection.proper.normalized.vs.old = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec.old0[1,selected_groups]/colSums(varpart.groups.expTmin.indSelec.old0[,selected_groups]),
                                                                           y=varpart.groups.expTmin.indSelec0[1,selected_groups]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=20),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected biotic axes", y="Relative variance purely explained\n by independently selected biotic axes - proper normaliz.") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_rel.pure.biotic.global.selection_vs_rel.pure.biotic.independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.biotic.independent.selection.properly.normalized_vs_old_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.rel.pure.biotic.ind.selection.proper.normalized.vs.old)
    dev.off()
    
    plot.rel.pure.expTmin.ind.selection.proper.normalized.vs.old = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec.old0[7,selected_groups]/colSums(varpart.groups.expTmin.indSelec.old0[,selected_groups]),
                                                                          y=varpart.groups.expTmin.indSelec0[7,selected_groups]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=20),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected currents axes", y="Relative variance purely explained\n by independently selected currents axes - proper normaliz.") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_rel.pure.currents.global.selection_vs_rel.pure.currents.independent.selection_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.currents.independent.selection.properly.normalized_vs_old_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.rel.pure.expTmin.ind.selection.proper.normalized.vs.old)
    dev.off()
    
    }
    
    ###########################################
    # global selection realization comparison #
    ###########################################
    {
    
    varpart.groups.expTmin.real1.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.real1.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    varpart.groups.expTmin.real2.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.real2.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    varpart.groups.expTmin.real3.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.real3.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    varpart.groups.expTmin.real1.globalSelec0 = varpart.groups.expTmin.real1.globalSelec
    varpart.groups.expTmin.real1.globalSelec0[varpart.groups.expTmin.real1.globalSelec0<0] = 0
    varpart.groups.expTmin.real2.globalSelec0 = varpart.groups.expTmin.real2.globalSelec
    varpart.groups.expTmin.real2.globalSelec0[varpart.groups.expTmin.real2.globalSelec0<0] = 0
    varpart.groups.expTmin.real3.globalSelec0 = varpart.groups.expTmin.real3.globalSelec
    varpart.groups.expTmin.real3.globalSelec0[varpart.groups.expTmin.real3.globalSelec0<0] = 0
  
    env_selected_real2.globalSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    env_selected_real3.globalSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection1",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    
    real2_real3_abiotic2_selection = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:(length(taxo_groups)-2))
    {
      if (env_selected_real2.globalSelec[[i_taxon]][[1]][2] && env_selected_real3.globalSelec[[i_taxon]][[1]][2] || !env_selected_real2.globalSelec[[i_taxon]][[1]][2] && !env_selected_real3.globalSelec[[i_taxon]][[1]][2])
      {
        real2_real3_abiotic2_selection[i_taxon] = 0
      } else if (env_selected_real2.globalSelec[[i_taxon]][[1]][2] && !env_selected_real3.globalSelec[[i_taxon]][[1]][2])
      {
        real2_real3_abiotic2_selection[i_taxon] = 1
      } else if (!env_selected_real2.globalSelec[[i_taxon]][[1]][2] && env_selected_real3.globalSelec[[i_taxon]][[1]][2])
        real2_real3_abiotic2_selection[i_taxon] = -1
    }
    
    real2_real3_abiotic3_selection = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:(length(taxo_groups)-2))
    {
      if (env_selected_real2.globalSelec[[i_taxon]][[1]][3] && env_selected_real3.globalSelec[[i_taxon]][[1]][3] || !env_selected_real2.globalSelec[[i_taxon]][[1]][3] && !env_selected_real3.globalSelec[[i_taxon]][[1]][3])
      {
        real2_real3_abiotic3_selection[i_taxon] = 0
      } else if (env_selected_real2.globalSelec[[i_taxon]][[1]][3] && !env_selected_real3.globalSelec[[i_taxon]][[1]][3])
      {
        real2_real3_abiotic3_selection[i_taxon] = 1
      } else if (!env_selected_real2.globalSelec[[i_taxon]][[1]][3] && env_selected_real3.globalSelec[[i_taxon]][[1]][3])
        real2_real3_abiotic3_selection[i_taxon] = -1
    }
    
    real2_real3_abiotic1_selection = vector(length = length(taxo_groups), mode = "numeric")
    for (i_taxon in 1:(length(taxo_groups)-2))
    {
      if (env_selected_real2.globalSelec[[i_taxon]][[1]][1] && env_selected_real3.globalSelec[[i_taxon]][[1]][1] || !env_selected_real2.globalSelec[[i_taxon]][[1]][1] && !env_selected_real3.globalSelec[[i_taxon]][[1]][1])
      {
        real2_real3_abiotic1_selection[i_taxon] = 0
      } else if (env_selected_real2.globalSelec[[i_taxon]][[1]][1] && !env_selected_real3.globalSelec[[i_taxon]][[1]][1])
      {
        real2_real3_abiotic1_selection[i_taxon] = 1
      } else if (!env_selected_real2.globalSelec[[i_taxon]][[1]][1] && env_selected_real3.globalSelec[[i_taxon]][[1]][1])
        real2_real3_abiotic1_selection[i_taxon] = -1
    }
    
    test = vector(length = length(taxo_groups), mode = "logical")
    for (i_taxon in 1:(length(taxo_groups)-2))
    {
      test[i_taxon] = all(env_selected_real2.globalSelec[[i_taxon]][[1]] == env_selected_real3.globalSelec[[i_taxon]][[1]])
    }
    
    real2_over_real3_abiotic_ratio = (varpart.groups.expTmin.real2.globalSelec0[5,]/colSums(varpart.groups.expTmin.real2.globalSelec0))/(varpart.groups.expTmin.real3.globalSelec0[5,]/colSums(varpart.groups.expTmin.real3.globalSelec0))
    
    significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection1",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    plot.global.selection.real = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.real1.globalSelec0[,selected_groups & significant_global_model]),
                                                                       y=colSums(varpart.groups.expTmin.real2.globalSelec0[,selected_groups & significant_global_model]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=22),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total explained variance\n by globally selected axes - real.1", y="Total explained variance\n by globally selected axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.global.selection.real)
    dev.off()
    
    plot.abiotic.global.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.globalSelec0[5,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real1.globalSelec0[,selected_groups & significant_global_model]),
                                                        y=varpart.groups.expTmin.real2.globalSelec0[5,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real2.globalSelec0[,selected_groups & significant_global_model]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=22),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by globally selected abiotic axes - real.1", y="Relative variance purely explained\n by globally selected abiotic axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.abiotic.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.abiotic.global.selection.real)
    dev.off()
    
    plot.biotic.global.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.globalSelec0[1,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real1.globalSelec0[,selected_groups & significant_global_model]),
                                                                y=varpart.groups.expTmin.real2.globalSelec0[1,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real2.globalSelec0[,selected_groups & significant_global_model]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=22),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by globally selected biotic axes - real.1", y="Relative variance purely explained\n by globally selected biotic axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.biotic.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.biotic.global.selection.real)
    dev.off()
    
    plot.expTmin.global.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.globalSelec0[7,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real1.globalSelec0[,selected_groups & significant_global_model]),
                                                               y=varpart.groups.expTmin.real2.globalSelec0[7,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real2.globalSelec0[,selected_groups & significant_global_model]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=22),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by globally selected currents axes - real.1", y="Relative variance purely explained\n by globally selected currents axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.currents.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.expTmin.global.selection.real)
    dev.off()
    
    }
    
    #############################################################
    # both directions global selection - realization comparison #
    #############################################################
    {
    
    varpart.groups.expTmin.real1.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_bothDirectionsGlobalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.real1.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_bothDirectionsGlobalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    varpart.groups.expTmin.real2.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_bothDirectionsGlobalSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.real2.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_bothDirectionsGlobalSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    varpart.groups.expTmin.real1.globalSelec0 = varpart.groups.expTmin.real1.globalSelec
    varpart.groups.expTmin.real1.globalSelec0[varpart.groups.expTmin.real1.globalSelec0<0] = 0
    varpart.groups.expTmin.real2.globalSelec0 = varpart.groups.expTmin.real2.globalSelec
    varpart.groups.expTmin.real2.globalSelec0[varpart.groups.expTmin.real2.globalSelec0<0] = 0
  
    # env_selected_real1.globalSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_bothDirectionsGlobalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    # env_selected_real2.globalSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_bothDirectionsGlobalSelection1",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_bothDirectionsGlobalSelection1",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    plot.global.selection.real = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.real1.globalSelec0[,selected_groups & significant_global_model]),
                                                                       y=colSums(varpart.groups.expTmin.real2.globalSelec0[,selected_groups & significant_global_model]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=22),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total explained variance\n by globally selected axes - real.1", y="Total explained variance\n by globally selected axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_bothDirectionsVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.global.selection.real)
    dev.off()
    
    plot.abiotic.global.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.globalSelec0[5,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real1.globalSelec0[,selected_groups & significant_global_model]),
                                                        y=varpart.groups.expTmin.real2.globalSelec0[5,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real2.globalSelec0[,selected_groups & significant_global_model]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=22),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by globally selected abiotic axes - real.1", y="Relative variance purely explained\n by globally selected abiotic axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.abiotic.global.selection_real2_vs_real1_ggplot_bothDirectionsVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.abiotic.global.selection.real)
    dev.off()
    
    plot.biotic.global.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.globalSelec0[1,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real1.globalSelec0[,selected_groups & significant_global_model]),
                                                                y=varpart.groups.expTmin.real2.globalSelec0[1,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real2.globalSelec0[,selected_groups & significant_global_model]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=22),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by globally selected biotic axes - real.1", y="Relative variance purely explained\n by globally selected biotic axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.biotic.global.selection_real2_vs_real1_ggplot_bothDirectionsVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.biotic.global.selection.real)
    dev.off()
    
    plot.expTmin.global.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.globalSelec0[7,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real1.globalSelec0[,selected_groups & significant_global_model]),
                                                               y=varpart.groups.expTmin.real2.globalSelec0[7,selected_groups & significant_global_model]/colSums(varpart.groups.expTmin.real2.globalSelec0[,selected_groups & significant_global_model]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=22),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by globally selected currents axes - real.1", y="Relative variance purely explained\n by globally selected currents axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.currents.global.selection_real2_vs_real1_ggplot_bothDirectionsVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.expTmin.global.selection.real)
    dev.off()
    
    }
    
    #################################################
    # independent selection realization comparison #
    #################################################
    {
    
    varpart.groups.expTmin.real1.indSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.real1.indSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    varpart.groups.expTmin.real2.indSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.real2.indSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection1_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    varpart.groups.expTmin.real1.indSelec0 = varpart.groups.expTmin.real1.indSelec
    varpart.groups.expTmin.real1.indSelec0[varpart.groups.expTmin.real1.indSelec0 < 0] = 0
    varpart.groups.expTmin.real2.indSelec0 = varpart.groups.expTmin.real2.indSelec
    varpart.groups.expTmin.real2.indSelec0[varpart.groups.expTmin.real2.indSelec0 < 0] = 0
    
    # significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_independentSelection1",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    significant_groups = vector(length = length(taxo_groups), mode = "logical")
    for (i_taxon in 1:length(taxo_groups))
      significant_groups[i_taxon] = all(significant_global_model[[i_taxon]])
    
    plot.independent.selection.real = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.real1.indSelec0[,selected_groups & significant_groups]),
                                                                       y=colSums(varpart.groups.expTmin.real2.indSelec0[,selected_groups & significant_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=20),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total explained variance\n by independently selected axes - real.1", y="Total explained variance\n by independently selected axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.variance.independent.selection_real2_vs_real1_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.independent.selection.real)
    dev.off()
    
    plot.abiotic.independent.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.indSelec0[5,selected_groups & significant_groups]/colSums(varpart.groups.expTmin.real1.indSelec0[,selected_groups & significant_groups]),
                                                        y=varpart.groups.expTmin.real2.indSelec0[5,selected_groups & significant_groups]/colSums(varpart.groups.expTmin.real2.indSelec0[,selected_groups & significant_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=20),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected abiotic axes - real.1", y="Relative variance purely explained\n by independently selected abiotic axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.abiotic.independent.selection_real2_vs_real1_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.abiotic.independent.selection.real)
    dev.off()
    
    plot.biotic.independent.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.indSelec0[1,selected_groups & significant_groups]/colSums(varpart.groups.expTmin.real1.indSelec0[,selected_groups & significant_groups]),
                                                                y=varpart.groups.expTmin.real2.indSelec0[1,selected_groups & significant_groups]/colSums(varpart.groups.expTmin.real2.indSelec0[,selected_groups & significant_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=20),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected biotic axes - real.1", y="Relative variance purely explained\n by independently selected biotic axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.biotic.independent.selection_real2_vs_real1_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.biotic.independent.selection.real)
    dev.off()
    
    plot.expTmin.independent.selection.real = ggplot(data=data.frame(x=varpart.groups.expTmin.real1.indSelec0[7,selected_groups & significant_groups]/colSums(varpart.groups.expTmin.real1.indSelec0[,selected_groups & significant_groups]),
                                                               y=varpart.groups.expTmin.real2.indSelec0[7,selected_groups & significant_groups]/colSums(varpart.groups.expTmin.real2.indSelec0[,selected_groups & significant_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title = element_text(size=20),
            plot.title = element_text(hjust=0, size=24),
            plot.margin = unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance purely explained\n by independently selected currents axes - real.1", y="Relative variance purely explained\n by independently selected currents axes - real.2") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_tot.variance.global.selection_real2_vs_real1_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_rel.pure.currents.independent.selection_real2_vs_real1_ggplot_forwardVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.expTmin.independent.selection.real)
    dev.off()
    
    }
    
    #################################
    # Gibbs VEM fraction comparison #
    #################################
    {
      varpart.env.spatial.VEM = readRDS(paste0(results_folder,"/varpart_lda_environment-currents_bothDirectionsIndependentSelection_PCA0_abioticPCA_bioticPCA_eigenvalueThres0.8_noLagoon.rds"))[[1]]
      
      plot.tot.var.Gibbs.vs.VEM = ggplot(data=data.frame(x=colSums(varpart.env.spatial.VEM)[selected_groups],y=colSums(varpart.env.spatial)[selected_groups])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="Total explained variance\n VEM", y="Total explained variance\n Gibbs cross-valid.") +
        # geom_smooth(aes(x,y),method='lm') 
        geom_abline(slope = 1,intercept = 0, linetype = "dashed")
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_tot.var_Gibbs_vs_VEM_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_selected",ifelse(div_threshold == 2,"",div_threshold),"_noDinophyceae_noNegativeAdjR2.pdf"))
      print(plot.tot.var.Gibbs.vs.VEM)
      dev.off() 
      
      plot.pure.currents.Gibbs.vs.VEM = ggplot(data=data.frame(x=(varpart.env.spatial.VEM[3,]/colSums(varpart.env.spatial.VEM))[selected_groups],y=(varpart.env.spatial[3,]/colSums(varpart.env.spatial))[selected_groups])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="Rel. variance explained purely by currents\n VEM", y="Rel. variance explained purely by currents\n Gibbs cross-valid.") +
        # geom_smooth(aes(x,y),method='lm') 
        geom_abline(slope = 1,intercept = 0, linetype = "dashed")
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.pure.currents_Gibbs_vs_VEM_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_selected",ifelse(div_threshold == 2,"",div_threshold),"_noDinophyceae_noNegativeAdjR2.pdf"))
      print(plot.pure.currents.Gibbs.vs.VEM )
      dev.off()
      
      plot.pure.env.Gibbs.vs.VEM = ggplot(data=data.frame(x=(varpart.env.spatial.VEM[1,]/colSums(varpart.env.spatial.VEM))[selected_groups],y=(varpart.env.spatial[1,]/colSums(varpart.env.spatial))[selected_groups])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="Rel. variance explained purely by\n the environment - VEM", y="Rel. variance explained purely by\n the environment - Gibbs cross-valid") +
        # geom_smooth(aes(x,y),method='lm') 
        geom_abline(slope = 1,intercept = 0, linetype = "dashed")
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.pure.environment_Gibbs_vs_VEM_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_selected",ifelse(div_threshold == 2,"",div_threshold),"_noDinophyceae_noNegativeAdjR2.pdf"))
      print(plot.pure.env.Gibbs.vs.VEM )
      dev.off()
    }
    
    ####################################
    # pure fraction vs. total variance #
    ####################################
    {
    
    varpart.groups.expTmin.globalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.globalSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_globalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    varpart.groups.expTmin.bothDirGlobalSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_bothDirectionsGlobalSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    
    varpart.groups.expTmin.indSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    varpart.groups.expTmin.indSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    
    varpart.groups.expTmin.globalSelec0 = varpart.groups.expTmin.globalSelec
    varpart.groups.expTmin.globalSelec0[varpart.groups.expTmin.globalSelec0<0] = 0
    varpart.groups.expTmin.bothDirGlobalSelec0 = varpart.groups.expTmin.bothDirGlobalSelec
    varpart.groups.expTmin.bothDirGlobalSelec0[varpart.groups.expTmin.bothDirGlobalSelec0<0] = 0
    varpart.groups.expTmin.indSelec0 = varpart.groups.expTmin.indSelec
    varpart.groups.expTmin.indSelec0[varpart.groups.expTmin.indSelec0<0] = 0
    
    significant_global_model_globalSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    significant_global_model_bothDirGlobalSelec = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_bothDirectionsglobalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    # significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_globalSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_independentSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
    # significant_groups = vector(length = length(taxo_groups), mode = "logical")
    significant_global_model_indSelec = vector(length = length(taxo_groups), mode = "logical")
    for (i_taxon in 1:length(taxo_groups))
      significant_global_model_indSelec[i_taxon] = all(significant_global_model[[i_taxon]])
    
    ###########################
    div_threshold = 1000
    
    plot.pure.env.vs.tot.var = list()
    plot.pure.currents.vs.tot.var = list()
    for (i_case in 1:2)
    {
      plot.pure.env.vs.tot.var[[i_case]] = ggplot(data=data.frame(x=colSums(varpart.env.spatial[[i_case]])[selected_groups & diversity>div_threshold],
                                                                   y=(varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
        geom_point(aes(x,y)) +
        # geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
        geom_smooth(aes(x,y), method = "lm", col = "black") +
        scale_x_log10() +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x=paste("Total",c("surface","DCM")[i_case],"explained variance"),
             y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by the environment"))
      # geom_smooth(aes(x,y),method='lm',col="black") 
      
      plot.pure.currents.vs.tot.var[[i_case]] = ggplot(data=data.frame(x=colSums(varpart.env.spatial[[i_case]])[selected_groups & diversity>div_threshold],
                                                                  y=(varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
        geom_point(aes(x,y)) +
        # geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
        geom_smooth(aes(x,y), method = "lm", col = "black") +
        scale_x_log10() +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x=paste("Total",c("surface","DCM")[i_case],"explained variance"), 
             y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by currents"))
    }
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.pure.env.currents_vs_tot.var_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
               "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
    print(plot.pure.env.vs.tot.var[[1]])
    print(plot.pure.currents.vs.tot.var[[1]])
    print(plot.pure.env.vs.tot.var[[2]])
    print(plot.pure.currents.vs.tot.var[[2]])
    dev.off()
    
    ###################
    plot.pure.abiotic.vs.total.env.variance = ggplot(data=data.frame(x=varpart.groups0[1,selected_groups]+varpart.groups0[2,selected_groups]+varpart.groups0[3,selected_groups],y=varpart.groups0[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total explained variance", y="Pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart_pure_abiotic_vs_total_variance",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.pure.abiotic.vs.total.env.variance)
    dev.off()
    
    ##################
    plot.pure.biotic.vs.total.env.variance = ggplot(data=data.frame(x=varpart.groups0[1,selected_groups]+varpart.groups0[2,selected_groups]+varpart.groups0[3,selected_groups],y=varpart.groups0[3,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Total explained variance", y="Pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart_pure_biotic_vs_total_variance",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.pure.biotic.vs.total.env.variance)
    dev.off()
    
    ##################
    plot.pure.abiotic.vs.adjr2 = ggplot(data=data.frame(x=varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups],y=varpart.groups[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Total abiotic explained variance", y="Pure abiotic explained variance")
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart_pure_abiotic_vs_abiotic_adjR2",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
    print(plot.pure.abiotic.vs.adjr2)
    dev.off()
    
    ##################
    plot.pure.taxoGroups.biotic.vs.adjr2 = ggplot(data=data.frame(x=varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups],y=varpart.groups[3,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      ggtitle("Pure biotic vs. total biotic adjR2 30 axes") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Total biotic explained variance", y="Pure biotic explained variance") +
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart_pure_taxoGroups_biotic_vs_biotic_adjR2",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
    # print(plot.adjr2.abiotic.3.vs.2.firstAxes)
    print(plot.pure.taxoGroups.biotic.vs.adjr2)
    dev.off()
    
    ##################
    plot.pure.abiotic.vs.adjr2 = ggplot(data=data.frame(x=varpart.functions[1,selected_groups]+varpart.functions[2,selected_groups],y=varpart.functions[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Total abiotic explained variance", y="Pure abiotic explained variance") +
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.functions_pure_abiotic_vs_abiotic_adjR2",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
    # print(plot.adjr2.abiotic.3.vs.2.firstAxes)
    print(plot.pure.abiotic.vs.adjr2)
    dev.off()
    
    ##################
    plot.pure.functions.biotic.vs.adjr2 = ggplot(data=data.frame(x=varpart.functions[3,selected_groups]+varpart.functions[2,selected_groups],y=varpart.functions[3,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      ggtitle("Pure biotic vs. total biotic adjR2 5 axes") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Total biotic explained variance", y="Pure biotic explained variance") +
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.functions_pure_functions_biotic_vs_biotic_adjR2",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,".pdf"))
    # print(plot.adjr2.abiotic.3.vs.2.firstAxes)
    print(plot.pure.functions.biotic.vs.adjr2)
    dev.off()
    
    }
    
    ######################
    # biotic vs. abiotic #
    ######################
    {
    
    varpart.groups.expTmin0 = varpart.groups
    varpart.groups.expTmin0[varpart.groups.expTmin0<0] = 0
    
    # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
    
    plot.relative.pure.biotic.vs.relative.pure.abiotic = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]),
                                                                                y=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative pure abiotic explained variance", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_relative.pure.abiotic_ggplot_forwardIndependentVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.abiotic)
    dev.off()
    
     plot.relative.pure.biotic.vs.relative.pure.abiotic = ggplot(data=data.frame(x=varpart.groups.expTmin.globalSelec0[5,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]),
                                                                                y=varpart.groups.expTmin.globalSelec0[1,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative pure abiotic explained variance", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_relative.pure.abiotic_ggplot_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.abiotic)
    dev.off()
    
    plot.relative.pure.biotic.vs.relative.pure.abiotic = ggplot(data=data.frame(x=varpart.groups.expTmin.bothDirGlobalSelec0[5,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.bothDirGlobalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]),
                                                                                y=varpart.groups.expTmin.bothDirGlobalSelec0[1,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.bothDirGlobalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative pure abiotic explained variance", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_relative.pure.abiotic_ggplot_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.abiotic)
    dev.off()
    
    ##################
    plot.pure.biotic.vs.pure.abiotic = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained purely by abiotic conditions", y="Variance explained purely by biotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.biotic_vs_pure.abiotic_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.biotic.vs.pure.abiotic)
    dev.off()
    
    plot.pure.biotic.vs.abiotic = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[c(5,2),selected_groups & significant_global_model_indSelec]),y=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained by abiotic conditions", y="Variance explained purely by biotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.biotic_vs_abiotic.without.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.biotic.vs.abiotic)
    dev.off()
    
    plot.pure.abiotic.vs.biotic = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[c(1,2),selected_groups & significant_global_model_indSelec]),y=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained by biotic conditions", y="Variance explained purely by abiotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.abiotic_vs_biotic.without.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.abiotic.vs.biotic)
    dev.off()
    
    plot.pure.abiotic.vs.mixed.biotic.abiotic = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[2,selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained\n by both biotic and abiotic conditions", y="Variance explained purely\n by abiotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.abiotic_vs_mixed.biotic.abiotic.without.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.abiotic.vs.mixed.biotic.abiotic)
    dev.off()
    
    plot.pure.biotic.vs.mixed.biotic.abiotic = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[2,selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained\n by both biotic and abiotic conditions", y="Variance explained purely\n by biotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.biotic_vs_mixed.biotic.abiotic.without.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.biotic.vs.mixed.biotic.abiotic)
    dev.off()
    
    ##################
    plot.relative.pure.biotic.vs.relative.pure.env = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin0[c(1,2,5),selected_groups])/colSums(varpart.groups.expTmin0[,selected_groups]),
                                                                                y=varpart.groups.expTmin0[1,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance\n explained purely by the environment", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_relative.pure.environment_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.env)
    dev.off()
    
    ##################
    plot.relative.pure.biotic.vs.relative.pure.expTmin = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]),
                                                                                y=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance \nexplained purely by currents", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_relative.pure.expTmin_ggplot_forwardIndependentVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.expTmin)
    dev.off()
    
    plot.relative.pure.biotic.vs.relative.pure.expTmin = ggplot(data=data.frame(x=varpart.groups.expTmin.globalSelec0[7,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]),
                                                                                y=varpart.groups.expTmin.globalSelec0[1,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance \nexplained purely by currents", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_relative.pure.expTmin_ggplot_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.expTmin)
    dev.off()
    
    plot.relative.pure.biotic.vs.relative.pure.expTmin = ggplot(data=data.frame(x=varpart.groups.expTmin.bothDirGlobalSelec0[7,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.bothDirGlobalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]),
                                                                                y=varpart.groups.expTmin.bothDirGlobalSelec0[1,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.bothDirGlobalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance \nexplained purely by currents", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_relative.pure.expTmin_ggplot_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.expTmin)
    dev.off()
    
    ##################
    plot.relative.pure.abiotic.vs.relative.pure.expTmin = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]),
                                                                                y=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance \nexplained purely by currents", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.abiotic_vs_relative.pure.expTmin_ggplot_forwardIndependentVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.relative.pure.expTmin)
    dev.off()
    
    plot.relative.pure.abiotic.vs.relative.pure.expTmin = ggplot(data=data.frame(x=varpart.groups.expTmin.globalSelec0[7,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]),
                                                                                y=varpart.groups.expTmin.globalSelec0[5,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance \nexplained purely by currents", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.abiotic_vs_relative.pure.expTmin_ggplot_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.relative.pure.expTmin)
    dev.off()
    
     plot.relative.pure.abiotic.vs.relative.pure.expTmin = ggplot(data=data.frame(x=varpart.groups.expTmin.globalSelec0[7,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]),
                                                                                y=varpart.groups.expTmin.globalSelec0[5,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance \nexplained purely by currents", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.abiotic_vs_relative.pure.expTmin_ggplot_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.relative.pure.expTmin)
    dev.off()
    
    ##################
    plot.relative.pure.environment.vs.relative.pure.expTmin = ggplot(data=data.frame(x=varpart.groups.expTmin0[7,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]),
                                                                                 y=colSums(varpart.groups.expTmin0[c(1,2,5),selected_groups])/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance \nexplained purely by currents", y="Relative variance \nexplained purely by environment") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.environment_vs_relative.pure.expTmin_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.environment.vs.relative.pure.expTmin)
    dev.off()
    
    ##################
    plot.relative.pure.biotic.vs.relative.pure.expTmin.abiotic = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin0[c(5,6,7),selected_groups])/colSums(varpart.groups.expTmin0[,selected_groups]),
                                                                                     y=varpart.groups.expTmin0[1,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Relative variance \nexplained purely by currents and abiotic conditions", y="Relative variance \nexplained purely by biotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_relative.pure.expTmin.abiotic_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.expTmin.abiotic)
    dev.off()
    
    ##################
    varpart.groups0 = varpart.groups
    varpart.groups0[varpart.groups0<0] = 0
    
    plot.pure.biotic.vs.pure.abiotic = ggplot(data=data.frame(x=varpart.groups0[1,selected_groups],y=varpart.groups0[3,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Pure abiotic explained variance", y="Pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart_pure_biotic_vs_pure_abiotic_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.pure.biotic.vs.pure.abiotic)
    dev.off()
    
    ##################
    plot.total.biotic.vs.total.abiotic = ggplot(data=data.frame(x=varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups],y=varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Total abiotic fraction", y="Total biotic fraction") +
      ylim(range(varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])) +
      xlim(range(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart_total_biotic_vs_total_abiotic_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.total.biotic.vs.total.abiotic)
    dev.off()
    
    ##################
    plot.relative.pure.biotic.vs.relative.pure.abiotic = ggplot(data=data.frame(x=varpart.groups0[1,selected_groups]/colSums(varpart.groups0[,selected_groups]),y=varpart.groups0[3,selected_groups]/colSums(varpart.groups0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Relative pure abiotic fraction", y="Relative pure biotic fraction") +
      geom_smooth(aes(x,y),method='lm')
    pdf(paste0("varpart_relative_pure_biotic_vs_relative_pure_abiotic_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.abiotic)
    dev.off()
    
    ##################
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
    functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
    
    plot.relative.pure.biotic.vs.relative.pure.abiotic = ggplot(data=data.frame(x=varpart.groups[1,selected_groups]/colSums(varpart.groups[,selected_groups]),y=varpart.groups[3,selected_groups]/colSums(varpart.groups[,selected_groups]))) +
      geom_point(aes(x,y,colour=dominant_function[selected_groups])) +
      theme_bw() +
      scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm"),
            legend.position="bottom",
            legend.text=element_text(size=10),
            legend.title=element_text(size=16)) +
      guides(colour = guide_legend(title.position="bottom")) +
      labs(x="Relative pure abiotic fraction", y="Relative pure biotic fraction")
    # pdf(paste0("varpart_relative_pure_biotic_vs_relative_pure_abiotic_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_functionColors_selected.pdf"))
    pdf(paste0("varpart_relative_pure_biotic_vs_relative_pure_abiotic_variableSelection_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_functionColors_selected.pdf"))
    print(plot.relative.pure.biotic.vs.relative.pure.abiotic)
    dev.off()
    
    }
    
    ############################
    # environment vs. currents #
    ############################
    {
    #############################
    # Relative fractions:  
      
      div_threshold = 1000
      for (i_case in 1:2)
      {
        plot.pure.env.vs.pure.currents = ggplot(data=data.frame(x=(varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold],y=(varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,8,1,0.5),"mm")) +
          labs(x=paste("Relative",if (i_case == 1) "surface" else "DCM","variance\n explained purely by currents"), y=paste("Relative",if (i_case == 1) "surface" else "DCM","variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents.",if (i_case == 1) "SUR" else "DCM","_rel.pure.environment_vs_rel.pure.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                   "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
        print(plot.pure.env.vs.pure.currents)
        dev.off()  
      }
      
      plot.mixed.env.currents.vs.pure.currents = ggplot(data=data.frame(x=(varpart.env.spatial[3,]/colSums(varpart.env.spatial))[selected_groups & diversity > 100],y=(varpart.env.spatial[2,]/colSums(varpart.env.spatial))[selected_groups & diversity > 100])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="Rel. variance explained purely by currents", y="Rel. variance explained\n jointly by currents and the environment") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.mixed.env.currents_vs_rel.pure.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
      print(plot.mixed.env.currents.vs.pure.currents)
      dev.off() 
      
      plot.tot.env.currents.vs.pure.rel.mixed = ggplot(data=data.frame(x=(varpart.env.spatial[2,]/colSums(varpart.env.spatial))[selected_groups & diversity > 100],y=colSums(varpart.env.spatial)[selected_groups & diversity > 100])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="Rel. variance explained\n jointly by currents and the environment", y="Total variance explained\n by currents and the env.") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.tot.var.env.currents_vs_rel.mixed.env.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
      print(plot.tot.env.currents.vs.pure.rel.mixed)
      dev.off() 
      
    ##############################
    # Tot. variance:
      plot.tot.env.currents.vs.VI.over.K = ggplot(data=data.frame(x=VI_over_K[selected_groups & diversity > div_threshold],y=colSums(varpart.env.spatial)[selected_groups & diversity > div_threshold])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="Dissimilarity between\n surface and DCM communities", y="Total variance explained\n by currents and the env.") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.tot.var.env.currents_vs_VI.over.K_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
      print(plot.tot.env.currents.vs.VI.over.K)
      dev.off()
      
      plot.tot.env.currents.vs.diversity = ggplot(data=data.frame(x=log10(as.vector(diversity))[selected_groups & diversity > div_threshold],y=colSums(varpart.env.spatial)[selected_groups & diversity > div_threshold])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="OTU richness (log10)", y="Total variance explained\n by currents and the env.") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.tot.var.env.currents_vs_log.diversity_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
      print(plot.tot.env.currents.vs.diversity)
      dev.off()
      
      plot.tot.env.currents.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & diversity > div_threshold],y=colSums(varpart.env.spatial)[selected_groups & diversity > div_threshold])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="Stability of the decomposition\n across initial conditions", y="Total variance explained\n by currents and the env.") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.tot.var.env.currents_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
      print(plot.tot.env.currents.vs.stability)
      dev.off()
      
    #############################
    # Raw fractions:  
      
    plot.tot.env.vs.tot.currents = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6,7),selected_groups & significant_global_model_indSelec]),y=colSums(varpart.groups.expTmin.indSelec0[1:6,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained by currents", y="Variance explained by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.environment_vs_tot.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.tot.env.vs.tot.currents)
    dev.off()
    
    plot.tot.env.vs.pure.currents = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[1:6,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained purely by currents", y="Variance explained by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.environment_vs_pure.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.tot.env.vs.pure.currents)
    dev.off()
    
    plot.tot.currents.vs.pure.env = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]),y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6,7),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained purely by the environment", y="Variance explained by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.currents_vs_pure.environment_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.tot.currents.vs.pure.env)
    dev.off()

    plot.pure.env.vs.tot.currents = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6,7),selected_groups & significant_global_model_indSelec]),y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained purely by the environment", y="Variance explained by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.environment_vs_tot.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.env.vs.tot.currents)
    dev.off()
    
    plot.pure.env.vs.pure.currents = ggplot(data=data.frame(x=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained purely by currents", y="Variance explained\n purely by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.environment_vs_pure.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.env.vs.pure.currents)
    dev.off()
    
    plot.pure.env.vs.mixed.currents.env = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]),y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained\n by both currents and the environment", y="Variance explained purely by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.environment_vs_mixed.environment.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.env.vs.mixed.currents.env)
    dev.off()
    
    plot.pure.currents.vs.mixed.currents.env = ggplot(data=data.frame(x=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]),y=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Variance explained\n by both currents and the environment", y="Variance explained purely by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.currents_vs_mixed.environment.currents_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.currents.vs.mixed.currents.env)
    dev.off()
    
    }
    
    #############################################
    # functions abundances vs groups abundances #
    #############################################
    {
    
    plot.functions.biotic.vs.groups.biotic = ggplot(data=data.frame(x=varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups],y=varpart.functions[3,selected_groups]+varpart.functions[2,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Group-based biotic fraction", y="Function-based biotic fraction") +
      # ylim(range(varpart.groups[3,selected_groups])) +
      # xlim(range(varpart.groups[1,selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart_function_biotic_vs_group_abiotic_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.functions.biotic.vs.groups.biotic)
    dev.off()
    
    ##################
    plot.pure.functions.biotic.vs.pure.groups.biotic = ggplot(data=data.frame(x=varpart.groups[3,selected_groups],y=varpart.functions[3,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Group-based pure biotic fraction", y="Function-based pure biotic fraction") +
      # ylim(range(varpart.groups[3,selected_groups])) +
      # xlim(range(varpart.groups[1,selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart_pure_function_biotic_vs_pure_group_abiotic_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.pure.functions.biotic.vs.pure.groups.biotic)
    dev.off()
    
    }
    
    #######################################################
    # Size plots                                          #
    #######################################################
    {
      load(paste0(results_folder,"/group_sizes_byStationByDepth_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
      
      #############################
      # Ratio:
      div_threshold = 100
      
      # no outlier (Nemertea and Spumellaria), lin-log scale:
      plot.currents.env.ratio.vs.size = list()
      for (i_case in 1:2)
      {
        plot.currents.env.ratio.vs.size[[i_case]] = ggplot(data=data.frame(x=size_relativeAbund[selected_groups & diversity>div_threshold & (varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,]) < 10],
                                                                           y=(varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,])[selected_groups & diversity>div_threshold & (varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,]) < 10])) +
                                                   geom_point(aes(x,y)) +
                                                   scale_x_log10() +
                                                   theme_bw() +
                                                   # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
                                                   # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
                                                   theme(axis.text = element_text(size=22),
                                                         axis.title=element_text(size=24),
                                                         plot.title=element_text(hjust=0, size=24),
                                                         plot.margin=unit(c(1,6,1,0.5),"mm")) +
                                                   #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
                                                   labs(x="Mean size (micron)", y="") +
                                                   geom_smooth(aes(x,y),method='lm',col="black") 
      } 
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_pure.currents.env.ratio_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.currents.env.ratio.vs.size[[1]])
      print(plot.currents.env.ratio.vs.size[[2]])
      dev.off()
      
      # log-log scale, with Nemertea (15.6) and Spumellaria (18.5):
      plot.currents.env.ratio.vs.size = list()
      for (i_case in 1:2)
      {
        plot.currents.env.ratio.vs.size[[i_case]] = ggplot(data=data.frame(x=size_relativeAbund[selected_groups & diversity>div_threshold],
                                                                           y=(varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,])[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          scale_x_log10() +
          scale_y_log10() +
          theme_bw() +
          geom_hline(yintercept = 1, linetype="dashed") +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=22),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
          labs(x="Mean size (micron)", y="") +
          geom_smooth(aes(x,y),method='lm',col="black") 
      } 
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_pure.currents.env.ratio_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.currents.env.ratio.vs.size[[1]])
      print(plot.currents.env.ratio.vs.size[[2]])
      dev.off()
      
      # i_case = 1
      # test = lm(log(varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,])[selected_groups & diversity>div_threshold & 
      #                                                                            !is.na(varpart.env.spatial[[i_case]][3,]) & !is.na(varpart.env.spatial[[i_case]][1,]) & 
      #                                                                            !is.infinite(varpart.env.spatial[[i_case]][3,]) & !is.infinite(varpart.env.spatial[[i_case]][1,]) &
      #                                                                            varpart.env.spatial[[i_case]][3,] != 0 & varpart.env.spatial[[i_case]][1,] != 0] ~
      #     log(size_relativeAbund)[selected_groups & diversity>div_threshold & !is.na(varpart.env.spatial[[i_case]][3,]) & !is.na(varpart.env.spatial[[i_case]][1,]) & 
      #                          !is.infinite(varpart.env.spatial[[i_case]][3,]) & !is.infinite(varpart.env.spatial[[i_case]][1,]) & 
      #                          varpart.env.spatial[[i_case]][3,] != 0 & varpart.env.spatial[[i_case]][1,] != 0])
      # test = lm((varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold & 
      #                                                                                      !is.na(varpart.env.spatial[[i_case]][3,]) & !is.na(varpart.env.spatial[[i_case]][1,]) & 
      #                                                                                      !is.infinite(varpart.env.spatial[[i_case]][3,]) & !is.infinite(varpart.env.spatial[[i_case]][1,]) &
      #                                                                                      varpart.env.spatial[[i_case]][3,] != 0 & varpart.env.spatial[[i_case]][1,] != 0] ~
      #             log(size_relativeAbund)[selected_groups & diversity>div_threshold & !is.na(varpart.env.spatial[[i_case]][3,]) & !is.na(varpart.env.spatial[[i_case]][1,]) & 
      #                                       !is.infinite(varpart.env.spatial[[i_case]][3,]) & !is.infinite(varpart.env.spatial[[i_case]][1,]) & 
      #                                       varpart.env.spatial[[i_case]][3,] != 0 & varpart.env.spatial[[i_case]][1,] != 0])
      # summary(test)$adj.r.squared
      # anova(test)$`Pr(>F)`[1]
      
      
    ####################
      # Relative fractions: 
      plot.pure.env.vs.size = list()
      plot.pure.currents.vs.size = list()
      plot.tot.var.vs.size = list()
      for (i_case in 1:2)
      {
        plot.pure.env.vs.size[[i_case]] = ggplot(data=data.frame(x=size_relativeAbund[selected_groups & diversity>div_threshold],y=(varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Mean size (micron)", y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
        
        plot.pure.currents.vs.size[[i_case]] = ggplot(data=data.frame(x=size_relativeAbund[selected_groups & diversity>div_threshold],y=(varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Mean size (micron)", y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by currents")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
        
        plot.tot.var.vs.size[[i_case]] = ggplot(data=data.frame(x=size_relativeAbund[selected_groups & diversity>div_threshold],y=colSums(varpart.env.spatial[[i_case]])[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Mean size (micron)", y=paste("Total",c("surface","DCM")[i_case],"explained variance")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.pure.environment_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.pure.env.vs.size[[1]])
      print(plot.pure.env.vs.size[[2]])
      dev.off()
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.pure.currents_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.pure.currents.vs.size[[1]])
      print(plot.pure.currents.vs.size[[2]])
      dev.off()
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_tot.var_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.tot.var.vs.size[[1]])
      print(plot.tot.var.vs.size[[2]])
      dev.off()
      
    #############################
      # Raw fractions:  
      
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
    
    varpart.groups.expTmin0 = varpart.groups
    varpart.groups.expTmin0[varpart.groups.expTmin0<0] = 0
    
    # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
    
    plot.stability.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=mean_sim[selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Stability") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_stability_size_ggplot_independentVariableSelection_doubleSelected.pdf"))
    print(plot.stability.vs.size)
    dev.off()
    
    ####################
    # Ratio:
    div_threshold = 100
    
    # no outlier (Nemertea and Spumellaria), lin-log scale:
    plot.biotic.abiotic.ratio.vs.size = list()
    for (i_case in 1:2)
    {
      plot.biotic.abiotic.ratio.vs.size[[i_case]] = ggplot(data=data.frame(x=size_relativeAbund[selected_groups & diversity>div_threshold],
                                                                         y=(varpart.biotic.abiotic[[i_case]][3,]/varpart.env.spatial[[i_case]][1,])[selected_groups & diversity>div_threshold])) +
        geom_point(aes(x,y)) +
        scale_x_log10() +
        scale_y_log10() +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=22),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,6,1,0.5),"mm")) +
        labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by biotic vs. abiotic envir.")) +
        # labs(x="Mean size (micron)", y="") +
        geom_smooth(aes(x,y),method='lm',col="black") 
    } 
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.biotic.abiotic_pure.biotic.abiotic.ratio_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
               "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
    print(plot.biotic.abiotic.ratio.vs.size[[1]])
    print(plot.biotic.abiotic.ratio.vs.size[[2]])
    dev.off()
    
    ###########
    plot.pure.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Variance explained purely\n by abiotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.abiotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.abiotic.vs.size)
    dev.off()
    
    ####################
    plot.relative.pure.expTmin.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.groups.expTmin0[7,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure currents explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.expTmin_vs_size_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.expTmin.vs.size)
    dev.off()
    
    plot.relative.pure.expTmin.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure currents explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.expTmin_vs_size_ggplot_forwardIndependentVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.expTmin.vs.size)
    dev.off()
    
     plot.relative.pure.expTmin.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_globalSelec]),y=varpart.groups.expTmin.globalSelec0[7,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure currents explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.expTmin_vs_size_ggplot_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.expTmin.vs.size)
    dev.off()
    
     plot.relative.pure.expTmin.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_bothDirGlobalSelec]),y=varpart.groups.expTmin.bothDirGlobalSelec0[7,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.bothDirGlobalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure currents explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.expTmin_vs_size_ggplot_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.expTmin.vs.size)
    dev.off()
    
    #######################
    plot.tot.expTmin.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=colSums(varpart.groups.expTmin0[c(3,4,6,7),selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Variance explained by currents") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("AdjR2.expTmin_vs_size_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.tot.expTmin.vs.size)
    dev.off()
    
    #######################
    plot.pure.currents.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Variance explained purely by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.currents_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.currents.vs.size)
    dev.off()
    
    plot.currents.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6,7),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Variance explained by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.currents_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.currents.vs.size)
    dev.off()
    
    plot.environment.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=colSums(varpart.groups.expTmin.indSelec0[1:6,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Variance explained by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_environment_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.environment.vs.size)
    dev.off()
    
    plot.pure.environment.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Variance explained\n purely by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.environment_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.environment.vs.size)
    dev.off()
    
    plot.mixed.environment.currents.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Variance explained\n by both currents and the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_mixed.environment.currents_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.mixed.environment.currents.vs.size)
    dev.off()
    
    #######################
    
    plot.tot.variance.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & diversity>100]),y=colSums(varpart.env.spatial[,selected_groups & diversity>100]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Total variance explained\n by currents and the environment") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.tot.var.env.currents_vs_size_ggplot_selected",ifelse(div_threshold == 2,"",div_threshold),"_noNegativeAdjR2.pdf"))
    print(plot.tot.variance.vs.size)
    dev.off()
    
     plot.tot.variance.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_globalSelec]),y=colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Total variance \nexplained by currents and environment") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("AdjR2.total.currents.environment_vs_size_ggplot_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.tot.variance.vs.size)
    dev.off()
    
     plot.tot.variance.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_bothDirGlobalSelec]),y=colSums(varpart.groups.expTmin.bothDirGlobalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Total variance \nexplained by currents and environment") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("AdjR2.total.currents.environment_vs_size_ggplot_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.tot.variance.vs.size)
    dev.off()
    
    # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
    #######################
    plot.relative.pure.environment.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),
                                                                    y=colSums(varpart.groups.expTmin0[c(1,2,5),selected_groups])/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative variance\n explained by pure environment") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.environment_vs_size_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.environment.vs.size)
    dev.off()
    
    #######################
    plot.relative.pure.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),
                                                                    y=varpart.groups.expTmin0[5,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.abiotic_vs_size_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.size)
    dev.off()
    
    #######################
    plot.relative.pure.biotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),
                                                                y=varpart.groups.expTmin0[1,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_size_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.size)
    dev.off()
    
    #######################
    varpart.groups0 = varpart.groups
    varpart.groups0[varpart.groups0<0] = 0
    
    plot.pure.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.groups[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Pure abiotic fraction") +
      ylim(range(varpart.groups[1,selected_groups])) +
      xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart_pure_abiotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.pure.abiotic.vs.size)
    dev.off()
    
    ##################
    plot.pure.biotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.groups[3,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Pure biotic fraction") +
      ylim(range(varpart.groups[3,selected_groups])) +
      xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart_pure_taxoGroups_biotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.pure.biotic.vs.size)
    dev.off()
    
    ##################
    plot.relative.pure.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.groups0[1,selected_groups]/colSums(varpart.groups0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart_relative_pure_abiotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.size)
    dev.off()
    
    plot.relative.pure.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.abiotic_vs_size_ggplot_forwardIndependentVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.size)
    dev.off()
    
     plot.relative.pure.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_globalSelec]),y=varpart.groups.expTmin.globalSelec0[5,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.abiotic_vs_size_ggplot_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.size)
    dev.off()
    
     plot.relative.pure.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_bothDirGlobalSelec]),y=varpart.groups.expTmin.bothDirGlobalSelec0[5,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.bothDirGlobalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.abiotic_vs_size_ggplot_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.size)
    dev.off()
    
    ##################
    plot.relative.pure.biotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.groups0[3,selected_groups]/colSums(varpart.groups0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure biotic explained") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart_relative_pure_taxoGroups_biotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.size)
    dev.off()
    
    plot.relative.pure.biotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_indSelec]),y=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model_indSelec]/colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_size_ggplot_forwardIndependentVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.size)
    dev.off()
    
    plot.relative.pure.biotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_globalSelec]),y=varpart.groups.expTmin.globalSelec0[1,selected_groups & significant_global_model_globalSelec]/colSums(varpart.groups.expTmin.globalSelec0[,selected_groups & significant_global_model_globalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_size_ggplot_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.size)
    dev.off()
    
    plot.relative.pure.biotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups & significant_global_model_bothDirGlobalSelec]),y=varpart.groups.expTmin.bothDirGlobalSelec0[1,selected_groups & significant_global_model_bothDirGlobalSelec]/colSums(varpart.groups.expTmin.bothDirGlobalSelec0[,selected_groups & significant_global_model_bothDirGlobalSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_relative.pure.biotic_vs_size_ggplot_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.size)
    dev.off()
    
    ##################
    plot.pure.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.functions[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Pure abiotic fraction") +
      ylim(range(varpart.functions[1,selected_groups])) +
      xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.functions_pure_abiotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.pure.abiotic.vs.size)
    dev.off()
    
    ##################
    plot.pure.biotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.functions[3,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Pure biotic fraction") +
      ylim(range(varpart.functions[3,selected_groups])) +
      xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.functions_pure_biotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.pure.biotic.vs.size)
    dev.off()
    
    ##################
    plot.pure.biotic.over.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.groups[3,selected_groups]/varpart.groups[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Pure biotic over abiotic fraction") +
      ylim(range(varpart.groups[3,selected_groups]/varpart.groups[1,selected_groups])) +
      xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups_pure_biotic.over.abiotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.pure.biotic.over.abiotic.vs.size)
    dev.off()
    
    ##################
    plot.total.biotic.over.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=(varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Total biotic over abiotic fraction") +
      ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups_total_biotic.over.abiotic_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_selected.pdf"))
    print(plot.total.biotic.over.abiotic.vs.size)
    dev.off()
    
    ##################
    plot.total.biotic.abiotic.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund[selected_groups]),y=varpart.groups0[3,selected_groups]+varpart.groups0[2,selected_groups]+varpart.groups0[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean size (micron, log10)", y="Total biotic and abiotic explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups_total_explained_variance_vs_size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.biotic.abiotic.vs.size)
    dev.off()
    
    ##################
    diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    plot.total.biotic.abiotic.vs.diversity = ggplot(data=data.frame(x=log10(as.vector(diversity)[selected_groups]),y=varpart.groups0[3,selected_groups]+varpart.groups0[2,selected_groups]+varpart.groups0[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Diversity (log10)", y="Total biotic and abiotic explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups_total_explained_variance_vs_diversity_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.biotic.abiotic.vs.diversity)
    dev.off()
    
    }
    
    #######################################################
    # Stability plots                                     #
    #######################################################
    {
    
    mean_sim = readRDS(paste0(results_folder,"/mean_sim_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    #################
    plot.currents.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6,7),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.currents_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.currents.vs.stability)
    dev.off()
    
    plot.biotic.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[1:4,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained by biotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.biotic_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.biotic.vs.stability)
    dev.off()
    
    plot.abiotic.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[4:6,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained by abiotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.abiotic_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.abiotic.vs.stability)
    dev.off()
    
    #################
    plot.pure.env.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained purely by environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.environment_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.env.vs.stability)
    dev.off()
    
    plot.tot.env.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[1:6,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.environment_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.tot.env.vs.stability)
    dev.off()
    
    plot.pure.currents.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained purely by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.currents_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.currents.vs.stability)
    dev.off()
    
    plot.currents.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6,7),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_currents_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.currents.vs.stability)
    dev.off()
    
    plot.mixed.env.currents.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained \nby both currents and environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_mixed.env.currents_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.mixed.env.currents.vs.stability)
    dev.off()
    
    #################
    plot.pure.abiotic.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained purely\n by abiotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.abiotic_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.abiotic.vs.stability)
    dev.off()
    
    #################
    plot.currents.biotic.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[3,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained by currents and abiotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_currents.biotic_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.currents.vs.stability)
    dev.off()
    
    plot.biotic.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[1:4,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained by biotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.biotic_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.biotic.vs.stability)
    dev.off()
    
    plot.abiotic.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[4:6,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Variance explained by abiotic conditions") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.abiotic_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.abiotic.vs.stability)
    dev.off()
    
    #################
    plot.total.biotic.abiotic.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups],y=varpart.groups0[3,selected_groups]+varpart.groups0[2,selected_groups]+varpart.groups0[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Total biotic and abiotic explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups_total_explained_variance_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.biotic.abiotic.vs.stability)
    dev.off()
    
    ##################
    varpart.groups.expTmin0 = varpart.groups.expTmin
    varpart.groups.expTmin0[varpart.groups.expTmin0 < 0] = 0
    
    plot.total.currents.env.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups],y=colSums(varpart.groups.expTmin0)[selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Total explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_total.explained.variance_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.currents.env.vs.stability)
    dev.off()
    
    ##################
    
    plot.total.currents.env.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0)[selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Total explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_total.explained.variance_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_forwardIndependentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.total.currents.env.vs.stability)
    dev.off()
    
    plot.total.currents.env.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_globalSelec],y=colSums(varpart.groups.expTmin.globalSelec0)[selected_groups & significant_global_model_globalSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Total explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_total.explained.variance_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.currents.env.vs.stability)
    dev.off()
    
    plot.total.currents.env.vs.stability = ggplot(data=data.frame(x=mean_sim[selected_groups & significant_global_model_bothDirGlobalSelec],y=colSums(varpart.groups.expTmin.bothDirGlobalSelec0)[selected_groups & significant_global_model_bothDirGlobalSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Stability", y="Total explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_total.explained.variance_vs_stability_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.currents.env.vs.stability)
    dev.off()
    
    }
    
    #######################################################
    # Optimal K plots                                     #
    #######################################################
    {
      prevalence.corrected_K = readRDS(paste0(results_folder,"/Prevalence-corrected.number.of.assemblages_all.SUR.DCM_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))[[2]]
      #############################
      # Ratio:
      div_threshold = 100
      
      # log-log scale, with Nemertea (15.6) and Spumellaria (18.5):
      plot.currents.env.ratio.vs.K = list()
      for (i_case in 1:2)
      {
        plot.currents.env.ratio.vs.K[[i_case]] = ggplot(data=data.frame(x=prevalence.corrected_K[selected_groups & diversity>div_threshold,i_case],
                                                                           y=(varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,])[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          scale_y_log10() +
          theme_bw() +
          geom_hline(yintercept = 1, linetype="dashed") +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=22),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste("Number of",if (i_case == 1) "surface" else "DCM","community types"), y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
      } 
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_pure.currents.env.ratio_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.currents.env.ratio.vs.K[[1]])
      print(plot.currents.env.ratio.vs.K[[2]])
      dev.off()
      
      #############################
      # Relative fractions:  
      div_threshold = 1000
      
      for (i_case in 1:2)
      {
        plot.pure.env.vs.K = ggplot(data=data.frame(x=prevalence.corrected_K[selected_groups & diversity>div_threshold,i_case],y=(varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          # scale_x_continuous(limits = range(optimalK_prevalence.min.crossValid[selected_groups])) +
          geom_point(aes(x,y)) +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste("Number of",if (i_case == 1) "surface" else "DCM","community types"), y=paste("Relative",if (i_case == 1) "surface" else "DCM","variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black")
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents.",if (i_case == 1) "SUR" else "DCM","_rel.pure.environment_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                   "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
        print(plot.pure.env.vs.K)
        dev.off()
        
        plot.pure.currents.vs.K = ggplot(data=data.frame(x=prevalence.corrected_K[selected_groups & diversity>div_threshold,i_case],y=(varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # xlim(range(optimalK_prevalence.min.crossValid[selected_groups])) +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste("Number of",if (i_case == 1) "surface" else "DCM","community types"), y=paste("Relative",if (i_case == 1) "surface" else "DCM","variance\n explained purely by currents")) +
          geom_smooth(aes(x,y),method='lm',col="black")
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
        pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents.",if (i_case == 1) "SUR" else "DCM","_rel.pure.currents_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                   "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
        print(plot.pure.currents.vs.K)
        dev.off()
      }
      
      #############################
      # Raw fractions:  
      
      plot.pure.currents.vs.K = ggplot(data=data.frame(x=optimalK[selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[7,][selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        #ggtitle(colnames(adjr2)[j]) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of community types", y="Variance explained purely by currents") +
        # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
        # xlim(range(log10(size_relativeAbund)[selected_groups])) +
        geom_smooth(aes(x,y),method='lm') 
      pdf(paste0("varpart.groups.expTmin_pure.currents_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.pure.currents.vs.K)
      dev.off()
      
      plot.pure.environment.vs.K = ggplot(data=data.frame(x=optimalK[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),])[selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        #ggtitle(colnames(adjr2)[j]) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of community types", y="Variance explained\n purely by the environment") +
        # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
        # xlim(range(log10(size_relativeAbund)[selected_groups])) +
        geom_smooth(aes(x,y),method='lm') 
      pdf(paste0("varpart.groups.expTmin_pure.environment_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.pure.environment.vs.K)
      dev.off()
      
      plot.mixed.currents.environment.vs.K = ggplot(data=data.frame(x=optimalK[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),])[selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        #ggtitle(colnames(adjr2)[j]) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Number of community types", y="Variance explained\n jointly by currents and the environment") +
        # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
        # xlim(range(log10(size_relativeAbund)[selected_groups])) +
        geom_smooth(aes(x,y),method='lm') 
      pdf(paste0("varpart.groups.expTmin_mixed.currents.environment_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.mixed.currents.environment.vs.K)
      dev.off()
      
    ##################################  
    plot.total.currents.env.vs.stability = ggplot(data=data.frame(x=optimalK[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0)[selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Optimal number of assemblages", y="Total explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_total.explained.variance_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_forwardIndependentVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.currents.env.vs.stability)
    dev.off()
    
    plot.total.currents.env.vs.stability = ggplot(data=data.frame(x=optimalK[selected_groups & significant_global_model_globalSelec],y=colSums(varpart.groups.expTmin.globalSelec0)[selected_groups & significant_global_model_globalSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Optimal number of assemblages", y="Total explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_total.explained.variance_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_forwardGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.currents.env.vs.stability)
    dev.off()
    
    plot.total.currents.env.vs.stability = ggplot(data=data.frame(x=optimalK[selected_groups & significant_global_model_bothDirGlobalSelec],y=colSums(varpart.groups.expTmin.bothDirGlobalSelec0)[selected_groups & significant_global_model_bothDirGlobalSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Optimal number of assemblages", y="Total explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_total.explained.variance_vs_optimalK_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_bothDirectionsGlobalVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.currents.env.vs.stability)
    dev.off()
    
    }
    
    #######################################################
    # Connectivity plots                                  #
    #######################################################
    {
    
    prop_within_OTU_vect0 = readRDS(paste0(results_folder,"/Connectivity_1.5yearTminThres_10particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_expTmin_1.5yearTminThres_10particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
    
    # "Pure biotic","Mixed biotic-abiotic","Mixed biotic-currents","Mixed biotic-abiotic-currents","Pure abiotic","Mixed abiotic-currents","Pure currents"
    
    ##################
    varpart.groups.expTmin0 = varpart.groups.expTmin
    varpart.groups.expTmin0[varpart.groups.expTmin0 < 0] = 0
    
    plot.expTmin.variance.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=colSums(varpart.groups.expTmin0[c(3,4,6,7),selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Connectivity through currents", y="Variance explained by currents") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("AdjR2.expTmin_vs_connectivity.t_minThres.1.5y_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.expTmin.variance.vs.connectivity)
    dev.off()
    
    ##################
    plot.relative.pure.expTmin.vs.connectivity = ggplot(data=data.frame(x=1-prop_within_OTU_vect[selected_groups],y=varpart.groups.expTmin0[7,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
    # plot.pure.expTmin.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups.expTmin0[7,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      # labs(x="Connectivity through currents", y="Pure currents explained variance") +
      labs(x="Smoothed connectivity through currents", y="Relative pure currents explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("varpart.groups.expTmin_pure.expTmin_vs_connectivity.t_minThres.1.5y_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.expTmin_vs_connectivity.expTmin.tau.1.5y_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    # print(plot.pure.expTmin.vs.connectivity)
    print(plot.relative.pure.expTmin.vs.connectivity)
    dev.off()
    
    ##################
    plot.tot.env.vs.connectivity = ggplot(data=data.frame(x=1-prop_within_OTU_vect[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[1:6,selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Smoothed OTU connectivity through currents", y="Variance explained by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.environment_vs_connectivity.expTmin.tau.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.tot.env.vs.connectivity)
    dev.off()
    
    plot.pure.currents.vs.connectivity = ggplot(data=data.frame(x=1-prop_within_OTU_vect[selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Smoothed OTU connectivity through currents", y="Variance explained purely by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.currents_vs_connectivity.expTmin.tau.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.currents.vs.connectivity)
    dev.off()
    
    plot.tot.currents.vs.connectivity = ggplot(data=data.frame(x=1-prop_within_OTU_vect[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6,7),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Smoothed OTU connectivity through currents", y="Variance explained by currents") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_tot.currents_vs_connectivity.expTmin.tau.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.tot.currents.vs.connectivity)
    dev.off()
    
    plot.pure.env.vs.connectivity = ggplot(data=data.frame(x=1-prop_within_OTU_vect[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="OTU connectivity through currents", y="Variance explained\n purely by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_pure.environment_vs_connectivity.expTmin.tau.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.pure.env.vs.connectivity)
    dev.off()
    
    plot.mixed.env.currents.vs.connectivity = ggplot(data=data.frame(x=1-prop_within_OTU_vect[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Smoothed OTU connectivity through currents", y="Variance explained\n by both currents and the environment") +
      geom_smooth(aes(x,y),method='lm') 
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart.groups.expTmin_mixed.environment.currents_vs_connectivity.expTmin.tau.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
    print(plot.mixed.env.currents.vs.connectivity)
    dev.off()
    
    ##################
    # plot.relative.pure.expTmin.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups.expTmin0[7,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
    plot.pure.abiotic.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups.expTmin0[5,selected_groups]/colSums(varpart.groups.expTmin0)[selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Connectivity through currents", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_pure.abiotic_vs_connectivity.t_minThres.1.5y_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.pure.abiotic.vs.connectivity)
    dev.off()
    
    ##################
    # plot.relative.pure.expTmin.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups.expTmin0[7,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
    plot.pure.biotic.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups.expTmin0[1,selected_groups]/colSums(varpart.groups.expTmin0)[selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Connectivity through currents", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_pure.biotic_vs_connectivity.t_minThres.1.5y_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.pure.biotic.vs.connectivity)
    dev.off()
    
    ##################
    # plot.relative.pure.expTmin.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups.expTmin0[7,selected_groups]/colSums(varpart.groups.expTmin0[,selected_groups]))) +
    plot.pure.env.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=colSums(varpart.groups.expTmin0[c(1,2,5),selected_groups])/colSums(varpart.groups.expTmin0)[selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Connectivity through currents", y="Relative variance\n explained purely by the environment") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups.expTmin_pure.environment_vs_connectivity.t_minThres.1.5y_ggplot_forwardVariableSelection_noNegativeAdjR2.pdf"))
    print(plot.pure.env.vs.connectivity)
    dev.off()
    
    #####################
    varpart.groups0 = varpart.groups
    varpart.groups0[varpart.groups0<0] = 0
    
    plot.total.biotic.abiotic.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups0[3,selected_groups]+varpart.groups0[2,selected_groups]+varpart.groups0[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Connectivity through currents", y="Total biotic and abiotic explained variance") +
      # ylim(range((varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups])/(varpart.groups[1,selected_groups]+varpart.groups[2,selected_groups]))) +
      # xlim(range(log10(size_relativeAbund)[selected_groups])) +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups_total_explained_variance_vs_connectivity.t_minThres.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.total.biotic.abiotic.vs.connectivity)
    dev.off()
    
    ##################
    plot.relative.pure.biotic.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups0[3,selected_groups]/colSums(varpart.groups0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Connectivity through currents", y="Relative pure biotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups_pure.relative.biotic_vs_connectivity.t_minThres.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.biotic.vs.connectivity)
    dev.off()
    
    ##################
    plot.relative.pure.abiotic.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups0[1,selected_groups]/colSums(varpart.groups0[,selected_groups]))) +
      geom_point(aes(x,y)) +
      theme_bw() +
      #ggtitle(colnames(adjr2)[j]) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Connectivity through currents", y="Relative pure abiotic explained variance") +
      geom_smooth(aes(x,y),method='lm') 
    pdf(paste0("varpart.groups_pure.relative.abiotic_vs_connectivity.t_minThres.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_variableSelection_noNegativeAdjR2.pdf"))
    print(plot.relative.pure.abiotic.vs.connectivity)
    dev.off()
    
    ##################
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
    functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
    
    plot.total.biotic.abiotic.vs.connectivity = ggplot(data=data.frame(x=prop_within_OTU_vect[selected_groups],y=varpart.groups[3,selected_groups]+varpart.groups[2,selected_groups]+varpart.groups[1,selected_groups])) +
      geom_point(aes(x,y,colour=dominant_function[selected_groups])) +
      theme_bw() +
      # ggtitle(colnames(adjr2)[j]) +
      labs(x="Connectivity through currents", y="Cumulated biotic and abiotic fractions") +
      # ylim(range(adjr2[rda_available_groups,j])) +
      # xlim(range(prop_within_OTU_vect[rda_available_groups])) +
      scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
      theme(axis.title=element_text(size=16),
            text=element_text(size=15), 
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm"),
            legend.position="bottom",
            legend.text=element_text(size=10),
            legend.title=element_text(size=16)) + 
      guides(colour = guide_legend(title.position="bottom"))
    pdf(paste0("varpart.groups_cumulated.biotic.abiotic_vs_connectivity.t_minThres.1.5y_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_functionColors_selected.pdf"))
    print(plot.total.biotic.abiotic.vs.connectivity)
    dev.off()
    }
    
    #######################################################
    # Mean abundance plots                                #
    #######################################################
    {
      relativeAbund = readRDS(paste0(results_folder,"/groups_relativeAbund",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      
      plot.pure.abiotic.vs.mean.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[5,selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Mean abundance across stations (log10)", y="Variance explained purely\n by abiotic conditions") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_pure.abiotic_vs_mean.abundance_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.pure.abiotic.vs.mean.abundance)
      dev.off()
      
      #####################
      plot.pure.biotic.vs.mean.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[1,selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Mean abundance across stations (log10)", y="Variance explained purely\n by biotic conditions") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_pure.biotic_vs_mean.abundance_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.pure.biotic.vs.mean.abundance)
      dev.off()
      
      #####################
      plot.pure.currents.vs.mean.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Mean abundance across stations (log10)", y="Variance explained purely by currents") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_pure.currents_vs_mean.abundance_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.pure.currents.vs.mean.abundance)
      dev.off()
      
      plot.tot.env.vs.mean.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[1:6,selected_groups & significant_global_model_indSelec]))) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Mean abundance across stations (log10)", y="Variance explained by the environment") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_tot.environment_vs_mean.abundance_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.tot.env.vs.mean.abundance)
      dev.off()
      
      plot.pure.env.vs.mean.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),selected_groups & significant_global_model_indSelec]))) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Mean abundance\n across stations (log10)", y="Variance explained\n purely by the environment") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_pure.environment_vs_mean.abundance_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.pure.env.vs.mean.abundance)
      dev.off()
      
      plot.tot.currents.vs.mean.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6,7),selected_groups & significant_global_model_indSelec]))) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Mean abundance across stations (log10)", y="Variance explained by currents") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_tot.currents_vs_mean.abundance_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.tot.currents.vs.mean.abundance)
      dev.off()
      
      plot.tot.variance.vs.mean.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[,selected_groups & significant_global_model_indSelec]))) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Mean abundance across stations (log10)", y="Total variance explained\n by currents and the environment") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_tot.variance_vs_mean.abundance_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.tot.variance.vs.mean.abundance)
      dev.off()
      
      plot.mixed.env.currents.vs.mean.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),selected_groups & significant_global_model_indSelec]))) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="Mean abundance across stations (log10)", y="Variance explained\n by both currents and the environment") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_mixed.currents.environment_vs_mean.abundance_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.mixed.env.currents.vs.mean.abundance)
      dev.off()
    }
    
    ##################################################
    # Diversity plots                                #
    ##################################################
    {
      div_threshold = 1000
      plot.tot.var.vs.diversity = list()
      for (i_case in 1:2)
      {
        plot.tot.var.vs.diversity[[i_case]] = ggplot(data=data.frame(x=as.vector(diversity)[selected_groups & diversity>div_threshold],
                                                                   y=colSums(varpart.env.spatial[[i_case]])[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
          scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Number of OTUs", y=paste("Total",c("surface","DCM")[i_case],"explained variance"))
          # geom_smooth(aes(x,y),method='lm',col="black") 
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_tot.var_vs_diversity_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.tot.var.vs.diversity[[1]])
      print(plot.tot.var.vs.diversity[[2]])
      dev.off()
        
      plot.pure.currents.vs.diversity = ggplot(data=data.frame(x=log10(as.vector(diversity))[selected_groups & significant_global_model_indSelec],y=varpart.groups.expTmin.indSelec0[7,selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="OTU richness (log10)", y="Variance explained purely by currents") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_pure.currents_vs_diversity_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.pure.currents.vs.diversity)
      dev.off()
      
      plot.pure.environment.vs.diversity = ggplot(data=data.frame(x=log10(as.vector(diversity))[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),])[selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="OTU richness (log10)", y="Variance explained\n purely by the environment") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_pure.environment_vs_diversity_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.pure.environment.vs.diversity)
      dev.off()
      
      plot.mixed.environment.currents.vs.diversity = ggplot(data=data.frame(x=log10(as.vector(diversity))[selected_groups & significant_global_model_indSelec],y=colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),])[selected_groups & significant_global_model_indSelec])) +
        geom_point(aes(x,y)) +
        theme_bw() +
        # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
        # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(1,1,1,0.5),"mm")) +
        labs(x="OTU richness (log10)", y="Variance explained\n jointly by currents and the environment") +
        geom_smooth(aes(x,y),method='lm') 
      # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
      pdf(paste0("varpart.groups.expTmin_mixed.environment.currents_vs_diversity_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
      print(plot.mixed.environment.currents.vs.diversity)
      dev.off()
    }
    
    ##################################################
    # Spatial structure plots                        #
    ##################################################
    {
      div_threshold = 100
    
      plot.tot.var.vs.Moran.I = list()
      plot.tot.var.vs.charac.scale = list()
      plot.tot.var.vs.VI.over.K = list()
      for (i_case in 1:2)
      {
        plot.tot.var.vs.Moran.I[[i_case]] = ggplot(data=data.frame(x=I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case],
                                                         y=colSums(varpart.env.spatial[[i_case]])[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"spatial autocorrelation"), y=paste("Total",c("surface","DCM")[i_case],"explained variance")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
        
        plot.tot.var.vs.charac.scale[[i_case]] = ggplot(data=data.frame(x=charac_scale[selected_groups & diversity>div_threshold,i_case],
                                                         y=colSums(varpart.env.spatial[[i_case]])[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"charac. spatial scale"), y=paste("Total",c("surface","DCM")[i_case],"explained variance")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        
        plot.tot.var.vs.VI.over.K[[i_case]] = ggplot(data=data.frame(x=VI_over_K[selected_groups & diversity>div_threshold],
                                                           y=colSums(varpart.env.spatial[[i_case]])[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Dissimilarity between surface and DCM", y=paste("Total",c("surface","DCM")[i_case],"explained variance")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_tot.var_vs_Moran.I.square_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.tot.var.vs.Moran.I[[1]])
      print(plot.tot.var.vs.Moran.I[[2]])
      dev.off()
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_tot.var_vs_charac.scale_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.tot.var.vs.charac.scale[[1]])
      print(plot.tot.var.vs.charac.scale[[2]])
      dev.off()
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_tot.var_vs_VI.over.K_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.tot.var.vs.VI.over.K[[1]])
      print(plot.tot.var.vs.VI.over.K[[2]])
      dev.off()
      
      ################################
      plot.rel.env.vs.Moran.I = list()
      plot.rel.currents.vs.Moran.I = list()
      plot.rel.env.vs.charac.scale = list()
      plot.rel.currents.vs.charac.scale = list()
      plot.rel.env.vs.VI.over.K = list()
      plot.rel.currents.vs.VI.over.K = list()
      for (i_case in 1:2)
      {
        plot.rel.env.vs.Moran.I[[i_case]] = ggplot(data=data.frame(x=I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case],
                                                                   y=(varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"spatial autocorrelation"), y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
        plot.rel.currents.vs.Moran.I[[i_case]] = ggplot(data=data.frame(x=I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case],
                                                                  y=(varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"spatial autocorrelation"), y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by currents")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        
        plot.rel.env.vs.charac.scale[[i_case]] = ggplot(data=data.frame(x=charac_scale[selected_groups & diversity>div_threshold,i_case],
                                                                        y=(varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"charac. spatial scale"), y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        plot.rel.currents.vs.charac.scale[[i_case]] = ggplot(data=data.frame(x=charac_scale[selected_groups & diversity>div_threshold,i_case],
                                                                             y=(varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"charac. spatial scale"), y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by currents")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        
        plot.rel.env.vs.VI.over.K[[i_case]] = ggplot(data=data.frame(x=VI_over_K[selected_groups & diversity>div_threshold],
                                                                     y=(varpart.env.spatial[[i_case]][1,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Dissimilarity between surface and DCM", y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        plot.rel.currents.vs.VI.over.K[[i_case]] = ggplot(data=data.frame(x=VI_over_K[selected_groups & diversity>div_threshold],
                                                                     y=(varpart.env.spatial[[i_case]][3,]/colSums(varpart.env.spatial[[i_case]]))[selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Dissimilarity between surface and DCM", y=paste("Relative",c("surface","DCM")[i_case],"variance\n explained purely by currents")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.env.currents_vs_Moran.I.square_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.rel.env.vs.Moran.I[[1]])
      print(plot.rel.currents.vs.Moran.I[[1]])
      print(plot.rel.env.vs.Moran.I[[2]])
      print(plot.rel.currents.vs.Moran.I[[2]])
      dev.off()
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.env.currents_vs_charac.scale_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.rel.env.vs.charac.scale[[1]])
      print(plot.rel.currents.vs.charac.scale[[1]])
      print(plot.rel.env.vs.charac.scale[[2]])
      print(plot.rel.currents.vs.charac.scale[[2]])
      dev.off()
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_rel.env.currents_vs_VI.over.K_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.rel.env.vs.VI.over.K[[1]])
      print(plot.rel.currents.vs.VI.over.K[[1]])
      print(plot.rel.env.vs.VI.over.K[[2]])
      print(plot.rel.currents.vs.VI.over.K[[2]])
      dev.off()
      
      ################################
      plot.abs.env.vs.Moran.I = list()
      plot.abs.currents.vs.Moran.I = list()
      plot.abs.env.vs.charac.scale = list()
      plot.abs.currents.vs.charac.scale = list()
      plot.abs.env.vs.VI.over.K = list()
      plot.abs.currents.vs.VI.over.K = list()
      for (i_case in 1:2)
      {
        plot.abs.env.vs.Moran.I[[i_case]] = ggplot(data=data.frame(x=I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case],
                                                                   y=varpart.env.spatial[[i_case]][1,][selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"spatial autocorrelation"), y=paste("Absolute",c("surface","DCM")[i_case],"variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
        plot.abs.currents.vs.Moran.I[[i_case]] = ggplot(data=data.frame(x=I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case],
                                                                        y=varpart.env.spatial[[i_case]][3,][selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"spatial autocorrelation"), y=paste("Absolute",c("surface","DCM")[i_case],"variance\n explained purely by currents")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        
        plot.abs.env.vs.charac.scale[[i_case]] = ggplot(data=data.frame(x=charac_scale[selected_groups & diversity>div_threshold,i_case],
                                                                        y=varpart.env.spatial[[i_case]][1,][selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"charac. spatial scale"), y=paste("Absolute",c("surface","DCM")[i_case],"variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        plot.abs.currents.vs.charac.scale[[i_case]] = ggplot(data=data.frame(x=charac_scale[selected_groups & diversity>div_threshold,i_case],
                                                                             y=varpart.env.spatial[[i_case]][3,][selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x=paste(c("Surface","DCM")[i_case],"charac. spatial scale"), y=paste("Absolute",c("surface","DCM")[i_case],"variance\n explained purely by currents")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        
        plot.abs.env.vs.VI.over.K[[i_case]] = ggplot(data=data.frame(x=VI_over_K[selected_groups & diversity>div_threshold],
                                                                     y=varpart.env.spatial[[i_case]][1,][selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Dissimilarity between surface and DCM", y=paste("Absolute",c("surface","DCM")[i_case],"variance\n explained purely by the environment")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
        plot.abs.currents.vs.VI.over.K[[i_case]] = ggplot(data=data.frame(x=VI_over_K[selected_groups & diversity>div_threshold],
                                                                          y=varpart.env.spatial[[i_case]][3,][selected_groups & diversity>div_threshold])) +
          geom_point(aes(x,y)) +
          # scale_x_log10() +
          theme_bw() +
          # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
          # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_text(hjust=0, size=24),
                plot.margin=unit(c(1,6,1,0.5),"mm")) +
          labs(x="Dissimilarity between surface and DCM", y=paste("Absolute",c("surface","DCM")[i_case],"variance\n explained purely by currents")) +
          geom_smooth(aes(x,y),method='lm',col="black") 
      }
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_abs.env.currents_vs_Moran.I.square_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.abs.env.vs.Moran.I[[1]])
      print(plot.abs.currents.vs.Moran.I[[1]])
      print(plot.abs.env.vs.Moran.I[[2]])
      print(plot.abs.currents.vs.Moran.I[[2]])
      dev.off()
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_abs.env.currents_vs_charac.scale_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.abs.env.vs.charac.scale[[1]])
      print(plot.abs.currents.vs.charac.scale[[1]])
      print(plot.abs.env.vs.charac.scale[[2]])
      print(plot.abs.currents.vs.charac.scale[[2]])
      dev.off()
      pdf(paste0(figure_folder_Gibbs.VEM,"/varpart.env.currents_abs.env.currents_vs_VI.over.K_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,
                 "_independentVariableSelection_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000","_noNegativeAdjR2.pdf"))
      print(plot.abs.env.vs.VI.over.K[[1]])
      print(plot.abs.currents.vs.VI.over.K[[1]])
      print(plot.abs.env.vs.VI.over.K[[2]])
      print(plot.abs.currents.vs.VI.over.K[[2]])
      dev.off()
    }
    
    # Different numbers of axes kept:
    #######################################################
    #######################################################
    {
    
    # taxogroups PCA with stdzation and 30/76 first axes - abiotic PCA 3 first axes:
    varpart.groups0 =  varpart.groups
    varpart.groups.pval0 = varpart.groups.pval
    # functions PCA with stdzation and 5/9 first axes - abiotic PCA 3 first axes:
    varpart.functions0 =  varpart.functions
    varpart.functions.pval0 = varpart.functions.pval
    
    # taxogroups PCA with stdzation and 30/76 first axes - abiotic PCA 2 first axes:
    varpart.groups1 =  varpart.groups
    varpart.groups.pval1 = varpart.groups.pval
    # functions PCA with stdzation and 5/9 first axes - abiotic PCA 2 first axes:
    varpart.functions1 =  varpart.functions
    varpart.functions.pval1 = varpart.functions.pval
    
    # taxogroups PCA with stdzation and 2/76 first axes - abiotic PCA 3 first axes:
    varpart.groups2 =  varpart.groups
    varpart.groups.pval2 = varpart.groups.pval
    # functions PCA with stdzation and 2/9 first axes - abiotic PCA 3 first axes:
    varpart.functions2 =  varpart.functions
    varpart.functions.pval2 = varpart.functions.pval
    
    plot.adjr2.taxoGroups.30.vs.2.firstAxes = ggplot(data=data.frame(x=varpart.groups2[3,selected_groups]+varpart.groups2[2,selected_groups],y=varpart.groups0[3,selected_groups]+varpart.groups0[2,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      ggtitle("RDA adjR2 30 vs 2 taxoGroups PCA axes with stdzation") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="First 2 PCA axes", y="First 30 PCA axes") +
    # pdf(paste0("varpart_pure_taxoGroups_30_vs_2_PCAaxes.pdf"))
    pdf(paste0("RDA_adjR2_taxoGroups_30_vs_2_PCAaxes.pdf"))
    print(plot.adjr2.taxoGroups.30.vs.2.firstAxes)
    dev.off()
    
    # plot.adjr2.abiotic.3.vs.2.firstAxes = ggplot(data=data.frame(x=varpart.groups1[1,selected_groups]+varpart.groups1[2,selected_groups],y=varpart.groups0[1,selected_groups]+varpart.groups0[2,selected_groups])) +
    plot.pure.abiotic.3.vs.2.firstAxes = ggplot(data=data.frame(x=varpart.groups1[1,selected_groups],y=varpart.groups0[1,selected_groups])) +
      geom_point(aes(x,y)) +
      theme_bw() +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      ggtitle("Pure abiotic variance 3 vs 2 abiotic PCA axes with stdzation") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="First 2 PCA axes", y="First 3 PCA axes") +
    # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
    pdf(paste0("varpart_pure_abiotic_3_vs_2_PCAaxes.pdf"))
    # print(plot.adjr2.abiotic.3.vs.2.firstAxes)
    print(plot.pure.abiotic.3.vs.2.firstAxes)
    dev.off()
    
    }
  }
  
  if (abiotic_dissimilarity_all)
  {
    library(ggplot2)
    library(gridExtra)
    
    rda_available_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
    
    for (k in 1:nrow(Mantel_out[[1]]))
    {
      spl = split(plot.abiotic.dis[[k]][rda_available_groups[1:133]], (seq_along(plot.abiotic.dis[[k]][rda_available_groups[1:133]])-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
      # pdf("llh_vs_K_ggplot_errbar.pdf",height = 1.5*10, width = 1.5*10)
      pdf(paste0(figure_folder,"/Sorensen_vs_",rownames(Mantel_out[[1]])[k],"_dissimilarity_all_selected_ggplot1.pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
    }
    
    ############
    # Transforming adjr2 and pval into matrices for plotting
    mantel.r2 = t(matrix(ncol = length(taxo_groups), nrow = ncol(abiotic_data_trans_taxon), dimnames = list(colnames(abiotic_data_trans_taxon), taxo_groups), data = unlist(mantelr2)))
    mantel.pval = t(matrix(ncol = length(taxo_groups), nrow = ncol(abiotic_data_trans_taxon), dimnames = list(colnames(abiotic_data_trans_taxon), taxo_groups), data = unlist(mantelpval)))
    
    prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_2yearTminProportion_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    # Defining colours for functional groups:
    ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
    
    plot.mantel.r2_OTU.connectivity = list()
    for (j in 1:ncol(mantel.r2))
    {
      # plot.rda.adjr2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantel.adjr2[rda_available_groups,j]), geom="point") +
      plot.mantel.r2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = dominant_function[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantel.r2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(mantel.adjr2)[j]) +
        labs(x="Mean travel time connectivity within OTUs", y="Mantel R2") +
        ylim(range(mantel.r2[rda_available_groups,j])) +
        xlim(range(prop_within_OTU_vect[rda_available_groups])) +
        scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15), 
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              # legend.text=element_text(size=16),
              legend.text=element_text(size=10),
              legend.title=element_text(size=16)) + 
        # guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
        guides(colour = guide_legend(title.position="bottom"))
    }
    
    # plot.rda.adjr2_OTU.connectivity[[ncol(mantel.adjr2)+1]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantelr2_allvariables[rda_available_groups]), geom="point") +
    plot.mantel.r2_OTU.connectivity[[ncol(mantel.r2)+1]] = qplot(x = x, y = y, colour = dominant_function[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantelr2_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean travel time connectivity within OTUs", y="Mantel R2") +
      ylim(range(mantelr2_allvariables[rda_available_groups])) +
      xlim(range(prop_within_OTU_vect[rda_available_groups])) +
      scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean similarity across 100 real.") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
      theme(axis.title=element_text(size=16),
            text=element_text(size=15), 
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm"),
            legend.position="bottom",
            # legend.text=element_text(size=16),
            legend.text=element_text(size=10),
            legend.title=element_text(size=16)) + 
      # guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
      guides(colour = guide_legend(title.position="bottom"))
    
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_stabilityColors_selected.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_diversityColors_morethan50OTUs.pdf"))
    # pdf(paste0("Mantel_R2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected_sizeColors.pdf"))
    pdf(paste0(figure_folder,"/Mantel_R2_vs_OTU_connectivity_ggplot",mantel_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected_functionColors1.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_optimalKColors_selected.pdf"))
    for (j in 1:(ncol(mantel.r2)+1))
      print(plot.mantel.r2_OTU.connectivity[[j]])
    dev.off()
    
    ############################################
    plot.mantel.r2_OTU.connectivity = list()
    for (j in 1:ncol(mantel.r2))
    {
      # plot.rda.adjr2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantel.adjr2[rda_available_groups,j]), geom="point") +
      plot.mantel.r2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = mantel.pval[rda_available_groups,j], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantel.r2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(mantel.adjr2)[j]) +
        labs(x="Mean OTU connectivity per group", y="Mantel R2") +
        ylim(range(mantel.r2[rda_available_groups,j])) +
        xlim(range(prop_within_OTU_vect[rda_available_groups])) +
        scale_colour_gradientn(colours = c("red","blue","black"), values = rescale(c(0,0.05,1)), na.value = "grey50", guide = "colourbar", name = "Mantel p-value") +
        # scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15), 
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              # legend.text=element_text(size=16),
              legend.text=element_text(size=10),
              legend.title=element_text(size=16)) + 
        guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
      # guides(colour = guide_legend(title.position="bottom"))
    }
    
    # plot.rda.adjr2_OTU.connectivity[[ncol(mantel.adjr2)+1]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantelr2_allvariables[rda_available_groups]), geom="point") +
    plot.mantel.r2_OTU.connectivity[[ncol(mantel.r2)+1]] = qplot(x = x, y = y, colour = mantelpval_allvariables[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantelr2_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean OTU connectivity per group", y="Mantel R2") +
      ylim(range(mantelr2_allvariables[rda_available_groups])) +
      xlim(range(prop_within_OTU_vect[rda_available_groups])) +
      scale_colour_gradientn(colours = c("red","blue","black"), values = rescale(c(0,0.05,1)), na.value = "grey50", guide = "colourbar", name = "Mantel p-value") +
      # scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean similarity across 100 real.") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
      theme(axis.title=element_text(size=16),
            text=element_text(size=15), 
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm"),
            legend.position="bottom",
            # legend.text=element_text(size=16),
            legend.text=element_text(size=10),
            legend.title=element_text(size=16)) + 
      guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    # guides(colour = guide_legend(title.position="bottom"))
    
    # pdf(paste0(figure_folder,"/RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_stabilityColors_selected.pdf"))
    # pdf(paste0(figure_folder,"/RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_diversityColors_morethan50OTUs.pdf"))
    # pdf(paste0(figure_folder,"/Mantel_R2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected_sizeColors.pdf"))
    pdf(paste0(figure_folder,"/Mantel_R2_vs_OTU_connectivity_ggplot",mantel_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected_pvalColors1.pdf"))
    # pdf(paste0(figure_folder,"/RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_optimalKColors_selected.pdf"))
    for (j in 1:(ncol(mantel.r2)+1))
      print(plot.mantel.r2_OTU.connectivity[[j]])
    dev.off()
    
    ############################################
    mantel.slope = t(matrix(ncol = length(taxo_groups), nrow = ncol(abiotic_data_trans_taxon), dimnames = list(colnames(abiotic_data_trans_taxon), taxo_groups), data = unlist(mantelslope)))
    
    plot.mantel.slope_OTU.connectivity = list()
    for (j in 1:ncol(adjr2))
    {
      # plot.rda.adjr2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantel.adjr2[rda_available_groups,j]), geom="point") +
      plot.mantel.slope_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = dominant_function[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantel.slope[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(mantel.slope)[j]) +
        labs(x="Mean travel time connectivity within OTUs", y="Mantel slope") +
        ylim(range(mantel.slope[rda_available_groups,j])) +
        xlim(range(prop_within_OTU_vect[rda_available_groups])) +
        scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15), 
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              # legend.text=element_text(size=16),
              legend.text=element_text(size=10),
              legend.title=element_text(size=16)) + 
        # guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
        guides(colour = guide_legend(title.position="bottom"))
    }
    
    # plot.rda.adjr2_OTU.connectivity[[ncol(mantel.adjr2)+1]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantelr2_allvariables[rda_available_groups]), geom="point") +
    plot.mantel.slope_OTU.connectivity[[ncol(mantel.slope)+1]] = qplot(x = x, y = y, colour = dominant_function[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=mantelslope_allvariables[rda_available_groups]), geom="point") +
      theme_bw() +
      ggtitle("All variables") +
      theme(axis.title=element_text(size=16),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm")) +
      labs(x="Mean travel time connectivity within OTUs", y="Mantel slope") +
      ylim(range(mantelslope_allvariables[rda_available_groups])) +
      xlim(range(prop_within_OTU_vect[rda_available_groups])) +
      scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean similarity across 100 real.") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
      theme(axis.title=element_text(size=16),
            text=element_text(size=15), 
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm"),
            legend.position="bottom",
            # legend.text=element_text(size=16),
            legend.text=element_text(size=10),
            legend.title=element_text(size=16)) + 
      # guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
      guides(colour = guide_legend(title.position="bottom"))
    
    # pdf(paste0(figure_folder,"/RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_stabilityColors_selected.pdf"))
    # pdf(paste0(figure_folder,"/RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_diversityColors_morethan50OTUs.pdf"))
    # pdf(paste0(figure_folder,"/Mantel_R2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected_sizeColors.pdf"))
    pdf(paste0(figure_folder,"/Mantel_slope_vs_OTU_connectivity_ggplot",mantel_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_selected_functionColors1.pdf"))
    # pdf(paste0(figure_folder,"/RDA_adjR2_vs_OTU_connectivity_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_optimalKColors_selected.pdf"))
    for (j in 1:(ncol(mantel.slope)+1))
      print(plot.mantel.slope_OTU.connectivity[[j]])
    dev.off()
  }
  
  if (abiotic_dissimilarity_all && (rda_all || rda_lda))
  {
    library(ggplot2)
    library(gridExtra)
    
    adjr2 = t(matrix(ncol = length(taxo_groups), nrow = ncol(abiotic_data_trans_taxon), dimnames = list(colnames(abiotic_data_trans_taxon), taxo_groups), data = unlist(adjr2)))
    pval = t(matrix(ncol = length(taxo_groups), nrow = ncol(abiotic_data_trans_taxon), dimnames = list(colnames(abiotic_data_trans_taxon), taxo_groups), data = unlist(pval)))
    
    mantel.adjr2 = t(matrix(ncol = length(taxo_groups), nrow = ncol(abiotic_data_trans_taxon), dimnames = list(colnames(abiotic_data_trans_taxon), taxo_groups), data = unlist(mantelr2)))
    mantel.pval = t(matrix(ncol = length(taxo_groups), nrow = ncol(abiotic_data_trans_taxon), dimnames = list(colnames(abiotic_data_trans_taxon), taxo_groups), data = unlist(mantelpval)))
    
    mean_sim = readRDS(paste0(results_folder,"/mean_sim_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    rda_available_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
    
    plot.dis.vs.rda = list()
    for (j in 1:ncol(adjr2))
    {
      # plot.dis.vs.rda[[j]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=adjr2[rda_available_groups,j],y=mantel.adjr2[rda_available_groups,j]), geom="point") +
      plot.dis.vs.rda[[j]] = qplot(x = x, y = y, colour = mean_sim[rda_available_groups], data=data.frame(x=adjr2[rda_available_groups,j],y=mantel.adjr2[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(mantel.adjr2)[j]) +
        labs(x="LDA-based RDA adj. R2", y="Mantel R2") +
        xlim(c(max(min(adjr2[rda_available_groups,j]),-0.05),max(adjr2[rda_available_groups,j]))) +
        ylim(range(mantel.adjr2[rda_available_groups,j])) +
        geom_smooth(method='lm',aes(x,y),se=F) +
        # geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
        scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean similarity across 100 real.") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
        # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
        theme(axis.title=element_text(size=16),
              text=element_text(size=15), 
              plot.title=element_text(hjust=0, size=16),
              plot.margin=unit(c(15,1,1,0.5),"mm"),
              legend.position="bottom",
              legend.text=element_text(size=16),
              legend.title=element_text(size=16)) + 
        # axis.title=element_blank(),
        # axis.text = element_blank(), panel.background = element_blank(),
        # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
        guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    }
    
    # plot.dis.vs.rda[[ncol(adjr2)+1]] = qplot(x = x, y = y, colour = log10(size_absoluteAbund)[rda_available_groups], data=data.frame(x=adjr2_allvariables[rda_available_groups],y=mantelr2_allvariables[rda_available_groups]), geom="point") +
    plot.dis.vs.rda[[ncol(adjr2)+1]] = qplot(x = x, y = y, colour = mean_sim[rda_available_groups], data=data.frame(x=adjr2_allvariables[rda_available_groups],y=mantelr2_allvariables[rda_available_groups]), geom="point") +  
      theme_bw() +
      ggtitle("All variables") +
      labs(x="LDA-based RDA adj. R2", y="Mantel R2") +
      xlim(c(min(adjr2_allvariables[rda_available_groups]),max(adjr2_allvariables[rda_available_groups][!adjr2_allvariables[rda_available_groups] == max(adjr2_allvariables[rda_available_groups])]))) +
      ylim(range(mantelr2_allvariables[rda_available_groups])) +
      geom_smooth(method='lm',aes(x,y),se=F) +
      # geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
      scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean similarity across 100 real.") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "OTU richness (log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
      # scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Optimal number K of assemblages") +
      theme(axis.title=element_text(size=16),
            text=element_text(size=15), 
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(15,1,1,0.5),"mm"),
            legend.position="bottom",
            legend.text=element_text(size=16),
            legend.title=element_text(size=16)) + 
      # axis.title=element_blank(),
      # axis.text = element_blank(), panel.background = element_blank(),
      # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
      guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
    
    pdf(paste0(figure_folder,"/Mantel_R2_vs_RDA_adjR2_ggplot",abiotic_pca_insert,"_",ncol(adjr2),"variables_stabilityColors_selected1.pdf"))
    # pdf(paste0(figure_folder,"/Mantel_R2_vs_RDA_adjR2_ggplot",abiotic_pca_insert,"_",ncol(adjr2),"variables_diversityColors_morethan50OTUs.pdf"))
    # pdf(paste0(figure_folder,"/Mantel_R2_vs_RDA_adjR2_ggplot",abiotic_pca_insert,"_",ncol(adjr2),"variables_sizeColors_selected.pdf"))
    # pdf(paste0(figure_folder,"/Mantel_R2_vs_RDA_adjR2_ggplot",OTU_lda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_optimalKColors_selected.pdf"))
    for (j in 1:(ncol(adjr2)+1))
      print(plot.dis.vs.rda[[j]])
    dev.off()
  }
  
  if (relative_abiotic_sd_per_OTU)
  {
    mean_OTU_abiotic_dispersion_mat = t(matrix(ncol = length(taxo_groups), nrow = 2*ncol(abiotic_data_trans_taxon)-1, dimnames = list(colnames(OTU_abiotic_dispersion_allOTUs[[1]]), taxo_groups), data = unlist(mean_OTU_abiotic_dispersion)))
    
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    #rda_available_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
    # rda_available_groups = selected_groups
    rda_available_groups = vector(length = length(taxo_groups), mode = "logical")
    rda_available_groups[1:length(taxo_groups)] = T
    # rda_available_groups[1:133] = T
    # rda_available_groups = as.vector(diversity) > 50 
    
    ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
    functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
    
    ##############################################
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
    
    # plot.margin=unit(c(7,1,1,0.5),"mm"))
    # height = 1.5*10/4, width = 1.5*10/4
    
    plot.OTU.abiotic.sd_size = list()
    for (j in 1:ncol(mean_OTU_abiotic_dispersion_mat))
    {
      plot.OTU.abiotic.sd_size[[j]] = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund[rda_available_groups]),y=mean_OTU_abiotic_dispersion_mat[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(mean_OTU_abiotic_dispersion_mat)[j]) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="Mean size (micron, log10)", y="Relative abiotic st. dev. per OTU") +
        ylim(c(0,1.5)) +
        geom_hline(yintercept = 1, linetype = "dashed") +
        # ylim(range(adjr2[rda_available_groups,j])) +
        # xlim(range(log10(size_absoluteAbund)[rda_available_groups])) +
        geom_smooth(method='lm') 
      # scale_fill_gradientn(limits = range(pval[rda_available_groups,j]), colours = c("blue","goldenrod1","red"), 
      #                      values = rescale(min(pval[rda_available_groups,j]),0.05,max(pval[rda_available_groups,j])), na.value="cyan", guide = "colourbar")
    }
    
    # pdf(paste0("figure_folder,"/Mean_abiotic_dispersion_vs_size_ggplot_",ncol(mean_OTU_abiotic_dispersion_mat),"variables",abiotic_pca_insert,noArcticNoBiomark_insert,"_selected.pdf"))
    pdf(paste0(figure_folder,"/Mean_abiotic_dispersion_vs_size_ggplot_",ncol(mean_OTU_abiotic_dispersion_mat),"variables",abiotic_pca_insert,noArcticNoBiomark_insert,".pdf"))
    # for (j in 1:(ncol(adjr2)+1))
    for (j in 1:(ncol(mean_OTU_abiotic_dispersion_mat)))
      print(plot.OTU.abiotic.sd_size[[j]])
    dev.off()
    
    #############################################
    # plot.OTU.abiotic.sd_OTU.connectivity = list()
    # for (j in 1:ncol(adjr2))
    # {
    #   plot.rda.adjr2_OTU.connectivity[[j]] = qplot(x = x, y = y, colour = dominant_function[rda_available_groups], data=data.frame(x=prop_within_OTU_vect[rda_available_groups],y=adjr2[rda_available_groups,j]), geom="point") +
    #     theme_bw() +
    #     ggtitle(colnames(adjr2)[j]) +
    #     labs(x="Mean travel time connectivity within OTUs", y="RDA adjusted R2") +
    #     ylim(range(adjr2[rda_available_groups,j])) +
    #     xlim(range(prop_within_OTU_vect[rda_available_groups])) +
    #     scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    #     theme(axis.title=element_text(size=16),
    #           text=element_text(size=15), 
    #           plot.title=element_text(hjust=0, size=16),
    #           plot.margin=unit(c(15,1,1,0.5),"mm"),
    #           legend.position="bottom",
    #           legend.text=element_text(size=10),
    #           legend.title=element_text(size=16)) + 
    #     # axis.title=element_blank(),
    #     # axis.text = element_blank(), panel.background = element_blank(),
    #     # panel.grid.major = element_blank(), panel.grid.minor = element_blank())
    #     guides(colour = guide_legend(title.position="bottom"))
    # }
    # 
    # # pdf(paste0(figure_folder,"/RDA_adjR2_vs_OTU_connectivity_",travel_time_threshold,"yearTminProportion_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_functionColors_selected1.pdf"))
    # pdf(paste0("RDA_adjR2_vs_OTU_connectivity_",particle_thres,"particlesThres_meanPerOTU_ggplot",rda_insert,abiotic_pca_insert,"_",ncol(adjr2),"variables_functionColors_selected1.pdf"))
    # # for (j in 1:(ncol(adjr2)+1))
    # for (j in 1:ncol(adjr2))
    #   print(plot.rda.adjr2_OTU.connectivity[[j]])
    # dev.off()
  }
  
  if (relative_abiotic_sd_per_OTU && rda_lda)
  {
    mean_OTU_abiotic_dispersion_mat = t(matrix(ncol = length(taxo_groups), nrow = 2*ncol(abiotic_data_trans_taxon)-1, dimnames = list(colnames(OTU_abiotic_dispersion_allOTUs[[1]]), taxo_groups), data = unlist(mean_OTU_abiotic_dispersion)))
    adjr2_mat = t(matrix(ncol = length(taxo_groups), nrow = 2*ncol(abiotic_data_trans_taxon)-1, dimnames = list(rownames(RDA_out_lda), taxo_groups), data = unlist(adjr2)))
    
    plot.OTU.abiotic.sd_vs_rda.lda = list()
    for (j in 1:ncol(mean_OTU_abiotic_dispersion_mat))
    {
      plot.OTU.abiotic.sd_vs_rda.lda[[j]] = qplot(x = x, y = y, data=data.frame(x=adjr2[rda_available_groups,j],y=mean_OTU_abiotic_dispersion_mat[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(mean_OTU_abiotic_dispersion_mat)[j]) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="Adj. R2 RDA on LDA decomposition", y="Relative abiotic st. dev. per OTU") +
        # ylim(range(adjr2[rda_available_groups,j])) +
        # xlim(range(log10(size_absoluteAbund)[rda_available_groups])) +
        geom_smooth(method='lm') 
      # scale_fill_gradientn(limits = range(pval[rda_available_groups,j]), colours = c("blue","goldenrod1","red"), 
      #                      values = rescale(min(pval[rda_available_groups,j]),0.05,max(pval[rda_available_groups,j])), na.value="cyan", guide = "colourbar")
    }
    
    pdf(paste0(figure_folder,"/Mean_abiotic_dispersion_vs_adj_R2_RDA_LDA_ggplot_",ncol(mean_OTU_abiotic_dispersion_mat),"variables",abiotic_pca_insert,"_selected.pdf"))
    # for (j in 1:(ncol(adjr2)+1))
    for (j in 1:(ncol(mean_OTU_abiotic_dispersion_mat)))
      print(plot.OTU.abiotic.sd_size[[j]])
    dev.off()
  }
  
  if (relative_abiotic_dissimilarity_per_OTU)
  {
    mean_dissimilarity_within_OTU_mat = t(matrix(ncol = length(taxo_groups), nrow = 2*ncol(abiotic_data_trans_taxon)-1, dimnames = list(colnames(rownames_Mantel_out), taxo_groups), data = unlist(mean_dissimilarity_within_OTU)))
    
    ##############################################
    load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
    
    # plot.margin=unit(c(7,1,1,0.5),"mm"))
    # height = 1.5*10/4, width = 1.5*10/4
    
    plot.OTU.abiotic.dissimilarity_size = list()
    for (j in 1:ncol(mean_dissimilarity_within_OTU_mat))
    {
      plot.OTU.abiotic.dissimilarity_size[[j]] = qplot(x = x, y = y, data=data.frame(x=log10(size_absoluteAbund[rda_available_groups]),y=mean_OTU_abiotic_dissimilarity_mat[rda_available_groups,j]), geom="point") +
        theme_bw() +
        ggtitle(colnames(mean_OTU_abiotic_dissimilarity_mat)[j]) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_text(hjust=0, size=24),
              plot.margin=unit(c(15,1,1,0.5),"mm")) +
        labs(x="Mean size (micron, log10)", y="Relative abiotic dissimilarity per OTU") +
        # ylim(range(adjr2[rda_available_groups,j])) +
        # xlim(range(log10(size_absoluteAbund)[rda_available_groups])) +
        geom_smooth(method='lm') 
      # scale_fill_gradientn(limits = range(pval[rda_available_groups,j]), colours = c("blue","goldenrod1","red"), 
      #                      values = rescale(min(pval[rda_available_groups,j]),0.05,max(pval[rda_available_groups,j])), na.value="cyan", guide = "colourbar")
    }
    
    pdf(paste0(figure_folder,"/Mean_abiotic_dissimilarity_vs_size_ggplot_",ncol(mean_OTU_abiotic_dissimilarity_mat),"variables",abiotic_pca_insert,"_selected.pdf"))
    # for (j in 1:(ncol(adjr2)+1))
    for (j in 1:(ncol(mean_dissimilarity_within_OTU_mat)))
      print(plot.OTU.abiotic.dissimilarity_size[[j]])
    dev.off() 
  }
  
  #########################
  # Plotting the PCA decomposition of abiotic variables
  if (plot_a.biotic)
  {
    library(colorspace)
    
    # setwd(figure_folder)
    
    if (abiotic_pca)
    {
      # variance_prop = vector(length=ncol(abiotic_data_trans),mode="numeric")
      # for (j in 1:ncol(abiotic_data_trans))
      #   variance_prop[j] = sum(abiotic_PCA$eig[1:j])/sum(abiotic_PCA$eig)

      # pdf(paste0("Explained_variance_",ncol(abiotic_data_trans),"variables.pdf"))
      # par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      # plot(variance_prop,ylab="Proportion of variance",xlab="Number of dimensions")
      # dev.off()
      
      library(ade4)
      
      for (case in c("SUR","DCM"))
      {
        i_case = which(c("SUR","DCM") == case)
        abiotic_data = abiotic_data_all[stations_depths[,2] == case,]
        
        if (any(apply(abiotic_data,2,is.na)))
        {
          abiotic_data_trans = abiotic_data[,!(as.vector(unlist(lapply(apply(apply(abiotic_data,2,is.na),2,which),length))) > 3)]
        } else 
          abiotic_data_trans = abiotic_data
        
        # Centering and standardizing the abiotic data:
        # abiotic_data_trans = sweep(sweep(abiotic_data_trans,2,colMeans(abiotic_data_trans, na.rm = T),"-"),2,apply(abiotic_data_trans,2,sd,na.rm=T),"/")
        abiotic_data_trans = scale(abiotic_data_trans)
        
        # PCA on standardized ("normed") data, ie centered and divided by std. dev. for each column 
        # Removing stations where one abiotic value is missing:
        stations_to_remove = apply(apply(abiotic_data_trans,2,is.na),1,any)
        # Removing Latitude from the abiotic variables on which PCA is applied
        abiotic_PCA = dudi.pca(as.data.frame(abiotic_data_trans[!stations_to_remove,colnames(abiotic_data_trans)!="Distance_to_coast"]), row.w = rep(1, nrow(abiotic_data_trans[!stations_to_remove,]))/nrow(abiotic_data_trans[!stations_to_remove,]), 
                               # col.w = rep(1, ncol(abiotic_data_trans) - 1),
                               # col.w = c(1,1/3,1/3,1/3,1,1/3,1/3,1/3,1,1),
                               col.w = rep(1,ncol(abiotic_data_trans)),
                               # col.w = c(1,1,1,1/3,1/3,1/3,1,1),
                               center = TRUE, scale = TRUE, scannf = F, nf = ncol(abiotic_data_trans))
        
        pdf(paste0(figure_folder_Gibbs.VEM,"/Explained.variance.abiotic.PCA.",case,"_",nrow(abiotic_PCA$co),"variables.pdf"))
        par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
        plot(abiotic_PCA$eig/sum(abiotic_PCA$eig),ylab="Proportion of variance",xlab="PCA axis")
        abline(h = 1/nrow(abiotic_PCA$co), lty = 2)
        dev.off()
        
        pdf(paste0(figure_folder_Gibbs.VEM,"/Explained.variance.abiotic.PCA.",case,"_",nrow(abiotic_PCA$co),"variables_barplot.pdf"))
        par(cex.lab=1.5,cex.main=1.7,cex.axis=2,lwd=2)
        barplot(abiotic_PCA$eig,ylab="",xlab="",col="black")
        abline(h = 1, lty = 2)
        dev.off()
        
        pdf(paste0(figure_folder_Gibbs.VEM,"/abiotic.PCA.axes.",case,"_",nrow(abiotic_PCA$co),"variables_noweights.pdf"))
        #bottom left top right
        #par(mar=c(5.1,4.1,4.1,2.1)
        par(mar=c(7.1,4.1,4.1,2.1))
        par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
        for (axis_index in 1:ncol(abiotic_PCA$li))
        { 
          variable_sort = sort.int(abiotic_PCA$c1[,axis_index]^2,decreasing=T,index.return=T)
          variable_weights = data.frame(variable_sort$x,abiotic_PCA$c1[variable_sort$ix,axis_index],rownames(abiotic_PCA$co)[variable_sort$ix])
          variable_color = vector(length=nrow(abiotic_PCA$co),mode="character")
          variable_color[which(variable_weights[,2]>0)]="black"
          variable_color[which(variable_weights[,2]<0)]="red"
          
          x = plot(variable_weights[,1],type="p",ann=T,xaxt="n",ylab = "Environmental variable proportion in axis", xlab="",col=variable_color,
                   main = paste("Axis #",axis_index," ",format(abiotic_PCA$eig[axis_index]/ncol(abiotic_PCA$li)*100,digits=2),"% variance",sep=""))
          axis(1, at=1:nrow(abiotic_PCA$co), labels = F)
          labels = variable_weights[,3]
          # text(1:ncol(abiotic_data), par("usr")[3], adj = 0, srt = 45, pos=1, labels = labels, xpd = T, cex=1.2)
          text(1:nrow(abiotic_PCA$co), par("usr")[3], srt = 45, pos=1, offset=3, labels = labels, xpd = T, cex=1)
          #title=paste("Axis #",element_index," ",format(chemi_PCA$eig[element_index]/ncol(data_chemi)*100,digits=2),"% variance",sep="")
        }
        dev.off()
      }
    }
    
    if (biotic_pca)
    {
      # variance_prop = vector(length=ncol(read_abundance_per_group_trans[,selected_groups]),mode="numeric")
      # for (j in 1:ncol(read_abundance_per_group_trans[,selected_groups]))
      #   variance_prop[j] = sum(read_abundance_PCA$eig[1:j])/sum(read_abundance_PCA$eig)
      # 
      # pdf(paste0("Explained_variance_PCA_read_abundance_",ncol(read_abundance_per_group_trans[,selected_groups]),"variables.pdf"))
      # par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      # plot(variance_prop,ylab="Proportion of variance",xlab="Number of dimensions")
      # dev.off()
      
      # pdf(paste0("Explained_variance_PCA_absolute_abundance_",ncol(absoluteAbund_trans[,selected_groups]),"variables.pdf"))
      # par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      # plot(absoluteAbund_PCA$eig/sum(absoluteAbund_PCA$eig),ylab="Proportion of variance",xlab="PCA axis")
      # abline(h = 1/ncol(absoluteAbund_trans[,selected_groups]), lty = 2)
      # dev.off()
      
      # pdf(paste0("Explained_variance_PCA_relative_abundance_",nrow(relativeAbund_PCA$co),"variables_noStdzation.pdf"))
      pdf(paste0(figure_folder,"/Explained_variance_PCA_relative_abundance_",nrow(relativeAbund_PCA0$co),"variables",stdzation_insert,".pdf"))
      par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      plot(relativeAbund_PCA0$eig/sum(relativeAbund_PCA0$eig),ylab="Proportion of variance",xlab="PCA axis")
      abline(h = 1/nrow(relativeAbund_PCA$co), lty = 2)
      dev.off()
      
      pdf(paste0(figure_folder,"/Explained_variance_PCA_relative_abundance_",nrow(relativeAbund_PCA0$co),"variables",stdzation_insert,"_barplot.pdf"))
      par(cex.lab=1.5,cex.main=1.7,cex.axis=2,lwd=2)
      barplot(relativeAbund_PCA0$eig/sum(relativeAbund_PCA0$eig),ylab="",xlab="",col="black")
      abline(h = 1/nrow(relativeAbund_PCA0$co), lty = 2)
      dev.off()
      
      # pdf(paste0("Explained_variance_PCA_functions_absoluteAbund_selected_",ncol(functions_absoluteAbund_selected_trans),"variables.pdf"))
      # par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      # plot(functions_absoluteAbund_selected_PCA$eig/sum(functions_absoluteAbund_selected_PCA$eig),ylab="Proportion of variance",xlab="PCA axis")
      # abline(h = 1/ncol(functions_absoluteAbund_selected_trans), lty = 2)
      # dev.off()
      
      # pdf(paste0("Explained_variance_PCA_functions_relativeAbund_selected_",nrow(functions_relativeAbund_selected_PCA$co),"variables_noStdzation.pdf"))
      pdf(paste0(figure_folder,"/Explained_variance_PCA_functions_relativeAbund_selected_",nrow(functions_relativeAbund_selected_PCA0$co),"variables",stdzation_insert,".pdf"))
      par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      plot(functions_relativeAbund_selected_PCA0$eig/sum(functions_relativeAbund_selected_PCA0$eig),ylab="Proportion of variance",xlab="PCA axis")
      abline(h = 1/nrow(functions_relativeAbund_selected_PCA0$co), lty = 2)
      dev.off()
      
      pdf(paste0(figure_folder,"/Explained_variance_PCA_functions_relativeAbund_",nrow(functions_relativeAbund_PCA0$co),"variables",stdzation_insert,".pdf"))
      par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      plot(functions_relativeAbund_PCA0$eig/sum(functions_relativeAbund_PCA0$eig),ylab="Proportion of variance",xlab="PCA axis")
      abline(h = 1/nrow(functions_relativeAbund_PCA0$co), lty = 2)
      dev.off()
    }
    
    pdf(paste0(figure_folder,"/expTmin_distance_PCoA_positive_eigenvalues.pdf"))
    par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
    plot(expTmin_distance_pcoa$values$Eigenvalues[1:61],ylab="Eigenvalue",xlab="Eigenvector")
    abline(h = 1, lty = 2)
    dev.off()
    
    pdf(paste0(figure_folder,"/expTmin_distance_PCoA_positive_eigenvalues_barplot.pdf"))
    par(cex.lab=1.5,cex.main=1.7,cex.axis=2,lwd=2,bty = "o")
    barplot(expTmin_distance_pcoa$values$Eigenvalues[1:61]/sum(expTmin_distance_pcoa$values$Eigenvalues[1:61]),ylab="", col = "black")
    dev.off()
    # sum(expTmin_distance_pcoa$values$Eigenvalues[1:61])
    # sum(expTmin_distance_pcoa$values$Eigenvalues)
    
    if (biotic_pca)
    {
      # pdf(paste0("read_abundance_PCA_axes_",ncol(read_abundance_per_group_trans[,selected_groups]),"variables_weights.pdf"))
      # # pdf(paste0("read_abundance_PCA_axes_",length(which(read_abundance_PCA$eig>1)),"variables_weights.pdf"))
      # #bottom left top right
      # #par(mar=c(5.1,4.1,4.1,2.1)
      # par(mar=c(7.1,4.1,4.1,2.1))
      # par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      # for (axis_index in 1:ncol(read_abundance_PCA$li))
      # { 
      #   variable_sort = sort.int(read_abundance_PCA$c1[,axis_index]^2,decreasing=T,index.return=T)
      #   variable_weights = data.frame(variable_sort$x,read_abundance_PCA$c1[variable_sort$ix,axis_index],colnames(read_abundance_per_group_trans[,selected_groups])[variable_sort$ix])
      #   variable_color = vector(length=ncol(read_abundance_PCA$li),mode="character")
      #   variable_color[which(variable_weights[,2]>0)]="black"
      #   variable_color[which(variable_weights[,2]<0)]="red"
      #   
      #   x = plot(variable_weights[,1],type="p",ann=T,xaxt="n",ylab = "Environmental variable proportion in axis", xlab="",col=variable_color,
      #            main = paste("Axis #",axis_index," ",format(read_abundance_PCA$eig[axis_index]/ncol(read_abundance_PCA$li)*100,digits=2),"% variance",sep=""))
      #   axis(1, at=1:ncol(read_abundance_PCA$li), labels = F)
      #   labels = variable_weights[,3]
      #   # text(1:ncol(abiotic_data), par("usr")[3], adj = 0, srt = 45, pos=1, labels = labels, xpd = T, cex=1.2)
      #   text(1:ncol(read_abundance_PCA$li), par("usr")[3], srt = 45, pos=1, offset=3, labels = labels, xpd = T, cex=0.5)
      #   #title=paste("Axis #",element_index," ",format(chemi_PCA$eig[element_index]/ncol(data_chemi)*100,digits=2),"% variance",sep="")
      # }
      # dev.off()
      
      # pdf(paste0("relative_abundance_PCA_axes_",nrow(relativeAbund_PCA$co),"variables_noStdzation.pdf"))
      pdf(paste0(figure_folder,"/relative_abundance_PCA_axes_",nrow(relativeAbund_PCA0$co),"variables",stdzation_insert,".pdf"))
      # pdf(paste0("read_abundance_PCA_axes_",length(which(read_abundance_PCA$eig>1)),"variables_weights.pdf"))
      #bottom left top right
      #par(mar=c(5.1,4.1,4.1,2.1)
      par(mar=c(7.1,4.1,4.1,2.1))
      par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      for (axis_index in 1:ncol(relativeAbund_PCA0$li))
      { 
        variable_sort = sort.int(relativeAbund_PCA0$c1[,axis_index]^2,decreasing=T,index.return=T)
        # variable_weights contains the squared normed loadings of the current axis on all input variables sorted by decreasing order,
        # the signed normed loadings of the current axis in the same order, and the names of all input variables: 
        variable_weights = data.frame(variable_sort$x,relativeAbund_PCA0$c1[variable_sort$ix,axis_index],rownames(relativeAbund_PCA0$co)[variable_sort$ix])
        variable_color = vector(length=nrow(relativeAbund_PCA0$co),mode="character")
        variable_color[which(variable_weights[,2]>0)]="black"
        variable_color[which(variable_weights[,2]<0)]="red"
        
        # The "eigenvalue" of each axis is given as the actual eigenvalue divided by the trace, times the number of input variables
        x = plot(variable_weights[,1],type="p",ann=T,xaxt="n",ylab = "Environmental variable proportion in axis", xlab="",col=variable_color,
                 main = paste0("Axis #",axis_index," - Eigenvalue = ",format(relativeAbund_PCA0$eig[axis_index]/sum(relativeAbund_PCA0$eig)*nrow(relativeAbund_PCA0$co),digits=4)))
        axis(1, at=1:nrow(relativeAbund_PCA0$co), labels = F)
        labels = variable_weights[,3]
        # text(1:ncol(abiotic_data), par("usr")[3], adj = 0, srt = 45, pos=1, labels = labels, xpd = T, cex=1.2)
        text(1:nrow(relativeAbund_PCA0$co), par("usr")[3], srt = 45, pos=1, offset=3, labels = labels, xpd = T, cex=0.5)
        #title=paste("Axis #",element_index," ",format(chemi_PCA$eig[element_index]/ncol(data_chemi)*100,digits=2),"% variance",sep="")
      }
      dev.off()
      
      # pdf(paste0("functions_relativeAbund_PCA_axes_",nrow(functions_relativeAbund_selected_PCA$co),"variables_noStdzation.pdf"))
      pdf(paste0(figure_folder,"/functions_relativeAbund_PCA_axes_",nrow(functions_relativeAbund_PCA0$co),"variables",stdzation_insert,".pdf"))
      # pdf(paste0("read_abundance_PCA_axes_",length(which(read_abundance_PCA$eig>1)),"variables_weights.pdf"))
      #bottom left top right
      #par(mar=c(5.1,4.1,4.1,2.1)
      par(mar=c(7.1,4.1,4.1,2.1))
      par(cex.lab=1.5,cex.main=1.7,cex.axis=1.5,lwd=2)
      for (axis_index in 1:ncol(functions_relativeAbund_PCA0$li))
      { 
        variable_sort = sort.int(functions_relativeAbund_PCA0$c1[,axis_index]^2,decreasing=T,index.return=T)
        variable_weights = data.frame(variable_sort$x,functions_relativeAbund_PCA0$c1[variable_sort$ix,axis_index],rownames(functions_relativeAbund_PCA0$co)[variable_sort$ix])
        variable_color = vector(length=nrow(functions_relativeAbund_PCA0$co),mode="character")
        variable_color[which(variable_weights[,2]>0)]="black"
        variable_color[which(variable_weights[,2]<0)]="red"
        
        x = plot(variable_weights[,1],type="p",ann=T,xaxt="n",ylab = "Environmental variable proportion in axis", xlab="",col=variable_color,
                 main = paste0("Axis #",axis_index," - Eigenvalue = ",format(functions_relativeAbund_PCA0$eig[axis_index]/sum(functions_relativeAbund_PCA0$eig)*nrow(functions_relativeAbund_PCA0$co),digits=4)))
        axis(1, at=1:nrow(functions_relativeAbund_PCA0$co), labels = F)
        labels = variable_weights[,3]
        # text(1:ncol(abiotic_data), par("usr")[3], adj = 0, srt = 45, pos=1, labels = labels, xpd = T, cex=1.2)
        text(1:nrow(functions_relativeAbund_PCA0$co), par("usr")[3], srt = 45, pos=1, offset=3, labels = labels, xpd = T, cex=1)
        #title=paste("Axis #",element_index," ",format(chemi_PCA$eig[element_index]/ncol(data_chemi)*100,digits=2),"% variance",sep="")
      }
      dev.off()
    }
    
    if (abiotic_pca)
    {
      # c("Marine.biome","Ocean.region","Biogeographical.province")
      pdf(paste0(figure_folder,"/abiotic_PCA_geographic_classes_",ncol(abiotic_data_trans),"variables_axes1-2.pdf"))
      for (k in 1:4)
      {
        colors = rainbow_hcl(length(levels(as.factor(geographic_classes[!stations_to_remove,k]))))
        #par(mar = c(2.1, 2.1, 2.1, 1.1))
        geographic_classes_noWAtlantic = geographic_classes
        geographic_classes_noWAtlantic[geographic_classes[,4] == "W. Atlantic",4] = NA
        s.class(abiotic_PCA$li,xax=1,yax=2,fac=as.factor(geographic_classes_noWAtlantic[!stations_to_remove,k]),col=colors)
      }
      dev.off()
      
      pdf(paste0(figure_folder,"/abiotic_PCA_geographic_classes_",ncol(abiotic_data_trans),"variables_axes1-3.pdf"))
      for (k in 1:4)
      {
        colors = rainbow_hcl(length(levels(as.factor(geographic_classes[!stations_to_remove,k]))))
        #par(mar = c(2.1, 2.1, 2.1, 1.1))
        geographic_classes_noWAtlantic = geographic_classes
        geographic_classes_noWAtlantic[geographic_classes[,4] == "W. Atlantic",4] = NA
        s.class(abiotic_PCA$li,xax=1,yax=3,fac=as.factor(geographic_classes_noWAtlantic[!stations_to_remove,k]),col=colors)
      }
      dev.off()
      
      pdf(paste0(figure_folder,"/abiotic_PCA_geographic_classes_",ncol(abiotic_data_trans),"variables_axes2-3.pdf"))
      for (k in 1:4)
      {
        colors = rainbow_hcl(length(levels(as.factor(geographic_classes[!stations_to_remove,k]))))
        #par(mar = c(2.1, 2.1, 2.1, 1.1))
        geographic_classes_noWAtlantic = geographic_classes
        geographic_classes_noWAtlantic[geographic_classes[,4] == "W. Atlantic",4] = NA
        s.class(abiotic_PCA$li,xax=2,yax=3,fac=as.factor(geographic_classes_noWAtlantic[!stations_to_remove,k]),col=colors)
      }
      dev.off()
      
      pdf(paste0(figure_folder,"/abiotic_PCA_corcircle_",ncol(abiotic_data_trans),"variables.pdf"))
      #par(mar = c(2.1, 2.1, 2.1, 1.1))
      s.corcircle(abiotic_PCA$co, full = F, box = TRUE)
      dev.off()
      
      pdf(paste0(figure_folder,"/abiotic_PCA_geographic_classes_corcircle_",ncol(abiotic_data_trans),"variables.pdf"),width=2*6,height=6)
      for (k in 1:4)
      {
        colors = rainbow_hcl(length(levels(as.factor(geographic_classes[!stations_to_remove,k]))))
        par(mfrow=c(1,2))
        geographic_classes_noWAtlantic = geographic_classes
        geographic_classes_noWAtlantic[geographic_classes[,4] == "W. Atlantic",4] = NA
        scatter(abiotic_PCA,clabel=NULL)
        s.class(abiotic_PCA$li,fac=as.factor(geographic_classes_noWAtlantic[!stations_to_remove,k]),col=colors)
      }
      dev.off()
      
      # pdf("abiotic_PCA_label.pdf")
      # #par(mar = c(2.1, 2.1, 2.1, 1.1))
      # s.label(abiotic_PCA$li)
      # dev.off()
      # 
      # pdf("abiotic_PCA_geographic_classes_label.pdf",width=2*6,height=6)
      # for (k in 1:3)
      # {
      #   colors = rainbow_hcl(length(levels(as.factor(geographic_classes[!stations_to_remove,k]))))
      #   par(mfrow=c(1,2))
      #   s.label(abiotic_PCA$li)
      #   s.class(abiotic_PCA$li,fac=as.factor(geographic_classes[!stations_to_remove,k]),col=colors)
      # }
      # dev.off()
      
      pdf(paste0(figure_folder,"/abiotic_PCA_scatter_",ncol(abiotic_data_trans),"variables.pdf"))
      scatter(abiotic_PCA,clabel=NULL)
      dev.off()
      
      # pdf(paste0("abiotic_PCA_arrow_",ncol(abiotic_data_trans),"variables.pdf"))
      # s.arrow(abiotic_PCA$co,box = TRUE)
      # dev.off()
      
      # pdf("abiotic_PCA_class_label_scatter.pdf",width=2*6,height=2*6)
      # par(mfrow=c(2,2))
      # scatter(abiotic_PCA,clabel=NULL)
      # s.class(abiotic_PCA$li,fac=as.factor(Soil_data[,2]),col=colors)
      # Soil_data1 = read.table("/Users/guilhemsommeria-klein/Desktop/These/Donnes_betadiv/Sols/Soil_data_transformed_shortnames1.csv", colClasses="vector", sep=";")
      # Soil_data1 = Soil_data1[-1,]
      # s.label(abiotic_PCA$li)
      # s.class(abiotic_PCA$li,fac=as.factor(Soil_data1[,2]),col=colors1)
      # dev.off()
    }
    
    if (biotic_pca)
    {
      pdf(paste0(figure_folder,"/read_abundance_PCA_geographic_classes_corcircle_",ncol(read_abundance_PCA$li),"variables.pdf"),width=2*6,height=6)
      for (k in 1:4)
      {
        colors = rainbow_hcl(length(levels(as.factor(geographic_classes[,k]))))
        par(mfrow=c(1,2))
        geographic_classes_noWAtlantic = geographic_classes
        geographic_classes_noWAtlantic[geographic_classes[,4] == "W. Atlantic",4] = NA
        scatter(read_abundance_PCA,clabel=NULL)
        s.class(read_abundance_PCA$li,fac=as.factor(geographic_classes_noWAtlantic[,k]),col=colors)
      }
      dev.off()
      
      pdf(paste0(figure_folder,"/read_abundance_PCA_scatter_",ncol(read_abundance_PCA$li),"variables.pdf"))
      scatter(read_abundance_PCA,clabel=NULL)
      dev.off()
      
      pdf(paste0(figure_folder,"/read_abundance_PCA_corcircle_",ncol(read_abundance_PCA$li),"variables.pdf"))
      #par(mar = c(2.1, 2.1, 2.1, 1.1))
      s.corcircle(read_abundance_PCA$co, full = F, box = TRUE)
      dev.off()
    }
    
    mean_sim = readRDS(paste0(results_folder,"/mean_sim_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    pdf(paste0(figure_folder,"/abiotic_PCA_geographic_classes_",ncol(abiotic_data_trans),"variables_taxoGroups_selected.pdf"))
    for (taxon in c("AllTaxa",taxo_groups[selected_groups]))
    {
      i_taxon = ifelse(taxon != "AllTaxa", which(taxo_groups == taxon), length(taxo_groups)+1)
      #par(mar = c(2.1, 2.1, 2.1, 1.1))
      data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      nb_topics = c(optimalK,ifelse(noArcticNoBiomark==1,8,7))[i_taxon]
      spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
      # load(paste0(data.folder_name,"/coord.Rdata"))
      
      coord_taxon = coord[rownames(spatial_topicmix_kriged[[1]]),]
      
      # AllTaxa_topics = c("Upwelling","Indian Ocean","Medit.","Temp. Atlantic","Tropical DCM","Tropical Surf.","C. Pacific","E. Pacific","W. Atlantic","Red Sea")
      topicmix = matrix(nrow = nrow(coord_taxon), ncol = nb_topics, dimnames = list(rownames(coord_taxon),paste("Assemblage",1:nb_topics)), data = 0)
      for (k in 1:nb_topics)
        topicmix[,k] = spatial_topicmix_kriged[[k]]$z.pred
      
      dominant_topic = vector(length = nrow(topicmix), mode = "numeric")
      for (i in 1:length(dominant_topic))
      {
        if (length(which(topicmix[i,] == max(topicmix[i,]))) == 1)
          dominant_topic[i] = which(topicmix[i,] == max(topicmix[i,]))
        else
          dominant_topic[i] = sample(which(topicmix[i,] == max(topicmix[i,])),1)
      }
      
      geographic_classes_taxoGroups = (1:nb_topics)[dominant_topic]
      names(geographic_classes_taxoGroups) = rownames(topicmix)
      
      # Selecting rownames(abiotic_PCA$li) out of geographic_classes_taxoGroups removes stations not present in abiotic_PCA$li, 
      # but creates NA when geographic_classes_taxoGroups misses some of the stations of abiotic_PCA$li.
      # They have to be removed before plotting
      colors = rainbow_hcl(length(levels(as.factor(geographic_classes_taxoGroups[rownames(abiotic_PCA$li)]))))
      s.class(abiotic_PCA$li[!is.na(geographic_classes_taxoGroups[rownames(abiotic_PCA$li)]),],fac=as.factor(geographic_classes_taxoGroups[rownames(abiotic_PCA$li)][!is.na(geographic_classes_taxoGroups[rownames(abiotic_PCA$li)])]),col=colors)
      
      title(main = paste(taxon,"- Diversity =",c(diversity,201023)[i_taxon],"- Stability =",c(mean_sim,NA)[i_taxon]))
    }
    dev.off()
    
    ############################################
    # Plotting PCA axes
    
    # To perform kriging:
    library(kriging)
    # To plot the kriged maps:
    library(ggplot2)
    library(gridExtra)
    library(scales)
    library(gstat)
    # To call grid.newpage()
    library(grid)
    # To plot shapes using readOGR (not available on cluster):
    library(rgdal)
    library(sp)
    library(rgeos)
    library(maptools)
    # To use raster manipulating functions:
    library(raster)
    # To use coltorgb:
    library(grDevices)
    library(ggtree)
    
    background_map_path = data_folder
    background_map_file = "ne_50m_ocean"
    # Loading background map: 
    background = readOGR(dsn = paste0(background_map_path,"/",background_map_file), layer = background_map_file)
    background@data$id = rownames(background@data)
    backgroundPoints = fortify(background, region="id")
    backgroundGgplot = merge(backgroundPoints, background@data, by="id") 
    
    if (abiotic_pca)
    {
      tmp.plot = list()
      range_int = list()
      z.pred.k = list()
      # Plotting all abiotic variables that are not fully composed of NAs (PAR.PC, NPP.uqartakuvik, acCDOM.atushi, sCDOM.atushi) 
      # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
      for (k in 1:ncol(abiotic_PCA$li))
      {
        tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
        z.pred.k[[k]] = abiotic_PCA$li[rownames(abiotic_data),k]
        
        range_int[[k]] = range(z.pred.k[[k]][!is.na(z.pred.k[[k]])])
        # Setting NA values in abiotic variables to a large value, so as to distinguih them from the NA introduced by the missing stations-depths when plotting
        NA_value = range_int[[k]][2] + (range_int[[k]][2] - range_int[[k]][1])/10
        z.pred.k[[k]][is.na(z.pred.k[[k]])] = NA_value
        
        for (station in stations_names)
        {
          station_indices = which(stations_depths$Station == station)
          
          if (length(station_indices) == 1)
          {
            if (stations_depths$Depth[station_indices] == "SUR")
            {
              pie = ggplot(data.frame(x=c(z.pred.k[[k]][station_indices],NA),y=c(1,1)), aes(x=1, y, fill=x))
            } else if (stations_depths$Depth[station_indices] == "DCM")
            {
              pie = ggplot(data.frame(x=c(NA,z.pred.k[[k]][station_indices]),y=c(1,1)), aes(x=1, y, fill=x))
            }
          } else
            pie = ggplot(data.frame(x=z.pred.k[[k]][station_indices],y=rep(1,length(station_indices))), aes(x=1, y, fill=x))
          
          if (range_int[[k]][1]<0)
          {
            colours = c("darkgreen","blue","red","cyan")
            values = rescale(c(range_int[[k]][1],0,range_int[[k]][2],NA_value))
            # colours = c("darkgreen","blue","red")
            # values = rescale(c(range_int[[k]][1],0,range_int[[k]][2]))
          } else
          {
            colours = c("blue","red","cyan")
            values = rescale(c(range_int[[k]][1],range_int[[k]][2],NA_value))
            # colours = c("blue","red")
            # values = rescale(c(range_int[[k]][1],range_int[[k]][2]))
          }
          pie = pie + 
            #             scale_fill_brewer(palette="color.pal.heat") +
            #             scale_fill_brewer(palette="heat.colors") +
            scale_fill_gradientn(limits = c(range_int[[k]][1],NA_value), colours = colours, values = values, na.value="transparent", guide = "colourbar") +
            #scale_fill_gradientn(colours=color.pal.heat(2)) +
            #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
            geom_bar(stat="identity", width=1) + 
            coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
            xlab(NULL) + ylab(NULL) + 
            theme_transparent()
          #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
          tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[station_indices[1]],coord$y[station_indices[1]],width=0.09, height=0.09)        
        }
      }
      
      # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
      for (k in 1:ncol(abiotic_PCA$li))
      {
        tmp.plot[[k]] = tmp.plot[[k]] +
          coord_equal() +
          #labs(fill=paste0("Assemblage ",k)) +  
          theme_minimal() + ggtitle(paste(colnames(abiotic_PCA$li)[k],"- range:",range_int[[k]][1],"-",range_int[[k]][2])) +
          #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
          #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
          theme(legend.position="bottom", legend.text=element_text(size=7),
                legend.title=element_text(size=8), axis.title=element_blank(),
                axis.text = element_blank(), panel.background = element_blank(),
                panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                plot.title=element_text(hjust=0), plot.margin=unit(c(2,2,2,2),"mm")) +
          # theme(legend.position="bottom", legend.text=element_text(size=7), 
          #       legend.title=element_text(size=8), axis.title=element_blank(), 
          #       axis.text = element_blank(), panel.background = element_blank(),
          #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
          guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
      }
      
      # pdf("Abiotic_maps_all.pdf")
      pdf(paste0(figure_folder,"/PCA_axes_maps_",ncol(abiotic_PCA$li),"axes_noweights.pdf"))
      for (k in 1:ncol(abiotic_PCA$li))
        print(tmp.plot[[k]])
      dev.off()
    }
    
    if (biotic_pca)
    {
      # PCA on function  abundances:
      ##############################
      tmp.plot = list()
      range_int = list()
      z.pred.k = list()
      # Plotting all abiotic variables that are not fully composed of NAs (PAR.PC, NPP.uqartakuvik, acCDOM.atushi, sCDOM.atushi) 
      # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
      for (k in 1:ncol(functions_relativeAbund_PCA0$li))
      {
        tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
        # Restablishing the stations with NA values that were removed to compute the PCA:
        z.pred.k[[k]] = functions_relativeAbund_PCA0$li[rownames(functions_relativeAbund0),k]
        
        range_int[[k]] = range(z.pred.k[[k]][!is.na(z.pred.k[[k]])])
        # Setting NA values in abiotic variables to a large value, so as to distinguih them from the NA introduced by the missing stations-depths (plotted as 'transparent') when plotting
        NA_value = range_int[[k]][2] + (range_int[[k]][2] - range_int[[k]][1])/10
        z.pred.k[[k]][is.na(z.pred.k[[k]])] = NA_value
        
        for (station in stations_names)
        {
          station_indices = which(stations_depths$Station == station)
          
          if (length(station_indices) == 1)
          {
            if (stations_depths$Depth[station_indices] == "SUR")
            {
              pie = ggplot(data.frame(x=c(z.pred.k[[k]][station_indices],NA),y=c(1,1)), aes(x=1, y, fill=x))
            } else if (stations_depths$Depth[station_indices] == "DCM")
            {
              pie = ggplot(data.frame(x=c(NA,z.pred.k[[k]][station_indices]),y=c(1,1)), aes(x=1, y, fill=x))
            }
          } else
            pie = ggplot(data.frame(x=z.pred.k[[k]][station_indices],y=rep(1,length(station_indices))), aes(x=1, y, fill=x))
          
          if (range_int[[k]][1]<0)
          {
            colours = c("darkgreen","blue","red","cyan")
            values = rescale(c(range_int[[k]][1],0,range_int[[k]][2],NA_value))
            # colours = c("darkgreen","blue","red")
            # values = rescale(c(range_int[[k]][1],0,range_int[[k]][2]))
          } else
          {
            colours = c("blue","red","cyan")
            values = rescale(c(range_int[[k]][1],range_int[[k]][2],NA_value))
            # colours = c("blue","red")
            # values = rescale(c(range_int[[k]][1],range_int[[k]][2]))
          }
          pie = pie + 
            #             scale_fill_brewer(palette="color.pal.heat") +
            #             scale_fill_brewer(palette="heat.colors") +
            scale_fill_gradientn(limits = c(range_int[[k]][1],NA_value), colours = colours, values = values, na.value="transparent", guide = "colourbar") +
            #scale_fill_gradientn(colours=color.pal.heat(2)) +
            #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
            geom_bar(stat="identity", width=1) + 
            coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
            xlab(NULL) + ylab(NULL) + 
            theme_transparent()
          #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
          tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[station_indices[1]],coord$y[station_indices[1]],width=0.09, height=0.09)        
        }
      }
      
      # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
      for (k in 1:ncol(functions_relativeAbund_PCA0$li))
      {
        tmp.plot[[k]] = tmp.plot[[k]] +
          coord_equal() +
          #labs(fill=paste0("Assemblage ",k)) +  
          theme_minimal() + ggtitle(paste(colnames(functions_relativeAbund_PCA0$li)[k],"- range:",range_int[[k]][1],"-",range_int[[k]][2])) +
          #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
          #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
          theme(legend.position="bottom", legend.text=element_text(size=7),
                legend.title=element_text(size=8), axis.title=element_blank(),
                axis.text = element_blank(), panel.background = element_blank(),
                panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                plot.title=element_text(hjust=0), plot.margin=unit(c(2,2,2,2),"mm")) +
          # theme(legend.position="bottom", legend.text=element_text(size=7), 
          #       legend.title=element_text(size=8), axis.title=element_blank(), 
          #       axis.text = element_blank(), panel.background = element_blank(),
          #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
          guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
      }
      
      # pdf("Abiotic_maps_all.pdf")
      # pdf(paste0("Functions_PCA_axes_maps_",ncol(functions_relativeAbund_PCA$li),"axes_noStdzation.pdf"))
      pdf(paste0(figure_folder,"/Functions_PCA_axes_maps_",ncol(functions_relativeAbund_PCA0$li),"axes",stdzation_insert,".pdf"))
      for (k in 1:ncol(functions_relativeAbund_PCA0$li))
        print(tmp.plot[[k]])
      dev.off()
      
      # PCA on group abundances:
      ##########################
      tmp.plot = list()
      range_int = list()
      z.pred.k = list()
      # Plotting all abiotic variables that are not fully composed of NAs (PAR.PC, NPP.uqartakuvik, acCDOM.atushi, sCDOM.atushi) 
      # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
      for (k in 1:ncol(relativeAbund_PCA0$li))
      {
        tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
        z.pred.k[[k]] = relativeAbund_PCA0$li[rownames(relativeAbund),k]
        
        range_int[[k]] = range(z.pred.k[[k]][!is.na(z.pred.k[[k]])])
        # Setting NA values in abiotic variables to a large value, so as to distinguih them from the NA introduced by the missing stations-depths when plotting
        NA_value = range_int[[k]][2] + (range_int[[k]][2] - range_int[[k]][1])/10
        z.pred.k[[k]][is.na(z.pred.k[[k]])] = NA_value
        
        for (station in stations_names)
        {
          station_indices = which(stations_depths$Station == station)
          
          if (length(station_indices) == 1)
          {
            if (stations_depths$Depth[station_indices] == "SUR")
            {
              pie = ggplot(data.frame(x=c(z.pred.k[[k]][station_indices],NA),y=c(1,1)), aes(x=1, y, fill=x))
            } else if (stations_depths$Depth[station_indices] == "DCM")
            {
              pie = ggplot(data.frame(x=c(NA,z.pred.k[[k]][station_indices]),y=c(1,1)), aes(x=1, y, fill=x))
            }
          } else
            pie = ggplot(data.frame(x=z.pred.k[[k]][station_indices],y=rep(1,length(station_indices))), aes(x=1, y, fill=x))
          
          if (range_int[[k]][1]<0)
          {
            colours = c("darkgreen","blue","red","cyan")
            values = rescale(c(range_int[[k]][1],0,range_int[[k]][2],NA_value))
            # colours = c("darkgreen","blue","red")
            # values = rescale(c(range_int[[k]][1],0,range_int[[k]][2]))
          } else
          {
            colours = c("blue","red","cyan")
            values = rescale(c(range_int[[k]][1],range_int[[k]][2],NA_value))
            # colours = c("blue","red")
            # values = rescale(c(range_int[[k]][1],range_int[[k]][2]))
          }
          pie = pie + 
            #             scale_fill_brewer(palette="color.pal.heat") +
            #             scale_fill_brewer(palette="heat.colors") +
            scale_fill_gradientn(limits = c(range_int[[k]][1],NA_value), colours = colours, values = values, na.value="transparent", guide = "colourbar") +
            #scale_fill_gradientn(colours=color.pal.heat(2)) +
            #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
            geom_bar(stat="identity", width=1) + 
            coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
            xlab(NULL) + ylab(NULL) + 
            theme_transparent()
          #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
          tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[station_indices[1]],coord$y[station_indices[1]],width=0.09, height=0.09)        
        }
      }
      
      # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
      for (k in 1:ncol(relativeAbund_PCA0$li))
      {
        tmp.plot[[k]] = tmp.plot[[k]] +
          coord_equal() +
          #labs(fill=paste0("Assemblage ",k)) +  
          theme_minimal() + ggtitle(paste(colnames(relativeAbund_PCA$li)[k],"- range:",range_int[[k]][1],"-",range_int[[k]][2])) +
          #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
          #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
          theme(legend.position="bottom", legend.text=element_text(size=7),
                legend.title=element_text(size=8), axis.title=element_blank(),
                axis.text = element_blank(), panel.background = element_blank(),
                panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                plot.title=element_text(hjust=0), plot.margin=unit(c(2,2,2,2),"mm")) +
          # theme(legend.position="bottom", legend.text=element_text(size=7), 
          #       legend.title=element_text(size=8), axis.title=element_blank(), 
          #       axis.text = element_blank(), panel.background = element_blank(),
          #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
          guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
      }
      
      # pdf("Abiotic_maps_all.pdf")
      # pdf(paste0("Taxonomic_groups_relativeAbund_PCA_axes_maps_",ncol(relativeAbund_PCA$li),"axes_noStdzation.pdf"))
      pdf(paste0(figure_folder,"/Taxonomic_groups_relativeAbund_PCA_axes_maps_",ncol(relativeAbund_PCA0$li),"axes",stdzation_insert,".pdf"))
      for (k in 1:ncol(relativeAbund_PCA0$li))
        print(tmp.plot[[k]])
      dev.off()
    }
    
    #######################################################
    # Plotting the distribution maps of abiotic variables
    tmp.plot = list()
    range_int = list()
    z.pred.k = list()
    # Plotting all abiotic variables that are not fully composed of NAs (PAR.PC, NPP.uqartakuvik, acCDOM.atushi, sCDOM.atushi) 
    # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
    for (k in 1:ncol(abiotic_data))
    {
      tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
      z.pred.k[[k]] = abiotic_data[,k]
      
      range_int[[k]] = range(z.pred.k[[k]][!is.na(z.pred.k[[k]])])
      # Setting NA values in abiotic variables to a large value, so as to distinguih them from the NA introduced by the missing stations-depths when plotting
      NA_value = range_int[[k]][2] + (range_int[[k]][2] - range_int[[k]][1])/10
      z.pred.k[[k]][is.na(z.pred.k[[k]])] = NA_value
      
      for (station in stations_names)
      {
        station_indices = which(stations_depths$Station == station)
        
        if (length(station_indices) == 1)
        {
          if (stations_depths$Depth[station_indices] == "SUR")
          {
            pie = ggplot(data.frame(x=c(z.pred.k[[k]][station_indices],NA),y=c(1,1)), aes(x=1, y, fill=x))
          } else if (stations_depths$Depth[station_indices] == "DCM")
          {
            pie = ggplot(data.frame(x=c(NA,z.pred.k[[k]][station_indices]),y=c(1,1)), aes(x=1, y, fill=x))
          }
        } else
          pie = ggplot(data.frame(x=z.pred.k[[k]][station_indices],y=rep(1,length(station_indices))), aes(x=1, y, fill=x))
        
        if (range_int[[k]][1]<0)
        {
          colours = c("darkgreen","blue","red","cyan")
          values = rescale(c(range_int[[k]][1],0,range_int[[k]][2],NA_value))
          # colours = c("darkgreen","blue","red")
          # values = rescale(c(range_int[[k]][1],0,range_int[[k]][2]))
        } else
        {
          colours = c("blue","red","cyan")
          values = rescale(c(range_int[[k]][1],range_int[[k]][2],NA_value))
          # colours = c("blue","red")
          # values = rescale(c(range_int[[k]][1],range_int[[k]][2]))
        }
        pie = pie + 
          #             scale_fill_brewer(palette="color.pal.heat") +
          #             scale_fill_brewer(palette="heat.colors") +
          scale_fill_gradientn(limits = c(range_int[[k]][1],NA_value), colours = colours, values = values, na.value="transparent", guide = "colourbar") +
          #scale_fill_gradientn(colours=color.pal.heat(2)) +
          #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
          geom_bar(stat="identity", width=1) + 
          coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
          xlab(NULL) + ylab(NULL) + 
          theme_transparent()
        #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
        tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[station_indices[1]],coord$y[station_indices[1]],width=0.09, height=0.09)        
      }
    }
    
    # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
    for (k in 1:ncol(abiotic_data))
    {
      tmp.plot[[k]] = tmp.plot[[k]] +
        coord_equal() +
        #labs(fill=paste0("Assemblage ",k)) +  
        theme_minimal() + ggtitle(paste(colnames(abiotic_data)[k],"- range:",range_int[[k]][1],"-",range_int[[k]][2])) +
        #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
        #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
        theme(legend.position="bottom", legend.text=element_text(size=7),
              legend.title=element_text(size=8), axis.title=element_blank(),
              axis.text = element_blank(), panel.background = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
              plot.title=element_text(hjust=0), plot.margin=unit(c(2,2,2,2),"mm")) +
        # theme(legend.position="bottom", legend.text=element_text(size=7), 
        #       legend.title=element_text(size=8), axis.title=element_blank(), 
        #       axis.text = element_blank(), panel.background = element_blank(),
        #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
        guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
    }
    
    # # test.pie = ggplot(data.frame(x=c(0,1,2,3,4,5,6),y=rep(1,7)), aes(x=1, y, fill=x)) +
    # test.pie = ggplot(data.frame(x=c(0,1),y=rep(1,2)), aes(x=1, y, fill=x)) +
    #   #scale_fill_gradient2(limits = c(0,6), low="yellow", high="red", mid = "blue", midpoint = 1, na.value="transparent", guide = "colourbar") +
    #   scale_fill_gradientn(colours = c("cyan","blue","red"), values = c(0,NA,1), na.value="transparent", guide = "colourbar") +
    #   geom_bar(stat="identity", width=1) +
    #   coord_polar(theta="y",start=3*pi/2) + theme_tree() +
    #   xlab(NULL) + ylab(NULL) +
    #   theme_transparent()
    # pdf("test.pdf")
    # print(test.pie)
    # dev.off()
    
    # pdf("Abiotic_maps_all.pdf")
    pdf(paste0(figure_folder,"/Abiotic_maps_",ncol(abiotic_data),"variables.pdf"))
    for (k in 1:ncol(abiotic_data))
      print(tmp.plot[[k]])
    dev.off()
    
    #########################################
    # Plotting the distribution maps of biotic functions
    tmp.plot = list()
    range_int = list()
    z.pred.k = list()
    # Plotting all abiotic variables that are not fully composed of NAs (PAR.PC, NPP.uqartakuvik, acCDOM.atushi, sCDOM.atushi) 
    # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
    for (k in 1:ncol(functions_relativeAbund_selected))
    {
      tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
      z.pred.k[[k]] = functions_relativeAbund_selected[,k]
      
      range_int[[k]] = range(z.pred.k[[k]][!is.na(z.pred.k[[k]])])
      # Setting NA values in abiotic variables to a large value, so as to distinguih them from the NA introduced by the missing stations-depths when plotting
      NA_value = range_int[[k]][2] + (range_int[[k]][2] - range_int[[k]][1])/10
      z.pred.k[[k]][is.na(z.pred.k[[k]])] = NA_value
      
      for (station in stations_names)
      {
        station_indices = which(stations_depths$Station == station)
        
        if (length(station_indices) == 1)
        {
          if (stations_depths$Depth[station_indices] == "SUR")
          {
            pie = ggplot(data.frame(x=c(z.pred.k[[k]][station_indices],NA),y=c(1,1)), aes(x=1, y, fill=x))
          } else if (stations_depths$Depth[station_indices] == "DCM")
          {
            pie = ggplot(data.frame(x=c(NA,z.pred.k[[k]][station_indices]),y=c(1,1)), aes(x=1, y, fill=x))
          }
        } else
          pie = ggplot(data.frame(x=z.pred.k[[k]][station_indices],y=rep(1,length(station_indices))), aes(x=1, y, fill=x))
        
        if (range_int[[k]][1]<0)
        {
          colours = c("darkgreen","blue","red","cyan")
          values = rescale(c(range_int[[k]][1],0,range_int[[k]][2],NA_value))
          # colours = c("darkgreen","blue","red")
          # values = rescale(c(range_int[[k]][1],0,range_int[[k]][2]))
        } else
        {
          colours = c("blue","red","cyan")
          values = rescale(c(range_int[[k]][1],range_int[[k]][2],NA_value))
          # colours = c("blue","red")
          # values = rescale(c(range_int[[k]][1],range_int[[k]][2]))
        }
        pie = pie + 
          #             scale_fill_brewer(palette="color.pal.heat") +
          #             scale_fill_brewer(palette="heat.colors") +
          scale_fill_gradientn(limits = c(range_int[[k]][1],NA_value), colours = colours, values = values, na.value="transparent", guide = "colourbar") +
          #scale_fill_gradientn(colours=color.pal.heat(2)) +
          #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
          geom_bar(stat="identity", width=1) + 
          coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
          xlab(NULL) + ylab(NULL) + 
          theme_transparent()
        #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
        tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[station_indices[1]],coord$y[station_indices[1]],width=0.09, height=0.09)        
      }
    }
    
    # # test.pie = ggplot(data.frame(x=c(0,1,2,3,4,5,6),y=rep(1,7)), aes(x=1, y, fill=x)) +
    # test.pie = ggplot(data.frame(x=c(0,1),y=rep(1,2)), aes(x=1, y, fill=x)) +
    #   #scale_fill_gradient2(limits = c(0,6), low="yellow", high="red", mid = "blue", midpoint = 1, na.value="transparent", guide = "colourbar") +
    #   scale_fill_gradientn(colours = c("cyan","blue","red"), values = c(0,NA,1), na.value="transparent", guide = "colourbar") +
    #   geom_bar(stat="identity", width=1) +
    #   coord_polar(theta="y",start=3*pi/2) + theme_tree() +
    #   xlab(NULL) + ylab(NULL) +
    #   theme_transparent()
    # pdf("test.pdf")
    # print(test.pie)
    # dev.off()
    
    # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
    for (k in 1:ncol(functions_relativeAbund_selected))
    {
      tmp.plot[[k]] = tmp.plot[[k]] +
        coord_equal() +
        #labs(fill=paste0("Assemblage ",k)) +  
        theme_minimal() + ggtitle(paste(colnames(functions_relativeAbund_selected)[k],"- range:",range_int[[k]][1],"-",range_int[[k]][2])) +
        #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
        #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
        theme(legend.position="bottom", legend.text=element_text(size=7),
              legend.title=element_text(size=8), axis.title=element_blank(),
              axis.text = element_blank(), panel.background = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
              plot.title=element_text(hjust=0), plot.margin=unit(c(2,2,2,2),"mm")) +
        # theme(legend.position="bottom", legend.text=element_text(size=7), 
        #       legend.title=element_text(size=8), axis.title=element_blank(), 
        #       axis.text = element_blank(), panel.background = element_blank(),
        #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
        guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
    }
    
    # pdf("Abiotic_maps_all.pdf")
    pdf(paste0(figure_folder,"/functions_relativeAbund_selectedGroups_maps_",ncol(functions_relativeAbund_selected),"variables.pdf"))
    for (k in 1:ncol(functions_relativeAbund_selected))
      print(tmp.plot[[k]])
    dev.off()
    
    #########################################
    # Plotting the distribution maps of biotic groups
    tmp.plot = list()
    range_int = list()
    z.pred.k = list()
    # Plotting all abiotic variables that are not fully composed of NAs (PAR.PC, NPP.uqartakuvik, acCDOM.atushi, sCDOM.atushi) 
    # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
    for (k in 1:ncol(relativeAbund[,selected_groups]))
    {
      tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
      z.pred.k[[k]] = relativeAbund[,k]
      
      range_int[[k]] = range(z.pred.k[[k]][!is.na(z.pred.k[[k]])])
      # Setting NA values in abiotic variables to a large value, so as to distinguih them from the NA introduced by the missing stations-depths when plotting
      NA_value = range_int[[k]][2] + (range_int[[k]][2] - range_int[[k]][1])/10
      z.pred.k[[k]][is.na(z.pred.k[[k]])] = NA_value
      
      for (station in stations_names)
      {
        station_indices = which(stations_depths$Station == station)
        
        if (length(station_indices) == 1)
        {
          if (stations_depths$Depth[station_indices] == "SUR")
          {
            pie = ggplot(data.frame(x=c(z.pred.k[[k]][station_indices],NA),y=c(1,1)), aes(x=1, y, fill=x))
          } else if (stations_depths$Depth[station_indices] == "DCM")
          {
            pie = ggplot(data.frame(x=c(NA,z.pred.k[[k]][station_indices]),y=c(1,1)), aes(x=1, y, fill=x))
          }
        } else
          pie = ggplot(data.frame(x=z.pred.k[[k]][station_indices],y=rep(1,length(station_indices))), aes(x=1, y, fill=x))
        
        if (range_int[[k]][1]<0)
        {
          colours = c("darkgreen","blue","red","cyan")
          values = rescale(c(range_int[[k]][1],0,range_int[[k]][2],NA_value))
          # colours = c("darkgreen","blue","red")
          # values = rescale(c(range_int[[k]][1],0,range_int[[k]][2]))
        } else
        {
          colours = c("blue","red","cyan")
          values = rescale(c(range_int[[k]][1],range_int[[k]][2],NA_value))
          # colours = c("blue","red")
          # values = rescale(c(range_int[[k]][1],range_int[[k]][2]))
        }
        pie = pie + 
          #             scale_fill_brewer(palette="color.pal.heat") +
          #             scale_fill_brewer(palette="heat.colors") +
          scale_fill_gradientn(limits = c(range_int[[k]][1],NA_value), colours = colours, values = values, na.value="transparent", guide = "colourbar") +
          #scale_fill_gradientn(colours=color.pal.heat(2)) +
          #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
          geom_bar(stat="identity", width=1) + 
          coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
          xlab(NULL) + ylab(NULL) + 
          theme_transparent()
        #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
        tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[station_indices[1]],coord$y[station_indices[1]],width=0.09, height=0.09)        
      }
    }
    
    # # test.pie = ggplot(data.frame(x=c(0,1,2,3,4,5,6),y=rep(1,7)), aes(x=1, y, fill=x)) +
    # test.pie = ggplot(data.frame(x=c(0,1),y=rep(1,2)), aes(x=1, y, fill=x)) +
    #   #scale_fill_gradient2(limits = c(0,6), low="yellow", high="red", mid = "blue", midpoint = 1, na.value="transparent", guide = "colourbar") +
    #   scale_fill_gradientn(colours = c("cyan","blue","red"), values = c(0,NA,1), na.value="transparent", guide = "colourbar") +
    #   geom_bar(stat="identity", width=1) +
    #   coord_polar(theta="y",start=3*pi/2) + theme_tree() +
    #   xlab(NULL) + ylab(NULL) +
    #   theme_transparent()
    # pdf("test.pdf")
    # print(test.pie)
    # dev.off()
    
    # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
    for (k in 1:ncol(relativeAbund[,selected_groups]))
    {
      tmp.plot[[k]] = tmp.plot[[k]] +
        coord_equal() +
        #labs(fill=paste0("Assemblage ",k)) +  
        theme_minimal() + ggtitle(paste(colnames(relativeAbund)[k],"- range:",range_int[[k]][1],"-",range_int[[k]][2])) +
        #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
        #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
        theme(legend.position="bottom", legend.text=element_text(size=7),
              legend.title=element_text(size=8), axis.title=element_blank(),
              axis.text = element_blank(), panel.background = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
              plot.title=element_text(hjust=0), plot.margin=unit(c(2,2,2,2),"mm")) +
        # theme(legend.position="bottom", legend.text=element_text(size=7), 
        #       legend.title=element_text(size=8), axis.title=element_blank(), 
        #       axis.text = element_blank(), panel.background = element_blank(),
        #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
        guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
    }
    
    # pdf("Abiotic_maps_all.pdf")
    pdf(paste0(figure_folder,"/relativeAbund_selected_maps_",ncol(relativeAbund[,selected_groups]),"variables.pdf"))
    for (k in 1:ncol(relativeAbund[,selected_groups]))
      print(tmp.plot[[k]])
    dev.off()
    
    ####################################################
    library(scales)
    
    pdf(paste0(figure_folder,"/biplot_expTmin_distance",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
    biplot(expTmin_distance_pcoa)
    dev.off()
    
    # tmp.plot = list()
    # range_int = list()
    # z.pred.k = list()
    # for (k in 1:ncol(expTmin_distance_pcoa$vectors))
    # {
    #   tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
    #   z.pred.k[[k]] = expTmin_distance_pcoa$vectors[,k]
    #   
    #   range_int[[k]] = range(z.pred.k[[k]][!is.na(z.pred.k[[k]])])
    #   # Setting NA values in abiotic variables to a large value, so as to distinguih them from the NA introduced by the missing stations-depths when plotting
    #   NA_value = range_int[[k]][2] + (range_int[[k]][2] - range_int[[k]][1])/10
    #   z.pred.k[[k]][is.na(z.pred.k[[k]])] = NA_value
    #   
    #   for (station in stations_names)
    #   {
    #     station_indices = which(stations_depths$Station == station)
    #     
    #     if (length(station_indices) == 1)
    #     {
    #       if (stations_depths$Depth[station_indices] == "SUR")
    #       {
    #         pie = ggplot(data.frame(x=c(z.pred.k[[k]][station_indices],NA),y=c(1,1)), aes(x=1, y, fill=x))
    #       } else if (stations_depths$Depth[station_indices] == "DCM")
    #       {
    #         pie = ggplot(data.frame(x=c(NA,z.pred.k[[k]][station_indices]),y=c(1,1)), aes(x=1, y, fill=x))
    #       }
    #     } else
    #       pie = ggplot(data.frame(x=z.pred.k[[k]][station_indices],y=rep(1,length(station_indices))), aes(x=1, y, fill=x))
    #     
    #     if (range_int[[k]][1]<0)
    #     {
    #       colours = c("darkgreen","blue","red","cyan")
    #       values = rescale(c(range_int[[k]][1],0,range_int[[k]][2],NA_value))
    #       # colours = c("darkgreen","blue","red")
    #       # values = rescale(c(range_int[[k]][1],0,range_int[[k]][2]))
    #     } else
    #     {
    #       colours = c("blue","red","cyan")
    #       values = rescale(c(range_int[[k]][1],range_int[[k]][2],NA_value))
    #       # colours = c("blue","red")
    #       # values = rescale(c(range_int[[k]][1],range_int[[k]][2]))
    #     }
    #     pie = pie + 
    #       #             scale_fill_brewer(palette="color.pal.heat") +
    #       #             scale_fill_brewer(palette="heat.colors") +
    #       scale_fill_gradientn(limits = c(range_int[[k]][1],NA_value), colours = colours, values = values, na.value="transparent", guide = "colourbar") +
    #       #scale_fill_gradientn(colours=color.pal.heat(2)) +
    #       #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
    #       geom_bar(stat="identity", width=1) + 
    #       coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
    #       xlab(NULL) + ylab(NULL) + 
    #       theme_transparent()
    #     #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
    #     tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[station_indices[1]],coord$y[station_indices[1]],width=0.09, height=0.09)        
    #   }
    # }
    # 
    # # # test.pie = ggplot(data.frame(x=c(0,1,2,3,4,5,6),y=rep(1,7)), aes(x=1, y, fill=x)) +
    # # test.pie = ggplot(data.frame(x=c(0,1),y=rep(1,2)), aes(x=1, y, fill=x)) +
    # #   #scale_fill_gradient2(limits = c(0,6), low="yellow", high="red", mid = "blue", midpoint = 1, na.value="transparent", guide = "colourbar") +
    # #   scale_fill_gradientn(colours = c("cyan","blue","red"), values = c(0,NA,1), na.value="transparent", guide = "colourbar") +
    # #   geom_bar(stat="identity", width=1) +
    # #   coord_polar(theta="y",start=3*pi/2) + theme_tree() +
    # #   xlab(NULL) + ylab(NULL) +
    # #   theme_transparent()
    # # pdf("test.pdf")
    # # print(test.pie)
    # # dev.off()
    # 
    # # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
    # for (k in 1:ncol(expTmin_distance_pcoa$vectors))
    # {
    #   tmp.plot[[k]] = tmp.plot[[k]] +
    #     coord_equal() +
    #     #labs(fill=paste0("Assemblage ",k)) +  
    #     theme_minimal() + ggtitle(paste(colnames(expTmin_distance_pcoa$vectors)[k],"- eigenvalue:",expTmin_distance_pcoa$values$Eigenvalues[k])) +
    #     #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
    #     #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
    #     theme(legend.position="bottom", legend.text=element_text(size=7),
    #           legend.title=element_text(size=8), axis.title=element_blank(),
    #           axis.text = element_blank(), panel.background = element_blank(),
    #           panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
    #           plot.title=element_text(hjust=0), plot.margin=unit(c(0.1,0.1,0.1,0.1),"mm")) +
    #     # theme(legend.position="bottom", legend.text=element_text(size=7), 
    #     #       legend.title=element_text(size=8), axis.title=element_blank(), 
    #     #       axis.text = element_blank(), panel.background = element_blank(),
    #     #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
    #     #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
    #     guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
    # }
    
    # pdf("Abiotic_maps_all.pdf")
    pdf(paste0(figure_folder,"/expTmin_distance_positiveEigenvalues_maps.pdf"))
    for (k in 1:ncol(expTmin_distance_pcoa$vectors))
      print(tmp.plot[[k]])
    dev.off()
    
    # # Plotting the eigenvectors of the whole expTmin distance matrix stations, for Surface stations:
    # pdf(paste0("expTmin_distance_positiveEigenvalues_marmaps_SUR.pdf"))
    # for (k in 1:ncol(expTmin_distance_pcoa$vectors))
    # {
    #   # Plotting Surface:
    #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    #   z = as.data.frame(expTmin_distance_pcoa$vectors)[stations_depths$Depth == "SUR",k]
    #   points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
    #          pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    # }
    # dev.off()
    # 
    # # Plotting the eigenvectors of the whole expTmin distance1 matrix stations, for Surface stations:
    # pdf(paste0("expTmin_distance1_positiveEigenvalues_marmaps_SUR.pdf"))
    # for (k in 1:ncol(expTmin_distance1_pcoa$vectors))
    # {
    #   # Plotting Surface:
    #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    #   z = as.data.frame(expTmin_distance1_pcoa$vectors)[stations_depths$Depth == "SUR",k]
    #   points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
    #          pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    # }
    # dev.off()
    # 
    # pdf(paste0("expTmin_distance_1000partThres_positiveEigenvalues_marmaps_SUR.pdf"))
    # for (k in 1:ncol(expTmin_distance_pcoa$vectors))
    # {
    #   # Plotting Surface:
    #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    #   z = as.data.frame(expTmin_distance_pcoa$vectors)[stations_depths$Depth == "SUR",k]
    #   points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
    #          pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    # }
    # dev.off()
    
    #####################
    # # Plotting the eigenvectors of the Tmin distance matrix of all stations, for Surface stations:
    # pdf(paste0("Tmin_distance_positiveEigenvalues_marmaps_SUR.pdf"))
    # for (k in 1:ncol(Tmin_distance_pcoa$vectors))
    # {
    #   # Plotting Surface:
    #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    #   z = as.data.frame(Tmin_distance_pcoa$vectors)[stations_depths$Depth == "SUR",k]
    #   points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
    #          pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    # }
    # dev.off()
    # 
    # # Plotting the eigenvectors of the Tmin distance1 matrix of all stations, for Surface stations:
    # pdf(paste0("Tmin_distance1_positiveEigenvalues_marmaps_SUR.pdf"))
    # for (k in 1:ncol(Tmin_distance1_pcoa$vectors))
    # {
    #   # Plotting Surface:
    #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    #   z = as.data.frame(Tmin_distance1_pcoa$vectors)[stations_depths$Depth == "SUR",k]
    #   points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
    #          pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    # }
    # dev.off()
    # 
    # # Plotting the eigenvectors of the Tmin distance2 matrix of all stations, for Surface stations:
    # pdf(paste0("Tmin_distance2_positiveEigenvalues_marmaps_SUR.pdf"))
    # for (k in 1:ncol(Tmin_distance2_pcoa$vectors))
    # {
    #   # Plotting Surface:
    #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    #   z = as.data.frame(Tmin_distance2_pcoa$vectors)[stations_depths$Depth == "SUR",k]
    #   points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
    #          pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    # }
    # dev.off()
    
    #######################
    
    # Plotting the AEM vectors of the Tmin connectivity matrix (thres. 1000 part, 10 y) of all stations without weights, for Surface stations:
    # pdf(paste0("Tmin_connectivity_1000part10y_allAEM_noWeight_marmaps_SUR.pdf"))
    # for (k in 1:ncol(Tmin_1000p10y_aem$vectors))
    # {
    #   # Plotting Surface:
    #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    #   z = as.data.frame(Tmin_1000p10y_aem$vectors)[stations_depths$Depth == "SUR",k]
    #   points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
    #          pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    # }
    # dev.off()
    
    library(marmap)
    library(vegan)
    # Loading batymetric data for the specified range of longitudes and latitudes in degrees, whith resolution in minutes
    bat = getNOAA.bathy(-180, 180, -90, 90, res = 20, keep=F)
    blues = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1")
    greys = c(grey(0.6), grey(0.93), grey(0.99))
    
    ######################
    # Plotting the eigenvectors of the mixed layer distance matrix, for Surface stations:
    pdf(paste0(figure_folder,"/MixedLayer_distance_positiveEigenvalues_marmaps_SUR.pdf"))
    for (k in 1:ncol(SUR_DCM_distance_pcoa$vectors))
    {
      # Plotting Surface:
      plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
      plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
      z = as.data.frame(SUR_DCM_distance_pcoa$vectors)[stations_depths$Depth == "SUR",k]
      points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
             pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    }
    dev.off()
    
    # Plotting the eigenvectors of the mixed layer distance matrix, for DCM stations:
    pdf(paste0(figure_folder,"/MixedLayer_distance_positiveEigenvalues_marmaps_DCM.pdf"))
    for (k in 1:ncol(SUR_DCM_distance_pcoa$vectors))
    {
      # Plotting Surface:
      plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
      plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
      z = as.data.frame(SUR_DCM_distance_pcoa$vectors)[stations_depths$Depth == "DCM",k]
      points(cbind(coord$x[stations_depths$Depth == "DCM"],coord$y[stations_depths$Depth == "DCM"]),
             pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    }
    dev.off()
    
    ######################
    # Plotting the eigenvectors of the expTmin matrix of SUR stations only:
    pdf(paste0(figure_folder_Gibbs.VEM,"/MEM_tminThres",tmin_thres_SUR,"y_SUR_positiveEigenvalues_marmaps.pdf"))
    for (k in 1:ncol(truncated_Tmin_SUR_pcoa$vectors))
    {
      # Plotting Surface:
      plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
      plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
      z = as.data.frame(truncated_Tmin_SUR_pcoa$vectors)[,k]
      points(coord_SUR[,c(2,1)], pch = 21, cex=1.2, 
             bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    }
    dev.off()
    
    # Plotting the eigenvectors of the expTmin matrix of DCM stations only:
    pdf(paste0(figure_folder_Gibbs.VEM,"/MEM_tminThres",tmin_thres_DCM,"y_DCM_positiveEigenvalues_marmaps.pdf"))
    for (k in 1:ncol(truncated_Tmin_DCM_pcoa$vectors))
    {
      # Plotting Surface:
      plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
      plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
      z = as.data.frame(truncated_Tmin_DCM_pcoa$vectors)[,k]
      points(cbind(coord_DCM[,c(2,1)]),
             pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    }
    dev.off()
    
    # # Plotting the eigenvectors of the Tmin distance2 matrix of SUR stations only:
    # pdf(paste0("Tmin_distance2_SUR_positiveEigenvalues_marmaps.pdf"))
    # for (k in 1:ncol(Tmin_distance2_SUR_pcoa$vectors))
    # {
    #   # Plotting Surface:
    #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    #   z = as.data.frame(Tmin_distance2_SUR_pcoa$vectors)[,k]
    #   points(cbind(coord$x[stations_depths$Depth == "SUR"],coord$y[stations_depths$Depth == "SUR"]),
    #          pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    # }
    # dev.off()
    
    ######################
    # Plotting the eigenvectors of the abiotic PCA:
    pdf(paste0(figure_folder_Gibbs.VEM,"/Abiotic_PCA_",ncol(abiotic_PCA$li),"axes_marmaps.pdf"))
    for (k in 1:ncol(abiotic_PCA$li))
    {
      # Plotting Surface:
      plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
      plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
      z = as.data.frame(abiotic_PCA$li)[,k]
      points(cbind(coord[,c(2,1)]),
             pch = 21, cex=1.2, bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
    }
    dev.off()
      
    ####################################################
    
    tmp.plot = list()
    range_int = list()
    z.pred.k = list()
    for (k in 1:ncol(expTmin_distance_nmds$points))
    {
      tmp.plot[[k]] = ggplot(data = backgroundGgplot, aes(x=long, y=lat, group=group)) + geom_path(color = "black", size=0.1, inherit.aes = T)
      z.pred.k[[k]] = expTmin_distance_nmds$points[,k]
      
      range_int[[k]] = range(z.pred.k[[k]][!is.na(z.pred.k[[k]])])
      # Setting NA values in abiotic variables to a large value, so as to distinguih them from the NA introduced by the missing stations-depths when plotting
      NA_value = range_int[[k]][2] + (range_int[[k]][2] - range_int[[k]][1])/10
      z.pred.k[[k]][is.na(z.pred.k[[k]])] = NA_value
      
      for (station in stations_names)
      {
        station_indices = which(stations_depths$Station == station)
        
        if (length(station_indices) == 1)
        {
          if (stations_depths$Depth[station_indices] == "SUR")
          {
            pie = ggplot(data.frame(x=c(z.pred.k[[k]][station_indices],NA),y=c(1,1)), aes(x=1, y, fill=x))
          } else if (stations_depths$Depth[station_indices] == "DCM")
          {
            pie = ggplot(data.frame(x=c(NA,z.pred.k[[k]][station_indices]),y=c(1,1)), aes(x=1, y, fill=x))
          }
        } else
          pie = ggplot(data.frame(x=z.pred.k[[k]][station_indices],y=rep(1,length(station_indices))), aes(x=1, y, fill=x))
        
        if (range_int[[k]][1]<0)
        {
          colours = c("darkgreen","blue","red","cyan")
          values = rescale(c(range_int[[k]][1],0,range_int[[k]][2],NA_value))
          # colours = c("darkgreen","blue","red")
          # values = rescale(c(range_int[[k]][1],0,range_int[[k]][2]))
        } else
        {
          colours = c("blue","red","cyan")
          values = rescale(c(range_int[[k]][1],range_int[[k]][2],NA_value))
          # colours = c("blue","red")
          # values = rescale(c(range_int[[k]][1],range_int[[k]][2]))
        }
        pie = pie + 
          #             scale_fill_brewer(palette="color.pal.heat") +
          #             scale_fill_brewer(palette="heat.colors") +
          scale_fill_gradientn(limits = c(range_int[[k]][1],NA_value), colours = colours, values = values, na.value="transparent", guide = "colourbar") +
          #scale_fill_gradientn(colours=color.pal.heat(2)) +
          #             scale_fill_manual(values=z.pred.k[samples_indices_data2m]) +
          geom_bar(stat="identity", width=1) + 
          coord_polar(theta="y",start=3*pi/2) + theme_tree() + 
          xlab(NULL) + ylab(NULL) + 
          theme_transparent()
        #           tmp.one.plot.piechart %<>% subview(tmp.one.plot.piechart,pie,coordTara$Long[samples_indices_data2m[1]],coordTara$Lat[samples_indices_data2m[1]],width=0.1, height=0.1)
        tmp.plot[[k]] = subview(tmp.plot[[k]],pie,coord$x[station_indices[1]],coord$y[station_indices[1]],width=0.09, height=0.09)        
      }
    }
    
    # # test.pie = ggplot(data.frame(x=c(0,1,2,3,4,5,6),y=rep(1,7)), aes(x=1, y, fill=x)) +
    # test.pie = ggplot(data.frame(x=c(0,1),y=rep(1,2)), aes(x=1, y, fill=x)) +
    #   #scale_fill_gradient2(limits = c(0,6), low="yellow", high="red", mid = "blue", midpoint = 1, na.value="transparent", guide = "colourbar") +
    #   scale_fill_gradientn(colours = c("cyan","blue","red"), values = c(0,NA,1), na.value="transparent", guide = "colourbar") +
    #   geom_bar(stat="identity", width=1) +
    #   coord_polar(theta="y",start=3*pi/2) + theme_tree() +
    #   xlab(NULL) + ylab(NULL) +
    #   theme_transparent()
    # pdf("test.pdf")
    # print(test.pie)
    # dev.off()
    
    # for (k in (1:ncol(abiotic_data))[!apply(apply(abiotic_data,2,is.na),2,all) & selected_variables != "Ice.free.period"])
    for (k in 1:ncol(expTmin_distance_nmds$points))
    {
      tmp.plot[[k]] = tmp.plot[[k]] +
        coord_equal() +
        #labs(fill=paste0("Assemblage ",k)) +  
        theme_minimal() + ggtitle(paste(colnames(expTmin_distance_nmds$points)[k])) +
        #           scale_x_continuous(limits=c(5,395), expand = c(0,0)) +
        #           scale_y_continuous(limits=c(5,295), expand = c(0,0)) +
        theme(legend.position="bottom", legend.text=element_text(size=7),
              legend.title=element_text(size=8), axis.title=element_blank(),
              axis.text = element_blank(), panel.background = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
              plot.title=element_text(hjust=0), plot.margin=unit(c(0.1,0.1,0.1,0.1),"mm")) +
        # theme(legend.position="bottom", legend.text=element_text(size=7), 
        #       legend.title=element_text(size=8), axis.title=element_blank(), 
        #       axis.text = element_blank(), panel.background = element_blank(),
        #       panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        #       plot.title=element_text(hjust=0), plot.margin=unit(c(0,1,-2,2),"mm")) +
        guides(colour = guide_colorbar(barwidth = 8, barheight = 0.4, title.position="bottom"))
    }
    
    # pdf("Abiotic_maps_all.pdf")
    pdf(paste0(figure_folder,"/expTmin_distance_nmds_2dimensions_maps.pdf"))
    for (k in 1:ncol(expTmin_distance_nmds$points))
      print(tmp.plot[[k]])
    dev.off()
  }
}

if (alltaxa_assemblage_composition)
{
  # K = 10
  K = 16
  nb_iter = 1000
  nb_real = 100
  thin = 25
  burnin = 2000
  # Gibbs_VEM_insert= "_VEM"
  # Gibbs_VEM_insert = "_GibbsShortChainNoAverage10sampleFold"
  Gibbs_VEM_insert = "_Gibbs"
  if (Gibbs_VEM_insert == "_VEM")
  {
    data.folder = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
    assemblage_composition = readRDS(paste0(data.folder,"/Rtopicmodels_LDA_VEM_nb_topics",K,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/assemblage_composition.rds"))
  # } else if (Gibbs_VEM_insert == "_GibbsShortChainNoAverage10sampleFold")
  } else if (Gibbs_VEM_insert == "_Gibbs")
  {
    # data.folder = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
    data.folder = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
    # assemblage_composition = readRDS(paste0(data.folder,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta0.1_nb_topics10_nb_iter2000_nb_real100_occurrence/1st_best_realization/assemblage_composition.rds"))
    assemblage_composition = readRDS(paste0(data.folder,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",K,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/assemblage_composition.rds"))
  }
  
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  taxo_groups_unmodified = levels(as.factor(assemblage_composition$taxogroup2))[sort.int(table(as.factor(assemblage_composition$taxogroup2)),index.return = T,decreasing = T)$ix]
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # functions = levels(as.factor(assemblage_composition$Function))[sort.int(table(as.factor(assemblage_composition$Function)),index.return = T,decreasing = T)$ix]
  functions = c("phototroph","photohost","endophotosymbiont","phagotroph","copepoda","pteropoda","gelatineous_carnivores_filterers","other metazoa","parasite","unknown")
  # selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity>100
  # selected_functions = !functions %in% c("pteropoda","endophotosymbiont","unknown")

  if (Gibbs_VEM_insert == "_VEM")
  {
    if (K == 3)
    {
      assemblage_labels = c("Temperate - Subtropical","Tropical - Equatorial","Arctic - Subarctic")
      assemblage_reordering = c(2,1,3)
    } else if (K == 10)
    {
      assemblage_labels = c("Equatorial Pacific","Tropical Surface","Upwellings","Tropical DCM","Temperate Atlantic","Groenland & European Arctic","Mediterranean","Red Sea & Persian Gulf","Siberian & N. Am. Arctic","Misc.")
      assemblage_reordering = c(6,9,3,5,7,8,2,4,1,10)
    }
    
    load(paste0(data.folder,"/data2m.Rdata")) 
    data2m[data2m > 0] = 1
    threshold= 1/sum(data2m)
    OTU_presence = assemblage_composition[,1:K] >= threshold
  } else if (Gibbs_VEM_insert == "_Gibbs")
  {
    if (K == 10)
    {
      assemblage_labels = c("Non-Arctic global community","Arctic global community","Temperate Atlantic\n and tropical DCM","Upwellings",
                            "Siberian & N. Am. Arctic","Equatorial Pacific","Ind. Ocean and E. Pacific","Mediterranean","Subtropical","Misc.")
      assemblage_reordering = c(1,6,7,9,3,10,8,4,5,2)
    } else if (K == 16)
    {
      assemblage_labels = c("Global non-Arctic","Global Arctic","Tropical DCM","Global equatorial",
                            "Southern Ocean","Equatorial Pacific","Mediterranean","Tropical Surface",
                            "Subtropical Atlantic","Temperate Upwellings","Eastern Pacific Upwellings","Diplonemid-rich",
                            "Lower Arctic","Subarctic North Atlantic","Red Sea","Persian Gulf")
      # assemblage_reordering = c(1,3,6,4,8,7,9,11,10,12,15,16,2,13,5,14)
      assemblage_reordering = c(1,3,9,7,
                                10,8,4,6,
                                11,16,15,12,
                                2,13,5,14)
    } else
    {
      assemblage_labels = 1:K
      assemblage_reordering = 1:K
    }
      
    # Setting the threshold for OTU presence-absence:
    threshold = vector(mode = "numeric", length = K)
    for (k in 1:K)
      threshold[k] = sort(assemblage_composition[,k],decreasing=T)[100000]*2
    OTU_presence = t(apply(assemblage_composition[,1:K],1, function(g) g >= threshold))
  }
  # Computing endemics and ubiquists:
  endemic_OTUs = unlist(lapply(apply(OTU_presence,1,which),length)) == 1
  endemicity_assemblage = unlist(lapply(apply(OTU_presence,1,which),function(g) g[1]))
  ubiquist_OTUs = apply(OTU_presence,1,all)
  assemblage_richness = unlist(lapply(apply(OTU_presence,2,which),length))
  assemblage_endemic_richness = unlist(lapply(apply(OTU_presence & endemic_OTUs,2,which),length))
  
  library(colorspace)
  
  ####################################################################
  # Checking the validity of the threshold for OTU presence-absence: #
  ####################################################################
  
  pdf(paste0(figure_folder,"/Assemblage_OTU_prevalence_AllTaxa_K",K,Gibbs_VEM_insert,".pdf"),width = ifelse(K == 10,7*5/2,7*3/2), height = ifelse(K == 10, 7, 7/2))
  if (K == 10 || K == 21 || K == 16)
  {
    par(mfrow = c(2,5))
  } else if (K == 3)
    par(mfrow = c(1,3))
  par(mar = c(5,5,4,1))
  for (k in 1:K)
  {
    if (k == 1)
      plot(sort(log10(assemblage_composition[,k]),decreasing = T),main = assemblage_labels[k], ylab = "OTU prevalence in assemblage", xlab = "OTUs sorted by decreasing prevalence", type = "l", cex = 0.7, cex.axis = 1.5, cex.lab = 1.7, cex.main = 1.7)
    else
      plot(sort(log10(assemblage_composition[,k]),decreasing = T),main = assemblage_labels[k], ylab = "", xlab = "", type = "l", cex = 0.7, cex.axis = 1.5, cex.lab = 1.7, cex.main = 1.7)
    if (Gibbs_VEM_insert == "_VEM")
      abline(h = log10(1/sum_data2m), lty =2)
    else
      abline(h = log10(sort(assemblage_composition[,k],decreasing=T)[100000]*2), lty =2)
  }
  dev.off()
  
  #########################################################
  # Setting OTUs with abundance below the threshold to 0: #
  #########################################################
  
  assemblage_composition[,1:K][!OTU_presence] = 0
  colnames(assemblage_composition) = c(assemblage_labels,colnames(assemblage_composition)[(K+1):ncol(assemblage_composition)])
  # Renormalizing assemblages:
  assemblage_composition[,1:K] = sweep(assemblage_composition[,1:K],2,colSums(assemblage_composition[,1:K]),"/")
  
  #################################
  # Hierarchical comparison tree: #
  #################################
  
  library(vegan)
  library(cluster)
  
  # Hellinger_assemblages = 1/sqrt(2)*dist(t(sqrt(assemblage_composition[,1:K])), method = "euclidean", diag = FALSE, upper = FALSE)
  Jaccard_assemblages = vegan::designdist(t(assemblage_composition[,1:K]), "(b+c)/(a+b+c)", abcd=TRUE)
  Sorensen_assemblages = vegan::designdist(t(assemblage_composition[,1:K]), "(b+c)/(2*a+b+c)", abcd=TRUE)
  Simpson_assemblages = vegan::designdist(t(assemblage_composition[,1:K]), "pmin(b,c)/(pmin(b,c)+a)", abcd=TRUE)
  
  upgma_Hellinger = agnes(Hellinger_assemblages, diss =T, method = "average", keep.diss =F, keep.data =F)
  upgma_Jaccard = agnes(Jaccard_assemblages, diss =T, method = "average", keep.diss =F, keep.data =F)
  upgma_Sorensen = agnes(Sorensen_assemblages, diss =T, method = "average", keep.diss =F, keep.data =F)
  upgma_Simpson = agnes(Simpson_assemblages, diss =T, method = "average", keep.diss =F, keep.data =F)
  
  # pdf(paste0(figure_folder,"/UPGMA_Hellinger_Gibbs100r_16t_AllTaxa.pdf"))
  # plot(upgma_Hellinger, which.plots=2, ann=F, cex=2, cex.axis = 2, lwd=1.5)
  # title("Average Hellinger")
  # dev.off()
  
  pdf(paste0(figure_folder,"/UPGMA_Jaccard_Gibbs100r_16t_AllTaxa.pdf"))
  plot(upgma_Jaccard, which.plots=2, ann=F, cex=2, cex.axis = 2, lwd=1.5)
  title("Average Jaccard")
  dev.off()
  
  pdf(paste0(figure_folder,"/UPGMA_Sorensen_Gibbs100r_16t_AllTaxa.pdf"))
  plot(upgma_Sorensen, which.plots=2, ann=F, cex=2, cex.axis = 2, lwd=1.5)
  title("Average Sorensen")
  dev.off()
  
  pdf(paste0(figure_folder,"/UPGMA_SimpsonAssemblages_Gibbs100r_16t_AllTaxa.pdf"))
  plot(upgma_Simpson, which.plots=2, ann=F, cex=1.4, cex.axis = 1.4, lwd=1.5)
  abline(h=0.875,lty=2,lwd=1.5)
  title("Average Simpson")
  dev.off()
  
  pvclust_Simpson = pvclust(t(assemblage_composition[,1:K]),
                              #method.dist = "euclidean",
                              #method.dist = "cor",
                              method.dist = function(x) vegan::designdist(x, "pmin(b,c)/(pmin(b,c)+a)", abcd=TRUE),
                              # method.dist = function(x) 1/sqrt(2)*dist(sqrt(x), method = "euclidean", diag = FALSE, upper = FALSE),
                              # method.dist = "cor", 
                              method.hclust = "average", 
                              nboot=1000)
  
  nb_clust_range = 2:10
  ii = 0
  mean_sd_sil_Simpson = matrix(nrow = length(nb_clust_range), ncol = 2, data = 0, dimnames = list(nb_clust_range,c("Mean","sd")))
  for (nb_clust in nb_clust_range)
  {
    ii = ii+1
    grp_Simpson = cutree(pvclust_Simpson$hclust, k = nb_clust)
    sil_Simpson = silhouette(grp_Simpson, Simpson_assemblages)
    mean_sd_sil_Simpson[ii,] = c(mean(sil_Simpson[,3]),sd(sil_Simpson[,3]))
  }
  
  library(Hmisc)
  pdf(paste0(figure_folder,"/UPGMA_SimpsonAssemblages_Gibbs100r_16t_AllTaxa_nbClustSilhouette.pdf"))
  errbar(nb_clust_range,mean_sd_sil_Simpson[,1],
         yplus=mean_sd_sil_Simpson[,1]+mean_sd_sil_Simpson[,2],
         yminus=mean_sd_sil_Simpson[,1]-mean_sd_sil_Simpson[,2],ylab = "Mean silhouette", xlab = "Number of clusters")
  dev.off()
  
  # pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_pvclust0.97.pdf"))
  pdf(paste0(figure_folder,"/UPGMA_SimpsonAssemblages_Gibbs100r_16t_AllTaxa_pvclust.pdf"))
  # pdf(paste0(figure_folder,"/Complete_stations_Hellinger_Gibbs100r_16t_AllTaxa_pvclust.pdf"))
  # pdf(paste0(figure_folder,"/UPGMA_stations_cor_Gibbs100r_16t_AllTaxa_pvclust.pdf"))
  plot(pvclust_Simpson, ann=F, cex=0.5, cex.axis = 2, lwd=1.5)
  #abline(lty=2,h=0.59,lwd=1.5)
  #rect.hclust(upgma_Hellinger_SUR, k = nb_clust, border = col)
  # pvrect(pvclust_Hellinger,alpha = 0.97)
  title("Average Simpson")
  # title("Correlation")
  dev.off()
  
  # pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_",nb_clust,"clusters.pdf"))
  # plot(upgma_Hellinger, which.plots=2, ann=F, cex=0.5, cex.axis = 2, lwd=1.5)
  # #rect.hclust(upgma_Hellinger, k = nb_clust, border = 2:17)
  # rect.hclust(upgma_Hellinger, k = nb_clust, border = col)
  # title("Average Hellinger")
  # dev.off()
  
  ##########################################################################
  # Computing the composition of assemblages in terms of taxonomic groups: #
  ##########################################################################
  
  assemblage_group_composition = matrix(nrow = length(taxo_groups), ncol = K, dimnames = list(taxo_groups_unmodified,assemblage_labels), data = 0)
  assemblage_group_endemic_proportion = matrix(nrow = length(taxo_groups), ncol = K, dimnames = list(taxo_groups_unmodified,assemblage_labels), data = 0)
  assemblage_group_ubiquist_proportion = matrix(nrow = length(taxo_groups), ncol = K, dimnames = list(taxo_groups_unmodified,assemblage_labels), data = 0)
  for (group in taxo_groups_unmodified)
  {
    i_group = which(taxo_groups_unmodified == group)
    assemblage_group_composition[i_group,] =  colSums(assemblage_composition[assemblage_composition$taxogroup2 %in% group,1:K])
    for (k in 1:K)
    {
      assemblage_group_endemic_proportion[i_group,k] = sum(assemblage_composition[assemblage_composition$taxogroup2 %in% group & endemic_OTUs & endemicity_assemblage == k,k])
      assemblage_group_ubiquist_proportion[i_group,k] = sum(assemblage_composition[assemblage_composition$taxogroup2 %in% group & ubiquist_OTUs,k])
    }
  }
  
  group_abundances = setNames(rowSums(assemblage_group_composition),rownames(assemblage_group_composition))
  selected_OTU_proportion_all = sort.int(group_abundances[selected_groups],decreasing = T,index.return = T)$ix
  # selected_OTU_richness is equal to as.vector(diversity)[selected_groups]
  # selected_OTU_richness = sort(table(as.factor(assemblage_composition$taxogroup2[assemblage_composition$taxogroup2 %in% taxo_groups_unmodified[selected_groups]])),decreasing = T)
  
  ###################################################################
  # Computing the composition of assemblages in terms of functions: #
  ###################################################################
  
  function_names = c("Phototroph","Photohost","Endophotosymbiont","Phagotroph","Copepoda","Pteropoda","Gel. carn. filterers","Other metazoa","Parasite","Unknown")
  assemblage_function_composition = matrix(nrow = length(functions), ncol = K, dimnames = list(function_names,assemblage_labels), data = 0)
  assemblage_function_endemic_proportion = matrix(nrow = length(functions), ncol = K, dimnames = list(function_names,assemblage_labels), data = 0)
  assemblage_function_ubiquist_proportion = matrix(nrow = length(functions), ncol = K, dimnames = list(function_names,assemblage_labels), data = 0)
  for (fun in functions)
  {
    i_group = which(functions == fun)
    assemblage_function_composition[i_group,] =  colSums(assemblage_composition[assemblage_composition$Function %in% fun,1:K])
    for (k in 1:K)
    {
      assemblage_function_endemic_proportion[i_group,k] = sum(assemblage_composition[assemblage_composition$Function %in% fun & endemic_OTUs & endemicity_assemblage == k,k])
      assemblage_function_ubiquist_proportion[i_group,k] = sum(assemblage_composition[assemblage_composition$Function %in% fun & ubiquist_OTUs,k])
    }
  }
  function_colors = c("darkgreen","chartreuse2","orange","firebrick2","cadetblue","darkblue","darkturquoise","dodgerblue1","darkgoldenrod1","grey")
  
  # dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # # dominant_function_simplified  = dominant_function
  # # dominant_function_simplified[dominant_function == "copepoda" & "other metazoa" & "pteropoda"] = "Metazoa"
  # functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
  # ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
  
  library(colorspace)
  
  ###############################################################################################
  # Plotting the taxonomic composition of assemblages - each assemblage as a separate barplot:  #
  ###############################################################################################
  
  # pdf(paste0(figure_folder,"/Assemblage_composition_taxogroup_10mostPrevalentPerAssemblage_AllTaxa_K",K,Gibbs_VEM_insert,"_selected.pdf"),width = ifelse(K == 10,7*5/2,7*3/2), height = ifelse(K == 10, 7, 7/2))
  # par(mar=c(6.1,4.1,4.1,1.1))
  # # par(mar=c(1.1,1.1,1.1,1.1))
  # if (K == 10 || K == 21 || K == 16)
  # {
  #   par(mfrow = c(2,5))
  # } else if (K == 3)
  #   par(mfrow = c(1,3))
  # selected_OTU_proportion = matrix(nrow = length(taxo_groups[selected_groups]), ncol = K, data = 0)
  # for (k in 1:K)
  # {
  #   selected_OTU_proportion[,k] = sort.int(assemblage_group_composition[selected_groups,k],decreasing = T,index.return = T)$ix
  #   x = barplot(c(assemblage_group_composition[selected_groups,k][selected_OTU_proportion[1:10,k]],1-sum(assemblage_group_composition[selected_groups,k][selected_OTU_proportion[1:10,k]])), 
  #               space = 1, xaxt="n", ylim = c(0,max(assemblage_group_composition)))
  #   labs = c(rownames(assemblage_group_composition[selected_groups,])[selected_OTU_proportion[1:10,k]],"Others")
  #   text(cex=0.8, x=x+1, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
  #   # text(cex=1, x=x+0.3, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
  #   title(ylab = "Prevalence in assemblage", main = colnames(assemblage_group_composition)[k])
  # }
  # dev.off()
  # 
  # pdf(paste0(figure_folder,"/Assemblage_composition_taxogroup_",if (K==10) 14 else if (K==3) 13 else if (K==16) 15,"groups_AllTaxa_K",K,Gibbs_VEM_insert,"_selected.pdf"),
  #     width = if (K == 10) 7*5/2 else if (K == 3) 7*3/2 else if (K == 16) 7*4/2, height = if (K == 10) 7 else if (K == 3) 7/2 else if (K == 16) 14)
  # par(mar=c(6.1,4.1,4.1,1.1))
  # # par(mar=c(1.1,1.1,1.1,1.1))
  # if (Gibbs_VEM_insert == "_VEM" && K == 10)
  # {
  #   par(mfrow = c(2,5))
  #   # Groups that span the 10 most prevalent groups in all assemblages: levels(as.factor(selected_OTU_proportion[1:10,]))
  #   # They are ordered by their global prevalence across assemblages: selected_OTU_proportion_all[1:17]
  #   selected_OTU_proportion = c(1,7,3,2,5,4,8,9,10,6,11,12,19,14)
  # } else if (Gibbs_VEM_insert == "_Gibbs" && K == 16)
  # {
  #   par(mfrow = c(4,4))
  #   selected_OTU_proportion = c(1,2,3,7,4,5,6,8,9,10,11,13,14,19,17)
  # } else if (Gibbs_VEM_insert == "_VEM" && K == 3)
  # {
  #   par(mfrow = c(1,3))
  #   selected_OTU_proportion = c(1,7,3,5,2,8,4,9,10,6,11,14,19)
  # }
  # for (k in assemblage_reordering)
  # {
  #   x = barplot(c(assemblage_group_composition[selected_groups,k][selected_OTU_proportion],1-sum(assemblage_group_composition[selected_groups,k][selected_OTU_proportion])), 
  #               space = 1, xaxt="n", ylim = c(0,max(assemblage_group_composition)))
  #   labs = c(rownames(assemblage_group_composition[selected_groups,])[selected_OTU_proportion],"Others")
  #   text(cex=1.2, x=x+1, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
  #   # text(cex=1, x=x+0.7, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
  #   title(ylab = "Prevalence in assemblage", main = colnames(assemblage_group_composition)[k])
  # }
  # dev.off()
  # 
  # # pdf(paste0("Assemblage_composition_taxogroup_",ifelse(K==10,14,13),"groups_AllTaxa_K",K,"_selected_endemicsUbiquists.pdf"),width = ifelse(K == 10,7*5/2,7*3/2), height = ifelse(K == 10, 7, 7/2))
  # # pdf(paste0(figure_folder,"/Assemblage_composition_taxogroup_",if (K==10) 14 else if (K==3) 13 else if (K==16) 15,"groups_AllTaxa_K",K,Gibbs_VEM_insert,"_selected_endemicsUbiquists.pdf"),
  # pdf(paste0(figure_folder,"/Assemblage_composition_taxogroup_",if (K==10) 14 else if (K==3) 13 else if (K==16) 11,"groups_AllTaxa_K",K,Gibbs_VEM_insert,"_selected_endemicsUbiquists.pdf"),
  #     width = if (K == 10) 7*4/2 else if (K == 3) 7*3/2 else if (K == 16) 7*4/2, height = if (K == 10) 7*3/2 else if (K == 3) 7/2 else if (K == 16) 14)
  #     # width = ifelse(K == 10,7*4/2,7*3/2), height = ifelse(K == 10, 7*3/2, 7/2))
  # # par(mar=c(1.1,1.1,1.1,1.1))
  # if (Gibbs_VEM_insert == "_VEM" && K == 10)
  # {
  #   # par(mfrow = c(2,5))
  #   par(mfrow = c(3,4))
  #   # Groups that span the 10 most prevalent groups in all assemblages: levels(as.factor(selected_OTU_proportion[1:10,]))
  #   # They are ordered by their global prevalence across assemblages: selected_OTU_proportion_all[1:17]
  #   selected_OTU_proportion = c(1,7,3,2,5,4,8,9,10,6,11,12,19,14)
  # } else if (Gibbs_VEM_insert == "_Gibbs" && K == 16)
  # {
  #   par(mfrow = c(4,4))
  #   # selected_OTU_proportion = c(1,2,3,7,4,5,6,8,9,10,11,13,14,19,17)
  #   # Reduced to the 11 first groups:
  #   selected_OTU_proportion = c(1,2,3,7,4,5,6,8,9,10,11)
  # } else if (Gibbs_VEM_insert == "_VEM" && K == 3)
  # {
  #   par(mfrow = c(1,3))
  #   selected_OTU_proportion = c(1,7,3,5,2,8,4,9,10,6,11,14,19)
  # }
  # for (k in assemblage_reordering)
  # {
  #   par(mar=c(7.1,ifelse(k==assemblage_reordering[1],5.1,4.1),4.1,1.1))
  #   x = barplot(t(matrix(c(assemblage_group_endemic_proportion[selected_groups,k][selected_OTU_proportion],
  #                             sum(assemblage_group_endemic_proportion[,k])-sum(assemblage_group_endemic_proportion[selected_groups,k][selected_OTU_proportion]),
  #                         assemblage_group_composition[selected_groups,k][selected_OTU_proportion]-assemblage_group_endemic_proportion[selected_groups,k][selected_OTU_proportion]-assemblage_group_ubiquist_proportion[selected_groups,k][selected_OTU_proportion],
  #                             1-sum(assemblage_group_composition[selected_groups,k][selected_OTU_proportion])-(sum(assemblage_group_endemic_proportion[,k]) - sum(assemblage_group_endemic_proportion[selected_groups,k][selected_OTU_proportion]))-(sum(assemblage_group_ubiquist_proportion[,k])-sum(assemblage_group_ubiquist_proportion[selected_groups,k][selected_OTU_proportion])),
  #                         assemblage_group_ubiquist_proportion[selected_groups,k][selected_OTU_proportion],
  #                             sum(assemblage_group_ubiquist_proportion[,k])-sum(assemblage_group_ubiquist_proportion[selected_groups,k][selected_OTU_proportion])),ncol=3)), 
  #               space = 1, 
  #               xaxt="n", cex.axis = 1.7, ylim = c(0,max(assemblage_group_composition)), col = t(matrix(unlist(lapply(c("black","grey","white"),rep,length(selected_OTU_proportion))),ncol=3)))
  #   labs = c(rownames(assemblage_group_composition[selected_groups,])[selected_OTU_proportion],"Others")
  #   text(cex=1.5, x=x+1, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
  #   if (k == assemblage_reordering[1])
  #     title(ylab = "Prevalence in assemblage", main = paste(colnames(assemblage_group_composition)[k],"-\n",assemblage_richness[k],"OTUs"), cex.lab = 1.8, cex.main = 1.8, adj = 0)
  #   else 
  #     title(main = paste(colnames(assemblage_group_composition)[k],"-\n",assemblage_richness[k],"OTUs"), cex.main = 1.8, adj = 0)
  # }
  # dev.off()
  
  ################################################################################################
  # Plotting the functional composition of assemblages - each assemblage as a separate barplot:  #
  ################################################################################################
  
  # # pdf(paste0("Assemblage_composition_functions_AllTaxa_K",K,"_selected_endemicsUbiquists.pdf"),width = ifelse(K == 10,7*5/2,7*3/2), height = ifelse(K == 10, 7, 7/2))
  # # pdf(paste0("Assemblage_composition_functions_AllTaxa_K",K,Gibbs_VEM_insert,"_selected_endemicsUbiquists_3lines.pdf"),width = ifelse(K == 10,7*4/2,7*3/2), height = ifelse(K == 10, 7*3/2, 7/2))
  # pdf(paste0(figure_folder,"/Assemblage_composition_functions_AllTaxa_K",K,Gibbs_VEM_insert,"_selected_endemicsUbiquists.pdf"),
  #     width = if (K == 10) 7*4/2 else if (K == 3) 7*3/2 else if (K == 16) 7*4/2, height = if (K == 10) 7*3/2 else if (K == 3) 7/2 else if (K == 16) 14)
  # par(mar=c(8.8,5.1,4.1,1.1))
  # # par(mar=c(1.1,1.1,1.1,1.1))
  # if (Gibbs_VEM_insert == "_VEM" && K == 10)
  # {
  #   # par(mfrow = c(2,5))
  #   par(mfrow = c(3,4))
  # } else if (Gibbs_VEM_insert == "_VEM" && K == 3)
  # {
  #   par(mfrow = c(1,3))
  # } else if (Gibbs_VEM_insert == "_Gibbs" && K == 16)
  # {
  #   par(mfrow = c(4,4))
  # }
  # for (k in assemblage_reordering)
  # {
  #   x = barplot(t(matrix(c(assemblage_function_endemic_proportion[,k],
  #                          assemblage_function_composition[,k]-assemblage_function_endemic_proportion[,k]-assemblage_function_ubiquist_proportion[,k],
  #                          assemblage_function_ubiquist_proportion[,k]),ncol=3)), 
  #               space = 1,
  #               # space = 0,
  #               xaxt="n", cex.axis = 1.7, ylim = c(0,max(assemblage_function_composition)), col = t(matrix(unlist(lapply(c("black","grey","white"),rep,length(functions))),ncol=3)))
  #   labs = rownames(assemblage_function_composition)
  #   labs[labs == "gelatineous_carnivores_filterers"] = "gel. carniv. filterers"
  #   # text(cex=0.8, x=x+1, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
  #   text(cex=1.5, x=x+0.7, y=-0.02, labels = labs, xpd=TRUE, srt=45, pos=2)
  #   if (k == assemblage_reordering[1])
  #     title(ylab = "Prevalence in assemblage", main = paste(colnames(assemblage_function_composition)[k],"-\n",assemblage_richness[k],"OTUs"), cex.lab = 1.8, cex.main = 1.8, adj = 0)
  #   else 
  #     title(main = paste(colnames(assemblage_function_composition)[k],"-\n",assemblage_richness[k],"OTUs"), cex.main = 1.8, adj = 0)
  # }
  # dev.off()
  
  ###################################
  # Tests of taxonomic composition: #
  ###################################
  
  ########### Test 1:
  
  # load(paste0(data.folder,"/data2m.Rdata"))
  # # load(paste0(data.folder_name,"/data2m_unmerged.Rdata"))
  # # data2m = data2m0
  # # samples_data2m = colnames(data2m)
  # data2m[data2m>0] = 1
  # cumulative_prevalence_per_group = vector(length=length(taxo_groups),mode="numeric")
  # for (i_group in 1:length(taxo_groups))
  #   cumulative_prevalence_per_group[i_group] = sum(rowSums(data2m[taxo_ref$taxogroup2 == taxo_groups_unmodified[i_group],]))
  # 
  # spatial_topicmix_kriged = readRDS(paste0(data.folder,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",K,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds"))
  # # selecting the z.pred columns in all topics:
  # documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
  # # setting one topic per column
  # documents = matrix(documents,ncol=K,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:K)))
  # cumulative_prevalence_per_assemblage = vector(length=K,mode="numeric")
  # for (k in 1:K)
  #   cumulative_prevalence_per_assemblage[k] = sum(documents[,k]*colSums(data2m))
  # 
  # nb_real = 10000
  # signif_results = matrix(nrow = length(taxo_groups), ncol = K, data = 0, dimnames=list(taxo_groups,1:K))
  # for (k in 1:K)
  # {
  #   # length(taxo_groups)*nb_real matrix:
  #   random_samples = rmultinom(nb_real, round(cumulative_prevalence_per_assemblage[k]), cumulative_prevalence_per_group)
  #   # Normalizing the simulated assemblage composition for each real:
  #   random_samples = scale(random_samples,center=F,scale=colSums(random_samples))
  #   # 2*length(taxo_groups) matrix containing the 0.05 and 0.95 quantiles for each group:
  #   quantiles = apply(random_samples,1,quantile,probs = c(0.05,0.95))
  #   # length(taxo_groups)*K matrix recording whether each group is significantly prevalent or rare in each assemblage:
  #   signif_results[quantiles[1,]>assemblage_group_composition[,k],k] = -1
  #   signif_results[quantiles[2,]<assemblage_group_composition[,k],k] = 1
  # }
  # 
  # chisq.pval = vector(length = K, mode = "numeric")
  # for (k in 1:K)
  #   chisq.pval[k] = chisq.test(x = round(assemblage_group_composition[c(1,2,3,7,4,5,6,8,9,10,11),k]*cumulative_prevalence_per_assemblage[k]), 
  #                              p = as.vector(scale(cumulative_prevalence_per_group[c(1,2,3,7,4,5,6,8,9,10,11)],
  #                                                  center=F,
  #                                                  scale=sum(cumulative_prevalence_per_group[c(1,2,3,7,4,5,6,8,9,10,11)]))))$p.value
  
  ########### Test 2:
  
  # cumulative_prevalence_per_group = vector(length=length(taxo_groups),mode="numeric")
  # for (i_group in 1:length(taxo_groups))
  #   global_group_distribution[i_group] = length(which(taxo_ref$taxogroup2 == taxo_groups_unmodified[i_group]))
  # 
  # cumulative_prevalence_per_assemblage = vector(length=K,mode="numeric")
  # for (k in 1:K)
  #   cumulative_prevalence_per_assemblage[k] = sum(documents[,k]*colSums(data2m))
  # 
  # nb_real = 10000
  # signif_results = matrix(nrow = length(taxo_groups), ncol = K, data = 0, dimnames=list(taxo_groups,1:K))
  # for (k in 1:K)
  # {
  #   # length(taxo_groups)*nb_real matrix:
  #   random_samples = rmultinom(nb_real, round(cumulative_prevalence_per_assemblage[k]), cumulative_prevalence_per_group)
  #   # Normalizing the simulated assemblage composition for each real:
  #   random_samples = scale(random_samples,center=F,scale=colSums(random_samples))
  #   # 2*length(taxo_groups) matrix containing the 0.05 and 0.95 quantiles for each group:
  #   quantiles = apply(random_samples,1,quantile,probs = c(0.05,0.95))
  #   # length(taxo_groups)*K matrix recording whether each group is significantly prevalent or rare in each assemblage:
  #   signif_results[quantiles[1,]>assemblage_group_composition[,k],k] = -1
  #   signif_results[quantiles[2,]<assemblage_group_composition[,k],k] = 1
  # }
  
  # load(paste0(data.folder,"/taxo_ref.Rdata"))
  # functions_OTUs = taxo_ref$Function
  ########################
  
  ########################################################################################################
  # Plotting the taxonomic and functional composition of assemblages - each assemblage as a stacked bar: #
  ########################################################################################################
  
  assemblage_labels = c("Global non-Arctic","Global Arctic","Tropical DCM","Global equatorial",
                        "Southern Ocean","Equatorial Pacific","Mediterranean","Tropical Surface",
                        "Subtropical Atlantic","Temperate Upwellings","Eastern Pacific Upwellings","Diplonemid-rich",
                        "Lower Arctic","Subarctic North Atlantic","Red Sea","Persian Gulf")
  # Same order as in the map:
  # topic_reordering = c(1,3,9,7,
  #                      10,8,4,6,
  #                      11,16,15,12,
  #                      14,5,13,2)
  color.pal1 = colorRampPalette(c("#7F0000","red","darkorange1","darkgoldenrod1","yellow"),space = "Lab")
  color.pal2 = colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")
  color.pal3 = colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")
  color.pal4 = colorRampPalette(c("#00007F","#007FFF","cyan"),space = "Lab")
  col_assemblages = c(color.pal1(6),color.pal2(3),color.pal3(3),rev(color.pal4(4)))
  
  # nb_groups = vector(length = ncol(assemblage_group_composition), mode = "numeric")
  # for (i in 1:ncol(assemblage_group_composition))
  # {
  #   nb_groups[i] = length(which(assemblage_group_composition[,i] != 0))
  # }
  
  # pdf(paste0(figure_folder,"/Assemblage_composition_taxogroup_11groups_AllTaxa_K",K,"_stackedBarPlot+AssemblageRichness.pdf"), height = 14, width = 9.5)
  # par(mfrow=c(2,1))
  pdf(paste0(figure_folder,"/Assemblage_richness_AllTaxa_K",K,"_withEndemics.pdf"))
  par(mar=c(0.1,4.1,1.1,11.2))
  barplot = rbind(assemblage_endemic_richness,assemblage_richness-assemblage_endemic_richness)[,assemblage_reordering]
  barplot(barplot,
          legend.text=F,
          xaxt="n", cex.axis = 1.3, space = 0.5)
  for (k in 1:K)
  {
    barplot.k = barplot
    barplot.k[,-k] = 0
    barplot(barplot.k,
            legend.text=F,
            col = rep(col_assemblages[k],2),
            xaxt="n", yaxt="n", space = 0.5, add=T)
    barplot(barplot.k,
            legend.text=F,
            col = "black",
            density = c(20,0),
            xaxt="n", yaxt="n", space = 0.5, add=T)
  }
  title(ylab="Nb of OTUs in biome",cex.lab=1.3)
  dev.off()
  
  pdf(paste0(figure_folder,"/Assemblage_composition_taxogroup_",ifelse(K==10,14,11),"groups_AllTaxa_K",K,"_stackedBarPlot.pdf"))
  # par(mar=c(7.5,4.1,1.1,7.1))
  par(mar=c(1.5,4.1,2.1,14.5))
  if (Gibbs_VEM_insert == "_Gibbs" && K == 16)
  {
    #par(mfrow = c(4,4))
    # selected_OTU_proportion = c(1,2,3,7,4,5,6,8,9,10,11,13,14,19,17)
    # Reduced to the 11 first groups (ordered by their global abundance):
    # selected_OTU_proportion = rev(c(1,2,3,7,4,5,6,8,9,10,11))
    # Custom order:
    selected_OTU_proportion = c(2, 3,6,13,17, 19, 4,11,16,14, 1,9,7,8,15, 5,12,18, 10)
    #                   "Excavata", "Metazoa", "Archaeplastida", "Rhizaria", "Alveolata", "Stramenopila", "Incerta Sedis"
  }
  if (K == 10)
  {
    colours = c(rep(rainbow_hcl(length(selected_OTU_proportion)/2)[sample(1:(length(selected_OTU_proportion)/2),length(selected_OTU_proportion)/2)],2),"grey")
  } else
    # colours = c(rainbow_hcl(length(selected_OTU_proportion))[sample(1:length(selected_OTU_proportion),length(selected_OTU_proportion))],"grey")
    # function_colors = c("darkgreen","chartreuse2","orange","firebrick2","cadetblue","darkblue","darkturquoise","dodgerblue1","darkgoldenrod1","grey")
    colours = c("burlywood1",#"darkgoldenrod1",
                colorRampPalette(c("darkgreen","chartreuse2"),space = "Lab")(4),
                #"cornsilk1",
                "mintcream",
                colorRampPalette(c("darkblue","darkturquoise"),space = "Lab")(4),
                colorRampPalette(c("firebrick2","darkgoldenrod1"),space = "Lab")(5),
                colorRampPalette(c("darkviolet","deeppink"),space = "Lab")(3),
                # "burlywood1",
                "darkseagreen",
                "grey")
    colours = desaturate(colours, amount = 0.2)
    
    # function_names = c("Phototrophs","Collodaria","Phagotrophs","Dinophyceae","Copepoda","Pteropoda","Gel. carn. filterers","Other metazoa","Parasites","Unknown")
    # function_colors = c("darkviolet","darkblue","firebrick","firebrick2",
    #                     colorRampPalette(c("darkgreen","chartreuse2"),space = "Lab")(4),
    #                     "darkgoldenrod1","grey")
    
  barplot = rbind(assemblage_group_composition[selected_groups,assemblage_reordering][selected_OTU_proportion,],
                  Others = rep(1,K)-colSums(assemblage_group_composition[selected_groups,assemblage_reordering][selected_OTU_proportion,]))
  labs = c(rownames(assemblage_group_composition[selected_groups,assemblage_reordering][selected_OTU_proportion,]),"Others")
  labs[6] = c("Mamiellophyc.")
  labs[c(12,13)] = c("MALV I","MALV II")
  labs[15] = c("Apicomplexa")
  labs[c(17,18)] = c("MAST 3,12","MAST 4,6-11")
  x = barplot(barplot,
          col=colours,
          legend.text = rev(labs),
          space = 0.5, xaxt = "n", yaxt = "n",   
          args.legend = list(bty = "n", x= 45, y=0.1, cex = 1.3, fill = colours),
          ylim=c(1,0))
  labs = c("0.0","0.2","0.4","0.6","0.8","1.0")
  axis(2, labels = labs, at = rev(seq(0,1,by=0.2)), cex.axis = 1.3)
  # for (k in 1:K)
  # {
  #   barplot.k = barplot
  #   barplot.k[,-k] = 0
  #   # density = rbind(signif_results[selected_groups,assemblage_reordering][selected_OTU_proportion,],rep(0,K))*20
  #   barplot(barplot.k,
  #           col = colours,
  #           legend.text = F,
  #           xaxt="n", space = 0.5, 
  #           # args.legend = list(bty = "n", x= 32.5, y=0.5))
  #           # args.legend = list(bty = "n", x= 31.5, y=0.4, cex = 1.3, fill = colours),
  #           ylim=c(1,0),
  #           add=T)
    # density = c(signif_results[selected_groups,assemblage_reordering][selected_OTU_proportion,k],0)*20
    # density[density < 0] = 0
    # barplot(barplot.k,
    #         col = NA,
    #         density = density,
    #         legend.text = F,
    #         xaxt="n", space = 0.5, 
    #         # args.legend = list(bty = "n", x= 32.5, y=0.5))
    #         # args.legend = list(bty = "n", x= 31.5, y=0.4, cex = 1.3, fill = colours),
    #         ylim=c(1,0),
    #         add=T)
    # density = -c(signif_results[selected_groups,assemblage_reordering][selected_OTU_proportion,k],0)*20
    # density[density < 0] = 0
    # barplot(barplot.k,
    #         col = "red",
    #         density = density,
    #         angle = 135,
    #         legend.text = F,
    #         xaxt="n", space = 0.5,
    #         # args.legend = list(bty = "n", x= 32.5, y=0.5))
    #         # args.legend = list(bty = "n", x= 31.5, y=0.4, cex = 1.3, fill = colours),
    #         ylim=c(1,0),
    #         add=T)
  # }
  #colours = terrain.colors(nrow(silva_phylum_mat1))[sample(1:nrow(silva_phylum_mat1),nrow(silva_phylum_mat1))]
  #x = barplot(sweep(silva_phylum_mat1,2,colSums(silva_phylum_mat1),"/"),col=colours,
  #xaxt="n", space = 0.5)
  #legend("topright",rownames(silva_phylum_mat1),col=colours)
  title(ylab="Prevalence in assemblage",cex.lab=1.3)
  # labs = assemblage_labels[topic_reordering]
  # labs = 1:16
  # text(cex=1.5, x=x+0.8, y=-0.035, labels = labs, xpd=TRUE, srt=0, pos=2)
  dev.off()
  ##########
  
  ############################################
  # endemic_OTUs = unlist(lapply(apply(OTU_presence,1,which),length)) == 1
  # endemicity_assemblage = unlist(lapply(apply(OTU_presence,1,which),function(g) g[1]))
  # ubiquist_OTUs = apply(OTU_presence,1,all)
  # assemblage_richness = unlist(lapply(apply(OTU_presence,2,which),length))
  # assemblage_endemic_richness = unlist(lapply(apply(OTU_presence & endemic_OTUs,2,which),length))
  # OTUs found in exactly 2 assemblages:
  twoAssemblage_OTUs = unlist(lapply(apply(OTU_presence,1,which),length)) == 2
  # OTU richness shared between 2 assemblages, for each assemblage:
  assemblage_shared_richness = matrix(nrow = K, ncol = K, data = 0)
  for (k in 1:K)
  {
    for (k1 in 1:K)
    {
      if (k1 != k)
        assemblage_shared_richness[k1,k] = length(which(twoAssemblage_OTUs & OTU_presence[,k] & OTU_presence[,k1]))
      else 
        assemblage_shared_richness[k1,k] = 0
    }
  }
  
  pdf(paste0(figure_folder,"/Assemblage_composition_taxogroup_11groups_AllTaxa_K",K,"_stackedBarPlot+AssemblageRichness+AssemblageSimilarity.pdf"), height = 14, width = 9.5)
  par(mfrow=c(2,1))
  # pdf(paste0(figure_folder,"/Assemblage_richness_AllTaxa_K",K,"_withEndemics.pdf"))
  par(mar=c(0.1,4.1,1.1,8.6))
  barplot = rbind(assemblage_endemic_richness,assemblage_shared_richness[assemblage_reordering,],assemblage_richness-assemblage_endemic_richness-colSums(assemblage_shared_richness))[,assemblage_reordering]
  barplot(barplot,
          legend.text=F,
          xaxt="n", space = 0.5)
  for (k in 1:K)
  {
    barplot.k = barplot
    barplot.k[,-k] = 0
    barplot(barplot.k,
            legend.text=F,
            col = c(col_assemblages[k],col_assemblages[1:K],"black"),
            xaxt="n", space = 0.5, add=T)
    barplot(barplot.k,
            legend.text=F,
            col = "black",
            density = c(0,rep(20,K),0),
            xaxt="n", space = 0.5, add=T)
  }
  title(ylab="Nb of OTUs in biome",cex.lab=1.3)
  # dev.off()
  #############
  # pdf(paste0(figure_folder,"/Assemblage_composition_taxogroup_",ifelse(K==10,14,11),"groups_AllTaxa_K",K,"_stackedBarPlot.pdf"), height = 14, width = 7)
  # par(mar=c(7.5,4.1,1.1,7.1))
  par(mar=c(1.5,4.1,2.1,8.6))
  if (Gibbs_VEM_insert == "_Gibbs" && K == 16)
  {
    #par(mfrow = c(4,4))
    # selected_OTU_proportion = c(1,2,3,7,4,5,6,8,9,10,11,13,14,19,17)
    # Reduced to the 11 first groups:
    selected_OTU_proportion = rev(c(1,2,3,7,4,5,6,8,9,10,11))
  }
  if (K == 10)
  {
    colours = c(rep(rainbow_hcl(length(selected_OTU_proportion)/2)[sample(1:(length(selected_OTU_proportion)/2),length(selected_OTU_proportion)/2)],2),"grey")
  # } else if (K == 16)
  # {
  #   nb_colors = floor(length(selected_OTU_proportion)/2)
  #   color_order = sample(1:(nb_colors+1),nb_colors+1)
  #   colours = c(rainbow_hcl(nb_colors)[color_order[color_order != nb_colors+1]],
  #               rainbow_hcl(nb_colors+1)[color_order],
  #               "grey")
  } else
    colours = c(rainbow_hcl(length(selected_OTU_proportion))[sample(1:length(selected_OTU_proportion),length(selected_OTU_proportion))],"grey")
  x = barplot(rbind(assemblage_group_composition[selected_groups,assemblage_reordering][selected_OTU_proportion,], 
                    Others = rep(1,K)-colSums(assemblage_group_composition[selected_groups,assemblage_reordering][selected_OTU_proportion,])),
              col=colours,
              legend.text = rev(c(rownames(assemblage_group_composition[selected_groups,assemblage_reordering][selected_OTU_proportion,]),"Others")),
              xaxt="n", space = 0.5, 
              # args.legend = list(bty = "n", x= 32.5, y=0.5))
              args.legend = list(bty = "n", x= 31.5, y=0.4, cex = 1.3, fill = colours),
              ylim=c(1,0))
  #colours = terrain.colors(nrow(silva_phylum_mat1))[sample(1:nrow(silva_phylum_mat1),nrow(silva_phylum_mat1))]
  #x = barplot(sweep(silva_phylum_mat1,2,colSums(silva_phylum_mat1),"/"),col=colours,
  #xaxt="n", space = 0.5)
  #legend("topright",rownames(silva_phylum_mat1),col=colours)
  title(ylab="Prevalence in biome",cex.lab=1.3)
  # labs = assemblage_labels[topic_reordering]
  labs = 1:16
  text(cex=1.5, x=x+0.7, y=-0.035, labels = labs, xpd=TRUE, srt=0, pos=2)
  dev.off()
  ##########
  
  ##############
  pdf(paste0(figure_folder,"/Assemblage_composition_functions_AllTaxa_K",K,"_stackedBarPlot.pdf"), width = 9.5)
  par(mar=c(1.5,4.1,2.1,11.2))
  # x = barplot(rbind(assemblage_function_composition[selected_functions,assemblage_reordering], Others = rep(1,K)-colSums(assemblage_function_composition[selected_functions,assemblage_reordering])),
  #             col=c(rainbow_hcl(length(which(selected_functions)))[sample(1:length(which(selected_functions)),length(which(selected_functions)))],"grey"),
  #             legend.text = T, xaxt="n", space = 0.5, 
  #             args.legend = list(bty = "n", x= 25 + 1, y=1))
  x = barplot(assemblage_function_composition[nrow(assemblage_function_composition):1,assemblage_reordering],
              col=rev(function_colors),
              legend.text = T, xaxt="n", space = 0.5, cex.axis = 1.3,
              args.legend = list(bty = "n", x = 34, y = 0.6, cex = 1.3))
  # title(ylab="Prevalence in biome",cex.lab=1.3)
  # labs = assemblage_labels[assemblage_reordering]
  labs = 1:16
  text(cex=1.5, x=x+0.8, y=1.035, labels = labs, xpd=TRUE, srt=0, pos=2)
  dev.off()
  ###############

  pdf(paste0(figure_folder,"/Assemblage_composition_functions_AllTaxa_K",K,"_stackedBarPlot_pres.pdf"), width = 9.5)
  par(mar=c(1.5,4.1,2.1,16.2))
  # x = barplot(rbind(assemblage_function_composition[selected_functions,assemblage_reordering], Others = rep(1,K)-colSums(assemblage_function_composition[selected_functions,assemblage_reordering])),
  #             col=c(rainbow_hcl(length(which(selected_functions)))[sample(1:length(which(selected_functions)),length(which(selected_functions)))],"grey"),
  #             legend.text = T, xaxt="n", space = 0.5, 
  #             args.legend = list(bty = "n", x= 25 + 1, y=1))
  x = barplot(assemblage_function_composition[nrow(assemblage_function_composition):1,assemblage_reordering],
              col=rev(function_colors),
              legend.text = T, xaxt="n", space = 0.5, cex.axis = 1.3,
              args.legend = list(bty = "n", x = 40, y = 0.6, cex = 1.8))
  # title(ylab="Prevalence in biome",cex.lab=1.3)
  # labs = assemblage_labels[assemblage_reordering]
  labs = 1:16
  text(cex=1.4, x=x+0.95, y=1.035, labels = labs, xpd=TRUE, srt=0, pos=2)
  dev.off()
}

if (functional_maps)
{
  data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTAxa",noArcticNoBiomark_insert,noLagoon_insert)
  load(paste0(data.folder_name,"/coord.Rdata"))
  
  load(paste0(data.folder_name,"/data2m.Rdata"))
  # load(paste0(data.folder_name,"/data2m_unmerged.Rdata"))
  # data2m = data2m0
  # samples_data2m = colnames(data2m)
  load(paste0(data.folder_name,"/taxo_ref.Rdata"))
  functions_OTUs = taxo_ref$Function
  #functions = levels(as.factor(functions_OTUs))[sort.int(table(as.factor(functions_OTUs)),index.return = T,decreasing = T)$ix]
  functions = c("phototroph","photohost","endophotosymbiont","phagotroph","copepoda","pteropoda","gelatineous_carnivores_filterers","other metazoa","parasite","unknown")
  function_names = c("Phototroph","Photohost","Endophotosymbiont","Phagotroph","Copepoda","Pteropoda","Gel. carn. filterers","Other metazoa","Parasite","Unknown")
  function_colors = c("darkgreen","chartreuse2","orange","firebrick2","cadetblue","darkblue","darkturquoise","dodgerblue1","darkgoldenrod1","grey")
  
  station_functional_composition = matrix(nrow = ncol(data2m), ncol = length(functions), data = 0, dimnames = list(rownames(coord),function_names))
  for (j in 1:length(functions))
  {
    for (i in 1:ncol(data2m))
      station_functional_composition[i,j] = length(which(data2m[,i] > 0 & functions_OTUs == functions[j]))
  }
  station_functional_composition = t(scale(t(station_functional_composition),center=F,scale=rowSums(station_functional_composition)))
  
  pdf(paste0(figure_folder,"/AllTaxa_functionalDistribution_SurDCMplots_marmap_largePies_lowerRes.pdf"))
  # pdf(paste0(figure_folder,"/",group,"_Gibbs100r",nb_topics,"t",ifelse(nb_topics==nb_topics1,"",paste0("_",nb_topics1,"firstTopics")),"_SurDCMplots_marmap_barplot2D.pdf"))
  # pdf(paste0(figure_folder,"/",group,"_Gibbs100r",nb_topics,"t",ifelse(nb_topics==nb_topics1,"",paste0("_",nb_topics1,"firstTopics")),"_SurDCMplots_marmap_xyplot.pdf"))
  # pdf("AllTaxa_VEM100r10t_SurDCMplots_marmap.pdf")
  # pdf("AllTaxa_GibbsAlpha0.1Best100r10t_SurDCMplots_marmap.pdf")
  # par(mar=c(0,0.2,0,0.2))
  # Plotting Surface:
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.2, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  #
  # present_topics = apply(spatial_topicmix_kriged_all_topics[,3:(2+(nb_topics0))],1,function(g) which(g>0))
  # pure_stations = unlist(lapply(present_topics,function(g) length(g))) == 1
  # points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR" & pure_stations],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR" & pure_stations]),
  #        pch = 21, cex=1.2, bg = col[unlist(present_topics[stations_depths[,2] == "SUR" & pure_stations])])
  pie.colors.matrix = data.frame(matrix(nrow = length(which(stations_depths[,2] == "SUR")), ncol=length(functions), data = NA))
  pie.slices.matrix = data.frame(matrix(nrow = length(which(stations_depths[,2] == "SUR")), ncol=length(functions), data = NA))
  ii_pie = 0
  for (i_pie in which(stations_depths[,2] == "SUR"))
  {
    ii_pie = ii_pie+1
    station_functions = which(station_functional_composition[i_pie,] > 0)
    pie.colors.matrix[ii_pie,] = c(function_colors[station_functions],rep(NA,length(functions)-length(station_functions)))
    pie.slices.matrix[ii_pie,] = c(station_functional_composition[i_pie,station_functions],rep(NA,length(functions)-length(station_functions)))
  }
  space.pies(coord$x[stations_depths[,2] == "SUR"], coord$y[stations_depths[,2] == "SUR"],
             pie.slices = pie.slices.matrix, pie.colors = pie.colors.matrix,
             # pie.radius=3, pie.space=0.01,
             pie.radius=6, pie.space=0.4,
             link=TRUE, seg.lwd=1, seg.col=1, seg.lty=1, coord=NULL)
  #
  # draw.xy(x = spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"], 
  #         y = spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"],
  #         xx = rep(0.1,nrow(spatial_topicmix_kriged_all_topics[stations_depths[,2] == "SUR",])),
  #         yy = spatial_topicmix_kriged_all_topics[stations_depths[,2] == "SUR",3],
  #         width = 2, height = 10, border = 1,col=col[1], lwd=20,
  #         type = "h",
  #         silent = F)
  #
  # draw.barplot2D(x = spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"], 
  #                y = spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"],
  #                z = as.matrix(spatial_topicmix_kriged_all_topics[stations_depths[,2] == "SUR",3:ncol(spatial_topicmix_kriged_all_topics)]),
  #                width = 10, height = 10, lwd.frame = 0.001, col.frame = NULL, scale =T,
  #                col = col)
  # Plotting DCM:
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.2, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  # points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "DCM" & pure_stations],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "DCM" & pure_stations]),
  #        pch = 21, cex=1.2, bg = col[unlist(present_topics[stations_depths[,2] == "DCM" & pure_stations])])
  pie.colors.matrix = data.frame(matrix(nrow = length(which(stations_depths[,2] == "DCM")), ncol=length(functions), data = NA))
  pie.slices.matrix = data.frame(matrix(nrow = length(which(stations_depths[,2] == "DCM")), ncol=length(functions), data = NA))
  ii_pie = 0
  for (i_pie in which(stations_depths[,2] == "DCM"))
  {
    ii_pie = ii_pie+1
    station_topics = which(station_functional_composition[i_pie,] > 0)
    pie.colors.matrix[ii_pie,] = c(function_colors[station_functions],rep(NA,length(functions)-length(station_functions)))
    pie.slices.matrix[ii_pie,] = c(station_functional_composition[i_pie,station_functions],rep(NA,length(functions)-length(station_functions)))
  }
  space.pies(coord$x[stations_depths[,2] == "DCM"], coord$y[stations_depths[,2] == "DCM"],
             pie.slices = pie.slices.matrix, pie.colors = pie.colors.matrix, 
             # pie.radius=3, pie.space=0.01,
             pie.radius=6, pie.space=0.4,
             link=TRUE, seg.lwd=1, seg.col=1, seg.lty=1, coord=NULL)
  dev.off()
  
  ###
}

if (alltaxa_biogeographic_clustering)
{
  # Clustering:
  library(vegan)
  library(cluster)
  # Kriging:
  library(kriging)
  # To plot the kriged maps:
  library(ggplot2)
  library(gridExtra)
  library(scales)
  library(gstat)
  # To call grid.newpage()
  library(grid)
  # To plot shapes using readOGR (not available on cluster):
  library(rgdal)
  library(sp)
  library(rgeos)
  library(maptools)
  # To use raster manipulating functions:
  library(raster)
  # To use coltorgb:
  library(grDevices)
  library(ggtree)
  # To use theme_transparent and geom_subview:
  library(ggimage)
  library(marmap)
  
  nb_topics = 16
  nb_iter = 1000
  nb_real = 100
  thin = 25
  burnin = 2000
  # Gibbs_VEM_insert= "_VEM"
  # Gibbs_VEM_insert = "_GibbsShortChainNoAverage10sampleFold"
  Gibbs_VEM_insert = "_Gibbs"
  if (Gibbs_VEM_insert == "_VEM")
  {
    data.folder = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
    # assemblage_composition = readRDS(paste0(data.folder,"/Rtopicmodels_LDA_VEM_nb_topics",K,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/assemblage_composition.rds"))
    # } else if (Gibbs_VEM_insert == "_GibbsShortChainNoAverage10sampleFold")
  } else if (Gibbs_VEM_insert == "_Gibbs")
  {
    data.folder = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noArcticNoBiomark_insert,noLagoon_insert)
    # assemblage_composition = readRDS(paste0(data.folder,"/Rtopicmodels_LDA_Gibbs_alpha0.05:K_delta0.1_nb_topics10_nb_iter2000_nb_real100_occurrence/1st_best_realization/assemblage_composition.rds"))
    # assemblage_composition = readRDS(paste0(data.folder,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",K,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/assemblage_composition.rds"))
  }
  
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # taxo_groups_unmodified = levels(as.factor(assemblage_composition$taxogroup2))[sort.int(table(as.factor(assemblage_composition$taxogroup2)),index.return = T,decreasing = T)$ix]
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # functions = levels(as.factor(assemblage_composition$Function))[sort.int(table(as.factor(assemblage_composition$Function)),index.return = T,decreasing = T)$ix]
  functions = c("phototroph","photohost","endophotosymbiont","phagotroph","copepoda","pteropoda","gelatineous_carnivores_filterers","other metazoa","parasite","unknown")
  # selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity>100
  
  spatial_topicmix_kriged = readRDS(paste0(data.folder,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds"))
  
  # selecting the z.pred columns in all topics:
  documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
  # setting one topic per column
  documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("assemblage",1:nb_topics)))
  spatial_topicmix_kriged_all_topics = cbind(data.frame(x = spatial_topicmix_kriged[[1]]$x, y = spatial_topicmix_kriged[[1]]$y),documents)
  
  ############
  Hellinger_stations = 1/sqrt(2)*dist(sqrt(documents), method = "euclidean", diag = FALSE, upper = FALSE)
  Jaccard_stations = vegan::designdist(documents, "(b+c)/(a+b+c)", abcd=TRUE)
  Sorensen_stations = vegan::designdist(documents, "(b+c)/(2*a+b+c)", abcd=TRUE)
  Simpson_stations = vegan::designdist(documents, "pmin(b,c)/(pmin(b,c)+a)", abcd=TRUE)
  
  upgma_Hellinger = agnes(Hellinger_stations, diss =T, method = "average", keep.diss =F, keep.data =F)
  upgma_Jaccard = agnes(Jaccard_stations, diss =T, method = "average", keep.diss =F, keep.data =F)
  upgma_Sorensen = agnes(Sorensen_stations, diss =T, method = "average", keep.diss =F, keep.data =F)
  upgma_Simpson = agnes(Simpson_stations, diss =T, method = "average", keep.diss =F, keep.data =F)
  
  library(pvclust)
  pvclust_Hellinger = pvclust(t(sqrt(documents)),
                              method.dist = "euclidean",
                              #method.dist = "cor",
                              # method.dist = function(x) 1/sqrt(2)*dist(sqrt(x), method = "euclidean", diag = FALSE, upper = FALSE),
                              # method.dist = "cor", 
                              method.hclust = "average", 
                              nboot=1000)
  
  # pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_pvclust0.97.pdf"))
  pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_pvclust_hline13clusters.pdf"))
  # pdf(paste0(figure_folder,"/Complete_stations_Hellinger_Gibbs100r_16t_AllTaxa_pvclust.pdf"))
  # pdf(paste0(figure_folder,"/UPGMA_stations_cor_Gibbs100r_16t_AllTaxa_pvclust.pdf"))
  plot(pvclust_Hellinger, ann=F, cex=0.5, cex.axis = 2, lwd=1.5)
  abline(lty=2,h=0.59,lwd=1.5)
  #rect.hclust(upgma_Hellinger_SUR, k = nb_clust, border = col)
  # pvrect(pvclust_Hellinger,alpha = 0.97)
  title("Average Hellinger")
  # title("Correlation")
  dev.off()
  
  pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_",nb_clust,"clusters.pdf"))
  plot(upgma_Hellinger, which.plots=2, ann=F, cex=0.5, cex.axis = 2, lwd=1.5)
  #rect.hclust(upgma_Hellinger, k = nb_clust, border = 2:17)
  rect.hclust(upgma_Hellinger, k = nb_clust, border = col)
  title("Average Hellinger")
  dev.off()
  
  library(dendextend)
  pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_",nb_clust,"clusters_dendextend.pdf"))
  dend = color_branches(as.dendrogram(upgma_Hellinger),k=nb_clust, col=col)
  plot(dend, horiz=T, ann=F, cex=0.5, cex.axis = 2, lwd=2)
  rect.dendrogram(dend, k = nb_clust, horiz=T)
  labels(dend) = ""
  #abline(v = heights_per_k.dendrogram(dend)[paste0(nb_clust)], lwd = 2, lty = 2, col = "blue")
  title("Average Hellinger")
  dev.off()
  
  # Cophenetic distances:
  plot(Hellinger_stations,cophenetic(pvclust_Hellinger$hclust),asp=1)
  abline(0, 1)
  ########
  
  # grp_Jaccard = cutree(upgma_Jaccard, k = nb_clust)
  # grp_Sorensen = cutree(upgma_Sorensen, k = nb_clust)
  # grp_Simpson = cutree(upgma_Simpson, k = nb_clust)
  nb_clust_range = 5:30
  
  ii = 0
  mean_sd_sil_Hellinger = matrix(nrow = length(nb_clust_range), ncol = 2, data = 0, dimnames = list(nb_clust_range,c("Mean","sd")))
  for (nb_clust in nb_clust_range)
  {
    ii = ii+1
    grp_Hellinger = cutree(upgma_Hellinger, k = nb_clust)
    sil_Hellinger = silhouette(grp_Hellinger, Hellinger_stations)
    mean_sd_sil_Hellinger[ii,] = c(mean(sil_Hellinger[,3]),sd(sil_Hellinger[,3]))
  }
  
  library(Hmisc)
  pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_SUR-DCM_nbClustSilhouette.pdf"))
  errbar(nb_clust_range,mean_sd_sil_Hellinger[,1],
         yplus=mean_sd_sil_Hellinger[,1]+mean_sd_sil_Hellinger[,2],
         yminus=mean_sd_sil_Hellinger[,1]-mean_sd_sil_Hellinger[,2],ylab = "Mean silhouette", xlab = "Number of clusters")
  dev.off()
  
  signif_thres_range = seq(from=0.90,to=0.99,by=0.01)
  ii = 0
  mean_sd_sil_Hellinger = matrix(nrow = length(signif_thres_range), ncol = 3, data = 0, dimnames = list(signif_thres_range,c("Nb_clust","Mean_sil","sd_sil")))
  for (signif_thres in signif_thres_range)
  {
    ii = ii+1
    pvpick_Hellinger = pvpick(pvclust_Hellinger,alpha = signif_thres)
    nb_clust = length(pvpick_Hellinger$clusters)
    grp_Hellinger = rep(0,nrow(documents))
    names(grp_Hellinger) = rownames(documents)
    for (i_clust in 1:nb_clust)
    {
      grp_Hellinger[names(grp_Hellinger) %in% pvpick_Hellinger$clusters[[i_clust]]] = i_clust
    }
    grp_Hellinger[grp_Hellinger == 0] = (nb_clust+1):(nb_clust+length(which(grp_Hellinger == 0)))
    #grp_Hellinger = cutree(upgma_Hellinger_SUR, k = nb_clust)
    #grp_Hellinger = cutree(pvclust_Hellinger_SUR$hclust, k = nb_clust)
    # sil_Hellinger = silhouette(grp_Hellinger[grp_Hellinger != 1], as.dist(as.matrix(Hellinger_stations_SUR)[grp_Hellinger != 1,grp_Hellinger != 1]))
    sil_Hellinger = silhouette(grp_Hellinger, Hellinger_stations)
    # grp_Hellinger = cutree(upgma_Hellinger_DCM, k = nb_clust)
    # sil_Hellinger = silhouette(grp_Hellinger, Hellinger_stations_DCM)
    mean_sd_sil_Hellinger[ii,] = c(nb_clust,mean(sil_Hellinger[1:nb_clust,3]),sd(sil_Hellinger[1:nb_clust,3]))
  }
  
  library(Hmisc)
  pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_SUR-DCM_pvclustSilhouette.pdf"))
  errbar(signif_thres_range,mean_sd_sil_Hellinger[,2],
         yplus=mean_sd_sil_Hellinger[,2]+mean_sd_sil_Hellinger[,3],
         yminus=mean_sd_sil_Hellinger[,2]-mean_sd_sil_Hellinger[,3],ylab = "Mean silhouette", xlab = "Significance threshold")
  dev.off()
  
  ########
  #pvpick_Hellinger = pvpick(pvclust_Hellinger,alpha = 0.95)
  # pvpick_Hellinger = pvpick(pvclust_Hellinger,alpha = 0.90)
  pvpick_Hellinger = pvpick(pvclust_Hellinger,alpha = 0.96)
  nb_clust = length(pvpick_Hellinger$clusters)
  grp_Hellinger = rep(1,nrow(documents))
  names(grp_Hellinger) = rownames(documents)
  for (i_clust in 1:nb_clust)
  {
    grp_Hellinger[names(grp_Hellinger) %in% pvpick_Hellinger$clusters[[i_clust]]] = i_clust+1
  }
  #########
  nb_clust = 13
  # grp_Hellinger = cutree(upgma_Hellinger, k = nb_clust)
  #grp_Hellinger = cutree(upgma_Hellinger, k = nb_clust)
  grp_Hellinger = cutree(pvclust_Hellinger$hclust, k = nb_clust)
  #########
  
  color.pal1 = colorRampPalette(c("#7F0000","red","darkorange1","darkgoldenrod1","yellow"),space = "Lab")
  color.pal2 = colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")
  color.pal3 = colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")
  color.pal4 = colorRampPalette(c("#00007F","#007FFF","cyan"),space = "Lab")
  
  #######
  bat = getNOAA.bathy(-180, 180, -90, 90, res = 20, keep=F)
  blues = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1")
  greys = c(grey(0.6), grey(0.93), grey(0.99))
  ######
  
  ##########
  #cutree:
  col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))
  #pvclust:
  col = c("pink",color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4),"mediumorchid2")
  
  pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_Surplots_topicByTopic_marmap_stationClusteringHellinger_",nb_clust,"clusters.pdf"))
  # pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_Surplots_topicByTopic_marmap_stationClusteringUPGMAHellinger_",nb_clust,"clustersPVclust0.96.pdf"))
  # for (k in 1:(nb_clust+1))
  for (k in 1:nb_clust)
  {
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"]),
           pch = 21, cex=1.2, bg = ifelse(grp_Hellinger[stations_depths[,2] == "SUR"] == k, col[k], "white"))
  }
  dev.off()
  
  # pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_DCMplots_topicByTopic_marmap_stationClusteringHellinger_",nb_clust,"clusters.pdf"))
  pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_DCMplots_topicByTopic_marmap_stationClusteringUPGMAHellinger_",nb_clust,"clustersPVclust0.97.pdf"))
  for (k in 1:nb_clust)
  {
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "DCM"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "DCM"]),
           pch = 21, cex=1.2, bg = ifelse(grp_Hellinger[stations_depths[,2] == "DCM"] == k, col[k], "white"))
  }
  dev.off()
  
  ###########
  ######### cutree:
  if (nb_clust == 13)
    col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,2,11,7,6,3,5,14,12,8,9,13,16)]
  else if (nb_clust == 14)
    col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,2,11,7,6,3,5,14,15,8,9,12,13,16)]
  else if (nb_clust == 15)
    col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,2,11,10,7,6,3,5,14,15,8,9,12,13,16)]
  else if (nb_clust == 16)
    col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,2,11,10,7,6,3,5,1,14,15,8,9,12,13,16)]
  # col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(7))
  else if (nb_clust == 17)
    col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(5))[c(4,2,11,10,7,6,3,5,1,14,15,8,9,12,13,16,17)]
  else if (nb_clust == 18)
    col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(5),"violet")[c(4,2,11,10,7,6,18,3,5,1,14,15,8,9,12,13,16,17)]
  ########### pvclust:
  if (nb_clust == 13)
    col = c("pink",color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(1,c(11,5,13,1,14,4,3,6,2,7,12,8,16)+1)]
  else if (nb_clust == 17 && thres == 0.97)
    col = c("pink",color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4),"mediumorchid2")[c(1,c(17,1,2,10,11,5,15,9,12,14,4,15,3,6,7,8,16)+1)]
  else if (nb_clust == 17 && thres == 0.96)
    col = c("pink",color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4),"mediumorchid2")[c(1,c(17,1,2,5,11,10,15,9,14,4,12,15,3,6,7,8,16)+1)]
  
  pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_SurDCMplots_marmap_stationClusteringUPGMAHellinger_",nb_clust,"clustersPVclust0.96.pdf"))
  # present_topics = apply(spatial_topicmix_kriged_all_topics[,3:(2+(nb_topics0))],1,function(g) which(g>0))
  #
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"]),
         pch = 21, cex=1.2, 
         # bg = ifelse(!is.na(grp_Hellinger[stations_depths[,2] == "SUR"]),col[grp_Hellinger[stations_depths[,2] == "SUR"]],"black"))
         bg = col[grp_Hellinger[stations_depths[,2] == "SUR"]])
  #
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "DCM"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "DCM"]),
         pch = 21, cex=1.2, 
         bg = col[grp_Hellinger[stations_depths[,2] == "DCM"]])
  # bg = col[grp_Hellinger[stations_depths[,2] == "DCM"]])
  dev.off()
  
  ###############
  # Surf. or DCM only clustering:
  ###############
  Hellinger_stations_DCM = 1/sqrt(2)*dist(sqrt(documents[stations_depths[,2] == "SUR",]), method = "euclidean", diag = FALSE, upper = FALSE)
  upgma_Hellinger_DCM = agnes(Hellinger_stations_SUR, diss =T, method = "average", keep.diss =F, keep.data =F)
  # Hellinger_stations_DCM = 1/sqrt(2)*dist(sqrt(documents[stations_depths[,2] == "DCM",]), method = "euclidean", diag = FALSE, upper = FALSE)
  # upgma_Hellinger_DCM = agnes(Hellinger_stations_DCM, diss =T, method = "average", keep.diss =F, keep.data =F)
  
  library(pvclust)
  pvclust_Hellinger_SUR = pvclust(t(sqrt(documents[stations_depths[,2] == "SUR",])),
                                  method.dist = "euclidean",
                                  #method.dist = "cor",
                                  # method.dist = function(x) 1/sqrt(2)*dist(sqrt(x), method = "euclidean", diag = FALSE, upper = FALSE),
                                  # method.dist = "cor", 
                                  method.hclust = "average", 
                                  nboot=1000)
  
  pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_SURonly_pvclust0.98.pdf"))
  # pdf(paste0(figure_folder,"/Complete_stations_Hellinger_Gibbs100r_16t_AllTaxa_SURonly_pvclust.pdf"))
  # pdf(paste0(figure_folder,"/UPGMA_stations_cor_Gibbs100r_16t_AllTaxa_SURonly_pvclust.pdf"))
  plot(pvclust_Hellinger_SUR, ann=F, cex=0.5, cex.axis = 2, lwd=1.5)
  #rect.hclust(upgma_Hellinger_SUR, k = nb_clust, border = col)
  pvrect(pvclust_Hellinger_SUR,alpha = 0.98)
  # title("Complete Hellinger")
  title("Average Hellinger")
  # title("Correlation")
  dev.off()
  
  #############
  signif_thres_range = seq(from=0.90,to=0.99,by=0.01)
  ii = 0
  mean_sd_sil_Hellinger = matrix(nrow = length(signif_thres_range), ncol = 3, data = 0, dimnames = list(signif_thres_range,c("Nb_clust","Mean_sil","sd_sil")))
  for (signif_thres in signif_thres_range)
  {
    ii = ii+1
    pvpick_Hellinger = pvpick(pvclust_Hellinger_DCM,alpha = signif_thres)
    nb_clust = length(pvpick_Hellinger$clusters)
    grp_Hellinger = rep(0,nrow(documents[stations_depths[,2] == "DCM",]))
    names(grp_Hellinger) = rownames(documents[stations_depths[,2] == "DCM",])
    for (i_clust in 1:nb_clust)
    {
      grp_Hellinger[names(grp_Hellinger) %in% pvpick_Hellinger$clusters[[i_clust]]] = i_clust
    }
    grp_Hellinger[grp_Hellinger == 0] = (nb_clust+1):(nb_clust+length(which(grp_Hellinger == 0)))
    #grp_Hellinger = cutree(upgma_Hellinger_SUR, k = nb_clust)
    #grp_Hellinger = cutree(pvclust_Hellinger_SUR$hclust, k = nb_clust)
    # sil_Hellinger = silhouette(grp_Hellinger[grp_Hellinger != 1], as.dist(as.matrix(Hellinger_stations_SUR)[grp_Hellinger != 1,grp_Hellinger != 1]))
    sil_Hellinger = silhouette(grp_Hellinger, Hellinger_stations_DCM)
    # grp_Hellinger = cutree(upgma_Hellinger_DCM, k = nb_clust)
    # sil_Hellinger = silhouette(grp_Hellinger, Hellinger_stations_DCM)
    mean_sd_sil_Hellinger[ii,] = c(nb_clust,mean(sil_Hellinger[1:nb_clust,3]),sd(sil_Hellinger[1:nb_clust,3]))
  }
  
  library(Hmisc)
  pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_DCMonly_pvclustSilhouette.pdf"))
  errbar(signif_thres_range,mean_sd_sil_Hellinger[,2],
         yplus=mean_sd_sil_Hellinger[,2]+mean_sd_sil_Hellinger[,3],
         yminus=mean_sd_sil_Hellinger[,2]-mean_sd_sil_Hellinger[,3],ylab = "Mean silhouette", xlab = "Significance threshold")
  dev.off()
  ############
  nb_clust_range = 2:30
  ii = 0
  mean_sd_sil_Hellinger = matrix(nrow = length(nb_clust_range), ncol = 2, data = 0, dimnames = list(nb_clust_range,c("Mean","sd")))
  for (nb_clust in nb_clust_range)
  {
    ii = ii+1
    #grp_Hellinger = cutree(upgma_Hellinger_SUR, k = nb_clust)
    grp_Hellinger = cutree(pvclust_Hellinger_SUR$hclust, k = nb_clust)
    sil_Hellinger = silhouette(grp_Hellinger, Hellinger_stations_SUR)
    # grp_Hellinger = cutree(upgma_Hellinger_DCM, k = nb_clust)
    # sil_Hellinger = silhouette(grp_Hellinger, Hellinger_stations_DCM)
    mean_sd_sil_Hellinger[ii,] = c(mean(sil_Hellinger[,3]),sd(sil_Hellinger[,3]))
  }
  
  # pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_SURonly_nbClustSilhouette.pdf"))
  pdf(paste0(figure_folder,"/Complete_stations_Hellinger_Gibbs100r_16t_AllTaxa_SURonly_nbClustSilhouette.pdf"))
  # pdf(paste0(figure_folder,"/UPGMA_stations_Hellinger_Gibbs100r_16t_AllTaxa_DCMonly_nbClustSilhouette.pdf"))
  errbar(nb_clust_range,mean_sd_sil_Hellinger[,1],
         yplus=mean_sd_sil_Hellinger[,1]+mean_sd_sil_Hellinger[,2],
         yminus=mean_sd_sil_Hellinger[,1]-mean_sd_sil_Hellinger[,2],ylab = "Mean silhouette", xlab = "Number of clusters")
  abline(v = 2, lty = 2)
  # abline(v = 11, lty = 2)
  # abline(v = 14, lty = 2)
  abline(v = 15, lty = 2)
  dev.off()
  
  # SUR only:
  ##########
  #nb_clust = 15
  # nb_clust = 5
  
  #grp_Hellinger = cutree(pvclust_Hellinger_SUR$hclust, k = nb_clust)
  # grp_Hellinger = cutree(upgma_Hellinger_SUR, k = nb_clust)
  
  pvpick_Hellinger = pvpick(pvclust_Hellinger_SUR,alpha = 0.96)
  nb_clust = length(pvpick_Hellinger$clusters)
  grp_Hellinger = rep(1,nrow(documents[stations_depths[,2] == "SUR",]))
  names(grp_Hellinger) = rownames(documents[stations_depths[,2] == "SUR",])
  for (i_clust in 1:nb_clust)
  {
    grp_Hellinger[names(grp_Hellinger) %in% pvpick_Hellinger$clusters[[i_clust]]] = i_clust+1
  }
  
  col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))
  #col = c("red","blue","green","orange","cyan")
  
  pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_topicByTopic_marmap_stationClusteringUPGMAHellinger_SURonly_",nb_clust,"clustersPVclust0.96.pdf"))
  for (k in 1:(nb_clust+1))
  {
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"]),
           pch = 21, cex=1.2, bg = ifelse(grp_Hellinger == k, col[k], "white"))
  }
  dev.off()
  
  ######## UPGMA:
  if (nb_clust == 14) #cut tree
    col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,7,11,10,6,3,5,14,15,8,9,12,13,16)]
  else if (nb_clust == 12) # pvclust
    col = c("pink",color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(1,c(3,10,1,5,2,4,6,12,14,7,8,16)+1)]
  ######## Complete:
  #col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,11,10,7,3,2,6,5,14,8,9,12,13,16,15)]
  
  pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_stationClusteringUPGMAHellinger_SURonly_",nb_clust,"clustersPVclust0.96.pdf"))
  # present_topics = apply(spatial_topicmix_kriged_all_topics[,3:(2+(nb_topics0))],1,function(g) which(g>0))
  #
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"]),
         pch = 21, cex=1.2, bg = col[grp_Hellinger])
  dev.off()
  
  # DCM only:
  ##########
  nb_clust = 11
  grp_Hellinger = cutree(upgma_Hellinger_DCM, k = nb_clust)
  
  col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))
  
  pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_topicByTopic_marmap_stationClusteringHellinger_DCMonly_",nb_clust,"clusters.pdf"))
  for (k in 1:nb_clust)
  {
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "DCM"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "DCM"]),
           pch = 21, cex=1.2, bg = ifelse(grp_Hellinger == k, col[k], "white"))
  }
  dev.off()
  
  col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,11,2,10,5,14,9,8,12,13,16)]
  
  pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t",ifelse(nb_clust==nb_clust1,"",paste0("_",nb_clust1,"firstClusters")),"_stationClusteringHellinger_DCMonly_",nb_clust,"clusters.pdf"))
  # present_topics = apply(spatial_topicmix_kriged_all_topics[,3:(2+(nb_topics0))],1,function(g) which(g>0))
  #
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "DCM"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "DCM"]),
         pch = 21, cex=1.2, bg = col[grp_Hellinger])
  dev.off()
  
  # pdf(paste0(figure_folder,"/UPGMA_stations_Jaccard_Gibbs100r_16t_AllTaxa.pdf"))
  # plot(upgma_Jaccard, which.plots=2, ann=F, cex=0.5, cex.axis = 2, lwd=1.5)
  # rect.hclust(upgma_Jaccard, k = nb_clust)
  # title("Average Jaccard")
  # dev.off()
  # 
  # pdf(paste0(figure_folder,"/UPGMA_stations_Sorensen_Gibbs100r_16t_AllTaxa.pdf"))
  # plot(upgma_Sorensen, which.plots=2, ann=F, cex=0.5, cex.axis = 2, lwd=1.5)
  # rect.hclust(upgma_Sorensen, k = nb_clust)
  # title("Average Sorensen")
  # dev.off()
  # 
  # pdf(paste0(figure_folder,"/UPGMA_stations_Simpson_Gibbs100r_16t_AllTaxa.pdf"))
  # plot(upgma_Simpson, which.plots=2, ann=F, cex=0.5, cex.axis = 2, lwd=1.5)
  # rect.hclust(upgma_Simpson, k = nb_clust)
  # title("Average Simpson")
  # dev.off()
  
  ############
  
  # topic_reordering = c(1,3,9,7,
  #                      10,8,4,6,
  #                      11,16,15,12,
  #                      14,5,13,2)
  # grp_Hellinger = grp_Hellinger[]
  
  # assemblage_reordering = c(1,3,6,4,8,7,9,11,10,12,15,16,2,13,5,14)
  #   topic_reordering = 1:9
  #spatial_topicmix_kriged_all_topics[,2 + (1:nb_topics)] = spatial_topicmix_kriged_all_topics[,2 + topic_reordering]
  
  
  
  ##########
  # pdf(paste0(figure_folder,"/AllTaxa_Gibbs100r",nb_topics,"t_Sur_marmap_stationClusteringHellinger_NbClusterComparison.pdf"),height=9,width=9)
  # par(mfrow = c(3,2))
  # # present_topics = apply(spatial_topicmix_kriged_all_topics[,3:(2+(nb_topics0))],1,function(g) which(g>0))
  # for (nb_clust in 14:18)
  # {
  #   if (nb_clust == 14)
  #     col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,2,11,7,6,3,5,14,15,8,9,12,13,16)]
  #   else if (nb_clust == 15)
  #     col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,2,11,10,7,6,3,5,14,15,8,9,12,13,16)]
  #   else if (nb_clust == 16)
  #     col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))[c(4,2,11,10,7,6,3,5,1,14,15,8,9,12,13,16)]
  #   # col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(7))
  #   else if (nb_clust == 17)
  #     col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(5))[c(4,2,11,10,7,6,3,5,1,14,15,8,9,12,13,16,17)]
  #   else if (nb_clust == 18)
  #     col = c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(5),"violet")[c(4,2,11,10,7,6,18,3,5,1,14,15,8,9,12,13,16,17)]
  # 
  #   grp_Hellinger = cutree(upgma_Hellinger, k = nb_clust)
  #   plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  #   plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  #   points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"]),
  #          pch = 21, cex=1.2, bg = col[grp_Hellinger[stations_depths[,2] == "SUR"]])
  # }
  # dev.off()
  
}

if (assemblage_maps)
{
  library(kriging)
  # To plot the kriged maps:
  library(ggplot2)
  library(gridExtra)
  library(scales)
  library(gstat)
  # To call grid.newpage()
  library(grid)
  # To plot shapes using readOGR (not available on cluster):
  library(rgdal)
  library(sp)
  library(rgeos)
  library(maptools)
  # To use raster manipulating functions:
  library(raster)
  # To use coltorgb:
  library(grDevices)
  library(ggtree)
  # To use theme_transparent and geom_subview:
  library(ggimage)
  library(marmap)
  
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100
  
  optimalK_min.crossValid = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
  optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
  optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
  optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]] 
  optimalK_prevalenceSUR.DCM.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalenceSUR-DCM.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
  optimalK_prevalenceSUR.DCM.min.crossValid.allTaxa = optimalK_prevalenceSUR.DCM.min.crossValid.complete[[1]]
  optimalK_prevalenceSUR.DCM.min.crossValid = optimalK_prevalenceSUR.DCM.min.crossValid.complete[[2]]
  
  data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTAxa",noArcticNoBiomark_insert,noLagoon_insert)
  load(paste0(data.folder_name,"/coord.Rdata"))
  
  Gibbs = 1
  VEM = 0
  #
  maps = 0
  barplots = 1
  additional_plots = 0
  
  nb_iter = 1000
  nb_real = 100
  thin = 25
  burnin = 2000
  
  # group_vect = c("Bacillariophyta","Collodaria","Acantharea","Arthropoda","Diplonemida","Dinophyceae")
  # number of topics to be represented (needs to be < nb_topics-1, or equal to nb_topics):
  # nb_topics1_vect = c(11,13,8,10,9,12)
  
  # group_vect = c("Chordata","Vannellida","MAST-3,_12","RAD-C")
  # group_vect = c("Phaeodaria","Annelida","Mollusca","Bacillariophyta","Dinophyceae","Chlorophyceae")
  group_vect = "AllTaxa"
  
  # Loading batymetric data for the specified range of longitudes and latitudes in degrees, whith resolution in minutes
  bat = getNOAA.bathy(-180, 180, -90, 90, res = 50, keep=T)
  blues = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1")
  greys = c(grey(0.6), grey(0.93), grey(0.99))

  # group = "AllTaxa"
  # group = "Bacillariophyta"
  # group = "Collodaria"
  # group = "Arthropoda"
  # group = "Diplonemida"
  # group = "Chordata"
  # group = "Mollusca"
  # group = "Acantharea"
  # group = "Dinophyceae"
  # group = "Bolidophyceae"
  
  pie_positions.SUR = read.table(results_folder,"/Surf_pies_modified.txt",sep=",",header=F)
  # pie_positions.SUR[c(55,57) - 1,] = pie_positions.SUR[c(57,55) - 1,]
  pie_positions.SUR[55:57 - 1,] = pie_positions.SUR[c(56,57,55) - 1,]
  pie_positions.SUR[56 - 1,] = pie_positions.SUR[56 - 1,] + c(1.5,0)
  pie_positions.SUR[45:46 - 1,] = pie_positions.SUR[46:45 - 1,]
  pie_positions.SUR[51 - 1,] = pie_positions.SUR[51 - 1,] + c(-2,3)
  rownames(pie_positions.SUR) = rownames(coord[stations_depths[,2] == "SUR",])[-44]
  
  pie_positions.DCM = read.table(results_folder,"/DCM_pies_modified.txt",sep=",",header=F)
  rownames(pie_positions.DCM) = rownames(coord[stations_depths[,2] == "DCM",])
  
  # File transfer from cluster:
  # for (group in taxo_groups[selected_groups][-(1:30)])
  # {
  #   nb_topics = optimalK_prevalence.min.crossValid[taxo_groups == group]
  #   if (!is.na(nb_topics))
  #   {
  #     data.folder_name = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",group,"_noLagoon/")
  #     local.data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",group,"_noLagoon/")
  #     target.file = paste0("Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence")
  #     command = paste0("cp -r ",data.folder_name,target.file," ",local.data.folder_name,target.file)
  #     system(command, intern=TRUE)
  #   }
  # }
  
  i_group = 0
  for (group in group_vect)
  {
    cat("\n",group)
    i_group = i_group+1
    if (group != "AllTaxa")
    {
      nb_topics = optimalK_prevalence.min.crossValid[taxo_groups == group]
      # nb_topics1 = nb_topics1_vect[i_group]
      nb_topics1 = nb_topics
    } else 
    {
      nb_topics = optimalK_prevalence.min.crossValid.allTaxa
      nb_topics1 = nb_topics
    }
      
    if (nb_topics == nb_topics1-1)
      cat("\n nb_topics1 must be < nb_topics-1 or = nb_topics.")
    # data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",group,"_noLagoon")
    # data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",group,"_noLagoon")
    # data.folder_name = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",group,"_noLagoon")
    data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",group,"_noLagoon")
    if (VEM)
    {
      spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
    } else if (Gibbs)
    {
      # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter250_nb_real100_best_thin2_burnin0_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
      spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds"))
    }
    
    # selecting the z.pred columns in all topics:
    documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
    # setting one topic per column
    documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("assemblage",1:nb_topics)))
    # Concatenating the spatial coord. with documents into spatial_topicmix_kriged_all_topics:
    spatial_topicmix_kriged_all_topics = cbind(data.frame(x = spatial_topicmix_kriged[[1]]$x, y = spatial_topicmix_kriged[[1]]$y),documents)
    
    # # Storing all assemblages into a single dataframe:
    # spatial_topicmix_kriged_all_topics = data.frame(x = spatial_topicmix_kriged[[1]]$x, y = spatial_topicmix_kriged[[1]]$y)
    # rownames(spatial_topicmix_kriged_all_topics) = rownames(spatial_topicmix_kriged[[1]])
    # for (k in 1:nb_topics)
    # {
    #   spatial_topicmix_kriged[[k]]$z.pred[spatial_topicmix_kriged[[k]]$z.pred < 0.001] = 0
    #   spatial_topicmix_kriged_all_topics = cbind(spatial_topicmix_kriged_all_topics,spatial_topicmix_kriged[[k]]$z.pred)
    #   colnames(spatial_topicmix_kriged_all_topics)[2+k] = paste0("z.pred",k)
    # }
    
    if (group == "AllTaxa" && Gibbs && nb_topics == 16 && nb_topics1 == 16)
    {
      color.pal1 = colorRampPalette(c("#7F0000","red","darkorange1","darkgoldenrod1","yellow"),space = "Lab")
      color.pal2 = colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")
      color.pal3 = colorRampPalette(c("azure4","antiquewhite3","aliceblue"),space = "Lab")
      color.pal4 = colorRampPalette(c("#00007F","#007FFF","cyan"),space = "Lab")
    } else
    {
      # color.pal = colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"),space = "Lab")
      color.pal = colorRampPalette(c("#00007F", "#007FFF", "cyan", "darkgreen", "yellow", "darkorange1", "red", "#7F0000"),space = "Lab")
      # color.pal = colorRampPalette(c("#00007F", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"),space = "Lab")
      color.pal.warm = colorRampPalette(c("#7F0000","red","darkorange1","darkgoldenrod1","yellow"),space = "Lab")
      color.pal.green = colorRampPalette(c("#7FFF7F","darkgreen"),space = "Lab")
      color.pal.blue = colorRampPalette(c("cyan","#007FFF","blue","#00007F"),space = "Lab")
      # color.pal = colorRampPalette(c("#00007F", "#007FFF", "cyan", "#7FFF7F", "darkgreen", "yellow", "darkgoldenrod1", "darkorange1", "red", "#7F0000"),space = "Lab")
      # color.pal = colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"),space = "Lab")
    }
    
    if (group != "AllTaxa" || nb_topics > nb_topics1)
    {
      # mean_latitude = vector(length = ncol(documents), mode = "numeric")
      # Computing the latitude of topics' barycentres in surface:
      mean_abs_latitude = vector(length = ncol(documents), mode = "numeric")
      for (k in 1:ncol(documents))
      {
        # mean_latitude[k] = weighted.mean(coord$y[rownames(coord) %in% rownames(documents) & stations_depths[,2] == "SUR"],
        #                                  w=documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",k]/sum(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",k]))
        mean_abs_latitude[k] = weighted.mean(abs(coord$y)[rownames(coord) %in% rownames(documents) & stations_depths[,2] == "SUR"],
                                             w=documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",k]/sum(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",k]))  
      }
      
      # Sorting topics by their abundance in surface samples:
      sorted_SUR_assemblages = sort.int(colSums(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]),decreasing=T,index.return=T)
      if (nb_topics > nb_topics1)
      {
        # Keeping only the nb_topics1 most abundant topics in Surf. samples for representation:
        spatial_topicmix_kriged_all_topics[,2+(1:(nb_topics1+1))] = cbind(spatial_topicmix_kriged_all_topics[,2 + sorted_SUR_assemblages$ix[1:nb_topics1]],
                                                                          rowSums(spatial_topicmix_kriged_all_topics[,2 + sorted_SUR_assemblages$ix[(nb_topics1+1):nb_topics]]))
        col = c(vector(length = nb_topics1, mode="numeric"),"grey")
      } else
      {
        spatial_topicmix_kriged_all_topics[,2+(1:nb_topics1)] = spatial_topicmix_kriged_all_topics[,2 + sorted_SUR_assemblages$ix[1:nb_topics1]]
        col = vector(length = nb_topics, mode="numeric")
      }
      
      # Dark red color for the most abundant topic:
      col[1] = "#7F0000"
      # sorted_latitudes = sort.int(mean_latitude[sorted_SUR_assemblages$ix[1:nb_topics1]][-1],decreasing=T,index.return=T)
      # Sorting the nb_topics1 most abundant topics by the absolute latitude of their barycentre, excluding the most abundant one:
      sorted_abs_latitudes = sort.int(mean_abs_latitude[sorted_SUR_assemblages$ix[1:nb_topics1]][-1],decreasing=T,index.return=T)
      # Blue palette for the topics above 50:
      if (length(which(sorted_abs_latitudes$x>arctic_bound)) == 1)
      {
        col[sorted_abs_latitudes$ix[sorted_abs_latitudes$x>arctic_bound]+1] = "cyan"
      } else if (length(which(sorted_abs_latitudes$x>arctic_bound)) == 2)
      {
        col[sorted_abs_latitudes$ix[sorted_abs_latitudes$x>arctic_bound]+1] = c("cyan","#007FFF")
      } else if (length(which(sorted_abs_latitudes$x>arctic_bound)) > 2)
        col[sorted_abs_latitudes$ix[sorted_abs_latitudes$x>arctic_bound]+1] = color.pal.blue(length(which(sorted_abs_latitudes$x>arctic_bound)))
      # Red-yellow palette for topics between 50 and 20, exclusing the dark red color already used for the most abundant topic:
      if (length(which(sorted_abs_latitudes$x<arctic_bound & sorted_abs_latitudes$x>tropic_bound)) > 0)
        col[sorted_abs_latitudes$ix[sorted_abs_latitudes$x<arctic_bound & sorted_abs_latitudes$x>tropic_bound]+1] = color.pal.warm(length(which(sorted_abs_latitudes$x<arctic_bound & sorted_abs_latitudes$x>tropic_bound))+1)[-1]
      # Green palette for topics between 0 and 20:
      if (length(which(sorted_abs_latitudes$x<tropic_bound)) > 0)
        col[sorted_abs_latitudes$ix[sorted_abs_latitudes$x<tropic_bound]+1] = color.pal.green(length(which(sorted_abs_latitudes$x<tropic_bound)))
    }
    
    if (group == "Bacillariophyta")
    {
      if (VEM && nb_topics == 6)
      {
        # reordering topics:
        topic_reordering = c(1,5,3,4,2,6)
        spatial_topicmix_kriged_all_topics[,(2+1):ncol(spatial_topicmix_kriged_all_topics)] = spatial_topicmix_kriged_all_topics[,2+topic_reordering]
      } else if (Gibbs)
      {
        # if (nb_topics == 14 && nb_topics1 == 8)
        #   topic_reordering = c(2,3,1,4,5,8,6,7,9)
        # else if (nb_topics == 12 && nb_topics1 == 8)
        # topic_reordering = c(2,3,1,4,5,8,7,6,9)
        # topic_reordering = 1:(nb_topics1+1)
        # spatial_topicmix_kriged_all_topics[,2 + (1:(nb_topics1+1))] = spatial_topicmix_kriged_all_topics[,2 + topic_reordering]
        
        # AllTaxa : c(color.pal1(6),color.pal2(3),color.pal3(3),color.pal4(4))
      }
    }
    
    if (group == "Arthropoda")
    {
      if (VEM && nb_topics == 8)
      {
        if (nb_topics == 8)
        {
          # reordering topics:
          topic_reordering = c(4,1,3,2,7,6,5,8)
        } else if (nb_topics == 6)
          # reordering topics:
          topic_reordering = c(1,6,4,3,2,5)
        spatial_topicmix_kriged_all_topics[,(2+1):ncol(spatial_topicmix_kriged_all_topics)] = spatial_topicmix_kriged_all_topics[,2+topic_reordering]
      } else if (Gibbs)
      {
        if (nb_topics > nb_topics1)
        {
          # if (nb_topics == 14 && nb_topics1 == 8)
          #   topic_reordering = c(2,3,1,4,5,8,6,7,9)
          # else if (nb_topics == 12 && nb_topics1 == 8)
          #   topic_reordering = c(2,3,1,4,5,8,7,6,9)
          # topic_reordering = 1:(nb_topics1+1)
          # spatial_topicmix_kriged_all_topics[,2 + (1:(nb_topics1+1))] = spatial_topicmix_kriged_all_topics[,2 + topic_reordering]
          # 
          # col = c(color.pal(nb_topics1),"grey")
        }
      }
    }
    
    if (group == "Collodaria")
    {
      if (VEM && nb_topics == 7)
      {
        # reordering topics:
        topic_reordering = c(6,1,5,4,2,3,7)
        spatial_topicmix_kriged_all_topics[,(2+1):ncol(spatial_topicmix_kriged_all_topics)] = spatial_topicmix_kriged_all_topics[,2+topic_reordering]
      } else if (Gibbs)
      {
        if (nb_topics > nb_topics1)
        {
          # if (nb_topics == 14 && nb_topics1 == 8)
          #   topic_reordering = c(2,3,1,4,5,8,6,7,9)
          # else if (nb_topics == 12 && nb_topics1 == 8)
          #   topic_reordering = c(2,3,1,4,5,8,7,6,9)
          # topic_reordering = 1:(nb_topics1+1)
          # spatial_topicmix_kriged_all_topics[,2 + (1:(nb_topics1+1))] = spatial_topicmix_kriged_all_topics[,2 + topic_reordering]
          # 
          # col = c(color.pal(nb_topics1),"grey")
        }
      }
    }
    
    if (group == "Acantharea")
    {
      if (VEM && nb_topics == 7)
      {
        # reordering topics:
        topic_reordering = c(5,2,1,3,6,4,7)
        spatial_topicmix_kriged_all_topics[,(2+1):ncol(spatial_topicmix_kriged_all_topics)] = spatial_topicmix_kriged_all_topics[,2+topic_reordering]
      } else if (Gibbs)
      {
        if (nb_topics > nb_topics1)
        {
          # if (nb_topics == 14 && nb_topics1 == 8)
          #   topic_reordering = c(2,3,1,4,5,8,6,7,9)
          # else if (nb_topics == 12 && nb_topics1 == 8)
          #   topic_reordering = c(2,3,1,4,5,8,7,6,9)
          # topic_reordering = 1:(nb_topics1+1)
          # spatial_topicmix_kriged_all_topics[,2 + (1:(nb_topics1+1))] = spatial_topicmix_kriged_all_topics[,2 + topic_reordering]
          
          # col = c(color.pal(10),"grey")[]
        }
      }
    }
    
    if (group == "AllTaxa")
    {
      if (Gibbs)
      {
        if (nb_topics1 < nb_topics)
        {
          spatial_topicmix_kriged_all_topics[,2 + (1:(nb_topics1+1))] = cbind(spatial_topicmix_kriged_all_topics[,2 + sort.int(colSums(documents),decreasing=T,index.return=T)$ix[1:nb_topics1]],
                                                                              rowSums(spatial_topicmix_kriged_all_topics[,2 + sort.int(colSums(documents),decreasing=T,index.return=T)$ix[(nb_topics1+1):nb_topics]]))
          col = c(color.pal(nb_topics1),"grey")
        } else
        {
          # topic_reordering = c(1,3,9,7,
          #                      10,8,4,6,
          #                      11,16,15,12,
          #                      14,5,13,2)
          topic_reordering = c(1,3,9,7,
                               10,8,4,6,
                               11,16,15,12,
                               2,13,5,14)
          # assemblage_reordering = c(1,3,6,4,8,7,9,11,10,12,15,16,2,13,5,14)
          #   topic_reordering = 1:9
          spatial_topicmix_kriged_all_topics[,2 + (1:nb_topics)] = spatial_topicmix_kriged_all_topics[,2 + topic_reordering]
          
          col = c(color.pal1(6),color.pal2(3),color.pal3(3),rev(color.pal4(4)))
        }
      }
    }
    
    ########
    # alpha = 0.1
    # delta = 0.1
    # nb_iter = 2000
    # nb_real = 100
    # local_dirname = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa_noLagoon/")
    # filename_insert = "Rtopicmodels_LDA_Gibbs"
    # for (nb_topics in 4:14)
    # {
    #   # alpha = 50/nb_topics
    #   local_subdirname = paste0(local_dirname,filename_insert,"_alpha",ifelse(alpha==50/nb_topics,"50:K",alpha),"_delta",delta,"_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_occurrence/")
    #   filename = paste0(filename_insert,"_alpha",ifelse(alpha==50/nb_topics,"50:K",alpha),"_delta",delta,"_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_occurrence.Rdata")
    #   load(paste0(local_subdirname,filename))
    #   for (i in 1:100)
    #     Result[[i]] = Result[[i]]@fitted[[1]]
    #   # test = load(paste0(local_subdirname,filename))
    #   # cat(test,"\n")
    #   save(Result,file=paste0(local_subdirname,filename))
    # }
    # for (nb_topics in 2:14)
    # {
    #   alpha = 50/nb_topics
    #   local_subdirname = paste0(local_dirname,filename_insert,"_alpha",ifelse(alpha==50/nb_topics,"50:K",alpha),"_delta",delta,"_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_occurrence/")
    #   filename = paste0(filename_insert,"_alpha",ifelse(alpha==50/nb_topics,"50:K",alpha),"_delta",delta,"_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_occurrence.Rdata")
    #   load(paste0(local_subdirname,filename))
    #   for (i in 1:100)
    #     Result[[i]] = Result[[i]]@fitted[[1]]
    #   # test = load(paste0(local_subdirname,filename))
    #   # cat(test,"\n")
    #   save(Result,file=paste0(local_subdirname,filename))
    # }
    # local_dirname = paste0(data_folder_workspace0,/18S_V9_TARA_CompleteSizeRange_byStationByDepth_Bacillariophyta_noLagoon/")
    # alpha = 0.1
    # for (nb_topics in 2:14)
    # {
    #   # alpha = 50/nb_topics
    #   local_subdirname = paste0(local_dirname,filename_insert,"_alpha",ifelse(alpha==50/nb_topics,"50:K",alpha),"_delta",delta,"_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_occurrence/")
    #   filename = paste0(filename_insert,"_alpha",ifelse(alpha==50/nb_topics,"50:K",alpha),"_delta",delta,"_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_occurrence.Rdata")
    #   load(paste0(local_subdirname,filename))
    #   for (i in 1:100)
    #     Result[[i]] = Result[[i]]@fitted[[1]]
    #   # test = load(paste0(local_subdirname,filename))
    #   # cat(test,"\n")
    #   save(Result,file=paste0(local_subdirname,filename))
    # }
    # for (nb_topics in 2:14)
    # {
    #   alpha = 50/nb_topics
    #   local_subdirname = paste0(local_dirname,filename_insert,"_alpha",ifelse(alpha==50/nb_topics,"50:K",alpha),"_delta",delta,"_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_occurrence/")
    #   filename = paste0(filename_insert,"_alpha",ifelse(alpha==50/nb_topics,"50:K",alpha),"_delta",delta,"_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_occurrence.Rdata")
    #   load(paste0(local_subdirname,filename))
    #   for (i in 1:100)
    #     Result[[i]] = Result[[i]]@fitted[[1]]
    #   # test = load(paste0(local_subdirname,filename))
    #   # cat(test,"\n")
    #   save(Result,file=paste0(local_subdirname,filename))
    # }
    
    #############
    # data(nw.atlantic)
    # atl = as.bathy(nw.atlantic)
    # test.plot = autoplot(atl, geom=c("raster", "contour"), colour=NA, size=0.1) + scale_fill_gradient2(low="dodgerblue4", mid="gainsboro", high="darkgreen")
    
    # setwd(data_folder)
    # #Try 1 (problem: uses only the first provided colors):
    # pdf("test_marmap.pdf")
    # plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys), c(min(bat), 0, blues))) #plot map without isobaths
    # plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    # pie.colors.matrix = matrix(rep(color.pal(nb_topics),length(which(stations_depths[,2] == "SUR"))),ncol=nb_topics,byrow = T)
    # pie.slices.matrix = spatial_topicmix_kriged_all_topics[stations_depths[,2] == "SUR",3:(2+nb_topics)]
    # space.pies(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"], spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"], pie.slices = pie.slices.matrix,
    #            pie.colors = pie.colors.matrix, pie.radius=3.5, pie.space=0.01,
    #            link=TRUE, seg.lwd=0.5, seg.col=1, seg.lty=1, coord=NULL)
    # dev.off()
    # 
    # # #Try 2 (problem: does not print the pies):
    # pdf("test_marmap.pdf")
    # plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys), c(min(bat), 0, blues))) #plot map without isobaths
    # plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    # for (i_pie in which(stations_depths[,2] == "SUR"))
    # {
    #   station_topics = which(spatial_topicmix_kriged_all_topics[i_pie,3:(2+nb_topics)] > 0)
    #   space.pies(spatial_topicmix_kriged_all_topics$x[i_pie], spatial_topicmix_kriged_all_topics$y[i_pie], pie.slices = spatial_topicmix_kriged_all_topics[i_pie, 2 + station_topics],
    #              pie.colors = matrix(color.pal(nb_topics)[station_topics],nrow=1), pie.radius=3.5, pie.space=0.01,
    #              link=TRUE, seg.lwd=0.5, seg.col=1, seg.lty=1, coord=NULL)
    # }
    # dev.off()
    # 
    # # #Try 3 (works, but there is a black bar in the "pure" stations indicating a zero proportion):
    # pdf("test_marmap.pdf")
    # plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys), c(min(bat), 0, blues))) #plot map without isobaths
    # plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    # pie.colors.matrix = data.frame(matrix(nrow = length(which(stations_depths[,2] == "SUR")), ncol=nb_topics, data = NA))
    # pie.slices.matrix = data.frame(matrix(nrow = length(which(stations_depths[,2] == "SUR")), ncol=nb_topics, data = NA))
    # ii_pie = 0
    # for (i_pie in which(stations_depths[,2] == "SUR"))
    # {
    #   ii_pie = ii_pie+1
    #   station_topics = which(spatial_topicmix_kriged_all_topics[i_pie,3:(2+nb_topics)] > 0)
    #   pie.colors.matrix[ii_pie,] = c(color.pal(nb_topics)[station_topics],rep(NA,nb_topics-length(station_topics)))
    #   pie.slices.matrix[ii_pie,] = c(spatial_topicmix_kriged_all_topics[i_pie,2+station_topics],rep(NA,nb_topics-length(station_topics)))
    # }
    # space.pies(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"], spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"], pie.slices = pie.slices.matrix,
    #            pie.colors = pie.colors.matrix, pie.radius=3.5, pie.space=0.01,
    #            link=TRUE, seg.lwd=0.5, seg.col=1, seg.lty=1, coord=NULL)
    # dev.off()
    
    ##########
    
    # Generating the legend for AllTaxa plots:
    if (group == "AllTaxa" && additional_plots)
    {
      if (VEM && nb_topics == 10)
      {
        assemblage_labels = c("Equatorial Pacific","Tropical Surface","Upwellings","Tropical DCM","Temperate Atlantic","Groenland & European Arctic","Mediterranean","Red Sea & Persian Gulf","Siberian & N. Am. Arctic","Misc.")
        col = rev(color.pal(10))
        data = matrix(nrow=10,ncol=3,data=abs(rnorm(30)),dimnames = list(rev(assemblage_labels),1:3))
        data[,2:3] = data[,2:3]/10
        pdf("legend.pdf")
        barplot(data,col=col,legend.text = T, args.legend = list(x="topright",bty = "n"))
        # legend(x="topright",legend=assemblage_labels,bty = "n",col=col)
        dev.off()
      } else if (Gibbs && nb_topics == 16 && nb_topics1 == nb_topics)
      {
        # assemblage_labels = c("Global non-Arctic","Global Arctic","Tropical DCM","Global equatorial",
        #                       "Southern Ocean","Equatorial Pacific","Mediterranean","Tropical Surface",
        #                       "Subtropical Atlantic","Temperate Upwellings","Eastern Pacific Upwellings","Diplomenid-rich",
        #                       "Lower Arctic","Subarctic North Atlantic","Red Sea","Persian Gulf")
        assemblage_labels = 1:16
        # topic_reordering = c(1,3,9,7,
        #                           10,8,4,6,
        #                           11,16,15,12,
        #                           2,13,5,14)
        topic_reordering = c(1,3,9,7,
                             10,8,4,6,
                             11,16,15,12,
                             2,13,5,14)
        data = matrix(nrow=nb_topics,ncol=3,data=abs(rnorm(3*nb_topics)),
                      dimnames = list(rev(assemblage_labels),1:3))
                      # dimnames = list(rev(assemblage_labels[topic_reordering]),1:3))
        data[,2:3] = data[,2:3]/10
        pdf(paste0(figure_folder,"/Gibbs_AllTaxa_16t_legend.pdf"))
        barplot(data,col=rev(col),legend.text = T, args.legend = list(x="topright",bty = "n"))
        # legend(x="topright",legend=assemblage_labels,bty = "n",col=col)
        dev.off()
      }
      
      pdf(paste0(figure_folder,"/Assemblage_station_abundance_AllTaxa_K",nb_topics,Gibbs_VEM_insert,".pdf"),width = ifelse(nb_topics == 10,7*5/2,7*3/2), height = ifelse(nb_topics == 10, 7, 7/2))
      if (nb_topics == 10 || nb_topics == 21 || nb_topics == 16)
      {
        par(mfrow = c(2,5))
      }
      par(mar = c(5,5,4,1))
      for (k in 1:nb_topics)
      {
        if (k == 1)
          plot(sort(documents[,k],decreasing = T),main = assemblage_labels[k], ylab = "Assemblage abundance in station", xlab = "Stations sorted by decreasing assemblage abundance", type = "l", cex = 0.7, cex.axis = 1.5, cex.lab = 1.7, cex.main = 1.7)
        else
          plot(sort(documents[,k],decreasing = T),main = assemblage_labels[k], ylab = "", xlab = "", type = "l", cex = 0.7, cex.axis = 1.5, cex.lab = 1.7, cex.main = 1.7)
      }
      dev.off()
      latitude.plot = list()
      for (i_case in 1:2)
      {
        case = c("SUR","DCM")[i_case]
        # plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)

        # JSD.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
        # latitude.plot[[i_case]] = ggplot(data = data.frame(x = spatial_topicmix_kriged_all_topics[stations_depths[,2] == case,2],spatial_topicmix_kriged_all_topics[stations_depths[,2] == case,2 + (1:nb_topics)]))
        latitude.plot[[i_case]] = ggplot(data = data.frame(spatial_topicmix_kriged_all_topics))
        for (k in 1:nb_topics)
        {
          plot.x = spatial_topicmix_kriged_all_topics[stations_depths[,2] == case & spatial_topicmix_kriged_all_topics[,2+k] != 0,2]
          plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
          plot.y = spatial_topicmix_kriged_all_topics[stations_depths[,2] == case & spatial_topicmix_kriged_all_topics[,2+k] != 0,2+k]
          latitude.plot[[i_case]] = latitude.plot[[i_case]] +
            # geom_smooth(aes(x,y),method='lm') +
            # geom_point(data = data.frame(x=plot.x,y=plot.y), aes(x,y), col = col[k]) +
            geom_line(data = data.frame(x=plot.x,y=plot.y), aes(x,y), col = col[k]) +
            # geom_line(data = data.frame(x = plot.x.order$x,
            #                             y = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y),
            #           aes(x,y), col = col[k]) +
            # geom_smooth(data = data.frame(x=spatial_topicmix_kriged_all_topics[stations_depths[,2] == case & spatial_topicmix_kriged_all_topics[,2+k] != 0,2],
            #                               y=spatial_topicmix_kriged_all_topics[stations_depths[,2] == case & spatial_topicmix_kriged_all_topics[,2+k] != 0,2+k]),
            #             aes(x,y), method = "lm", formula = y ~ splines::bs(x, 6), se = F, col = col[k]) +
            # geom_line(aes(x.smooth,y.smooth)) +
            theme_bw() +
            # ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
            theme(axis.title=element_text(size=24),
                  axis.text = element_text(size=17),
                  # plot.title=element_text(hjust=0, size=15),
                  plot.margin=unit(c(1,1,1,0.5),"mm")) +
            labs(x="Latitude", y="Prevalence of community type")
        }
      }
      pdf(paste0(figure_folder,"/Assemblage.latitude.curves.colors_allTaxa.pdf"))
      print(latitude.plot[[1]])
      print(latitude.plot[[2]])
      dev.off()
    }
    #########
    
    if (barplots)
    {
      # Plotting stations ordered by latitude, with proportions of assemblages as a barplot using the same colors as on the maps
      pdf(paste0(figure_folder,"/",group,"_16t_Gibbs_SurDCM_barplot_latitudeOrder.pdf"),height=4,width = 8)
      par(lwd = 0.3)
      barplot(t(spatial_topicmix_kriged_all_topics[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",3:ncol(spatial_topicmix_kriged_all_topics)]
                [sort.int(coord$y[rownames(coord) %in% rownames(documents) & stations_depths[,2] == "SUR"],index.return = T, decreasing = T)$ix,]),
              col=col, axisnames=F, legend.text = F, args.legend = list(x="topright",bty = "n"),ann=F, space = 0)
      barplot(t(spatial_topicmix_kriged_all_topics[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",3:ncol(spatial_topicmix_kriged_all_topics)]
                [sort.int(coord$y[rownames(coord) %in% rownames(documents) & stations_depths[,2] == "DCM"],index.return = T, decreasing = T)$ix,]),
              col=col, axisnames=F, legend.text = F, args.legend = list(x="topright",bty = "n"),ann=F, space = 0)
      barplot(t(spatial_topicmix_kriged_all_topics[,3:ncol(spatial_topicmix_kriged_all_topics)]
                [sort.int(coord$y[rownames(coord) %in% rownames(documents)],index.return = T, decreasing = T)$ix,]),
              col=col, axisnames=F, legend.text = F, args.legend = list(x="topright",bty = "n"),ann=F, space = 0)
      dev.off()
      
      # Plotting stations ordered by longitude, with proportions of assemblages as a barplot using the same colors as on the maps
      pdf(paste0(figure_folder,"/",group,"_16t_Gibbs_SurDCM_barplot_longitudeOrder.pdf"),height=4,width = 8)
      par(lwd = 0.3)
      barplot(t(spatial_topicmix_kriged_all_topics[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",3:ncol(spatial_topicmix_kriged_all_topics)]
                [sort.int(coord$x[rownames(coord) %in% rownames(documents) & stations_depths[,2] == "SUR"],index.return = T, decreasing = F)$ix,]),
              col=col, axisnames=F, legend.text = F, args.legend = list(x="topright",bty = "n"),ann=F, space = 0)
      barplot(t(spatial_topicmix_kriged_all_topics[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",3:ncol(spatial_topicmix_kriged_all_topics)]
                [sort.int(coord$x[rownames(coord) %in% rownames(documents) & stations_depths[,2] == "DCM"],index.return = T, decreasing = F)$ix,]),
              col=col, axisnames=F, legend.text = F, args.legend = list(x="topright",bty = "n"),ann=F, space = 0)
      barplot(t(spatial_topicmix_kriged_all_topics[,3:ncol(spatial_topicmix_kriged_all_topics)]
                [sort.int(coord$x[rownames(coord) %in% rownames(documents)],index.return = T, decreasing = F)$ix,]),
              col=col, axisnames=F, legend.text = F, args.legend = list(x="topright",bty = "n"),ann=F, space = 0)
      dev.off()
    }
    
    if (maps)
    {
      if (nb_topics == nb_topics1)
      {
        nb_topics0 = nb_topics
      } else 
        nb_topics0 = nb_topics1+1
      
      # library(mapplots)
      # data(landings)
      # data(coast)
      # # xlim <- c(-12,-5)
      # # ylim <- c(50,56)
      # xyz <- make.xyz(landings$Lon,landings$Lat,landings$LiveWeight,landings$Species)
      
      # #Try 4 (works, but pure stations and pies are plotted independently, without the possibility to avoid overlap):
      if (VEM)
      {
        pdf(paste0(figure_folder,"/",group,"_VEM100r",nb_topics,"t_SurDCMplots_marmap_reordered.pdf"))
      } else if (Gibbs)
        # pdf(paste0(figure_folder,"/",group,"_Gibbs100r",nb_topics,"t",ifelse(nb_topics==nb_topics1,"",paste0("_",nb_topics1,"firstTopics")),"_SurDCMplots_marmap_reordered.pdf"))
        pdf(paste0(figure_folder,"/",group,"_Gibbs100r",nb_topics,"t",ifelse(nb_topics==nb_topics1,"",paste0("_",nb_topics1,"firstTopics")),"_SurDCMplots_marmap_fixedPies_lowerRes.pdf"))
      # pdf(paste0(figure_folder,"/",group,"_Gibbs100r",nb_topics,"t",ifelse(nb_topics==nb_topics1,"",paste0("_",nb_topics1,"firstTopics")),"_SurDCMplots_marmap_barplot2D.pdf"))
      # pdf(paste0(figure_folder,"/",group,"_Gibbs100r",nb_topics,"t",ifelse(nb_topics==nb_topics1,"",paste0("_",nb_topics1,"firstTopics")),"_SurDCMplots_marmap_xyplot.pdf"))
      # pdf("AllTaxa_VEM100r10t_SurDCMplots_marmap.pdf")
      # pdf("AllTaxa_GibbsAlpha0.1Best100r10t_SurDCMplots_marmap.pdf")
      # par(mar=c(0,0.2,0,0.2))
      # Plotting Surface:
      plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
      plot(bat, lwd = 0.2, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
      #
      # present_topics = apply(spatial_topicmix_kriged_all_topics[,3:(2+(nb_topics0))],1,function(g) which(g>0))
      # pure_stations = unlist(lapply(present_topics,function(g) length(g))) == 1
      # points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR" & pure_stations],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR" & pure_stations]),
      #        pch = 21, cex=1.2, bg = col[unlist(present_topics[stations_depths[,2] == "SUR" & pure_stations])])
      # pie.colors.matrix = data.frame(matrix(nrow = length(which(stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR")), ncol=nb_topics0, data = NA))
      # pie.slices.matrix = data.frame(matrix(nrow = length(which(stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR")), ncol=nb_topics0, data = NA))
      pie.colors.matrix = data.frame(matrix(nrow = length(which(rownames(pie_positions.SUR) %in% rownames(documents))), ncol=nb_topics0, data = NA))
      pie.slices.matrix = data.frame(matrix(nrow = length(which(rownames(pie_positions.SUR) %in% rownames(documents))), ncol=nb_topics0, data = NA))
      ii_pie = 0
      # for (i_pie in which(stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR"))
      for (i_pie in which(rownames(documents) %in% rownames(pie_positions.SUR)))
      {
        ii_pie = ii_pie+1
        station_topics = which(spatial_topicmix_kriged_all_topics[i_pie,3:(2+(nb_topics0))] > 0)
        pie.colors.matrix[ii_pie,] = c(col[station_topics],rep(NA,(nb_topics0)-length(station_topics)))
        pie.slices.matrix[ii_pie,] = c(spatial_topicmix_kriged_all_topics[i_pie,2+station_topics],rep(NA,(nb_topics0)-length(station_topics)))
      }
      # space.pies(spatial_topicmix_kriged_all_topics$x[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR"], 
      #            spatial_topicmix_kriged_all_topics$y[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR"],
      space.pies(spatial_topicmix_kriged_all_topics$x[rownames(documents) %in% rownames(pie_positions.SUR)], 
                 spatial_topicmix_kriged_all_topics$y[rownames(documents) %in% rownames(pie_positions.SUR)],
                 pie.slices = pie.slices.matrix, pie.colors = pie.colors.matrix,
                 # pie.radius=3, pie.space=0.01,
                 pie.radius=6, pie.space=0.4,
                 link=TRUE, seg.lwd=1, seg.col=1, seg.lty=1, 
                 coord=pie_positions.SUR[rownames(pie_positions.SUR) %in% rownames(documents),])
      #
      # draw.xy(x = spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"], 
      #         y = spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"],
      #         xx = rep(0.1,nrow(spatial_topicmix_kriged_all_topics[stations_depths[,2] == "SUR",])),
      #         yy = spatial_topicmix_kriged_all_topics[stations_depths[,2] == "SUR",3],
      #         width = 2, height = 10, border = 1,col=col[1], lwd=20,
      #         type = "h",
      #         silent = F)
      #
      # draw.barplot2D(x = spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"], 
      #                y = spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"],
      #                z = as.matrix(spatial_topicmix_kriged_all_topics[stations_depths[,2] == "SUR",3:ncol(spatial_topicmix_kriged_all_topics)]),
      #                width = 10, height = 10, lwd.frame = 0.001, col.frame = NULL, scale =T,
      #                col = col)
      # Plotting DCM:
      plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
      plot(bat, lwd = 0.2, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
      # points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "DCM" & pure_stations],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "DCM" & pure_stations]),
      #        pch = 21, cex=1.2, bg = col[unlist(present_topics[stations_depths[,2] == "DCM" & pure_stations])])
      # pie.colors.matrix = data.frame(matrix(nrow = length(which(stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM")), ncol=nb_topics0, data = NA))
      # pie.slices.matrix = data.frame(matrix(nrow = length(which(stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM")), ncol=nb_topics0, data = NA))
      pie.colors.matrix = data.frame(matrix(nrow = length(which(rownames(pie_positions.DCM) %in% rownames(documents))), ncol=nb_topics0, data = NA))
      pie.slices.matrix = data.frame(matrix(nrow = length(which(rownames(pie_positions.DCM) %in% rownames(documents))), ncol=nb_topics0, data = NA))
      ii_pie = 0
      # for (i_pie in which(stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM"))
      for (i_pie in which(rownames(documents) %in% rownames(pie_positions.DCM)))
      {
        ii_pie = ii_pie+1
        station_topics = which(spatial_topicmix_kriged_all_topics[i_pie,3:(2+(nb_topics0))] > 0)
        pie.colors.matrix[ii_pie,] = c(col[station_topics],rep(NA,(nb_topics0)-length(station_topics)))
        pie.slices.matrix[ii_pie,] = c(spatial_topicmix_kriged_all_topics[i_pie,2+station_topics],rep(NA,(nb_topics0)-length(station_topics)))
      }
      # space.pies(spatial_topicmix_kriged_all_topics$x[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM"],
      #            spatial_topicmix_kriged_all_topics$y[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM"],
      space.pies(spatial_topicmix_kriged_all_topics$x[rownames(documents) %in% rownames(pie_positions.DCM)], 
                 spatial_topicmix_kriged_all_topics$y[rownames(documents) %in% rownames(pie_positions.DCM)],
                 pie.slices = pie.slices.matrix, pie.colors = pie.colors.matrix, 
                 pie.radius=6, pie.space=0.4,
                 link=TRUE, seg.lwd=1, seg.col=1, seg.lty=1, 
                 coord=pie_positions.DCM[rownames(pie_positions.DCM) %in% rownames(documents),])
      dev.off()
    }
  }
  # End of the loop over plotted groups.
  
  ##########################
  # Plot topic by topic:
  # pdf("AllTaxa_GibbsAlpha0.1Best100r10t_Surplots_topicByTopic_marmap.pdf")
  if (VEM)
  {
    pdf(paste0(group,"_VEM100r",nb_topics,"t_Surplots_topicByTopic_marmap.pdf"))
  } else if (Gibbs)
    pdf(paste0(group,"_Gibbs100r",nb_topics,"t_Surplots_topicByTopic_marmap.pdf"))
  for (k in 1:nb_topics)
  {
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "SUR"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "SUR"]),
           pch = 21, cex=1.2, bg = rgb(colorRamp(c("darkblue","firebrick2"),space = "Lab")(spatial_topicmix_kriged_all_topics[stations_depths[,2] == "SUR",2+k]),maxColorValue = 255))
  }
  dev.off()
  # pdf("AllTaxa_GibbsAlpha0.1Best100r10t_DCMplots_topicByTopic_marmap.pdf")
  if (VEM)
  {
    pdf(paste0(group,"_VEM100r",nb_topics,"t_DCMplots_topicByTopic_marmap.pdf"))
  } else if (Gibbs)
    pdf(paste0(group,"_Gibbs100r",nb_topics,"t_DCMplots_topicByTopic_marmap.pdf"))
  for (k in 1:nb_topics)
  {
    # Plotting DCM:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    points(cbind(spatial_topicmix_kriged_all_topics$x[stations_depths[,2] == "DCM"],spatial_topicmix_kriged_all_topics$y[stations_depths[,2] == "DCM"]),
           pch = 21, cex=1.2, bg = rgb(colorRamp(c("darkblue","firebrick2"),space = "Lab")(spatial_topicmix_kriged_all_topics[stations_depths[,2] == "DCM",2+k]),maxColorValue = 255))
  }
  dev.off()
  
  ###################
  # Plot station number:
  pdf(paste0(figure_folder,"/Plot_stationNumber_marmap.pdf"))
  # Plotting SUR:
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n",
       ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  points(coord[stations_depths[,2] == "SUR",2:1],
         pch = 20, cex=1.2)
  lines(coord[stations_depths[,2] == "SUR",2:1][1:102,], cex=1.2)
  lines(coord[stations_depths[,2] == "SUR",2:1][103:nrow(coord[stations_depths[,2] == "SUR",]),], cex=1.2)
  text(x=coord$x[stations_depths[,2] == "SUR"],y=coord$y[stations_depths[,2] == "SUR"],
       labels=1:nrow(coord[stations_depths[,2] == "SUR",]),
       pos=1,cex=0.6)
  # Plotting DCM:
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n",
       ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  points(coord[stations_depths[,2] == "DCM",2:1],
         pch = 20, cex=1.2)
  lines(coord[stations_depths[,2] == "DCM",2:1], cex=1.2)
  text(x=coord$x[stations_depths[,2] == "DCM"],y=coord$y[stations_depths[,2] == "DCM"],
       labels=1:nrow(coord[stations_depths[,2] == "DCM",]),
       pos=1,cex=0.6)
  dev.off()
}

if (Sur_DCM_comparison)
{
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  nb_iter = 1000 
  thin = 25
  burnin = 2000
  fold_size = 10
  # optimalK_min.crossValid = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs",fold_size,"sampleFolds2-35t_iter",nb_iter,"thin",thin,"burnin",burnin,"_2plusOTUs_noLagoon.rds"))[,1]
  optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
  optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
  optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]] 
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100
  # optimalK = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # selected_groups = readRDS(paste0(results_folder,"/selected_groups_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  VI = rep(NA,length(taxo_groups))
  # H_SUR_plus_H_DCM = rep(NA,length(taxo_groups))
  # I = rep(NA,length(taxo_groups))
  Normalized_VI = rep(NA,length(taxo_groups))
  VI_over_K = rep(NA,length(taxo_groups))
  ii_taxon = 0
  for (taxon in taxo_groups)
  {
    i_taxon = which(taxon == taxo_groups)
    # taxon = "AllTaxa"
    
    if (taxon %in% taxo_groups[selected_groups])
    {
      ii_taxon = ii_taxon+1
      
      # data.folder_name = paste0(data_folder,"/Old_data/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      #data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      data.folder_name = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      
      # nb_topics = optimalK[i_taxon]
      # nb_topics = optimalK_min.crossValid[i_taxon]
      nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
      spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real100_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds"))
      # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
      # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/2nd_best_realization_maxmatching/Spatial_topicmix_kriged.rds"))
      # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/3rd_best_realization_maxmatching/Spatial_topicmix_kriged.rds"))
      # spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/1st_best_realization/Spatial_topicmix_kriged.rds"))
      
      # selecting the z.pred columns in all topics:
      documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
      # setting one topic per column
      documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("assemblage",1:nb_topics)))
      
      documents_SUR = list()
      documents_DCM = list()
      selected_stations = list()                    
      i_station = 0
      for (station in levels(as.factor(stations_depths[,1])))
      {
        if (any(stations_depths[stations_depths[,1] == station,2] == "SUR") && any(stations_depths[stations_depths[,1] == station,2] == "DCM"))
        {
          i_station = i_station+1
          documents_SUR[[i_station]] = documents[stations_depths[,1] == station & stations_depths[,2] == "SUR",]
          documents_DCM[[i_station]] = documents[stations_depths[,1] == station & stations_depths[,2] == "DCM",]
          selected_stations[[i_station]] = station
        }
      }
      documents_SUR = t(data.frame(documents_SUR))
      documents_DCM = t(data.frame(documents_DCM))
      rownames(documents_SUR) = unlist(selected_stations)
      rownames(documents_DCM) = unlist(selected_stations)
      documents_SUR = sweep(documents_SUR,1,rowSums(documents_SUR),'/')
      documents_DCM = sweep(documents_SUR,1,rowSums(documents_DCM),'/')
      
      Pk_SUR = colMeans(documents_SUR)
      Pk1_DCM = colMeans(documents_DCM)
      # Pkk1 = matrix(nrow = ncol(documents_SUR), ncol = ncol(documents_DCM), data = NA)
      # Pkk1_over_PkPk1 = matrix(nrow = ncol(documents_SUR), ncol = ncol(documents_DCM), data = NA)
      sum_Pkk1_times_log_Pkk1_over_PkPk1 = 0
      for (k in 1:ncol(documents_SUR))
      {
        for (k1 in 1:ncol(documents_DCM))
        {
          Pkk1 = mean(documents_SUR[,k]*documents_DCM[,k1])
          # Pkk1_over_PkPk1[k,k1] = Pkk1[k,k1]/(Pk_SUR[k]*Pk1_DCM[k1])
          if (Pkk1>0)
            sum_Pkk1_times_log_Pkk1_over_PkPk1 = sum_Pkk1_times_log_Pkk1_over_PkPk1 + Pkk1*(log(Pkk1) - log(Pk_SUR[k]) - log(Pk1_DCM[k1]))
        }
      }
      # Computing the Variation of Information using probability values 
      H_SUR = -sum(Pk_SUR*log(Pk_SUR))
      H_DCM = -sum(Pk1_DCM*log(Pk1_DCM))
      # VI[i_taxon] = H_SUR + H_DCM - 2*sum(Pkk1*log(Pkk1_over_PkPk1))
      VI[i_taxon] = H_SUR + H_DCM - 2*sum_Pkk1_times_log_Pkk1_over_PkPk1
      # H_SUR_plus_H_DCM[i_taxon] = H_SUR + H_DCM
      # I[i_taxon] = sum(Pkk1*log(Pkk1_over_PkPk1))
      # I[i_taxon] = sum_Pkk1_times_log_Pkk1_over_PkPk1
      Normalized_VI[i_taxon] = VI[i_taxon]/(H_SUR + H_DCM)
      VI_over_K[i_taxon] = VI[i_taxon]/nb_topics
    }
  }
  
  ###############
  # setwd(data_folder)
  
  saveRDS(VI_over_K,file=paste0(results_folder,"/VI.over.K_SUR.DCM_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  saveRDS(Normalized_VI,file=paste0(results_folder,"/Normalized.VI_SUR.DCM_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  saveRDS(VI,file=paste0(results_folder,"/VI_SUR.DCM_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  
  significant_global_model = readRDS(paste0(results_folder,"/RDA_abiotic_relativeAbund_expTmin_envSelected_significantGlobalModel_nbSites_independentSelection",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
  significant_global_model_indSelec = vector(length = length(taxo_groups), mode = "logical")
  for (i_taxon in 1:length(taxo_groups))
    significant_global_model_indSelec[i_taxon] = all(significant_global_model[[i_taxon]])
  load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata"))
  varpart.groups.expTmin.indSelec = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
  varpart.groups.expTmin.indSelec.pval = readRDS(paste0(results_folder,"/varpart_lda_abiotic_vs_taxoGroups_vs_expTmin_independentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[2]]
  varpart.groups.expTmin.indSelec0 = varpart.groups.expTmin.indSelec
  varpart.groups.expTmin.indSelec0[varpart.groups.expTmin.indSelec0<0] = 0
  
  plot.VI_over_K.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund)[selected_groups & significant_global_model_indSelec],y=VI_over_K[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x=expression("Mean within-group body size ("*mu*"m, log10)"), y="Dissimilarity between\n Surface and DCM communities") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("SUR_DCM_VI_over_K_vs_body.size_ggplot_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.VI_over_K.vs.size)
  dev.off()
  
  plot.VI_over_K.vs.K = ggplot(data=data.frame(x=optimalK[selected_groups & significant_global_model_indSelec],y=VI_over_K[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Number of community types", y="Dissimilarity between\n Surface and DCM communities") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("SUR_DCM_VI_over_K_vs_optimalK_ggplot_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.VI_over_K.vs.K)
  dev.off()
  
  plot.VI_over_K.vs.pure.currents = ggplot(data=data.frame(x=(varpart.groups.expTmin.indSelec0[7,]/colSums(varpart.groups.expTmin.indSelec0))[selected_groups & significant_global_model_indSelec],y=VI_over_K[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Relative variance\n explained purely by currents", y="Dissimilarity between\n Surface and DCM communities") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("SUR_DCM_VI_over_K_vs_rel.pure.currents_ggplot_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.VI_over_K.vs.pure.currents)
  dev.off()
  
  plot.VI_over_K.vs.pure.env = ggplot(data=data.frame(x=(colSums(varpart.groups.expTmin.indSelec0[c(1,2,5),])/colSums(varpart.groups.expTmin.indSelec0))[selected_groups & significant_global_model_indSelec],y=VI_over_K[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Relative variance\n explained purely by the env.", y="Dissimilarity between\n Surface and DCM communities") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("SUR_DCM_VI_over_K_vs_rel.pure.env_ggplot_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.VI_over_K.vs.pure.env)
  dev.off()
  
  plot.VI_over_K.vs.mixed = ggplot(data=data.frame(x=(colSums(varpart.groups.expTmin.indSelec0[c(3,4,6),])/colSums(varpart.groups.expTmin.indSelec0))[selected_groups & significant_global_model_indSelec],y=VI_over_K[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Relative variance explained jointly\n by currents and the env.", y="Dissimilarity between\n Surface and DCM communities") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("SUR_DCM_VI_over_K_vs_rel.mixed_ggplot_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.VI_over_K.vs.mixed)
  dev.off()
  
  plot.VI_over_K.vs.tot.var = ggplot(data=data.frame(x=colSums(varpart.env.spatial)[selected_groups & diversity>100],y=VI_over_K[selected_groups & diversity>100])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Total variance explained\n by currents and the env.", y="Dissimilarity between\n Surface and DCM communities") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0(figure_folder,"/SUR_DCM_VI_over_K_vs_tot.var_ggplot_selected",ifelse(div_threshold==2,"",div_threshold),"_noNegativeAdjR2.pdf"))
  print(plot.VI_over_K.vs.tot.var)
  dev.off()
  
  ########
  plot.VI.over.K_vs_log.diversity = ggplot(data=data.frame(y=VI_over_K[selected_groups],
                                                           x=as.vector(diversity)[selected_groups])) +
    theme_bw() +
    scale_x_log10() +
    geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 3), se = F, col = "black") +
    # geom_smooth(aes(x,y), method = "lm", col = "black") +
    geom_point(aes(x = x, y = y)) +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_blank(),
          plot.margin=unit(c(1,10,1,0.5),"mm")) +
    # labs(x="Diversity (log10)", y="DCM Moran's I square weights")
    labs(x="Number of OTUs", y="Disimilarity between surface and DCM")
  pdf(file = paste0(figure_folder,"/VI.over.K_vs_log.diversity_Gibbs.prevalence.min.crossValid_selected100+1.pdf"))
  print(plot.VI.over.K_vs_log.diversity)
  dev.off()
  
  div_threshold = 100
  
  dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  dominant_function0 = dominant_function[selected_groups & diversity>div_threshold]
  # dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
  # dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
  dominant_function0[dominant_function0 == "unknown"] = NA
  dominant_function0[dominant_function0 == "photohost"] = "Collodaria"
  dominant_function0[dominant_function0 == "pteropoda"] = "Pteropoda"
  dominant_function0[dominant_function0 == "copepoda"] = "Copepoda"
  dominant_function0[dominant_function0 == "gelatineous_carnivores_filterers"] = "Gel. carn. filterers"
  dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Dinophyceae"] = "Dinophyceae"
  dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Bacillariophyta"] = "Bacillariophyta"
  dominant_function0[dominant_function0 == "phototroph"] = "Other phototrophs"
  dominant_function0[dominant_function0 == "phagotroph"] = "Phagotrophs"
  dominant_function0[dominant_function0 == "other metazoa"] = "Other metazoa"
  dominant_function0[dominant_function0 == "parasite"] = "Parasites"
  # alpha = rep(1,length(taxo_groups[selected_groups]))
  # alpha[dominant_function0 %in% c("copepoda","pteropoda")] = 0 
  # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them by deceasing number of groups:
  # dominant_function0 = factor(dominant_function0,names(sort(table(as.factor(dominant_function0)),decreasing = T)))
  # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them in the specified order:
  if (div_threshold == 100)
  {
    dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Pteropoda","Copepoda","Other metazoa","Parasites"))
    point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")
  } else if (div_threshold == 1000)
  {
    dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Copepoda","Parasites"))
    point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta")
  }
  
  boxplot.VI_over_K.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                         y = VI_over_K[selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
    scale_x_discrete(limits=levels(dominant_function0)) +
    geom_boxplot(aes(x,y)) +
  # boxplot.VI_over_K.functions = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0)],
  #                                                        y = VI_over_K[selected_groups][!is.na(dominant_function0)])) +
  #   geom_boxplot(aes(x= c(x[!x %in% c("copepoda","pteropoda")],NA,NA),
  #                    y = c(y[!x %in% c("copepoda","pteropoda")],NA,NA))) +
    geom_point(data = data.frame(x = factor(point_groups),
                                 y = VI_over_K[selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
               aes(x,y)) +
    # geom_point(aes(x = c(x[x %in% c("copepoda","pteropoda")],rep(NA,length(x)-2)),y = c(y[x %in% c("copepoda","pteropoda")],rep(NA,length(x)-2)))) +
    theme_bw() +
    theme(axis.title=element_text(size=20),
          axis.text=element_text(size=22),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          plot.margin=unit(c(1,1,1,7),"mm")) +
    labs(x="", y="Disimilarity between surface and DCM")
  pdf(paste0(figure_folder,"/VI.over.K_boxplot_allFunctionalGroups_Gibbs.prevalence.min.crossValid_selected",if (div_threshold == 1000) "1000" else if (div_threshold == 100) "100+1",".pdf"))
  print(boxplot.VI_over_K.functions)
  dev.off()
  
  # t.test(varpart.latitude.depth0[1,selected_groups][dominant_function0 == "phagotroph"],
  #        varpart.latitude.depth0[1,selected_groups][dominant_function0 == "parasite"])
}

if (MEM_structure)
{
  library(ape)
  library(ggplot2)
  library(gridExtra)
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100
  
  nb_increment = 20
  charac.dist = 1
  charac.tmin = 0
  
  data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTAxa",noArcticNoBiomark_insert,noLagoon_insert)
  load(paste0(data.folder_name,"/coord.Rdata"))
  
  ##############
  # Loading travel times:
  
  travel.folder_name = paste0(data_folder,"/Abiotic_data")
  travel_time_matrix_SUR = as.matrix(read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_10.csv"),sep="\t",header=T,row.names=1))
  # travel_time_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_1000.csv"),sep="\t",header=T,row.names=1)
  travel_time_matrix_SUR = travel_time_matrix_SUR[,-ncol(travel_time_matrix_SUR)]
  travel_time_matrix_DCM = as.matrix(read.table(paste0(travel.folder_name,"/tarrive_min_75m_10.csv"),sep=";",header=T,row.names=1))
  for (i in 2:nrow(travel_time_matrix_DCM))
  {
    for (j in 1:(i-1))
    {
      travel_time_matrix_DCM[i,j] = travel_time_matrix_DCM[j,i] = min(travel_time_matrix_DCM[i,j],travel_time_matrix_DCM[j,i])
    }
  }
  selected_travel_time_matrix_SUR = travel_time_matrix_SUR[selected_stations,paste0("X",selected_stations)]
  selected_travel_time_matrix_SUR = selected_travel_time_matrix_SUR[stations_depths[,2] == "SUR",stations_depths[,2] == "SUR"]
  selected_travel_time_matrix_DCM = travel_time_matrix_DCM[selected_stations,paste0("X",selected_stations)]
  selected_travel_time_matrix_DCM = selected_travel_time_matrix_DCM[stations_depths[,2] == "DCM",stations_depths[,2] == "DCM"]
  # selected_travel_time_matrix1000 = travel_time_matrix1000[selected_stations,paste0("X",selected_stations)]
  # selected_travel_time_matrix_asym1000 = travel_time_matrix_asym1000[selected_stations,paste0("X",selected_stations)]
  diag(selected_travel_time_matrix_SUR) = NA
  diag(selected_travel_time_matrix_DCM) = NA
  max_tmin.SUR = max(selected_travel_time_matrix_SUR,na.rm = T)
  min_tmin.SUR = min(selected_travel_time_matrix_SUR,na.rm = T)
  max_tmin.DCM = max(selected_travel_time_matrix_DCM,na.rm = T)
  min_tmin.DCM = min(selected_travel_time_matrix_DCM,na.rm = T)
  
  ##############
  # Plotting t_min hist:
  
  pdf(paste0(figure_folder,"/T_min_SUR_hist.pdf"))
  hist(as.matrix(selected_travel_time_matrix_SUR),breaks = 100,ann=F)
  abline(v=10, lty = 2)
  abline(v=2.1, lty = 2, col = "red")
  title(ylab = "Station pairs", xlab = "t_min")
  dev.off()
  
  pdf(paste0(figure_folder,"/T_min_DCM_hist.pdf"))
  hist(as.matrix(selected_travel_time_matrix_DCM),breaks = 100,ann=F)
  abline(v=10, lty = 2)
  abline(v=6.8, lty = 2, col = "red")
  abline(v=3.15, lty = 2, col = "green")
  title(ylab = "Station pairs", xlab = "t_min")
  dev.off()
  
  #################
  # Building t_min-based MEMs:
  
  tmin_thres_SUR = 2.1
  tmin_thres_DCM = 3.15
  coord_SUR = coord[stations_depths[,2] == "SUR",]
  coord_DCM = coord[stations_depths[,2] == "DCM",]
  
  truncated_Tmin_SUR = selected_travel_time_matrix_SUR
  truncated_Tmin_SUR[is.nan(truncated_Tmin_SUR)] = 4*tmin_thres_SUR
  truncated_Tmin_SUR[truncated_Tmin_SUR > tmin_thres_SUR] = 4*tmin_thres_SUR
  diag(truncated_Tmin_SUR) = 4*tmin_thres_SUR
  
  truncated_Tmin_DCM = selected_travel_time_matrix_DCM
  truncated_Tmin_DCM[is.nan(truncated_Tmin_DCM)] = 4*tmin_thres_DCM
  truncated_Tmin_DCM[truncated_Tmin_DCM > tmin_thres_DCM] = 4*tmin_thres_DCM
  diag(truncated_Tmin_DCM) = 4*tmin_thres_DCM
  
  devtools::source_url("https://github.com/guilhemSK/Useful_functions/raw/main/pcoa.all_fun.R")
  truncated_Tmin_SUR_pcoa = pcoa.all(as.dist(truncated_Tmin_SUR), rn = rownames(coord_SUR))
  truncated_Tmin_DCM_pcoa = pcoa.all(as.dist(truncated_Tmin_DCM), rn = rownames(coord_DCM))
  
  SUR_MEM = matrix(nrow = nrow(coord), ncol = ncol(truncated_Tmin_SUR_pcoa$vectors), dimnames = list(rownames(coord),1:ncol(truncated_Tmin_SUR_pcoa$vectors)), data = 0)
  SUR_MEM[rownames(truncated_Tmin_SUR_pcoa$vectors),] = truncated_Tmin_SUR_pcoa$vectors
  SUR_MEM_restricted = truncated_Tmin_SUR_pcoa$vectors
  SUR_MEM_restricted.ev = truncated_Tmin_SUR_pcoa$values
  
  DCM_MEM = matrix(nrow = nrow(coord), ncol = ncol(truncated_Tmin_DCM_pcoa$vectors), dimnames = list(rownames(coord),1:ncol(truncated_Tmin_DCM_pcoa$vectors)), data = 0)
  DCM_MEM[rownames(truncated_Tmin_DCM_pcoa$vectors),] = truncated_Tmin_DCM_pcoa$vectors
  DCM_MEM_restricted = truncated_Tmin_DCM_pcoa$vectors
  
  ##########
  # Plotting spantrees for tmin-based MEMs:
  
  library(marmap)
  library(vegan)
  # Loading batymetric data for the specified range of longitudes and latitudes in degrees, whith resolution in minutes
  bat = getNOAA.bathy(-180, 180, -90, 90, res = 20, keep=T)
  blues = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1")
  greys = c(grey(0.6), grey(0.93), grey(0.99))
  
  spantree_SUR = spantree(as.dist(selected_travel_time_matrix_SUR),toolong=tmin_thres_SUR)
  pdf(paste0(figure_folder,"/spantree_SUR_",tmin_thres_SUR,"y_thres_map.pdf"))
  plot(spantree_SUR, ord=coord_SUR[,c(2,1)], type = "p", ylim = c(-90,90))
  # plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues[3]))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = T) # highlight coastline
  dev.off()
  
  spantree_DCM = spantree(as.dist(selected_travel_time_matrix_DCM),toolong=tmin_thres_DCM)
  discon_pos = which(is.na(spantree_DCM$kid))
  spantree_DCM$kid[discon_pos[1]] = 1
  spantree_DCM$kid[discon_pos[2]] = 1
  spantree_DCM$kid[discon_pos[3]] = 1
  # spantree_col = rep("black",length(spantree_DCM$labels))
  # spantree_col[6] = spantree_col[10] = "red"
  # discon_pos = which(is.na(spantree_DCM$kid))
  # spantree_DCM_list = list()
  # for (i in 1:(length(discon_pos)+1))
  # {
  #   if (i == 1)
  #   {
  #     spantree_DCM_list[[i]] = spantree_DCM
  #     spantree_DCM_list[[i]]$kid = spantree_DCM$kid[1:(discon_pos[i]-1)]
  #     spantree_DCM_list[[i]]$dist = spantree_DCM$dist[1:(discon_pos[i]-1)]
  #     # spantree_DCM_list[[1]]$labels = spantree_DCM$labels[1:(discon_pos[1]-1)]
  #     # spantree_DCM_list[[1]]$n = discon_pos[1]-1
  #   } else if (i == (length(discon_pos)+1))
  #   {
  #     spantree_DCM_list[[i]] = spantree_DCM
  #     spantree_DCM_list[[i]]$kid = spantree_DCM$kid[(discon_pos[i-1]+1):length(spantree_DCM$kid)]
  #     spantree_DCM_list[[i]]$dist = spantree_DCM$dist[(discon_pos[i-1]+1):length(spantree_DCM$kid)]
  #     # spantree_DCM_list[[i]]$labels = spantree_DCM$labels[(discon_pos[i-1]+1):(discon_pos[i]-1)]
  #     # spantree_DCM_list[[i]]$n = (discon_pos[i]-discon_pos[i-1]-1)
  #   } else
  #   {
  #     spantree_DCM_list[[i]] = spantree_DCM
  #     spantree_DCM_list[[i]]$kid = spantree_DCM$kid[(discon_pos[i-1]+1):(discon_pos[i]-1)]
  #     spantree_DCM_list[[i]]$dist = spantree_DCM$dist[(discon_pos[i-1]+1):(discon_pos[i]-1)]
  #     # spantree_DCM_list[[i]]$labels = spantree_DCM$labels[(discon_pos[i-1]+1):(discon_pos[i]-1)]
  #     # spantree_DCM_list[[i]]$n = (discon_pos[i]-discon_pos[i-1]-1)
  #   }
  # }
  # spantree_DCM_1$kid = 
  pdf(paste0(figure_folder,"/spantree_DCM_",tmin_thres_DCM,"y_thres_map.pdf"))
  plot(spantree_DCM,ord=coord_DCM[,c(2,1)],col="black")
  plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues[3])), add=T) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  dev.off()
  
  ###############
  # Loading geographic distances:
  
  geographic_distances = as.matrix(read.table(paste0(data_folder,"/Abiotic_data/Geographic_distances.csv"),sep="\t",header=T,row.names=1))
  geographic_distances = geographic_distances[,-ncol(geographic_distances)]
  selected_geographic_distances = geographic_distances[selected_stations,paste0("X",selected_stations)]
  diag(selected_geographic_distances) = NA
  
  selected_geographic_distances_SUR = selected_geographic_distances[stations_depths[,2] == "SUR",stations_depths[,2] == "SUR"]
  max_dist.SUR = max(selected_geographic_distances_SUR,na.rm=T)
  min_dist.SUR = min(selected_geographic_distances_SUR,na.rm=T)
  selected_geographic_distances_DCM = selected_geographic_distances[stations_depths[,2] == "DCM",stations_depths[,2] == "DCM"]
  max_dist.DCM = max(selected_geographic_distances_DCM,na.rm=T)
  min_dist.DCM = min(selected_geographic_distances_DCM,na.rm=T)
  
  ###############
  # Plotting t_min vs. distance:
  
  plot = list()
  plot[[1]] = ggplot(data = data.frame(x = selected_geographic_distances_SUR[selected_travel_time_matrix_SUR<2],
                                       y = selected_travel_time_matrix_SUR[selected_travel_time_matrix_SUR<2]))
  plot[[2]] = ggplot(data = data.frame(x = selected_geographic_distances_SUR[!is.na(selected_geographic_distances_SUR)
                                                                             & !is.na(selected_travel_time_matrix_SUR)],
                                       y = selected_travel_time_matrix_SUR[!is.na(selected_geographic_distances_SUR)
                                                                           & !is.na(selected_travel_time_matrix_SUR)]))
  for (i in 1:2)
  {
    plot[[i]] = plot[[i]] +
    geom_point(aes(x,y), size = 0.6) +
    labs(x="Distance btw. stations (km)", y="Min. transport time (years)") +
    theme_bw() +
    theme(axis.text=element_text(size=12),
          axis.title=element_text(size=15),
          plot.title=element_text(hjust=0, size=15),
          plot.margin=unit(c(1,1,1,0.5),"mm"))
    if (i == 2)
      plot[[i]] = plot[[i]] + scale_y_log10()  
  }
  
  pdf(paste0(figure_folder,"/tmin0-2y_vs_distance_SUR.pdf"))
  print(plot[[1]])
  dev.off()
  
  pdf(paste0(figure_folder,"/log10.tmin_vs_distance_SUR.pdf"))
  print(plot[[2]])
  dev.off()
  
  ################
  # Building distance-based MEMs:
  
  library(marmap)
  library(vegan)
  
  dis_thres_SUR = 4778
  
  truncated_dis_SUR = selected_geographic_distances_SUR
  truncated_dis_SUR[is.nan(truncated_dis_SUR)] = 4*dis_thres_SUR
  truncated_dis_SUR[truncated_dis_SUR > dis_thres_SUR] = 4*dis_thres_SUR
  diag(truncated_dis_SUR) = 4*dis_thres_SUR
  
  devtools::source_url("https://github.com/guilhemSK/Useful_functions/raw/main/pcoa.all_fun.R")
  truncated_dis_SUR_pcoa = pcoa.all(as.dist(truncated_dis_SUR), rn = rownames(coord_SUR))
  
  SUR_dis_MEM = matrix(nrow = nrow(coord), ncol = ncol(truncated_dis_SUR_pcoa$vectors), 
                   dimnames = list(rownames(coord),1:ncol(truncated_dis_SUR_pcoa$vectors)), data = 0)
  SUR_dis_MEM[rownames(truncated_dis_SUR_pcoa$vectors),] = truncated_dis_SUR_pcoa$vectors
  SUR_dis_MEM_restricted = truncated_dis_SUR_pcoa$vectors
  SUR_dis_MEM_restricted[,c(1,2,5,6)] = -SUR_dis_MEM_restricted[,c(1,2,5,6)]
  SUR_dis_MEM_restricted.ev = truncated_dis_SUR_pcoa$values
  
  ###############
  # Plotting spantrees for distance-based MEMs:
  
  spantree_SUR = spantree(as.dist(selected_geographic_distances_SUR),toolong=dis_thres_SUR)
  pdf(paste0(figure_folder,"/spantree_SUR_",dis_thres_SUR,"km_thres_map.pdf"))
  plot(spantree_SUR,ord=coord_SUR[,c(2,1)])
  # plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  dev.off()
  
  dis_thres_DCM = 4778
  spantree_DCM = spantree(as.dist(selected_geographic_distances_DCM),toolong=dis_thres_DCM)
  # discon_pos = which(is.na(spantree_DCM$kid))
  # spantree_DCM$kid[discon_pos[1]] = 1
  # spantree_DCM$kid[discon_pos[2]] = 1
  # spantree_DCM$kid[discon_pos[3]] = 1
  pdf(paste0(figure_folder,"/spantree_DCM_",dis_thres_DCM,"km_thres_map.pdf"))
  plot(spantree_DCM,ord=coord_DCM[,c(2,1)],col="black")
  # plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
  plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
  dev.off()
  
  ###############
  # Building increments for distance and t_min
  
  Moran.function = function(weight_matrix,increment,maps)
  {
    nb_increment = length(increment)
    I = I_p.val = matrix(nrow = nb_increment, ncol = ncol(maps), data = 0)
    for (k in 1:ncol(maps))
    {
      for (i in 1:nb_increment)
      {
        weight_matrix_step = weight_matrix
        diag(weight_matrix_step) = 0
        weight_matrix_step[is.na(weight_matrix_step)] = 0
        weight_matrix_step[weight_matrix_step > increment[i]] = 0
        weight_matrix_step[weight_matrix_step != 0] = 1
        Moran_I = ape::Moran.I(maps[,k],weight_matrix_step)
        I[i,k] = Moran_I$observed
        I_p.val[i,k] = Moran_I$p.value
      }
    }
    return(list(I,I_p.val))
  }
  
  if (charac.tmin)
  {
    # increment_dist.SUR = min_dist.SUR*(max_dist.SUR/min_dist.SUR)^(1:nb_increment/nb_increment)
    increment_tmin.SUR = min_tmin.SUR*(max_tmin.SUR/min_tmin.SUR)^(1:nb_increment/nb_increment)
    I_result = Moran.function(selected_travel_time_matrix_SUR,increment_tmin.SUR,SUR_MEM_restricted)
    I_tmin.SUR = I_result[[1]]
    I_tmin.SUR_p.val = I_result[[2]]
  } else if (charac.dist)
  {
    increment_dist.SUR = min_dist.SUR + (1:nb_increment)*(max_dist.SUR-min_dist.SUR)/nb_increment
    # increment_tmin.SUR = min_tmin.SUR + (1:nb_increment)*(max_tmin.SUR-min_tmin.SUR)/nb_increment
    I_result = Moran.function(selected_geographic_distances_SUR,increment_dist.SUR,SUR_MEM_restricted)
    I_dist.SUR = I_result[[1]]
    I_dist.SUR_p.val = I_result[[2]]
  }
  
  ###############################
  # Computing characteristic time or distance for tmin-based MEMs:
  
  if (charac.tmin)
  {
    charac_tmin.SUR_scale = rep(NA,ncol(SUR_MEM_restricted))
    Moran.step.tmin.w.spline = list()
  } else if (charac.dist)
  {
    charac_dist.SUR_scale = rep(NA,ncol(SUR_MEM_restricted))
    Moran.step.dist.w.spline = list()
  }
  #for (k in 1:ncol(SUR_MEM_restricted))
  for (k in 1:14)
  {
    col.dist.vect = col.tmin.vect = rep("black",nb_increment)
    col.dist.vect[I_dist.SUR_p.val[,k] > 0.05 | is.na(I_dist.SUR_p.val[,k])] = "red"
    col.tmin.vect[I_tmin.SUR_p.val[,k] > 0.05 | is.na(I_tmin.SUR_p.val[,k])] = "red"
    if (charac.tmin)
    {
      # y.dist.SUR.smooth = smooth.spline(log10(increment_dist.SUR),I_dist.SUR[,k],df=5)$y
      # # spatial_scale[i_taxon,1] = increment_taxon[,1][sort.int(y.smooth,decreasing=T,index.return=T)$ix[1]]
      # Moran.step.dist.w.spline[[k]] = ggplot(data = data.frame(x = log10(increment_dist.SUR), y = I_dist.SUR[,k], y.smooth = y.dist.SUR.smooth)) +
      #   labs(x="Spatial scale (log10)", y="MEM surf. spatial autocorrelation")
      
      y.tmin.SUR.smooth = smooth.spline(log10(increment_tmin.SUR),I_tmin.SUR[,k],df=5)$y
      if (k == 1)
      {
        range = increment_tmin.SUR>5 & increment_tmin.SUR<50
      } else
        range = increment_tmin.SUR>1 & increment_tmin.SUR<10
      lin.regr = lm(y.tmin.SUR.smooth[range] ~ log10(increment_tmin.SUR[range]))
      b = summary(lin.regr)$coefficients[1,1]
      a = summary(lin.regr)$coefficients[2,1]
      charac_tmin.SUR_scale[k] = 10^(-b/a)
      Moran.step.tmin.w.spline[[k]] = ggplot(data = data.frame(x = log10(increment_tmin.SUR), y = I_tmin.SUR[,k], y.smooth = y.tmin.SUR.smooth)) +
        labs(x="Temporal scale (y, log10)", y="MEM surf. spatial autocorrelation") +
        xlim(log10(increment_tmin.SUR[1]),log10(722)) +
        geom_abline(slope = a,intercept = b, linetype = "dashed", size = 0.4) +
        # geom_vline(xintercept = -b/a, linetype = "dotted", size = 0.4)
        geom_point(aes(x,y), size = 0.6, col = col.tmin.vect) +
        geom_line(aes(x,y.smooth), size = 0.4) +
        geom_hline(yintercept = 0, linetype = "dashed", size = 0.4) +
        annotate(geom="text",
                 x=0.58*(log10(722)-log10(increment_tmin.SUR[1]))+log10(increment_tmin.SUR[1]),
                 y=0.85*max(I_tmin.SUR[,k]),
                 label=paste0("t = ",signif(charac_tmin.SUR_scale[k], digits = 3),"y"),
                 # label = bquote("Median"==.(format(median.adjR2.per.MEM[k],digits=2))),
                 hjust = 0,
                 size=6) +
        theme_bw() +
        ggtitle(paste("MEM",k)) +
        theme(axis.text=element_text(size=12),
              axis.title=element_text(size=15),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm"))  
    } else if (charac.dist)
    {
      y.dist.SUR.smooth = smooth.spline(increment_dist.SUR,I_dist.SUR[,k],df=5)$y
      if (k == 1)
      {
        lin.regr = lm(y.dist.SUR.smooth[9:14] ~ increment_dist.SUR[9:14])
      } else if (k == 2)
      {
        lin.regr = lm(y.dist.SUR.smooth[8:12] ~ increment_dist.SUR[8:12])
      } else if (k == 3)
      {
        lin.regr = lm(y.dist.SUR.smooth[4:10] ~ increment_dist.SUR[4:10])
      } else
        lin.regr = lm(y.dist.SUR.smooth[2:4] ~ increment_dist.SUR[2:4])
      
      b = summary(lin.regr)$coefficients[1,1]
      a = summary(lin.regr)$coefficients[2,1]
      charac_dist.SUR_scale[k] = -b/a
      Moran.step.dist.w.spline[[k]] = ggplot(data = data.frame(x = increment_dist.SUR, y = I_dist.SUR[,k], y.smooth = y.dist.SUR.smooth)) +
        labs(x="Spatial scale (km)", y="MEM surf. spatial autocorrelation") +
        geom_abline(slope = a,intercept = b, linetype = "dashed", size = 0.4) +
        geom_point(aes(x,y), size = 0.6, col = col.dist.vect) +
        geom_line(aes(x,y.smooth), size = 0.4) +
        geom_hline(yintercept = 0, linetype = "dashed", size = 0.4) +
        theme_bw() +
        # ggtitle(paste("MEM",k,"-",round(SUR_MEM_restricted.ev[k]))) +
        ggtitle(paste("MEM",k)) +
        annotate(geom="text",
                 x=0.35*max(increment_dist.SUR),
                 y=0.85*max(I_dist.SUR[,k]),
                 label=paste0("d = ",signif(charac_dist.SUR_scale[k], digits = 3)," km"),
                 # label = bquote("Median"==.(format(median.adjR2.per.MEM[k],digits=2))),
                 hjust = 0,
                 size=6) +
        theme(axis.text = element_text(size=12),
              axis.title=element_text(size=15),
              plot.title=element_text(hjust=0, size=15),
              plot.margin=unit(c(1,1,1,0.5),"mm"))
      
      # y.tmin.SUR.smooth = smooth.spline(increment_tmin.SUR,I_tmin.SUR[,k],df=5)$y
      # lin.regr = lm(y.tmin.SUR.smooth[2:4] ~ increment_tmin.SUR[2:4])
      # b = summary(lin.regr)$coefficients[1,1]
      # a = summary(lin.regr)$coefficients[2,1]
      # charac_tmin.SUR_scale[k] = -b/a
      # Moran.step.tmin.w.spline[[k]] = ggplot(data = data.frame(x = increment_tmin.SUR, y = I_tmin.SUR[,k], y.smooth = y.tmin.SUR.smooth)) +
      #   labs(x="Temporal scale", y="MEM surf. spatial autocorrelation") +
      #   geom_abline(slope = a,intercept = b, linetype = "dashed", size = 0.4)
        
    }
  }
  
  if (charac.tmin)
  {
    # saveRDS(charac_tmin.SUR_scale,
    #         paste0(results_folder,"/MEM.charac.tmin.scale_SUR.rds"))
    
    spl = split(Moran.step.tmin.w.spline[!is.na(Moran.step.tmin.w.spline)], 
                (seq_along(Moran.step.tmin.w.spline[!is.na(Moran.step.tmin.w.spline)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/Moran.step.MEM.w.spline",ifelse(log.scale,"_log.","_"),"tmin.SUR.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
  } else if (charac.dist)
  { 
    # saveRDS(charac_dist.SUR_scale,
    #         paste0(results_folder,"/MEM.charac.dist.scale_SUR.rds"))
    
    spl = split(Moran.step.dist.w.spline[!is.na(Moran.step.dist.w.spline)], 
                (seq_along(Moran.step.dist.w.spline[!is.na(Moran.step.dist.w.spline)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/Moran.step.MEM.w.spline",ifelse(log.scale,"_log.","_"),"dist.SUR.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
  }

}

if (spatial_structure)
{
  V4_stations = 0
  psbO_stations = 0
  
  # raref = NULL
  # raref = ".104"
  # raref = ".200"
  # raref = ".300"
  # raref = ".350.random"
  # raref = ".200.random"
  # raref = ".200.random"
  # raref = ".800.random"
  # raref = ".105"
  # raref = ".350" 
  # raref = ".500"
  raref = "random.group.div"
  
  # reals = 10
  reals = NULL
  
  if (V4_stations)
  {
    station_insert = "_V4.stations"
  } else if (psbO_stations)
  {
    station_insert = "_psbO.stations"
  } else
    station_insert = ""
  
  library(ape)
  library(entropy)
  library(ggplot2)
  library(gridExtra)
  library(vegan)
  library(splines)
  library(moments)
  taxo_groups = readRDS(paste0(results_folder,"/",short_marker,"taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/",short_marker,"diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  tot_reads = readRDS(paste0(results_folder,"/Total.read.numbers.rds"))
  load(paste0(results_folder,"/group_sizes_byStationByDepth_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
  if (data_Federico)
  {
    selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100
  } else if (data_V4)
  {
    selected_groups = 1:41
  } else if (data_psbO)
    selected_groups = 1:6
  if (!is.null(raref))
    tot_reads = readRDS(paste0(results_folder,"/Total.read.numbers.rds"))
  
  if (data_Federico)
  {
    if (is.null(raref))
    {
      optimalK_min.crossValid = readRDS(paste0(results_folder,"/optimalK_min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
      optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
      optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
      optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]] 
      optimalK_prevalenceSUR.DCM.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalenceSUR-DCM.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
      optimalK_prevalenceSUR.DCM.min.crossValid.allTaxa = optimalK_prevalenceSUR.DCM.min.crossValid.complete[[1]]
      optimalK_prevalenceSUR.DCM.min.crossValid = optimalK_prevalenceSUR.DCM.min.crossValid.complete[[2]]
      
      optimalK_sd.max.llh = readRDS(paste0(results_folder,"/optimalK_sd.max.llh_Gibbs100r2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))[,1]
    } else 
    {
      optimalK_prevalence.min.crossValid = readRDS(paste0(results_folder,"/",
                                                          if (raref == "random.group.div") raref
                                                          else paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)], collapse=""),
                                                          if (!is.null(reals)) paste0(".1-",reals) else "",
                                                          "_optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-25t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
    }
  } else
  {
    optimalK_prevalence.min.crossValid = readRDS(paste0(results_folder,"/",short_marker,"optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-30t_iter1000thin25burnin2000_2plusOTUs_noLagoon.rds"))
  }
  
  geographic_distances = read.table(paste0(data_folder,"/Abiotic_data/Geographic_distances.csv"),sep="\t",header=T,row.names=1)
  geographic_distances = geographic_distances[,-ncol(geographic_distances)]
  
  if (data_Federico)
  {
    if (V4_stations)
    {
      stations_depths = stations_depths_V4
      selected_stations = selected_stations_V4
      coord = coord_V4
    } else if (psbO_stations) 
    {
      stations_depths = stations_depths_psbO
      selected_stations = selected_stations_psbO
      coord = coord_psbO 
    } else
    {
      stations_depths = stations_depths_V9
      selected_stations = selected_stations_V9
      coord = coord_V9
    }
  }
  
  selected_geographic_distances = geographic_distances[selected_stations,paste0("X",selected_stations)]
  # selected_travel_time_matrix_SUR = selected_travel_time_matrix_SUR[stations_depths[,2] == "SUR",stations_depths[,2] == "SUR"]
  
  if (!is.null(raref))
  {
    raref_taxo_groups = taxo_groups[selected_groups & 
                                      tot_reads > (if (raref == ".104") 10^4 else if (raref == ".105") 10^5 else if (raref == ".106") 10^6 else 0) &
                                      diversity > (if (raref == ".200") 200 else if (raref == ".250") 250 else if (raref == ".300") 300 else if (raref == ".350") 350
                                                   else if (raref == ".500") 500 else if (raref == ".1000") 1000 
                                                   else if (raref == ".250.random") 250 else if (raref == ".350.random") 350 
                                                   else if (raref == ".200.random") 200 else if (raref == ".400.random") 400 else if (raref == ".800.random") 800
                                                   else 100)]
    
    if (!is.null(reals))
    {
      raref_taxo_groups = paste0(rep(paste0(raref_taxo_groups,raref,"."),each=reals),
                                 rep(1:reals,length(raref_taxo_groups)))
    } else if (raref == "random.group.div")
    {
      raref_taxo_groups = paste0(raref,".",3:length(taxo_groups[selected_groups]))
    } else
      raref_taxo_groups = paste0(raref_taxo_groups,raref)
  }
  
  nb_iter = 1000
  nb_real = 100
  thin = 25
  burnin = 2000
  
  heterogeneity = 0
  lat_analyses = 1
  sigma2 = 25 # for lat_analyses
  #sigma2.range = 1:50 # for lat_analyses
  tropic_bound = 23
  arctic_bound = 50
  basins = 1
  Shannon_Simpson = 0
  JSD_SUR_DCM = 0
  Moran_I = 1
  autocorr_scale = 1
  log.scale = 0
  nb_increment = 20
  
  # Precomputations:
  if (lat_analyses)
  {
    # Computing the exectation besaed on the relative number of stations in each latitudinal range:
    latitudinal_topic_distribution.expected = list(SUR = vector(length = 3, mode = "numeric"),
                                                   DCM = vector(length = 3, mode = "numeric"),
                                                   all = vector(length = 3, mode = "numeric"))
    weighted_latitudinal_topic_distribution.expected = list(SUR = vector(length = 3, mode = "numeric"),
                                                            DCM = vector(length = 3, mode = "numeric"),
                                                            all = vector(length = 3, mode = "numeric"))
    for (i_case in 1:3)
    {
      case = c("SUR","DCM","all")[i_case]
      if (i_case %in% c(1,2))
      {
        abs_latitude = abs(coord$y)[stations_depths[,2] == case]
      } else
        abs_latitude = abs(coord$y)
      latitudinal_topic_distribution.expected[[i_case]] = c(length(which(abs_latitude > arctic_bound))/length(abs_latitude),
                                                  length(which(abs_latitude < arctic_bound & abs_latitude > tropic_bound))/length(abs_latitude),
                                                  length(which(abs_latitude < tropic_bound))/length(abs_latitude))
      weighted_latitudinal_topic_distribution.expected[[i_case]] = c(length(which(abs_latitude > arctic_bound)), 
                                                           length(which(abs_latitude < arctic_bound & abs_latitude > tropic_bound)),
                                                           length(which(abs_latitude < tropic_bound)))
    }
    lat.skewness = list(SUR = vector(length = length(taxo_groups), mode = "numeric"),
                        DCM = vector(length = length(taxo_groups), mode = "numeric"),
                        all = vector(length = length(taxo_groups), mode = "numeric"))
    lat.skewness.allTaxa = rep(0,3)
  }
  if (basins)
  {
    load(paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTAxa",noArcticNoBiomark_insert,noLagoon_insert,
                       "/sample_ref.Rdata"))
    sample_ref_indices = vector(length = nrow(coord), mode = "numeric")
    for (i in 1:nrow(coord))
      sample_ref_indices[i] = which(sample_ref$Station.label == stations_depths[i,1] & sample_ref$Depth == stations_depths[i,2])[1]
    geographic_classes = sample_ref[sample_ref_indices,"Ocean.region"]
    
    if (data_V4 || data_psbO)
      geographic_classes[is.na(sample_ref_indices)] = c("[IO] Indian Ocean (MRGID:1904)","[AO] Arctic Ocean (MRGID:1906)")
  }
  if (JSD_SUR_DCM)
  {
    load(paste0(data.folder_name,"/sample_ref.Rdata"))
    
    sampling_depth = ML_depth = vector(length = nrow(coord), mode = "numeric")
    # names(sampling_depth) = names(ML_depth) = rownames(coord)
    for (i in 1:nrow(coord))
    {
      sampling_depth[i] = mean(as.numeric(sample_ref$Depth.nominal[sample_ref$Station.label == stations_depths[i,1] & sample_ref$Depth == stations_depths[i,2]]),na.rm=T)
      ML_depth[i] = mean(sample_ref$Depth.Mixed.Layer[sample_ref$Station.label == stations_depths[i,1] & sample_ref$Depth == stations_depths[i,2]],na.rm=T)
    }
  }
  
  # Initializations:
  if (heterogeneity)
  {
    mean_JSD_stations = matrix(nrow = length(taxo_groups), ncol = 2, dimnames = list(taxo_groups,c("SUR","DCM")), data = 0)
    mean_JSD_stations.allTaxa = vector(length = 2, mode = "numeric")
  }
  if (lat_analyses)
  {
    library(ape)
    lat_JSD = matrix(nrow = length(taxo_groups), ncol = 2, dimnames = list(taxo_groups,c("Sur","DCM")), data = 0)
    lat_JSD.allTaxa = c(0,0)
    names(lat_JSD.allTaxa) = c("Sur","DCM")
    
    lat_I_sym = lat_I_nonsym = lat_I_all = matrix(nrow = length(taxo_groups), ncol = 2, dimnames = list(taxo_groups,c("Sur","DCM")), data = 0)
    lat_I_sym.allTaxa = lat_I_nonsym.allTaxa = lat_I_all.allTaxa = c(0,0)
    names(lat_I_sym.allTaxa) = names(lat_I_nonsym.allTaxa) = names(lat_I_all.allTaxa) = c("Sur","DCM")
    
    # lat_JSD.allTaxa.range = matrix(nrow = length(sigma2.range), ncol = 2, dimnames = list(sigma2.range,c("Sur","DCM")), data = 0)
    # lat_I.allTaxa.range = matrix(nrow = length(sigma2.range), ncol = 2, dimnames = list(sigma2.range,c("Sur","DCM")), data = 0)
    
    latitudinal_topic_distribution = list(SUR = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c(paste0(">",arctic_bound,""),paste0(tropic_bound,"-",arctic_bound,""),paste0("<",tropic_bound,""))), data = 0),
                                          DCM = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c(paste0(">",arctic_bound,""),paste0(tropic_bound,"-",arctic_bound,""),paste0("<",tropic_bound,""))), data = 0),
                                          all = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c(paste0(">",arctic_bound,""),paste0(tropic_bound,"-",arctic_bound,""),paste0("<",tropic_bound,""))), data = 0))
    weighted_latitudinal_topic_distribution = list(SUR = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c(paste0(">",arctic_bound,""),paste0(tropic_bound,"-",arctic_bound,""),paste0("<",tropic_bound,""))), data = 0),
                                                   DCM = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c(paste0(">",arctic_bound,""),paste0(tropic_bound,"-",arctic_bound,""),paste0("<",tropic_bound,""))), data = 0),
                                                   all = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c(paste0(">",arctic_bound,""),paste0(tropic_bound,"-",arctic_bound,""),paste0("<",tropic_bound,""))), data = 0))
    latitudinal_topic_distribution.allTaxa = list(SUR = vector(length = 3, mode = "numeric"),
                                                  DCM = vector(length = 3, mode = "numeric"),
                                                  all = vector(length = 3, mode = "numeric"))
    weighted_latitudinal_topic_distribution.allTaxa = list(SUR = vector(length = 3, mode = "numeric"),
                                                           DCM = vector(length = 3, mode = "numeric"),
                                                           all = vector(length = 3, mode = "numeric"))
    prevalence.corrected_K = matrix(nrow = length(taxo_groups), ncol = 4, dimnames = list(taxo_groups,c("SUR","DCM","All","SUR and DCM")), data = 0)
  }
  if (basins)
  {
    # Lat_Rsquare = matrix(nrow = length(taxo_groups), ncol = 2, data = NA)
    # Lat_pval = matrix(nrow = length(taxo_groups), ncol = 2, data = NA)
    # province_dissim = matrix(nrow = length(taxo_groups), ncol = 2, data = NA)
    # province_dissim.allTaxa = vector(length = 2, mode = "numeric")
    # Lat_pval.allTaxa = vector(length = 2, mode = "numeric")
    # Lat_Rsquare.allTaxa = vector(length = 2, mode = "numeric")
    
    basin_I_within = basin_I_contrast = basin_I_between = matrix(nrow = length(taxo_groups), ncol = 2, dimnames = list(taxo_groups,c("Sur","DCM")), data = 0)
    basin_I_within.allTaxa = basin_I_contrast.allTaxa = basin_I_between.allTaxa = c(0,0)
    names(basin_I_within.allTaxa) = names(basin_I_contrast.allTaxa) = names(basin_I_between.allTaxa) = c("Sur","DCM")
  }
  if (Shannon_Simpson)
  {
    rownames_SUR = list()
    rownames_DCM = list()
    Shannon.SUR.latitude.plot = list()
    Shannon.SUR.latitude.plot.w.spline = list()
    Shannon.ind.SUR.latitude.plot.w.spline = list()
    Shannon.ind.SUR.abs.latitude.plot.w.spline = list()
    Shannon.DCM.latitude.plot = list()
    Shannon.DCM.latitude.plot.w.spline = list()
    Shannon.ind.DCM.latitude.plot.w.spline = list()
    Shannon.ind.DCM.abs.latitude.plot.w.spline = list()
    Shannon.latitude.plot = list()
    Shannon.latitude.plot.w.spline = list()
    Shannon.ind.latitude.plot = list()
    Shannon.ind.latitude.plot.w.spline = list()
    Shannon.abs.latitude.plot = list()
    Shannon.abs.latitude.plot.w.spline = list()
    Shannon.ind.abs.latitude.plot = list()
    Shannon.ind.abs.latitude.plot.w.spline = list()
    #####
    shannon = simpson = vector(length=length(taxo_groups), mode="list")
    shannon_SUR = simpson_SUR = vector(length=length(taxo_groups), mode="list")
    shannon_DCM = simpson_DCM = vector(length=length(taxo_groups), mode="list")
    shannon_total = simpson_total = rep(NA,length=length(taxo_groups))
    shannon_total_SUR = simpson_total_SUR = rep(NA,length=length(taxo_groups))
    shannon_total_DCM = simpson_total_DCM = rep(NA,length=length(taxo_groups))
    #####
    nb_dominants = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","All")), data=0)
    nb_dominants.allTaxa = vector(length = 3, mode="numeric")
    names(nb_dominants.allTaxa) = c("SUR","DCM","All")
    nb_absolute_dominants = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","All")), data=0)
    nb_absolute_dominants.allTaxa = vector(length = 3, mode="numeric")
    names(nb_absolute_dominants.allTaxa) = c("SUR","DCM","All")
  }
  if (JSD_SUR_DCM)
  {
    JSD = list()
    coord_JSD = list()
    # expected_JSD = vector(length=length(taxo_groups), mode="numeric")
    JSD.latitude.plot = list()
    # JSD.latitude.plot.w.expected = list()
    JSD.abs.latitude.plot = list()
    JSD.mixed.layer.plot = list()
    JSD.sampling.depth.plot = list()
  }
  if (Moran_I)
  {
    # I_linear = list()
    # I_inverse = list()
    # I_square = list()
    if (is.null(reals))
    {
      I_linear.observed_w.mean = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = 0)
      I_linear.p.value_w.mean = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = 0)
      # I_linear_mean = matrix(nrow = length(taxo_groups), ncol = 3, data = 0)
      I_inverse.observed_w.mean = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = 0)
      I_inverse.p.value_w.mean = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = 0)
      # I_inverse_mean = matrix(nrow = length(taxo_groups), ncol = 3, data = 0)
      I_square.observed_w.mean = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = 0)
      I_square.p.value_w.mean = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = 0)
      # I_square_mean = matrix(nrow = length(taxo_groups), ncol = 3, data = 0)
      I_linear.observed_w.mean_allTaxa = vector(length = 3, mode = "numeric")
      I_linear.p.value_w.mean_allTaxa = vector(length = 3, mode = "numeric")
      names(I_linear.observed_w.mean_allTaxa) = names(I_linear.p.value_w.mean_allTaxa) = c("SUR","DCM","Weighted.mean")
      # I_linear_mean_allTaxa = vector(length = 3, mode = "numeric")
      I_inverse.observed_w.mean_allTaxa = vector(length = 3, mode = "numeric")
      I_inverse.p.value_w.mean_allTaxa = vector(length = 3, mode = "numeric")
      names(I_inverse.observed_w.mean_allTaxa) = names(I_inverse.p.value_w.mean_allTaxa) = c("SUR","DCM","Weighted.mean")
      # I_inverse_mean_allTaxa = vector(length = 3, mode = "numeric")
      I_square.observed_w.mean_allTaxa = vector(length = 3, mode = "numeric")
      I_square.p.value_w.mean_allTaxa = vector(length = 3, mode = "numeric")
      names(I_square.observed_w.mean_allTaxa) = names(I_square.p.value_w.mean_allTaxa) = c("SUR","DCM","Weighted.mean")
      # I_square_mean_allTaxa = vector(length = 3, mode = "numeric")
      prevalence.corrected_K = matrix(nrow = length(taxo_groups), ncol = 4, dimnames = list(taxo_groups,c("SUR","DCM","All","SUR and DCM")), data = 0)
      nb_stat = matrix(nrow = length(taxo_groups), ncol = 2, dimnames = list(taxo_groups,c("SUR","DCM")), data = 0)
      if (autocorr_scale)
      {
        I_step_observed_w.mean = list()
        I_step_relative_w.mean = list()
        I_step_p.value_w.mean = list()
        increment = list()
      }
    } else
    {
      I_square.observed_w.mean = I_square.p.value_w.mean = vector(length = 3, mode = "list")
      names(I_square.observed_w.mean) = names(I_square.p.value_w.mean) = c("SUR","DCM","Weighted.mean")
      I_square.observed_w.mean[[1]] = I_square.observed_w.mean[[2]] = I_square.observed_w.mean[[3]] = matrix(nrow = length(taxo_groups), ncol = reals, dimnames = list(taxo_groups,paste("Samples",1:reals)), data = 0)
      I_square.p.value_w.mean[[1]] = I_square.p.value_w.mean[[2]] = I_square.p.value_w.mean[[3]] = matrix(nrow = length(taxo_groups), ncol = reals, dimnames = list(taxo_groups,paste("Samples",1:reals)), data = 0)
      
      I_square.observed_w.mean_allTaxa = I_square.p.value_w.mean_allTaxa = vector(length = 3, mode = "list")
      names(I_square.observed_w.mean_allTaxa) = names(I_square.p.value_w.mean_allTaxa) = c("SUR","DCM","Weighted.mean")
      I_square.observed_w.mean_allTaxa[[1]] = I_square.observed_w.mean_allTaxa[[2]] = I_square.observed_w.mean_allTaxa[[3]] = vector(length = reals, mode = "numeric")
      I_square.p.value_w.mean_allTaxa[[1]] = I_square.p.value_w.mean_allTaxa[[2]] = I_square.p.value_w.mean_allTaxa[[3]] = vector(length = reals, mode = "numeric")
    }
  }
  ii_taxon = 0
  for (taxon in (if (!is.null(raref)) raref_taxo_groups else taxo_groups[selected_groups]))
    # for (taxon in taxo_groups[1:54])
    # for (taxon in taxo_groups)
    # for (taxon in c("AllTaxa",taxo_groups))
  {
    if (!is.null(raref) && raref != "random.group.div")
    {
      true_taxon = strsplit(taxon,split=".",fixed=T)[[1]][1]
      if (!is.null(reals))
        real = as.numeric(strsplit(taxon,split=".",fixed=T)[[1]][length(strsplit(taxon,split=".",fixed=T)[[1]])])
      ii_taxon = ii_taxon+1
    } else if (!is.null(raref) && raref == "random.group.div")
    {
      ii_taxon = as.numeric(strsplit(taxon,split=".",fixed=T)[[1]][length(strsplit(taxon,split=".",fixed=T)[[1]])])
      true_taxon = taxo_groups[selected_groups][ii_taxon]
    } else
    {
      true_taxon = taxon
      ii_taxon = ii_taxon+1
    }
    if (true_taxon != "AllTaxa")
      i_taxon = which(true_taxon == taxo_groups)
    cat("\n",ifelse(true_taxon=="AllTaxa","AllTaxa",paste0(i_taxon,if (!is.null(reals)) paste0(".",real) else "","/",length(taxo_groups))))
    # data.folder_name = paste0(data_folder,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",
    #                           if (is.null(raref)) taxon else paste0(taxon,raref),noArcticNoBiomark_insert,noLagoon_insert)
    data.folder_name = paste0(data_folder_workspace2,"/",marker,"_TARA_CompleteSizeRange_byStationByDepth_",
                              taxon,noArcticNoBiomark_insert,noLagoon_insert)
    
    if (is.null(reals))
    {
      if (true_taxon != "AllTaxa")
        # nb_topics = optimalK_min.crossValid[i_taxon]
        nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
      else
        # nb_topics = 21
        nb_topics = optimalK_prevalence.min.crossValid.allTaxa
    } else 
    {
      if (true_taxon != "AllTaxa")
        # nb_topics = optimalK_min.crossValid[i_taxon]
        nb_topics = optimalK_prevalence.min.crossValid[i_taxon,real]
      else
        # nb_topics = 21
        nb_topics = optimalK_prevalence.min.crossValid.allTaxa[real]
    }
    
    # Gibbs_VEM_insert == "_GibbsShortChainNoAverage10sampleFold")
    # I_linear_taxon = list()
    # I_inverse_taxon = list()
    # I_square_taxon = list()
    # if (taxon != "AllTaxa")
    # {
    #   I_linear[[i_taxon]] = list()
    #   I_inverse[[i_taxon]] = list()
    #   I_square[[i_taxon]] = list()
    # } else
    # {
    #   I_linear_allTaxa = list()
    #   I_inverse_allTaxa = list()
    #   I_square_allTaxa = list()
    # }
    documents_file_name = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds")
    if (file.exists(documents_file_name))
    {
      spatial_topicmix_kriged = readRDS(documents_file_name)
      # selecting the z.pred columns in all topics:
      documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
      # setting one topic per column
      documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("assemblage",1:nb_topics)))
      
      if (heterogeneity)
      {
        for (i_case in 1:2)
        {
          case = c("SUR","DCM")[i_case]
          documents_case = documents[stations_depths[rownames(coord) %in% rownames(documents),2] == case,]
          JSD_case = 0
          for (i_station in 2:nrow(documents_case))
          {
            for (j_station in 1:(i_station-1))
            {
              support_distrib = documents_case[i_station,] !=0 | documents_case[j_station,] !=0
              documents_i_station = documents_case[i_station,support_distrib]
              documents_j_station = documents_case[j_station,support_distrib]
              ij_mixture = (documents_i_station+documents_j_station)/2
              JSD_case = JSD_case + 1/2*(KL.plugin(documents_i_station,ij_mixture) + KL.plugin(documents_j_station,ij_mixture))/log(2)
            }
          }
          if (taxon != "AllTaxa")
            mean_JSD_stations[i_taxon,i_case] = 2*JSD_case/(nrow(documents_case)*(nrow(documents_case)-1))
          else
            mean_JSD_stations.allTaxa[i_case] = 2*JSD_case/(nrow(documents_case)*(nrow(documents_case)-1))
        }
      }
      
      if (lat_analyses)
      {
        for (i_case in (if (data_Federico && (V4_stations || psbO_stations)) 1:2 else 1:3))
        {
          if (data_Federico && (V4_stations || psbO_stations))
          {  
            case = c("SUR","DCM")[i_case]  
          } else
            case = c("SUR","DCM","all")[i_case]  
          # mean_latitude = vector(length = ncol(documents), mode = "numeric")
          # Computing the latitude of topics' barycentres:
          mean_abs_latitude = vector(length = ncol(documents), mode = "numeric")
          if (case %in% c("SUR","DCM"))
          {
            if (case == "SUR")
            {
              documents_case = documents[rownames(documents) %in% rownames(coord),][stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]
              coord_case = coord[rownames(coord) %in% rownames(documents_case),]
              k_SUR_taxon = length(which(colSums(documents_case) > 1))
            } else if (case == "DCM")
            {
              documents_case = documents[rownames(documents) %in% rownames(coord),][stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",]
              coord_case = coord[rownames(coord) %in% rownames(documents_case),]
              k_DCM_taxon = length(which(colSums(documents_case) > 1))
            }
            
            # Computing JSD between latitudinal stripes:
            ###########################################
            
            # if (taxon == "AllTaxa")
            # {
            #   i_sigma2 = 0
            #   for (sigma2.increment in sigma2.range)
            #   {
            #     i_sigma2 = i_sigma2+1
            #     JSD_weighting_normalization = 0
            #     for (i_north in which(coord_case$y > 0))
            #     {
            #       for (i_south in which(coord_case$y < 0))
            #       {
            #         support_distrib = documents_case[i_north,] !=0 | documents_case[i_south,] !=0
            #         documents_north_station = documents_case[i_north,support_distrib]
            #         documents_south_station = documents_case[i_south,support_distrib]
            #         mixture = (documents_north_station+documents_south_station)/2
            #         JSD = 1/2*(KL.plugin(documents_north_station,mixture) + KL.plugin(documents_south_station,mixture))/log(2)
            #         JSD_weighting = exp(-(abs(coord_case$y[i_north]) - abs(coord_case$y[i_south]))^2/sigma2.increment)
            #         lat_JSD.allTaxa.range[i_sigma2,i_case] = lat_JSD.allTaxa.range[i_sigma2,i_case] + JSD*JSD_weighting
            #         JSD_weighting_normalization = JSD_weighting_normalization + JSD_weighting
            #       }
            #     }
            #     lat_JSD.allTaxa.range[i_sigma2,i_case] = lat_JSD.allTaxa.range[i_sigma2,i_case]/JSD_weighting_normalization
            #   }
            # }
              
            JSD_weighting_normalization = 0
            for (i_north in which(coord_case$y > 0))
            {
              for (i_south in which(coord_case$y < 0))
              {
                support_distrib = documents_case[i_north,] !=0 | documents_case[i_south,] !=0
                documents_north_station = documents_case[i_north,support_distrib]
                documents_south_station = documents_case[i_south,support_distrib]
                mixture = (documents_north_station+documents_south_station)/2
                JSD = 1/2*(KL.plugin(documents_north_station,mixture) + KL.plugin(documents_south_station,mixture))/log(2)
                JSD_weighting = exp(-(abs(coord_case$y[i_north]) - abs(coord_case$y[i_south]))^2/sigma2)
                if (taxon != "AllTaxa")
                  lat_JSD[i_taxon,i_case] = lat_JSD[i_taxon,i_case] + JSD*JSD_weighting
                else
                  lat_JSD.allTaxa[i_case] = lat_JSD.allTaxa[i_case] + JSD*JSD_weighting
                JSD_weighting_normalization = JSD_weighting_normalization + JSD_weighting
              }
            }  
            if (taxon != "AllTaxa")
              lat_JSD[i_taxon,i_case] = lat_JSD[i_taxon,i_case]/JSD_weighting_normalization
            else
              lat_JSD.allTaxa[i_case] = lat_JSD.allTaxa[i_case]/JSD_weighting_normalization
            
            #################
            # if (taxon == "AllTaxa")
            # {
            #   i_sigma2 = 0
            #   for (sigma2.increment in sigma2.range)
            #   {
            #     i_sigma2 = i_sigma2+1
            #     weight_matrix = matrix(nrow = nrow(documents_case), ncol = nrow(documents_case), data = 0)
            #     for (i_station in 2:nrow(documents_case))
            #     {
            #       for (j_station in 1:(i_station-1))
            #       {
            #         if (sign(coord_case$y[i_station]) == -sign(coord_case$y[j_station]))
            #         {
            #           weight_matrix[i_station,j_station] = weight_matrix[j_station,i_station] = exp(-(abs(coord_case$y[i_station]) - abs(coord_case$y[j_station]))^2/sigma2.increment)
            #         }
            #       }
            #     }
            #     I = vector(length = ncol(documents_case), mode = "numeric")
            #     for (k in 1:ncol(documents_case))
            #     {
            #       I[k] = ape::Moran.I(documents_case[,k],weight_matrix)$observed
            #     }
            #     lat_I.allTaxa.range[i_sigma2,i_case] = weighted.mean(I, w = colSums(documents_case))
            #   }
            # }
            
            ################
            weight_matrix_sym = weight_matrix_nonsym = weight_matrix_all = matrix(nrow = nrow(documents_case), ncol = nrow(documents_case), data = 0)
            for (i_station in 2:nrow(documents_case))
            {
              for (j_station in 1:(i_station-1))
              {
                if (sign(coord_case$y[i_station]) == -sign(coord_case$y[j_station]))
                {
                  weight_matrix_sym[i_station,j_station] = weight_matrix_sym[j_station,i_station] = exp(-(abs(coord_case$y[i_station]) - abs(coord_case$y[j_station]))^2/sigma2)
                }
                weight_matrix_all[i_station,j_station] = weight_matrix_all[j_station,i_station] = exp(-(abs(coord_case$y[i_station]) - abs(coord_case$y[j_station]))^2/sigma2)
                weight_matrix_nonsym[i_station,j_station] = weight_matrix_nonsym[j_station,i_station] = exp(-(coord_case$y[i_station] - coord_case$y[j_station])^2/sigma2)
              }
            }
            I_sym = I_nonsym = I_all = vector(length = ncol(documents_case), mode = "numeric")
            for (k in 1:ncol(documents_case))
            {
              if (!all(weight_matrix_sym == 0))
              {
                I_sym[k] = ape::Moran.I(documents_case[,k],weight_matrix_sym)$observed
              } else
                I_sym[k] = NA
              if (!all(weight_matrix_nonsym == 0))
              {
                I_nonsym[k] = ape::Moran.I(documents_case[,k],weight_matrix_nonsym)$observed
              } else
                I_nonsym[k] = NA
              if (!all(weight_matrix_all == 0))
              {
                I_all[k] = ape::Moran.I(documents_case[,k],weight_matrix_all)$observed
              } else
                I_all[k] = NA
            }
            if (taxon != "AllTaxa")
            {
              lat_I_sym[i_taxon,i_case] = weighted.mean(I_sym, w = colSums(documents_case))
              lat_I_nonsym[i_taxon,i_case] = weighted.mean(I_nonsym, w = colSums(documents_case))
              lat_I_all[i_taxon,i_case] = weighted.mean(I_all, w = colSums(documents_case))
            } else
            {
              lat_I_sym.allTaxa[i_case] = weighted.mean(I_sym, w = colSums(documents_case))
              lat_I_nonsym.allTaxa[i_case] = weighted.mean(I_nonsym, w = colSums(documents_case))
              lat_I_all.allTaxa[i_case] = weighted.mean(I_all, w = colSums(documents_case))
            }
              
            # Latitude distribution of assemblages:
            ########################################
            for (k in 1:ncol(documents))
            {
              # mean_latitude[k] = weighted.mean(coord$y[rownames(coord) %in% rownames(documents) & stations_depths[,2] == "SUR"],
              #                                  w=documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",k]/sum(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",k]))
              mean_abs_latitude[k] = weighted.mean(abs(coord_case$y),#[rownames(coord) %in% rownames(documents) & stations_depths[,2] == case],
                                                   w=documents_case[,k]/sum(documents_case[,k]))#[stations_depths[rownames(coord) %in% rownames(documents),2] == case,k]/sum(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == case,k]))  
            }
            # Sorting topics by their abundance in surface samples:
            sorted_assemblages = sort.int(colSums(documents_case),decreasing=T,index.return=T)
            # Selecting out the most abundant topic and the least abundant ones:
            selected_assemblages = colnames(documents_case) != colnames(documents_case)[sorted_assemblages$ix[1]] & colSums(documents_case) > 1
            
            if (taxon != "AllTaxa")
            {
              # Computing the number of topics belonging to each latitudinal range, not accounting for the most abundant one :
              latitudinal_topic_distribution[[i_case]][i_taxon,1] = length(which(mean_abs_latitude>arctic_bound & selected_assemblages))/ncol(documents_case[,selected_assemblages])
              latitudinal_topic_distribution[[i_case]][i_taxon,2] = length(which(mean_abs_latitude<arctic_bound & mean_abs_latitude>tropic_bound & selected_assemblages))/ncol(documents_case[,selected_assemblages])
              latitudinal_topic_distribution[[i_case]][i_taxon,3] = length(which(mean_abs_latitude<tropic_bound & selected_assemblages))/ncol(documents_case[,selected_assemblages])
              
              # Computing the contribution of topics belonging to each latitudinal range, not accounting for the most abundant one:
              weighted_latitudinal_topic_distribution[[i_case]][i_taxon,1] = sum(colSums(documents_case)[mean_abs_latitude>arctic_bound & selected_assemblages])
              weighted_latitudinal_topic_distribution[[i_case]][i_taxon,2] = sum(colSums(documents_case)[mean_abs_latitude<arctic_bound & mean_abs_latitude>tropic_bound & selected_assemblages])
              weighted_latitudinal_topic_distribution[[i_case]][i_taxon,3] = sum(colSums(documents_case)[mean_abs_latitude<tropic_bound & selected_assemblages])
              
              lat.skewness[[i_case]][i_taxon] = skewness(latitudinal_topic_distribution[[i_case]][i_taxon,]/latitudinal_topic_distribution.expected[[i_case]])
            } else
            {
              latitudinal_topic_distribution.allTaxa[[i_case]] = c(length(which(mean_abs_latitude>arctic_bound & selected_assemblages))/ncol(documents_case[,selected_assemblages]),
                                                                   length(which(mean_abs_latitude<arctic_bound & mean_abs_latitude>tropic_bound & selected_assemblages))/ncol(documents_case[,selected_assemblages]),
                                                                   length(which(mean_abs_latitude<tropic_bound & selected_assemblages))/ncol(documents_case[,selected_assemblages]))
              
              weighted_latitudinal_topic_distribution.allTaxa[[i_case]] = c(sum(colSums(documents_case)[mean_abs_latitude>arctic_bound & selected_assemblages]),
                                                                            sum(colSums(documents_case)[mean_abs_latitude<arctic_bound & mean_abs_latitude>tropic_bound & selected_assemblages]),
                                                                            sum(colSums(documents_case)[mean_abs_latitude<tropic_bound & selected_assemblages]))
              
              lat.skewness.allTaxa[i_case] = skewness(latitudinal_topic_distribution.allTaxa[[i_case]]/latitudinal_topic_distribution.expected[[i_case]])
            }
          } else
          {
            k_all_taxon = length(which(colSums(documents) > 1))
            k_SUR.DCM_taxon = length(which(colSums(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]) > 1 
                                           & colSums(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",]) > 1))
            
            for (k in 1:ncol(documents))
            {
              # mean_latitude[k] = weighted.mean(coord$y[rownames(coord) %in% rownames(documents) & stations_depths[,2] == "SUR"],
              #                                  w=documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",k]/sum(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",k]))
              mean_abs_latitude[k] = weighted.mean(abs(coord$y)[rownames(coord) %in% rownames(documents)],
                                                   w=documents[,k]/sum(documents[,k]))  
            }
            # Sorting topics by their abundance in surface samples:
            sorted_assemblages = sort.int(colSums(documents),decreasing=T,index.return=T)
            # Selecting out the most abundant topic and the least abundant one:
            selected_assemblages = colnames(documents) != colnames(documents)[sorted_assemblages$ix[1]] & colSums(documents) > 1
            
            if (taxon != "AllTaxa")
            {
              # Computing the number of topics belonging to each latitudinal range, not accounting for the most abundant one :
              latitudinal_topic_distribution[[i_case]][i_taxon,1] = length(which(mean_abs_latitude>arctic_bound & selected_assemblages))/ncol(documents[,selected_assemblages])
              latitudinal_topic_distribution[[i_case]][i_taxon,2] = length(which(mean_abs_latitude<arctic_bound & mean_abs_latitude>tropic_bound & selected_assemblages))/ncol(documents[,selected_assemblages])
              latitudinal_topic_distribution[[i_case]][i_taxon,3] = length(which(mean_abs_latitude<tropic_bound & selected_assemblages))/ncol(documents[,selected_assemblages])
              lat.skewness[[i_case]][i_taxon] = skewness(latitudinal_topic_distribution[[i_case]][i_taxon,]/latitudinal_topic_distribution.expected[[i_case]])
            } else
            {
              latitudinal_topic_distribution.allTaxa[[i_case]] = c(length(which(mean_abs_latitude>arctic_bound & selected_assemblages))/ncol(documents[,selected_assemblages]),
                                                                   length(which(mean_abs_latitude<arctic_bound & mean_abs_latitude>tropic_bound & selected_assemblages))/ncol(documents[,selected_assemblages]),
                                                                   length(which(mean_abs_latitude<tropic_bound & selected_assemblages))/ncol(documents[,selected_assemblages]))
              lat.skewness.allTaxa[i_case] = skewness(latitudinal_topic_distribution.allTaxa[[i_case]]/latitudinal_topic_distribution.expected[[i_case]])
            }
            
            if (taxon != "AllTaxa")
            {
              # Computing the contribution of topics belonging to each latitudinal range, not accounting for the most abundant one:
              weighted_latitudinal_topic_distribution[[i_case]][i_taxon,1] = sum(colSums(documents)[mean_abs_latitude>arctic_bound & selected_assemblages])
              weighted_latitudinal_topic_distribution[[i_case]][i_taxon,2] = sum(colSums(documents)[mean_abs_latitude<arctic_bound & mean_abs_latitude>tropic_bound & selected_assemblages])
              weighted_latitudinal_topic_distribution[[i_case]][i_taxon,3] = sum(colSums(documents)[mean_abs_latitude<tropic_bound & selected_assemblages])
              # Computing the exectation besaed on the relative number of stations in each latitudinal range:
            } else 
            {
              weighted_latitudinal_topic_distribution.allTaxa[[i_case]] = c(sum(colSums(documents)[mean_abs_latitude>arctic_bound & selected_assemblages]),
                                                                            sum(colSums(documents)[mean_abs_latitude<arctic_bound & mean_abs_latitude>tropic_bound & selected_assemblages]),
                                                                            sum(colSums(documents)[mean_abs_latitude<tropic_bound & selected_assemblages]))
            }
          }
        }
        if (taxon != "AllTaxa")
        {
          prevalence.corrected_K[i_taxon,] = c(k_SUR_taxon,k_DCM_taxon,k_all_taxon,k_SUR.DCM_taxon)
        } else if (taxon == "AllTaxa")   
        {
          prevalence.corrected_K.allTaxa = c(k_SUR_taxon,k_DCM_taxon,k_all_taxon,k_SUR.DCM_taxon)
        }
      }
      
      if (basins)
      {
        for (i_case in 1:2)
        {
          if (i_case == 1)
          {
            documents_case = documents[rownames(documents) %in% rownames(coord),][stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]
            # lat_case = abs(coord$y[stations_depths[,2] == "SUR" & rownames(coord) %in% rownames(documents)])
            # nb_stat_SUR = nrow(documents_case)
            # documents_case = documents_case[,colSums(documents_case) > 1/nrow(documents_case)]
            geographic_classes_case = geographic_classes[stations_depths[,2] == "SUR" & rownames(coord) %in% rownames(documents)]
          } else if (i_case == 2)
          {
            documents_case = documents[rownames(documents) %in% rownames(coord),][stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",]
            # lat_case = abs(coord$y[stations_depths[,2] == "DCM" & rownames(coord) %in% rownames(documents)])
            # nb_stat_DCM = nrow(documents_case)
            # documents_case = documents_case[,colSums(documents_case) > 1/nrow(documents_case)]
            geographic_classes_case = geographic_classes[stations_depths[,2] == "DCM" & rownames(coord) %in% rownames(documents)]
          }
          
          ###############
          # By oceanic basin:
          weight_matrix_within = weight_matrix_between = matrix(nrow = nrow(documents_case), ncol = nrow(documents_case), data = 0)
          weight_matrix_contrast = matrix(nrow = nrow(documents_case), ncol = nrow(documents_case), data = -1)
          for (i_station in 2:nrow(documents_case))
          {
            for (j_station in 1:(i_station-1))
            {
              if (geographic_classes_case[i_station] == geographic_classes_case[j_station])
              {
                weight_matrix_within[i_station,j_station] = weight_matrix_within[j_station,i_station] = 1
                weight_matrix_contrast[i_station,j_station] = weight_matrix_contrast[j_station,i_station] = 1
              } else
              {
                weight_matrix_between[i_station,j_station] = weight_matrix_between[j_station,i_station] = 1
              }
            }
          }
          I_within = I_contrast = I_between = vector(length = ncol(documents_case), mode = "numeric")
          for (k in 1:ncol(documents_case))
          {
            I_within[k] = ape::Moran.I(documents_case[,k],weight_matrix_within)$observed
            I_contrast[k] = ape::Moran.I(documents_case[,k],weight_matrix_contrast)$observed
            I_between[k] = ape::Moran.I(documents_case[,k],weight_matrix_between)$observed
          }
          # basin_I looks at how homogeneous each basin is in terms of assemblages; basin_I_contrast also looks at how different basins are from each other.
          if (taxon != "AllTaxa")
          {
            basin_I_within[i_taxon,i_case] = weighted.mean(I_within, w = colSums(documents_case))
            basin_I_contrast[i_taxon,i_case] = weighted.mean(I_contrast, w = colSums(documents_case))
            basin_I_between[i_taxon,i_case] = weighted.mean(I_between, w = colSums(documents_case))
          } else
          {
            basin_I_within.allTaxa[i_case] = weighted.mean(I_within, w = colSums(documents_case))
            basin_I_contrast.allTaxa[i_case] = weighted.mean(I_contrast, w = colSums(documents_case))
            basin_I_between.allTaxa[i_case] = weighted.mean(I_between, w = colSums(documents_case))
          }
          
          # RDA = rda(scale(documents_case) ~ scale(as.vector(lat_case)), na.action = na.exclude)
          # # as.numeric(unlist(c(sum(RDA$CCA$eig)/RDA$tot.chi,RsquareAdj(RDA)[2],anova(RDA)$'Pr(>F)'[1])))
          # if (taxon != "AllTaxa")
          # {
          #   Lat_Rsquare[i_taxon,i_case] = as.numeric(unlist(RsquareAdj(RDA)[2]))
          #   Lat_pval[i_taxon,i_case] = anova(RDA)$'Pr(>F)'[1]
          # } else
          # {
          #   Lat_Rsquare.allTaxa[i_case] = as.numeric(unlist(RsquareAdj(RDA)[2]))
          #   Lat_pval.allTaxa[i_case] = anova(RDA)$'Pr(>F)'[1]
          # }
          # 
          # classes = levels(as.factor(geographic_classes_case))
          # province_dissim_matrix = matrix(nrow = length(classes), ncol = length(classes), data = NA)
          # for (i1 in 2:length(classes))
          # {
          #   for (i2 in 1:(i1-1))
          #   {
          #     class1 = classes[i1]
          #     class2 = classes[i2]
          #     if (length(which(geographic_classes_case %in% class1)) > 1)
          #       documents_case_class1 = colMeans(documents_case[geographic_classes_case %in% class1,])
          #     else
          #       documents_case_class1 = documents_case[geographic_classes_case %in% class1,]
          #     documents_case_class1 = documents_case_class1/sum(documents_case_class1)
          #     if (length(which(geographic_classes_case %in% class2)) > 1)
          #       documents_case_class2 = colMeans(documents_case[geographic_classes_case %in% class2,])
          #     else
          #       documents_case_class2 = documents_case[geographic_classes_case %in% class2,]
          #     documents_case_class2 = documents_case_class2/sum(documents_case_class2)
          # 
          #     support_distrib = documents_case_class1 !=0 | documents_case_class2 !=0
          #     documents_case_class1 = documents_case_class1[support_distrib]
          #     documents_case_class2 = documents_case_class2[support_distrib]
          #     class1_class2_mixture = (documents_case_class1+documents_case_class2)/2
          #     
          #     province_dissim_matrix[i1,i2] = 1/2*(KL.plugin(documents_case_class1,class1_class2_mixture) + KL.plugin(documents_case_class2,class1_class2_mixture))
          #   }
          # }
          # if (taxon != "AllTaxa")
          # {
          #   province_dissim[i_taxon,i_case] = mean(province_dissim_matrix[!is.na(province_dissim_matrix)])
          # } else
          # {
          #   province_dissim.allTaxa[i_case] = mean(province_dissim_matrix[!is.na(province_dissim_matrix)])
          # }
        }
      }
      
      if (JSD_SUR_DCM)
      {
        JSD_taxon = list()
        stations = list()
        coord_taxon = list()
        sampling_depth_taxon = list()
        ML_depth_taxon = list()
        documents_SUR = list()
        documents_DCM = list()
        i_station = 0
        for (station in levels(as.factor(stations_depths[rownames(coord) %in% rownames(documents),1])))
        {
          if (any(rownames(coord) %in% rownames(documents) & stations_depths[,1] == station & stations_depths[,2] == "SUR") 
              && any(rownames(coord) %in% rownames(documents) & stations_depths[,1] == station & stations_depths[,2] == "DCM"))
          {
            # cat(paste(station,"\n"))
            i_station = i_station+1
            stations[[i_station]] = station
            coord_taxon[[i_station]] = colMeans(coord[rownames(coord) %in% rownames(documents) & stations_depths[,1] == station,])
            sampling_depth_taxon[[i_station]] = sampling_depth[rownames(coord) %in% rownames(documents) & stations_depths[,1] == station & stations_depths[,2] == "DCM"]
            ML_depth_taxon[[i_station]] = ML_depth[rownames(coord) %in% rownames(documents) & stations_depths[,1] == station & stations_depths[,2] == "DCM"]
            documents_SUR[[i_station]] = documents[stations_depths[rownames(coord) %in% rownames(documents),1] == station & stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]
            documents_DCM[[i_station]] = documents[stations_depths[rownames(coord) %in% rownames(documents),1] == station & stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",]
            support_distrib = documents_SUR[[i_station]] !=0 | documents_DCM[[i_station]] !=0
            documents_SUR_station = documents_SUR[[i_station]][support_distrib]
            documents_DCM_station = documents_DCM[[i_station]][support_distrib]
            SUR_DCM_mixture = (documents_SUR_station+documents_DCM_station)/2
            JSD_taxon[[i_station]] = 1/2*(KL.plugin(documents_SUR_station,SUR_DCM_mixture) + KL.plugin(documents_DCM_station,SUR_DCM_mixture))
          }
        }
        JSD_taxon = unlist(JSD_taxon)
        names(JSD_taxon) = unlist(stations)
        coord_taxon = matrix(data = unlist(coord_taxon),ncol=2,byrow = T,dimnames=list(c(unlist(stations)),c("Lat.","Long.")))
        sampling_depth_taxon = unlist(sampling_depth_taxon)
        ML_depth_taxon = unlist(ML_depth_taxon)
        if (taxon != "AllTaxa")
        {
          JSD[[i_taxon]] = matrix(nrow=length(JSD_taxon),ncol=2,data=0)
          JSD[[i_taxon]][,1] = JSD_taxon
          coord_JSD[[i_taxon]] = coord_taxon
        } else
        {
          JSD.allTaxa = matrix(nrow=length(JSD_taxon),ncol=2,data=0)
          JSD.allTaxa[,1] = JSD_taxon
          coord_JSD.allTaxa = coord_taxon
          ML_depth.allTaxa = ML_depth_taxon
          sampling_depth.allTaxa = sampling_depth_taxon
        }
        # Computing the expected JSD as the average JSD between Surf. and DCM stations:
        expected_JSD_taxon = 0
        for (i_station in 1:length(documents_SUR))
        {
          for (j_station in 1:length(documents_DCM))
          {
            support_distrib = documents_SUR[[i_station]] !=0 | documents_DCM[[j_station]] !=0
            documents_SUR_station = documents_SUR[[i_station]][support_distrib]
            documents_DCM_station = documents_DCM[[j_station]][support_distrib]
            SUR_DCM_mixture = (documents_SUR_station+documents_DCM_station)/2
            expected_JSD_taxon = expected_JSD_taxon + 1/2*(KL.plugin(documents_SUR_station,SUR_DCM_mixture) + KL.plugin(documents_DCM_station,SUR_DCM_mixture))
          }
        }
        expected_JSD_taxon = expected_JSD_taxon/length(documents_SUR)^2
        
        if (taxon != "AllTaxa")
        {
          JSD[[i_taxon]][,2] = JSD_taxon/expected_JSD_taxon
        } else
          JSD.allTaxa[,2] = JSD_taxon/expected_JSD_taxon
        
        ###############
        plot.x = coord_taxon[,1]
        plot.x.order = sort.int(coord_taxon[,1], decreasing = F, index.return = T)
        plot.y = JSD_taxon/expected_JSD_taxon
        
        JSD.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          geom_line(aes(x.smooth,y.smooth), size = 0.6) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=12),
                axis.text = element_text(size=12),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Latitude", y="Observed over expected\n J-S divergence between Surface and DCM")
          # labs(x="Latitude", y="Jensen-Shannon divergence\n between Surface and DCM")
        
        # JSD.latitude.plot.w.expected[[ii_taxon]] = JSD.latitude.plot[[ii_taxon]] + geom_hline(yintercept = expected_JSD_taxon, size = 0.6, linetype = "dashed")
        
        plot.y = JSD_taxon
        
        JSD.abs.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = abs(plot.x), y = plot.y)) +
          geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="abs(Latitude)", y="Jensen-Shannon divergence\n between Surface and DCM")
        
        plot.x = sampling_depth_taxon
        
        JSD.sampling.depth.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y)) +
          # geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 5), se = F) +
          geom_smooth(aes(x,y),method='lm',size=0.4) +
          geom_point(aes(x,y), size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="DCM sampling depth", y="Jensen-Shannon divergence\n between Surface and DCM")
        
        plot.x = ML_depth_taxon
        
        JSD.mixed.layer.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y)) +
          geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 5), se = F) +
          geom_point(aes(x,y), size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Mixed-layer depth", y="Jensen-Shannon divergence\n between Surface and DCM")
      }
      
      if (Shannon_Simpson)
      {
        documents_SUR = documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]
        documents_DCM = documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",]
        
        # Number of dominant assemblages:
        dominant_assemblages = apply(documents,1,function(x) which(x == max(x)))
        if (length(which(lapply(dominant_assemblages,length) > 1)) > 0)
        {
          for (i in which(lapply(dominant_assemblages,length) > 1))
            dominant_assemblages[[i]] = dominant_assemblages[[i]][length(dominant_assemblages[[i]])]
        }
        nb_dominants_all = length(levels(as.factor(unlist(dominant_assemblages))))
        absolute_dominant_assemblages = apply(documents,1,function(x) which(x > 0.5))
        nb_absolute_dominants_all = length(levels(as.factor(unlist(absolute_dominant_assemblages))))
        #
        dominant_assemblages = apply(documents_SUR,1,function(x) which(x == max(x)))
        if (length(which(lapply(dominant_assemblages,length) > 1)) > 0)
        {
          for (i in which(lapply(dominant_assemblages,length) > 1))
            dominant_assemblages[[i]] = dominant_assemblages[[i]][length(dominant_assemblages[[i]])]
        }
        nb_dominants_SUR = length(levels(as.factor(unlist(dominant_assemblages))))
        absolute_dominant_assemblages_SUR = apply(documents_SUR,1,function(x) which(x > 0.5))
        nb_absolute_dominants_SUR = length(levels(as.factor(unlist(absolute_dominant_assemblages_SUR))))
        #
        dominant_assemblages = apply(documents_DCM,1,function(x) which(x == max(x)))
        if (length(which(lapply(dominant_assemblages,length) > 1)) > 0)
        {
          for (i in which(lapply(dominant_assemblages,length) > 1))
            dominant_assemblages[[i]] = dominant_assemblages[[i]][length(dominant_assemblages[[i]])]
        }
        nb_dominants_DCM = length(levels(as.factor(unlist(dominant_assemblages))))
        absolute_dominant_assemblages_DCM = apply(documents_DCM,1,function(x) which(x > 0.5))
        nb_absolute_dominants_DCM = length(levels(as.factor(unlist(absolute_dominant_assemblages_DCM))))
        #
        if (taxon != "AllTaxa")
        {
          nb_dominants[i_taxon,3] = nb_dominants_all
          nb_dominants[i_taxon,2] = nb_dominants_DCM
          nb_dominants[i_taxon,1] = nb_dominants_SUR
          nb_absolute_dominants[i_taxon,3] = nb_absolute_dominants_all
          nb_absolute_dominants[i_taxon,2] = nb_absolute_dominants_DCM
          nb_absolute_dominants[i_taxon,1] = nb_absolute_dominants_SUR
        } else
        {
          nb_dominants.allTaxa[3] = nb_dominants_all
          nb_dominants.allTaxa[2] = nb_dominants_DCM
          nb_dominants.allTaxa[1] = nb_dominants_SUR
          nb_absolute_dominants.allTaxa[3] = nb_absolute_dominants_all
          nb_absolute_dominants.allTaxa[2] = nb_absolute_dominants_DCM
          nb_absolute_dominants.allTaxa[1] = nb_absolute_dominants_SUR
        }
        
        # Computing Shannon entropy and Simpson diversity in each station and for all pooled station in each group:
        shannon_taxon = simpson_taxon = vector(length = nrow(documents), mode = "numeric")
        names(shannon_taxon) = names(simpson_taxon) = rownames(documents)
        shannon_taxon_SUR = simpson_taxon_SUR = vector(length = nrow(documents_SUR),
                                                       mode = "numeric")
        names(shannon_taxon_SUR) = names(simpson_taxon_SUR) = rownames(documents_SUR)
        shannon_taxon_DCM = simpson_taxon_DCM = vector(length = nrow(documents_DCM),
                                                       mode = "numeric")
        names(shannon_taxon_DCM) = names(simpson_taxon_DCM) = rownames(documents_DCM)
        ii = iii = 0
        for (i in 1:nrow(documents))
        {
          shannon_station = simpson_station = 0
          for (k in 1:ncol(documents))
          {
            if (documents[i,k] != 0)
            {
              shannon_station = shannon_station - documents[i,k]*log(documents[i,k])
              simpson_station = simpson_station + documents[i,k]^2
            }
          }
          shannon_taxon[i] = shannon_station
          simpson_taxon[i] = simpson_station
          if (stations_depths[rownames(coord) %in% rownames(documents),2][i] == "SUR")
          {
            ii = ii+1
            shannon_taxon_SUR[ii] = shannon_station
            simpson_taxon_SUR[ii] = simpson_station
          } else (stations_depths[rownames(coord) %in% rownames(documents),2][i] == "DCM")
          {
            iii = iii+1
            shannon_taxon_DCM[iii] = shannon_station
            simpson_taxon_DCM[iii] = simpson_station
          }
        }
        ######
        total_documents = colMeans(documents)
        total_documents_SUR = colMeans(documents_SUR)
        total_documents_DCM = colMeans(documents_DCM)
        shannon_total_taxon = simpson_total_taxon = 0
        shannon_total_taxon_SUR = simpson_total_taxon_SUR = 0
        shannon_total_taxon_DCM = simpson_total_taxon_DCM = 0
        for (k in 1:ncol(documents))
        {
          if (total_documents[k] != 0)
          {
            shannon_total_taxon = shannon_total_taxon - total_documents[k]*log(total_documents[k])
            simpson_total_taxon = simpson_total_taxon + total_documents[k]^2
          }
          if (total_documents_SUR[k] != 0)
          {
            shannon_total_taxon_SUR = shannon_total_taxon_SUR - total_documents_SUR[k]*log(total_documents_SUR[k])
            simpson_total_taxon_SUR = simpson_total_taxon_SUR + total_documents_SUR[k]^2
          }
          if (total_documents_DCM[k] != 0)
          {
            shannon_total_taxon_DCM = shannon_total_taxon_DCM - total_documents_DCM[k]*log(total_documents_DCM[k])
            simpson_total_taxon_DCM = simpson_total_taxon_DCM + total_documents_DCM[k]^2
          }
        }
        #####
        if (taxon != "AllTaxa")
        {
          shannon[[i_taxon]] = shannon_taxon
          simpson[[i_taxon]] = simpson_taxon
          shannon_SUR[[i_taxon]] = shannon_taxon_SUR
          shannon_DCM[[i_taxon]] = shannon_taxon_DCM
          simpson_SUR[[i_taxon]] = simpson_taxon_SUR
          simpson_DCM[[i_taxon]] = simpson_taxon_DCM
          shannon_total[i_taxon] = unname(shannon_total_taxon)
          simpson_total[i_taxon] = unname(simpson_total_taxon)
          shannon_total_SUR[i_taxon] = unname(shannon_total_taxon_SUR)
          shannon_total_DCM[i_taxon] = unname(shannon_total_taxon_DCM)
          simpson_total_SUR[i_taxon] = unname(simpson_total_taxon_SUR)
          simpson_total_DCM[i_taxon] = unname(simpson_total_taxon_DCM)
          rownames_SUR[[i_taxon]] = rownames(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",])
          rownames_DCM[[i_taxon]] = rownames(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",])
        } else
        {
          shannon.allTaxa = shannon_taxon
          simpson.allTaxa = simpson_taxon
          shannon.allTaxa_SUR = shannon_taxon_SUR
          shannon.allTaxa_DCM = shannon_taxon_DCM
          simpson.allTaxa_SUR = simpson_taxon_SUR
          simpson.allTaxa_DCM = simpson_taxon_DCM
          shannon.allTaxa_total = unname(shannon_total_taxon)
          simpson.allTaxa_total = unname(simpson_total_taxon)
          shannon.allTaxa_total_SUR = unname(shannon_total_taxon_SUR)
          shannon.allTaxa_total_DCM = unname(shannon_total_taxon_DCM)
          simpson.allTaxa_total_SUR = unname(simpson_total_taxon_SUR)
          simpson.allTaxa_total_DCM = unname(simpson_total_taxon_DCM)
          rownames_SUR.allTaxa = rownames(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",])
          rownames_DCM.allTaxa = rownames(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",])
        }
        
        ###########
        plot.x = coord$y[rownames(coord) %in% rownames(documents)]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = exp(if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]])
        
        Shannon.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Latitude", y="Shannon's diversity")
        
        Shannon.latitude.plot.w.spline[[ii_taxon]] = Shannon.latitude.plot[[ii_taxon]] + geom_line(aes(x.smooth,y.smooth), size = 0.6)
        
        ###########
        plot.x = coord$y[rownames(coord) %in% rownames(documents)]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]]
        
        Shannon.ind.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Latitude", y="Shannon's index")
        
        Shannon.ind.latitude.plot.w.spline[[ii_taxon]] = Shannon.ind.latitude.plot[[ii_taxon]] + geom_line(aes(x.smooth,y.smooth), size = 0.6)
        
        ############
        plot.x = abs(coord$y)[rownames(coord) %in% rownames(documents)]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = exp(if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]])
        
        Shannon.abs.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Absolute latitude", y="Shannon's diversity")
        
        Shannon.abs.latitude.plot.w.spline[[ii_taxon]] = Shannon.abs.latitude.plot[[ii_taxon]] + geom_line(aes(x.smooth,y.smooth), size = 0.6)
        
        ############
        plot.x = abs(coord$y)[rownames(coord) %in% rownames(documents)]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]]
        
        Shannon.ind.abs.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Absolute latitude", y="Shannon's index")
        
        Shannon.ind.abs.latitude.plot.w.spline[[ii_taxon]] = Shannon.ind.abs.latitude.plot[[ii_taxon]] + geom_line(aes(x.smooth,y.smooth), size = 0.6)
        
        ##########
        plot.x = coord$y[rownames(coord) %in% if (taxon=="AllTaxa") rownames_SUR.allTaxa else rownames_SUR[[i_taxon]]]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = exp(if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]])[(if (taxon=="AllTaxa") names(shannon.allTaxa) else names(shannon[[i_taxon]])) %in% (if (taxon=="AllTaxa") rownames_SUR.allTaxa else rownames_SUR[[i_taxon]])]
        
        Shannon.SUR.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Latitude", y="Shannon's diversity - surface")
        
        Shannon.SUR.latitude.plot.w.spline[[ii_taxon]] = Shannon.SUR.latitude.plot[[ii_taxon]] + geom_line(aes(x.smooth,y.smooth), size = 0.6)
        
        ###########
        plot.x = coord$y[rownames(coord) %in% if (taxon=="AllTaxa") rownames_SUR.allTaxa else rownames_SUR[[i_taxon]]]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = (if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]])[(if (taxon=="AllTaxa") names(shannon.allTaxa) else names(shannon[[i_taxon]])) %in% (if (taxon=="AllTaxa") rownames_SUR.allTaxa else rownames_SUR[[i_taxon]])]
        
        Shannon.ind.SUR.latitude.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          # ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          geom_line(aes(x.smooth,y.smooth), size = 0.6) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Latitude", y="Shannon's index - surface")
        
        ###########
        plot.x = abs(coord$y)[rownames(coord) %in% if (taxon=="AllTaxa") rownames_SUR.allTaxa else rownames_SUR[[i_taxon]]]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = (if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]])[(if (taxon=="AllTaxa") names(shannon.allTaxa) else names(shannon[[i_taxon]])) %in% (if (taxon=="AllTaxa") rownames_SUR.allTaxa else rownames_SUR[[i_taxon]])]
        
        Shannon.ind.SUR.abs.latitude.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          # ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          geom_line(aes(x.smooth,y.smooth), size = 0.6) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Absolute latitude", y="Shannon's index - surface")
        
        #############
        plot.x = coord$y[rownames(coord) %in% if (taxon=="AllTaxa") rownames_DCM.allTaxa else rownames_DCM[[i_taxon]]]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = exp(if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]])[(if (taxon=="AllTaxa") names(shannon.allTaxa) else names(shannon[[i_taxon]])) %in% (if (taxon=="AllTaxa") rownames_DCM.allTaxa else rownames_DCM[[i_taxon]])]  
        
        Shannon.DCM.latitude.plot[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Latitude", y="Shannon's diversity - DCM")
        
        Shannon.DCM.latitude.plot.w.spline[[ii_taxon]] = Shannon.DCM.latitude.plot[[ii_taxon]] + geom_line(aes(x.smooth,y.smooth), size = 0.4)
        
        ###########
        plot.x = coord$y[rownames(coord) %in% if (taxon=="AllTaxa") rownames_DCM.allTaxa else rownames_DCM[[i_taxon]]]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = (if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]])[(if (taxon=="AllTaxa") names(shannon.allTaxa) else names(shannon[[i_taxon]])) %in% (if (taxon=="AllTaxa") rownames_DCM.allTaxa else rownames_DCM[[i_taxon]])]
        
        Shannon.ind.DCM.latitude.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          # ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          geom_line(aes(x.smooth,y.smooth), size = 0.6) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Latitude", y="Shannon's index - DCM")
        
        ###########
        plot.x = abs(coord$y)[rownames(coord) %in% if (taxon=="AllTaxa") rownames_DCM.allTaxa else rownames_DCM[[i_taxon]]]
        plot.x.order = sort.int(plot.x, decreasing = F, index.return = T)
        plot.y = (if (taxon=="AllTaxa") shannon.allTaxa else shannon[[i_taxon]])[(if (taxon=="AllTaxa") names(shannon.allTaxa) else names(shannon[[i_taxon]])) %in% (if (taxon=="AllTaxa") rownames_DCM.allTaxa else rownames_DCM[[i_taxon]])]
        
        Shannon.ind.DCM.abs.latitude.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = plot.x, y = plot.y, x.smooth = plot.x.order$x, y.smooth = smooth.spline(plot.x.order$x,plot.y[plot.x.order$ix],df=5)$y)) +
          # geom_smooth(aes(x,y),method='lm') +
          geom_point(aes(x,y), size = 0.6) +
          theme_bw() +
          # ggtitle(paste(taxon,"-",ifelse(taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          geom_line(aes(x.smooth,y.smooth), size = 0.6) +
          theme(axis.title=element_text(size=14),
                axis.text = element_text(size=14),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm")) +
          labs(x="Absolute latitude", y="Shannon's index - DCM")
      }
      
      if (Moran_I)
      {
        if (autocorr_scale)
        {
          I_step_observed_w.mean_taxon = matrix(nrow = nb_increment, ncol = 3, data = 0)
          I_step_relative_w.mean_taxon = matrix(nrow = nb_increment, ncol = 3, data = 0)
          I_step_p.value_w.mean_taxon = matrix(nrow = nb_increment, ncol = 3, data = 0)
          increment_taxon = matrix(nrow = nb_increment, ncol = 3, data = 0)
        }
        # Computing Moran's I (spatial autocorrelation) for each AEM vector and comparing it to its expected null value:
        for (case in 1:2)
        {
          if (data_Federico && (V4_stations || psbO_stations))
          {
            k_all_taxon = NA
            k_SUR.DCM_taxon = NA
            if (case == 1)
            {
              documents_case = documents[rownames(documents) %in% rownames(coord),][stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]
            } else if (case == 2)
            {
              documents_case = documents[rownames(documents) %in% rownames(coord),][stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",]
            }
          } else
          {
            k_all_taxon = length(which(colSums(documents) > 1))
            k_SUR.DCM_taxon = length(which(colSums(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]) > 1 
                                           & colSums(documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",]) > 1))
            if (case == 1)
            {
              documents_case = documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "SUR",]
            } else if (case == 2)
            {
              documents_case = documents[stations_depths[rownames(coord) %in% rownames(documents),2] == "DCM",]
            }
          }
          if (case == 1)
          {
            nb_stat_SUR = nrow(documents_case)
            k_SUR_taxon = length(which(colSums(documents_case) > 1))
            documents_case = documents_case[,colSums(documents_case) > 1/nrow(documents_case)]
          } else if (case == 2)
          {
            nb_stat_DCM = nrow(documents_case)
            k_DCM_taxon = length(which(colSums(documents_case) > 1))
            documents_case = documents_case[,colSums(documents_case) > 1/nrow(documents_case)]
          }
          
          selected_geographic_distances_case = selected_geographic_distances[rownames(coord) %in% rownames(documents_case),rownames(coord) %in% rownames(documents_case)]
          diag(selected_geographic_distances_case) = NA
          max_dist = max(selected_geographic_distances_case,na.rm=T)
          min_dist = min(selected_geographic_distances_case,na.rm=T)
          
          weight_matrix_linear = (1 - selected_geographic_distances_case/max_dist)/(1 - min_dist/max_dist)
          diag(weight_matrix_linear) = 0
          weight_matrix_inverse = (max_dist/selected_geographic_distances_case - 1)/(max_dist/min_dist - 1)
          diag(weight_matrix_inverse) = 0
          weight_matrix_square = ((max_dist/selected_geographic_distances_case)^2 - 1)/((max_dist/min_dist)^2 - 1)
          diag(weight_matrix_square) = 0
          
          # Computing Moran's I with step function weights for a sliding characteristic distance:
          if (autocorr_scale)
          {
            if (log.scale)
            {
              increment_taxon[,case] = min_dist*(max_dist/min_dist)^(1:nb_increment/nb_increment)
            } else
              increment_taxon[,case] = min_dist + (1:nb_increment)*(max_dist-min_dist)/nb_increment
            # 
            for (i in 1:nb_increment)
            {
              weight_matrix_step = selected_geographic_distances_case
              diag(weight_matrix_step) = 0
              weight_matrix_step[weight_matrix_step > increment_taxon[i,case]] = 0
              weight_matrix_step[weight_matrix_step != 0] = 1
              
              I_step_taxon = matrix(nrow =  ncol(documents_case), ncol = 3, data = 0)
              for (k in 1:ncol(documents_case))
              {
                I = ape::Moran.I(documents_case[,k],weight_matrix_step)
                I_step_taxon[k,1] = I$observed
                I_step_taxon[k,2] = I$expected
                I_step_taxon[k,3] = I$p.value
              }
              I_step_observed_w.mean_taxon[i,case] = weighted.mean(I_step_taxon[,1], w = colSums(documents_case))
              I_step_relative_w.mean_taxon[i,case] = weighted.mean(I_step_taxon[,1]-I_step_taxon[,2], w = colSums(documents_case))
              I_step_p.value_w.mean_taxon[i,case] = weighted.mean(I_step_taxon[,3], w = colSums(documents_case))
            }
          }
          
          I_linear_taxon = matrix(nrow =  ncol(documents_case), ncol = 3, data = 0)
          I_inverse_taxon = matrix(nrow =  ncol(documents_case), ncol = 3, data = 0)
          I_square_taxon = matrix(nrow =  ncol(documents_case), ncol = 3, data = 0)
          for (k in 1:ncol(documents_case))
          {
            I = ape::Moran.I(documents_case[,k],weight_matrix_linear)
            I_linear_taxon[k,1] = I$observed
            I_linear_taxon[k,2] = I$expected
            I_linear_taxon[k,3] = I$p.value
            
            I = ape::Moran.I(documents_case[,k],weight_matrix_inverse)
            I_inverse_taxon[k,1] = I$observed
            I_inverse_taxon[k,2] = I$expected
            I_inverse_taxon[k,3] = I$p.value
            
            I = ape::Moran.I(documents_case[,k],weight_matrix_square)
            I_square_taxon[k,1] = I$observed
            I_square_taxon[k,2] = I$expected
            I_square_taxon[k,3] = I$p.value
          }
          
          if (true_taxon != "AllTaxa")
          {
            # I_linear[[i_taxon]][[case]] = I_linear_taxon[[case]]
            # I_inverse[[i_taxon]][[case]] = I_inverse_taxon[[case]]
            # I_square[[i_taxon]][[case]] = I_square_taxon[[case]]
            
            if (is.null(reals))
            {
              I_linear.observed_w.mean[i_taxon,case] = weighted.mean(I_linear_taxon[,1], w = colSums(documents_case))
              I_inverse.observed_w.mean[i_taxon,case] = weighted.mean(I_inverse_taxon[,1], w = colSums(documents_case))
              I_square.observed_w.mean[i_taxon,case] = weighted.mean(I_square_taxon[,1], w = colSums(documents_case))
              I_linear.p.value_w.mean[i_taxon,case] = weighted.mean(I_linear_taxon[,3], w = colSums(documents_case))
              I_inverse.p.value_w.mean[i_taxon,case] = weighted.mean(I_inverse_taxon[,3], w = colSums(documents_case))
              I_square.p.value_w.mean[i_taxon,case] = weighted.mean(I_square_taxon[,3], w = colSums(documents_case))
            } else
            {
              I_square.observed_w.mean[[case]][i_taxon,real] = weighted.mean(I_square_taxon[,1], w = colSums(documents_case))
              I_square.p.value_w.mean[[case]][i_taxon,real] = weighted.mean(I_square_taxon[,3], w = colSums(documents_case))
            }
            
            # I_linear_mean[i_taxon,case] = mean(I_linear_taxon[[case]][,1])
            # I_inverse_mean[i_taxon,case] = mean(I_inverse_taxon[[case]][,1])
            # I_square_mean[i_taxon,case] = mean(I_square_taxon[[case]][,1])
          } else
          {
            # I_linear_allTaxa[[case]] = I_linear_taxon[[case]]
            # I_inverse_allTaxa[[case]] = I_inverse_taxon[[case]]
            # I_square_allTaxa[[case]] = I_square_taxon[[case]]
            
            if (is.null(reals))
            {
              I_linear.observed_w.mean_allTaxa[case] = weighted.mean(I_linear_taxon[,1], w = colSums(documents_case))
              I_inverse.observed_w.mean_allTaxa[case] = weighted.mean(I_inverse_taxon[,1], w = colSums(documents_case))
              I_square.observed_w.mean_allTaxa[case] = weighted.mean(I_square_taxon[,1], w = colSums(documents_case))
              I_linear.p.value_w.mean_allTaxa[case] = weighted.mean(I_linear_taxon[,3], w = colSums(documents_case))
              I_inverse.p.value_w.mean_allTaxa[case] = weighted.mean(I_inverse_taxon[,3], w = colSums(documents_case))
              I_square.p.value_w.mean_allTaxa[case] = weighted.mean(I_square_taxon[,3], w = colSums(documents_case))
            } else
            {
              I_square.observed_w.mean_allTaxa[[case]][real] = weighted.mean(I_square_taxon[,1], w = colSums(documents_case))
              I_square.p.value_w.mean_allTaxa[[case]][real] = weighted.mean(I_square_taxon[,3], w = colSums(documents_case))
            }
            
            # I_linear_mean_allTaxa[case] = mean(I_linear_taxon[[case]][,1])
            # I_inverse_mean_allTaxa[case] = mean(I_inverse_taxon[[case]][,1])
            # I_square_mean_allTaxa[case] = mean(I_square_taxon[[case]][,1])
          }
        }
        
        if (autocorr_scale)
        {
          for (i in 1:nb_increment)
          {
            I_step_observed_w.mean_taxon[i,3] = weighted.mean(c(I_step_observed_w.mean_taxon[i,1],I_step_observed_w.mean_taxon[i,2]),w=c(nb_stat_SUR,nb_stat_DCM))
            I_step_relative_w.mean_taxon[i,3] = weighted.mean(c(I_step_relative_w.mean_taxon[i,1],I_step_relative_w.mean_taxon[i,2]),w=c(nb_stat_SUR,nb_stat_DCM))
            I_step_p.value_w.mean_taxon[i,3] = weighted.mean(c(I_step_p.value_w.mean_taxon[i,1],I_step_p.value_w.mean_taxon[i,2]),w=c(nb_stat_SUR,nb_stat_DCM))
            increment_taxon[i,3] = weighted.mean(increment_taxon[i,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
          }
        }
        
        if (true_taxon != "AllTaxa")
        {
          if (is.null(reals))
          {
            prevalence.corrected_K[i_taxon,] = c(k_SUR_taxon,k_DCM_taxon,k_all_taxon,k_SUR.DCM_taxon)
            nb_stat[i_taxon,] = c(nb_stat_SUR,nb_stat_DCM)
            
            I_linear.observed_w.mean[i_taxon,3] = weighted.mean(I_linear.observed_w.mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_inverse.observed_w.mean[i_taxon,3] = weighted.mean(I_inverse.observed_w.mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_square.observed_w.mean[i_taxon,3] = weighted.mean(I_square.observed_w.mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_linear.p.value_w.mean[i_taxon,3] = weighted.mean(I_linear.p.value_w.mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_inverse.p.value_w.mean[i_taxon,3] = weighted.mean(I_inverse.p.value_w.mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_square.p.value_w.mean[i_taxon,3] = weighted.mean(I_square.p.value_w.mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            
            # I_linear_mean[i_taxon,3] = weighted.mean(I_linear_mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            # I_inverse_mean[i_taxon,3] = weighted.mean(I_inverse_mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            # I_square_mean[i_taxon,3] = weighted.mean(I_square_mean[i_taxon,1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            
            if (autocorr_scale)
            {
              I_step_observed_w.mean[[i_taxon]] = I_step_observed_w.mean_taxon
              I_step_relative_w.mean[[i_taxon]] = I_step_relative_w.mean_taxon
              I_step_p.value_w.mean[[i_taxon]] = I_step_p.value_w.mean_taxon
              increment[[i_taxon]] = increment_taxon
            }
          } else
          {
            I_square.observed_w.mean[[3]][i_taxon,real] = weighted.mean(c(I_square.observed_w.mean[[1]][i_taxon,real],I_square.observed_w.mean[[2]][i_taxon,real]),
                                                                        w=c(nb_stat_SUR,nb_stat_DCM))
            I_square.p.value_w.mean[[3]][i_taxon,real] = weighted.mean(c(I_square.p.value_w.mean[[1]][i_taxon,real],I_square.p.value_w.mean[[2]][i_taxon,real]),
                                                                       w=c(nb_stat_SUR,nb_stat_DCM))
          }
        } else
        {
          if (is.null(reals))
          {
            prevalence.corrected_K.allTaxa = c(k_SUR_taxon,k_DCM_taxon,k_all_taxon,k_SUR.DCM_taxon)
            nb_stat.allTaxa = c(nb_stat_SUR,nb_stat_DCM)
            
            I_linear.observed_w.mean_allTaxa[3] = weighted.mean(I_linear.observed_w.mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_inverse.observed_w.mean_allTaxa[3] = weighted.mean(I_inverse.observed_w.mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_square.observed_w.mean_allTaxa[3] = weighted.mean(I_square.observed_w.mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_linear.p.value_w.mean_allTaxa[3] = weighted.mean(I_linear.p.value_w.mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_inverse.p.value_w.mean_allTaxa[3] = weighted.mean(I_inverse.p.value_w.mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            I_square.p.value_w.mean_allTaxa[3] = weighted.mean(I_square.p.value_w.mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            
            # I_linear_mean_allTaxa[3] = weighted.mean(I_linear_mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            # I_inverse_mean_allTaxa[3] = weighted.mean(I_inverse_mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            # I_square_mean_allTaxa[3] = weighted.mean(I_square_mean_allTaxa[1:2],w=c(nb_stat_SUR,nb_stat_DCM))
            
            if (autocorr_scale)
            {
              I_step_observed_w.mean.allTaxa = I_step_observed_w.mean_taxon
              I_step_relative_w.mean.allTaxa = I_step_relative_w.mean_taxon
              I_step_p.value_w.mean.allTaxa = I_step_p.value_w.mean_taxon
              increment.allTaxa = increment_taxon
            }
          } else
          {
            I_square.observed_w.mean_allTaxa[[3]][real] = weighted.mean(c(I_square.observed_w.mean_allTaxa[[1]][real],I_square.observed_w.mean_allTaxa[[2]][real]),
                                                                                w=c(nb_stat_SUR,nb_stat_DCM))
            I_square.p.value_w.mean_allTaxa[[3]][real] = weighted.mean(c(I_square.p.value_w.mean_allTaxa[[1]][real],I_square.p.value_w.mean_allTaxa[[2]][real]),
                                                                               w=c(nb_stat_SUR,nb_stat_DCM))
          }
        }
      }
    } else
    {
      cat("\nMissing file.")
      if (heterogeneity)
      {
        if (taxon != "AllTaxa")
        {
          mean_JSD_stations[i_taxon] = c(NA,NA)
        } else
          mean_JSD_stations.allTaxa = c(NA,NA)
      }
      if (lat_analyses)
      {
        if (taxon != "AllTaxa")
        {
          lat_JSD[i_taxon,] = NA
          lat_I_sym[i_taxon,] = lat_I_nonsym[i_taxon,] = lat_I_all[i_taxon,] = NA
          weighted_latitudinal_topic_distribution[[1]][i_taxon,] = weighted_latitudinal_topic_distribution[[2]][i_taxon,] = weighted_latitudinal_topic_distribution[[3]][i_taxon,] = rep(NA,3)
          latitudinal_topic_distribution[[1]][i_taxon,] = latitudinal_topic_distribution[[2]][i_taxon,] = latitudinal_topic_distribution[[3]][i_taxon,] = rep(NA,3)
          lat.skewness[[1]] = lat.skewness[[2]] = lat.skewness[[3]] = NA
        } else
        {
          lat_JSD.allTaxa[] = NA
          lat_I_sym.allTaxa[] = lat_I_nonsym.allTaxa[] = lat_I_all.allTaxa[] = NA
          weighted_latitudinal_topic_distribution.allTaxa[[1]] = weighted_latitudinal_topic_distribution.allTaxa[[2]] = weighted_latitudinal_topic_distribution.allTaxa[[3]] = rep(NA,3)
          latitudinal_topic_distribution.allTaxa[[1]] = latitudinal_topic_distribution.allTaxa[[2]] = latitudinal_topic_distribution.allTaxa[[3]] = rep(NA,3)
          lat.skewness.allTaxa[1] = lat.skewness.allTaxa[2] = lat.skewness.allTaxa[3] = NA
        }
      }
      if (basins)
      {
        if (taxon != "AllTaxa")
        {
          basin_I_within[,i_case] = basin_I_contrast[,i_case] = basin_I_between[,i_case] = NA
        } else
        {
          basin_I_within.allTaxa[] = basin_I_contrast.allTaxa[] = basin_I_between.allTaxa[] = NA
        }
      }
      if (Shannon_Simpson)
      {
        Shannon.SUR.latitude.plot[[ii_taxon]] = NA
        Shannon.SUR.latitude.plot.w.spline[[ii_taxon]] = NA
        Shannon.DCM.latitude.plot[[ii_taxon]] = NA
        Shannon.DCM.latitude.plot.w.spline[[ii_taxon]] = NA
        if (taxon != "AllTaxa")
        {
          shannon[[i_taxon]] = simpson[[i_taxon]] = NA
          shannon_SUR[[i_taxon]] = simpson_SUR[[i_taxon]] = NA
          shannon_DCM[[i_taxon]] = simpson_DCM[[i_taxon]] = NA
          shannon_total[i_taxon] = simpson_total[i_taxon] = NA
          shannon_total_SUR[i_taxon] = simpson_total_SUR[i_taxon] = NA
          shannon_total_DCM[i_taxon] = simpson_total_DCM[i_taxon] = NA
          rownames_SUR[[i_taxon]] = NA
          rownames_DCM[[i_taxon]] = NA
          nb_dominants[i_taxon,] = rep(NA,3)
          nb_absolute_dominants[i_taxon,] = rep(NA,3)
        } else 
        {
          shannon.allTaxa = simpson.allTaxa = NA
          shannon.allTaxa_SUR = simpson.allTaxa_SUR = NA
          shannon.allTaxa_DCM = simpson.allTaxa_DCM = NA
          shannon.allTaxa_total = simpson.allTaxa_total = NA
          shannon.allTaxa_total_SUR = simpson.allTaxa_total_SUR = NA
          shannon.allTaxa_total_DCM = simpson.allTaxa_total_DCM = NA
          rownames_SUR.allTaxa = NA
          rownames_DCM.allTaxa = NA
          nb_dominants.allTaxa = rep(NA,3)
          nb_absolute_dominants.allTaxa = rep(NA,3)
        } 
      }
      if (JSD_SUR_DCM)
      {
        JSD[[i_taxon]] = NA
        coord_JSD[[i_taxon]] = NA
        JSD.latitude.plot[[ii_taxon]] = NA
        # JSD.latitude.plot.w.expected[[ii_taxon]] = NA
      }
      if (Moran_I)
      {
        # if (autocorr_scale)
        # {
        #   Moran.step.observed.plot.w.spline[[ii_taxon]] = Moran.step.observed.SUR.plot.w.spline[[ii_taxon]] = Moran.step.observed.DCM.plot.w.spline[[ii_taxon]] = NA
        #   Moran.step.relative.plot.w.spline[[ii_taxon]] = Moran.step.relative.SUR.plot.w.spline[[ii_taxon]] = Moran.step.relative.DCM.plot.w.spline[[ii_taxon]] = NA
        # }
        if (is.null(reals))
        {
          stop("Missing file: ",true_taxon)
        } else
          stop("Missing file: ",true_taxon,"-",real)
          
        if (is.null(reals))
        {
          if (true_taxon != "AllTaxa")
          {
            I_linear_w.mean[i_taxon,] = I_inverse_w.mean[i_taxon,] = I_square_w.mean[i_taxon,] = c(NA,NA,NA) 
            I_linear_mean[i_taxon,] = I_inverse_mean[i_taxon,] = I_square_mean[i_taxon,] = c(NA,NA,NA) 
            I_linear[[i_taxon]][[1]] = I_linear[[i_taxon]][[2]] = NA
            I_inverse[[i_taxon]][[1]] = I_inverse[[i_taxon]][[2]] = NA
            I_square[[i_taxon]][[1]] = I_square[[i_taxon]][[2]] = NA
            prevalence.corrected_K[i_taxon,] = rep(NA,4)
            nb_stat[i_taxon,] = rep(NA,2)
            if (autocorr_scale)
            {
              I_step_observed_w.mean[[i_taxon]] = I_step_expected_w.mean[[i_taxon]] = I_step_p.value_w.mean[[i_taxon]] = NA
              increment[[i_taxon]] = NA
            }
          } else
          {
            I_linear_w.mean_allTaxa = I_inverse_w.mean_allTaxa = I_square_w.mean_allTaxa = c(NA,NA,NA) 
            I_linear_mean_allTaxa = I_inverse_mean_allTaxa = I_square_mean_allTaxa = c(NA,NA,NA) 
            I_linear_allTaxa[[1]] = I_inverse_allTaxa[[1]] = I_square_allTaxa[[1]] = NA
            I_linear_allTaxa[[2]] = I_inverse_allTaxa[[2]] = I_square_allTaxa[[2]] = NA
            prevalence.corrected_K.allTaxa = rep(NA,4)
            nb_stat.allTaxa = rep(NA,2)
            if (autocorr_scale)
            {
              I_step_observed_w.mean.allTaxa = I_step_expected_w.mean.allTaxa = I_step_p.value_w.mean.allTaxa = NA
              increment.allTaxa = NA
            }
          }
        }
      }
    }
  }
  
  if (heterogeneity)
  {
    div_threshold = 1000
    
    plot.hetero_vs_Moran.I = list()
    for (i_case in 1:2)
    {
      plot.hetero_vs_Moran.I[[i_case]] = ggplot(data=data.frame(x=I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case],
                                                      y=mean_JSD_stations[selected_groups & diversity>div_threshold,i_case])) +
        theme_bw() +
        # geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
        # geom_smooth(aes(x,y), method = "lm", col = "black") +
        geom_point(aes(x = x, y = y)) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_blank(),
              plot.margin=unit(c(1,10,1,0.5),"mm")) +
        labs(x=paste(c("Surface","DCM")[i_case],"spatial autocorrelation"), y=paste(c("Surface","DCM")[i_case],"spatial heterogeneity"))
    }
    pdf(file = paste0(figure_folder,"/Spatial.heterogeneity_vs_Moran.I.square_Gibbs.prevalence.min.crossValid_selected",
                      if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
    print(plot.hetero_vs_Moran.I[[1]])
    print(plot.hetero_vs_Moran.I[[2]])
    dev.off()
    
    plot.hetero_vs_charac.scale = list()
    for (i_case in 1:2)
    {
      plot.hetero_vs_charac.scale[[i_case]] = ggplot(data=data.frame(x=charac_scale[selected_groups & diversity>div_threshold,i_case],
                                                           y=mean_JSD_stations[selected_groups & diversity>div_threshold,i_case])) +
        theme_bw() +
        # geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
        # geom_smooth(aes(x = x, y = y), method='lm', col="black") +
        geom_point(aes(x = x, y = y)) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_blank(),
              plot.margin=unit(c(1,10,1,0.5),"mm")) +
        labs(x=paste(c("Surface","DCM")[i_case],"charac. spatial scale"), y=paste(c("Surface","DCM")[i_case],"spatial heterogeneity"))
    }
    pdf(file = paste0(figure_folder,"/Spatial.heterogeneity_vs_charach.autocorr.scale_Gibbs.prevalence.min.crossValid_selected",
                      if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
    print(plot.hetero_vs_charac.scale[[1]])
    print(plot.hetero_vs_charac.scale[[2]])
    dev.off()
    
    plot.hetero_vs_diversity = list()
    for (i_case in 1:2)
    {
      plot.hetero_vs_diversity[[i_case]] = ggplot(data=data.frame(x=as.vector(diversity)[selected_groups & diversity>div_threshold],
                                                                     y=mean_JSD_stations[selected_groups & diversity>div_threshold,i_case])) +
        theme_bw() +
        scale_x_log10() +
        # geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
        # geom_smooth(aes(x = x, y = y), method='lm', col="black") +
        geom_point(aes(x = x, y = y)) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_blank(),
              plot.margin=unit(c(1,10,1,0.5),"mm")) +
        labs(x="Number of OTUs", y=paste(c("Surface","DCM")[i_case],"spatial heterogeneity"))
    }
    pdf(file = paste0(figure_folder,"/Spatial.heterogeneity_vs_log.diversity_Gibbs.prevalence.min.crossValid_selected",
                      if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
    print(plot.hetero_vs_diversity[[1]])
    print(plot.hetero_vs_diversity[[2]])
    dev.off()
  }
  
  if (lat_analyses)
  {
    if (data_Federico)
    {
      if (V4_stations || psbO_stations)
        saveRDS(lat_I_sym,paste0(results_folder,"/Lat_I",station_insert,"_sigma2.",sigma2,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      else
      # saveRDS(list(lat_JSD,lat_JSD.allTaxa),paste0(results_folder,"/Lat_JSD_sigma2.",sigma2,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        # saveRDS(list(lat_I_sym,lat_I_sym.allTaxa),paste0(results_folder,"/Lat_I_sigma2.",sigma2,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        saveRDS(list(lat_I_sym,lat_I_sym.allTaxa),paste0(results_folder,"/random.group.div_lat_I_sigma2.",sigma2,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    } else
      saveRDS(lat_I_sym,paste0(results_folder,"/",short_marker,"lat_I_sigma2.",sigma2,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    #############################
    # Assemblage number across latitudinal ranges:
    for (i_case in 1:3)
    {
      case = c("SUR","DCM","all")[i_case]
      # Assemblage number per latitudinal bin:
      #################
      # pdf(paste0(figure_folder,"/Assemblage.number_across.latitudinal.ranges.",tropic_bound,"-",arctic_bound,".",case,"_selected100+1_allTaxa.pdf"),height=7*4,width=7*5)
      pdf(paste0(figure_folder,"/Assemblage.number_across.latitudinal.ranges.",tropic_bound,"-",arctic_bound,".",case,"_allTaxa.pdf"),height=9,width=9)
      par(mar=c(10.2,8.1,6.1,1.1))
      # par(mfrow = c(4,5))
      x = barplot(latitudinal_topic_distribution.allTaxa[[i_case]]*(prevalence.corrected_K.allTaxa[i_case]-1),
                  col="grey",
                  # legend.text = T,
                  xaxt="n", space = 0.1, cex.axis = 2.5)
      # args.legend = list(bty = "n", x= ifelse(K==10,25,6.5) + 1, y=1))
      title(ylab=c("Nb of surface assemblages","Nb of DCM assemblages","Nb of assemblages")[i_case],cex.lab=2.8)
      # title(main="All Taxa",cex.main=3)
      labs = colnames(latitudinal_topic_distribution[[i_case]])
      text(cex=2.8, x=x+0.1, y=-0.03*max(latitudinal_topic_distribution.allTaxa[[i_case]]*(prevalence.corrected_K.allTaxa[i_case]-1)),
           labels = labs, xpd=TRUE, srt=45, pos=2)
      # for (taxon in taxo_groups[selected_groups])
      # {
      #   i_taxon = which(taxo_groups == taxon)
      #   x = barplot(latitudinal_topic_distribution[[i_case]][i_taxon,]*(prevalence.corrected_K[i_taxon,i_case]-1),
      #               col="grey",
      #               # legend.text = T,
      #               xaxt="n", space = 0.1, cex.axis = 2.5)
      #   # args.legend = list(bty = "n", x= ifelse(K==10,25,6.5) + 1, y=1))
      #   title(ylab=c("Nb of surface assemblages","Nb of DCM assemblages","Nb of assemblages")[i_case],cex.lab=2.8)
      #   title(main=taxo_groups[i_taxon],cex.main=3)
      #   labs = colnames(latitudinal_topic_distribution[[i_case]])
      #   text(cex=2.8, x=x+0.1, y=-0.03*max(latitudinal_topic_distribution[[i_case]][i_taxon,]*(prevalence.corrected_K[i_taxon,i_case]-1)),
      #        labels = labs, xpd=TRUE, srt=45, pos=2)
      # }
      dev.off()
      
      # pdf(paste0(figure_folder,"/Assemblage.number_wrt_expectation_across.latitudinal.ranges.",tropic_bound,"-",arctic_bound,".",case,"_selected100+1_allTaxa.pdf"),height=7*4,width=7*5)
      pdf(paste0(figure_folder,"/Assemblage.number_wrt_expectation_across.latitudinal.ranges.",tropic_bound,"-",arctic_bound,".",case,"_allTaxa.pdf"),height=9,width=9)
      par(mar=c(10.2,8.1,6.1,1.1))
      # par(mfrow = c(4,5))
      x = barplot(latitudinal_topic_distribution.allTaxa[[i_case]]/latitudinal_topic_distribution.expected[[i_case]],
                  col="grey",
                  # legend.text = T,
                  xaxt="n", space = 0.1, cex.axis = 2.5)
      # args.legend = list(bty = "n", x= ifelse(K==10,25,6.5) + 1, y=1))
      title(ylab=c("Nb of surface assemblages\n wrt expectation","Nb of DCM assemblages\n wrt expectation","Nb of assemblages\n wrt expectation")[i_case],cex.lab=2.8)
      # title(main="All Taxa",cex.main=3)
      labs = colnames(latitudinal_topic_distribution[[i_case]])
      text(cex=2.8, x=x+0.1, y=-0.03*max(latitudinal_topic_distribution.allTaxa[[i_case]]/latitudinal_topic_distribution.expected[[i_case]]),
           labels = labs, xpd=TRUE, srt=45, pos=2)
      # for (taxon in taxo_groups[selected_groups])
      # {
      #   i_taxon = which(taxo_groups == taxon)
      #   x = barplot(latitudinal_topic_distribution[[i_case]][i_taxon,]/latitudinal_topic_distribution.expected[[i_case]],
      #               col="grey",
      #               # legend.text = T,
      #               xaxt="n", space = 0.1, cex.axis = 2.5)
      #   # args.legend = list(bty = "n", x= ifelse(K==10,25,6.5) + 1, y=1))
      #   title(ylab=c("Nb of surface assemblages\n wrt expectation","Nb of DCM assemblages\n wrt expectation","Nb of assemblages\n wrt expectation")[i_case],cex.lab=2.8)
      #   title(main=taxo_groups[i_taxon],cex.main=3)
      #   labs = colnames(latitudinal_topic_distribution[[i_case]])
      #   text(cex=2.8, x=x+0.1, y=-0.03*max(latitudinal_topic_distribution[[i_case]][i_taxon,]/latitudinal_topic_distribution.expected[[i_case]]),
      #        labels = labs, xpd=TRUE, srt=45, pos=2)
      # }
      dev.off()
    }
    
    #######################
    div_threshold = 1000
    
    plot.prop.high.lat_vs_size = list()
    for (i_case in 1:3)
    {
      plot.prop.high.lat_vs_size[[i_case]] = ggplot(data=data.frame(x=size_absoluteAbund[selected_groups & diversity>div_threshold],
                                                                    y=(latitudinal_topic_distribution[[i_case]][,1]/latitudinal_topic_distribution.expected[[i_case]][1])[selected_groups & diversity>div_threshold])) +
        theme_bw() +
        scale_x_log10() +
        # geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
        geom_smooth(aes(x,y), method = "lm", col = "black") +
        geom_point(aes(x = x, y = y)) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_blank(),
              plot.margin=unit(c(1,10,1,0.5),"mm")) +
        labs(x="Mean group body size (micron)", y=paste("Nb of",c("surface","DCM","")[i_case],"high-latitude community types\n wrt expectation"))
    }
    pdf(file = paste0(figure_folder,"/Nb.high.lat.wrt.expectation_vs_size_Gibbs.prevalence.min.crossValid_selected",
                      if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
    print(plot.prop.high.lat_vs_size[[3]])
    print(plot.prop.high.lat_vs_size[[1]])
    print(plot.prop.high.lat_vs_size[[2]])
    dev.off()
    
    # Assemblage number per latitudinal bin - functional boxplot:
    ################
    div_threshold = 100
    
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    dominant_function0 = dominant_function[selected_groups & diversity>div_threshold]
    # dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
    # dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
    dominant_function0[dominant_function0 == "unknown"] = NA
    dominant_function0[dominant_function0 == "photohost"] = "Collodaria"
    dominant_function0[dominant_function0 == "pteropoda"] = "Pteropoda"
    dominant_function0[dominant_function0 == "copepoda"] = "Copepoda"
    dominant_function0[dominant_function0 == "gelatineous_carnivores_filterers"] = "Gel. carn. filterers"
    dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Dinophyceae"] = "Dinophyceae"
    dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Bacillariophyta"] = "Bacillariophyta"
    dominant_function0[dominant_function0 == "phototroph"] = "Other phototrophs"
    dominant_function0[dominant_function0 == "phagotroph"] = "Phagotrophs"
    dominant_function0[dominant_function0 == "other metazoa"] = "Other metazoa"
    dominant_function0[dominant_function0 == "parasite"] = "Parasites"
    # alpha = rep(1,length(taxo_groups[selected_groups]))
    # alpha[dominant_function0 %in% c("copepoda","pteropoda")] = 0 
    # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them by deceasing number of groups:
    # dominant_function0 = factor(dominant_function0,names(sort(table(as.factor(dominant_function0)),decreasing = T)))
    # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them in the specified order:
    if (div_threshold == 100)
    {
      dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Pteropoda","Copepoda","Other metazoa","Parasites"))
      point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")
    } else if (div_threshold == 1000)
    {
      dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Copepoda","Parasites"))
      point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta")
    } 
    
    for (i_case in 1:3)
    {
      case = c("surface","DCM","all")[i_case]
      
      boxplot.lat.skewness = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                y = lat.skewness[[i_case]][selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(point_groups),
                                     y = lat.skewness[[i_case]][selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=24),
              axis.text=element_text(size=22),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(2,1,1,0.5),"mm")) +
        labs(x="", y=paste("Skweness of the distribution\n of",case,"assemblages along latitude"))
      
      boxplot.abs.lat.skewness = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                     y = abs(lat.skewness[[i_case]])[selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(point_groups),
                                     y = abs(lat.skewness[[i_case]])[selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=24),
              axis.text=element_text(size=22),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(2,1,1,0.5),"mm")) +
        labs(x="", y=paste("Absolute skweness of the distribution\n of",case,"assemblages along latitude"))
      
      pdf(paste0(figure_folder,"/Assemblage.number.wrt.expectation.lat.skweness.",case,"_boxplot_allFunctionalGroups_selected",
                 if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
      print(boxplot.lat.skewness)
      print(boxplot.abs.lat.skewness)
      dev.off()
    }
    
    for (i_case in 1:3)
    {
      case = c("surface","DCM","all")[i_case]
      
      boxplot.high.lat = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                      y = (latitudinal_topic_distribution[[i_case]][,1]/latitudinal_topic_distribution.expected[[i_case]][1])
                                                  [selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(point_groups),
                                     y = (latitudinal_topic_distribution[[i_case]][,1]/latitudinal_topic_distribution.expected[[i_case]][1])
                                     [selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=22),
              axis.text=element_text(size=22),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(3,1,1,5),"mm")) +
        labs(x="", y=paste("Nb of high-latitude",case,"assemblages\n wrt expectation"))
      
      boxplot.mid.lat = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                 y = (latitudinal_topic_distribution[[i_case]][,2]/latitudinal_topic_distribution.expected[[i_case]][2])
                                                 [selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(point_groups),
                                     y = (latitudinal_topic_distribution[[i_case]][,2]/latitudinal_topic_distribution.expected[[i_case]][2])
                                     [selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=22),
              axis.text=element_text(size=22),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(2,1,1,0.5),"mm")) +
        labs(x="", y=paste("Nb of mid-latitude",case,"assemblages\n wrt expectation"))
      
      boxplot.low.lat = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                          y = (latitudinal_topic_distribution[[i_case]][,3]/latitudinal_topic_distribution.expected[[i_case]][3])
                                                 [selected_groups & diversity>div_threshold][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(point_groups),
                                     y = (latitudinal_topic_distribution[[i_case]][,3]/latitudinal_topic_distribution.expected[[i_case]][3])
                                     [selected_groups & diversity>div_threshold][dominant_function0 %in% point_groups]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=22),
              axis.text=element_text(size=22),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(2,1,1,0.5),"mm")) +
        labs(x="", y=paste("Nb of low-latitude",case,"assemblages\n wrt expectation"))
      
      pdf(paste0(figure_folder,"/Assemblage.number.wrt.expectation.",case,"_boxplot_allFunctionalGroups_selected",
                 if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
      print(boxplot.high.lat)
      print(boxplot.mid.lat)
      print(boxplot.low.lat)
      dev.off()
    }
    
    # Prevalence-weighted assemblage number per latitude:
    ###################
    pdf(paste0(figure_folder,"/Assemblage_prevalence_across_latitudinal_ranges_6groups.pdf"))
    par(mar=c(6.1,5.1,1.1,1.1))
    for (i_taxon in 1:6)
    {
      x = barplot(weighted_latitudinal_topic_distribution[i_taxon,],
                  col="grey",
                  # legend.text = T,
                  xaxt="n", space = 0.1, cex.axis = 1.5)
      # args.legend = list(bty = "n", x= ifelse(K==10,25,6.5) + 1, y=1))
      title(ylab="Prevalence of assemblages",cex.lab=1.7)
      # title(main=group_vect[i_taxon],cex.lab=1.7)
      labs = colnames(weighted_latitudinal_topic_distribution)
      text(cex=1.5, x=x+0.1, y=-0.06, labels = labs, xpd=TRUE, srt=45, pos=2)
    }
    dev.off()
    
    pdf(paste0(figure_folder,"/Assemblage_prevalence_wrt_expectation_across_latitudinal_ranges_6groups.pdf"))
    par(mar=c(6.1,5.1,1.1,1.1))
    for (i_taxon in 1:6)
    {
      x = barplot(weighted_latitudinal_topic_distribution[i_taxon,]/weighted_latitudinal_topic_distribution[7,],
                  col="grey",
                  # legend.text = T,
                  xaxt="n", space = 0.1, cex.axis = 1.5)
      # args.legend = list(bty = "n", x= ifelse(K==10,25,6.5) + 1, y=1))
      title(ylab="Prevalence of assemblages wrt expectation",cex.lab=1.7)
      # title(main=group_vect[i_taxon],cex.lab=1.7)
      labs = colnames(weighted_latitudinal_topic_distribution)
      text(cex=1.5, x=x+0.1, 
           y=-0.04*max(weighted_latitudinal_topic_distribution[i_taxon,]/weighted_latitudinal_topic_distribution[7,]),
           labels = labs, xpd=TRUE, srt=45, pos=2)
    }
    dev.off()
    ###############
  }
  
  if (basins)
  {
    if (data_Federico)
    {
      if (V4_stations || psbO_stations)
        saveRDS(basin_I_within,paste0(results_folder,"/Basin_I",station_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      else
        # saveRDS(list(basin_I_within,basin_I_within.allTaxa),paste0(results_folder,"/Basin_I",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        saveRDS(list(basin_I_within,basin_I_within.allTaxa),paste0(results_folder,"/random.group.div_basin_I",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    } else
      saveRDS(basin_I_within,paste0(results_folder,"/",short_marker,"basin_I",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      
    # col.vect = rep("black",length(which(selected_groups)))
    # col.vect[Lat_pval[selected_groups,1] > 0.05 | is.na(Lat_pval[selected_groups,1])] = "red"
    # plot.lat.Rsquare_vs_ocean.dissim_SUR = ggplot(data=data.frame(y=Lat_Rsquare[selected_groups,1],x=province_dissim[selected_groups,1])) +
    #   # ggtitle("") +
    #   theme_bw() +
    #   geom_smooth(aes(x = x, y = y), method='lm') +
    #   geom_point(aes(x = x, y = y), size = 0.4, col = col.vect) +
    #   theme(axis.title=element_text(size=9),
    #         axis.text = element_text(size=9),
    #         plot.title=element_text(hjust=0, size=12),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="Assemblage Surf. dissimilarity between oceans", y="Surface dependence on latitude")
    # # geom_smooth(aes(x = x, y = y), method='lm')
    # col.vect = rep("black",length(which(selected_groups)))
    # col.vect[Lat_pval[selected_groups,2] > 0.05 | is.na(Lat_pval[selected_groups,2])] = "red"
    # plot.lat.Rsquare_vs_ocean.dissim_DCM = ggplot(data=data.frame(y=Lat_Rsquare[selected_groups,2],x=province_dissim[selected_groups,2])) +
    #   theme_bw() +
    #   geom_smooth(aes(x = x, y = y), method='lm') +
    #   geom_point(aes(x = x, y = y), size = 0.4) +
    #   theme(axis.title=element_text(size=9),
    #         axis.text = element_text(size=9),
    #         plot.title=element_text(hjust=0, size=12),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="Assemblage DCM dissimilarity between oceans", y="DCM dependence on latitude")
    # # geom_smooth(aes(x = x, y = y), method='lm')
    # plot.list = list(list(plot.lat.Rsquare_vs_ocean.dissim_SUR),list(plot.lat.Rsquare_vs_ocean.dissim_DCM))
    # ppl = lapply(plot.list, function(g) marrangeGrob(grobs = g, nrow = 1, ncol = 1))
    # # spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
    # pdf(file = paste0(figure_folder,"/Latitude.regression_vs_ocean.dissimilarity_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1.pdf"),height = 1.5*10/4, width = 1.5*10/4)
    # print(ppl)
    # dev.off()
  }
  
  if (JSD_SUR_DCM)
  {
    saveRDS(list(list(JSD.allTaxa, coord_JSD.allTaxa),
                 list(JSD, coord_JSD)),
            file=paste0(results_folder,"/JSD_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    
    JSD_object = readRDS(paste0(results_folder,"/JSD_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    JSD.allTaxa = JSD_object[[1]][[1]]
    coord_JSD.allTaxa = JSD_object[[1]][[2]]
    JSD = JSD_object[[2]][[1]]
    coord_JSD = JSD_object[[2]][[2]]
    
    # Plot Surf.-DCM JSD maps group per group:
    ###############
    library(marmap)
    library(vegan)
    library(scales)
    # Loading batymetric data for the specified range of longitudes and latitudes in degrees, whith resolution in minutes
    bat = getNOAA.bathy(-180, 180, -90, 90, res = 20, keep=F)
    blues = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1")
    greys = c(grey(0.6), grey(0.93), grey(0.99))
    
    pdf(paste0(figure_folder,"/JSD.SUR-DCM_maps_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1.pdf"))
    for (taxon in taxo_groups)
    {
      i_taxon = which(taxo_groups == taxon)
      if (taxon %in% taxo_groups[selected_groups] && !is.na(JSD[[i_taxon]]))
      {
        # Plotting Surface:
        plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
        title(paste(taxon,"-",as.vector(diversity)[i_taxon],"OTUs"))
        plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
        z = JSD[[i_taxon]][,1]
        points(cbind(coord_JSD[[i_taxon]][,2],coord_JSD[[i_taxon]][,1]),
               pch = 21, cex=1.2, 
               # bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
               bg = rgb(colorRamp(c("blue","white","red"),space = "Lab")(rescale(z,to=c(0,1),from=range(z))),maxColorValue = 255))
      }
    }
    dev.off()
    
    # Plot Surf.-DCM JSD map AllTaxa:
    ###############
    pdf(paste0(figure_folder,"/JSD.SUR-DCM_map_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"))
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    title(paste("AllTaxa -",sum(diversity),"OTUs"))
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    z = JSD.allTaxa[,1]
    points(cbind(coord_JSD.allTaxa[,2],coord_JSD.allTaxa[,1]),
           pch = 21, cex=1.2, 
           # bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
           bg = rgb(colorRamp(c("blue","white","red"),space = "Lab")(rescale(z,to=c(0,1),from=range(z))),maxColorValue = 255))
    dev.off()
    
    # Plot Sampling depth map:
    ###############
    pdf(paste0(figure_folder,"/Sampling.depth.DCM_map_SUR-DCM.stations.pdf"))
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    title(paste("AllTaxa -",sum(diversity),"OTUs"))
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    z = sampling_depth.allTaxa
    points(cbind(coord_JSD.allTaxa[,2],coord_JSD.allTaxa[,1]),
           pch = 21, cex=1.2, 
           # bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
           bg = rgb(colorRamp(c("blue","white","red"),space = "Lab")(rescale(z,to=c(0,1),from=range(z))),maxColorValue = 255))
    dev.off()
    
    # Mixed Layer depth map:
    ###############
    pdf(paste0(figure_folder,"/Mixed.layer.depth_map_SUR-DCM.stations.pdf"))
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    title(paste("AllTaxa -",sum(diversity),"OTUs"))
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    z = ML_depth.allTaxa
    points(cbind(coord_JSD.allTaxa[,2],coord_JSD.allTaxa[,1]),
           pch = 21, cex=1.2, 
           # bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
           bg = rgb(colorRamp(c("blue","white","red"),space = "Lab")(rescale(z,to=c(0,1),from=range(z))),maxColorValue = 255))
    dev.off()
    
    # Plot Surf.-DCM JSD vs latitude group per group including AllTaxa:
    ###############
    spl = split(JSD.latitude.plot[!is.na(JSD.latitude.plot)], 
                (seq_along(JSD.latitude.plot[!is.na(JSD.latitude.plot)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/JSD.SUR-DCM.rel.to.expected.splined_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(JSD.abs.latitude.plot[!is.na(JSD.abs.latitude.plot)], 
                (seq_along(JSD.abs.latitude.plot[!is.na(JSD.abs.latitude.plot)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/JSD.SUR-DCM_vs_abs.latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    # spl = split(JSD.latitude.plot.w.expected[!is.na(JSD.latitude.plot.w.expected)], 
    #             (seq_along(JSD.latitude.plot.w.expected[!is.na(JSD.latitude.plot.w.expected)])-1) %/% 20)
    # ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    # pdf(paste0(figure_folder,"/JSD.SUR-DCM.splined.w.expected_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    # print(ppl)
    # dev.off()
    
    spl = split(JSD.sampling.depth.plot[!is.na(JSD.sampling.depth.plot)], 
                (seq_along(JSD.sampling.depth.plot[!is.na(JSD.sampling.depth.plot)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/JSD.SUR-DCM.splined_vs_sampling.depth_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(JSD.mixed.layer.plot[!is.na(JSD.mixed.layer.plot)], 
                (seq_along(JSD.mixed.layer.plot[!is.na(JSD.mixed.layer.plot)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/JSD.SUR-DCM.splined_vs_mixed.layer.depth_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
  }
  
  if (Shannon_Simpson)
  {
    saveRDS(list(shannon,shannon_SUR,shannon_DCM),file=paste0(results_folder,"/",short_marker,"Shannon.per.station_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
    saveRDS(list(simpson,simpson_SUR,simpson_DCM),file=paste0(results_folder,"/",short_marker,"Simpson.per.station_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
    saveRDS(list(shannon_total,shannon_total_SUR,shannon_total_DCM),file=paste0(results_folder,"/",short_marker,"Shannon.per.group_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
    saveRDS(list(simpson_total,simpson_total_SUR,simpson_total_DCM),file=paste0(results_folder,"/",short_marker,"Simpson.per.group_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
    saveRDS(list(nb_dominants,nb_absolute_dominants),file=paste0(results_folder,"/",short_marker,"Nb.dominant.assemblages.per.group_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
    # Plot Shannon diversity maps group per group for Surface stations:
    ###############
    library(marmap)
    library(vegan)
    # Loading batymetric data for the specified range of longitudes and latitudes in degrees, whith resolution in minutes
    bat = getNOAA.bathy(-180, 180, -90, 90, res = 50, keep=T)
    blues = c("lightsteelblue4", "lightsteelblue3", "lightsteelblue2", "lightsteelblue1")
    greys = c(grey(0.6), grey(0.93), grey(0.99))
    
    pdf(paste0(figure_folder,"/Shannon_index_exp_SUR_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1.pdf"))
    for (taxon in taxo_groups)
    {
      i_taxon = which(taxo_groups == taxon)
      if (taxon %in% taxo_groups[selected_groups] && !is.na(shannon[[i_taxon]]))
      {
        # Plotting Surface:
        plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
        title(taxon)
        plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
        z = exp(shannon[[i_taxon]][names(shannon[[i_taxon]]) %in% rownames_SUR[[i_taxon]]])
        points(cbind(coord$x[rownames(coord) %in% rownames_SUR[[i_taxon]]],coord$y[rownames(coord) %in% rownames_SUR[[i_taxon]]]),
               pch = 21, cex=1.2, 
               # bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
               bg = rgb(colorRamp(c("blue","white","red"),space = "Lab")(rescale(z,to=c(0,1),from=range(z))),maxColorValue = 255))
      }
    }
    dev.off()
    
    pdf(paste0(figure_folder,"/Shannon_index_exp_DCM_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1.pdf"))
    for (taxon in taxo_groups)
    {
      i_taxon = which(taxo_groups == taxon)
      if (taxon %in% taxo_groups[selected_groups] && !is.na(shannon[[i_taxon]]))
      {
        # Plotting Surface:
        plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
        title(taxon)
        plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
        z = exp(shannon[[i_taxon]][names(shannon[[i_taxon]]) %in% rownames_DCM[[i_taxon]]])
        points(cbind(coord$x[rownames(coord) %in% rownames_DCM[[i_taxon]]],coord$y[rownames(coord) %in% rownames_DCM[[i_taxon]]]),
               pch = 21, cex=1.2, 
               # bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
               bg = rgb(colorRamp(c("blue","white","red"),space = "Lab")(rescale(z,to=c(0,1),from=range(z))),maxColorValue = 255))
      }
    }
    dev.off()
    
    # Plot Shannon diversity vs latitude group per group:
    ###############
    spl = split(Shannon.SUR.latitude.plot[!is.na(Shannon.SUR.latitude.plot)], 
                (seq_along(Shannon.SUR.latitude.plot[!is.na(Shannon.SUR.latitude.plot)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/Shannon.index.exp.SUR_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(Shannon.SUR.latitude.plot.w.spline[!is.na(Shannon.SUR.latitude.plot.w.spline)], 
                (seq_along(Shannon.SUR.latitude.plot.w.spline[!is.na(Shannon.SUR.latitude.plot.w.spline)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/Shannon.index.exp.SUR.splined_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(Shannon.DCM.latitude.plot[!is.na(Shannon.DCM.latitude.plot)], 
                (seq_along(Shannon.DCM.latitude.plot[!is.na(Shannon.DCM.latitude.plot)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/Shannon.index.exp.DCM_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(Shannon.DCM.latitude.plot.w.spline[!is.na(Shannon.DCM.latitude.plot.w.spline)], 
                (seq_along(Shannon.DCM.latitude.plot.w.spline[!is.na(Shannon.DCM.latitude.plot.w.spline)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/Shannon.index.exp.DCM.splined_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(Shannon.ind.latitude.plot.w.spline[!is.na(Shannon.ind.latitude.plot.w.spline)], 
                (seq_along(Shannon.ind.latitude.plot.w.spline[!is.na(Shannon.ind.latitude.plot.w.spline)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/Shannon.index.SUR.DCM.splined_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    spl = split(Shannon.ind.abs.latitude.plot.w.spline[!is.na(Shannon.ind.abs.latitude.plot.w.spline)], 
                (seq_along(Shannon.ind.abs.latitude.plot.w.spline[!is.na(Shannon.ind.abs.latitude.plot.w.spline)])-1) %/% 20)
    ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
    pdf(paste0(figure_folder,"/Shannon.index.SUR.DCM.splined_vs_abs.latitude_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
    print(ppl)
    dev.off()
    
    # Plot Shannon diversity all taxa: 
    #############
    pdf(paste0(figure_folder,"/Shannon.index.exp.SUR.DCM.splined_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"))
    print(Shannon.latitude.plot.w.spline[[1]])
    dev.off()
    
    pdf(paste0(figure_folder,"/Shannon.index.exp.SUR.DCM.splined_vs_abs.latitude_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"))
    print(Shannon.abs.latitude.plot.w.spline[[1]])
    dev.off()
    
    pdf(paste0(figure_folder,"/Shannon.index.SUR.DCM.splined_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"),width=5,height=5)
    print(Shannon.ind.latitude.plot.w.spline[[1]])
    dev.off()
    
    pdf(paste0(figure_folder,"/Shannon.index.SUR.DCM.splined_vs_abs.latitude_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"),width=5,height=5)
    print(Shannon.ind.abs.latitude.plot.w.spline[[1]])
    dev.off()
    
    pdf(paste0(figure_folder,"/Shannon.index.SUR.splined_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"),width=5,height=5)
    print(Shannon.ind.SUR.latitude.plot.w.spline[[1]])
    dev.off()
    
    pdf(paste0(figure_folder,"/Shannon.index.SUR.splined_vs_abs.latitude_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"),width=5,height=5)
    print(Shannon.ind.SUR.abs.latitude.plot.w.spline[[1]])
    dev.off()
    
    pdf(paste0(figure_folder,"/Shannon.index.DCM.splined_vs_latitude_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"),width=5,height=5)
    print(Shannon.ind.DCM.latitude.plot.w.spline[[1]])
    dev.off()
    
    pdf(paste0(figure_folder,"/Shannon.index.DCM.splined_vs_abs.latitude_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"),width=5,height=5)
    print(Shannon.ind.DCM.abs.latitude.plot.w.spline[[1]])
    dev.off()
    
    # Plot Shannon diversity map AllTaxa for Surface and DCM stations:
    ###############
    pdf(paste0(figure_folder,"/Shannon_index_exp_Gibbs100r_optimalK_prevalence.min.crossValid_AllTaxa.pdf"))
    # Plotting Surface:
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    title("All Taxa")
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    z = exp(shannon.allTaxa[names(shannon.allTaxa) %in% rownames_SUR.allTaxa])
    points(cbind(coord$x[rownames(coord) %in% rownames_SUR.allTaxa],coord$y[rownames(coord) %in% rownames_SUR.allTaxa]),
           pch = 21, cex=1.2, 
           # bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
           bg = rgb(colorRamp(c("blue","white","red"),space = "Lab")(rescale(z,to=c(0,1),from=range(z))),maxColorValue = 255))
    #
    plot(bat, image = T, land = T, lty = 0, bty = "n", xaxt = "n", yaxt = "n", ann = F, bpal = list(c(0, max(bat), greys[1]), c(min(bat), 0, blues))) #plot map without isobaths
    title("All Taxa")
    plot(bat, lwd = 0.8, deep = 0, shallow = 0, step = 0, add = TRUE) # highlight coastline
    z = exp(shannon.allTaxa[names(shannon.allTaxa) %in% rownames_DCM.allTaxa])
    points(cbind(coord$x[rownames(coord) %in% rownames_DCM.allTaxa],coord$y[rownames(coord) %in% rownames_DCM.allTaxa]),
           pch = 21, cex=1.2, 
           # bg = rgb(colorRamp(c("green","blue","red"),space = "Lab")(rescale(z,to=c(0,1),from=c(-max(range(abs(z))),max(range(abs(z)))))),maxColorValue = 255))
           bg = rgb(colorRamp(c("blue","white","red"),space = "Lab")(rescale(z,to=c(0,1),from=range(z))),maxColorValue = 255))
    dev.off()
  }
  
  if (Moran_I)
  {
    if (data_Federico)
    {
      if (V4_stations || psbO_stations)
      {
        saveRDS(list(I_square.observed_w.mean,I_square.p.value_w.mean),
                file=paste0(results_folder,"/Moran.I",station_insert,"_inverse.squares_weighted.mean.over.topics_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
      } else if (!is.null(raref))
      {
        saveRDS(list(I_square.observed_w.mean,I_square.p.value_w.mean),
                file=paste0(results_folder,"/",
                if (raref == "random.group.div") raref
                else paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)], collapse=""),
                if (!is.null(reals)) paste0(".1-",reals) else "",
                "_Moran.I_inverse.squares_weighted.mean.over.topics_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
      } else
        saveRDS(list(I_square.observed_w.mean_allTaxa,I_square.observed_w.mean,I_square.p.value_w.mean_allTaxa,I_square.p.value_w.mean),
                file=paste0(results_folder,"/Moran.I_inverse.squares_weighted.mean.over.topics_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
    } else
    {
      saveRDS(list(I_square.observed_w.mean,I_square.p.value_w.mean),
              file=paste0(results_folder,"/",short_marker,"Moran.I_inverse.squares_weighted.mean.over.topics_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
    }
    
    saveRDS(list(prevalence.corrected_K.allTaxa,prevalence.corrected_K),
            file=paste0(results_folder,"/Prevalence-corrected.number.of.assemblages_all.SUR.DCM_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
    
    if (autocorr_scale)
    {
      if (data_Federico)
      {
        if (log.scale && !(V4_stations || psbO_stations))
        {
          saveRDS(list(list(increment.allTaxa, I_step_observed_w.mean.allTaxa, I_step_relative_w.mean.allTaxa, I_step_p.value_w.mean.allTaxa),
                       list(increment,I_step_observed_w.mean, I_step_relative_w.mean, I_step_p.value_w.mean)),
                  file=paste0(results_folder,"/MoranI_spatialAutocorr_20increment_log.scale_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        } else if (!log.scale)
        {
          if (V4_stations || psbO_stations)
          {
            saveRDS(list(increment,I_step_observed_w.mean, I_step_relative_w.mean, I_step_p.value_w.mean),
                    file=paste0(results_folder,"/MoranI",station_insert,"_spatialAutocorr_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
          } else if (!is.null(raref))
          {
            saveRDS(list(increment,I_step_observed_w.mean, I_step_relative_w.mean, I_step_p.value_w.mean),
                    file=paste0(results_folder,"/",
                                paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)], collapse=""),
                                "_MoranI_spatialAutocorr_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
          } else
            saveRDS(list(list(increment.allTaxa, I_step_observed_w.mean.allTaxa, I_step_relative_w.mean.allTaxa, I_step_p.value_w.mean.allTaxa),
                         list(increment,I_step_observed_w.mean, I_step_relative_w.mean, I_step_p.value_w.mean)),
                    file=paste0(results_folder,"/MoranI_spatialAutocorr_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        }
      } else
      {
        if (log.scale)
        {
          saveRDS(list(increment,I_step_observed_w.mean, I_step_relative_w.mean, I_step_p.value_w.mean),
                  file=paste0(results_folder,"/",short_marker,"MoranI_spatialAutocorr_20increment_log.scale_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        } else 
          saveRDS(list(increment,I_step_observed_w.mean, I_step_relative_w.mean, I_step_p.value_w.mean),
                  file=paste0(results_folder,"/",short_marker,"MoranI_spatialAutocorr_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      }
    }
    
    # Plot Moran'I vs diversity across groups:
    ########################
    
    if (autocorr_scale)
    {
      # Loading results:
      if (data_Federico)
      {
        if (V4_stations || psbO_stations)
        {
          Moran.step = readRDS(paste0(results_folder,"/MoranI",station_insert,"_spatialAutocorr_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
          increment = Moran.step[[1]]
          I_step_observed_w.mean = Moran.step[[2]]
          I_step_relative_w.mean = Moran.step[[3]]
          I_step_p.value_w.mean = Moran.step[[4]]
        } else if (!is.null(raref))
        {
          if (log.scale)
            Moran.step = readRDS(paste0(results_folder,"/",
                                        paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)], collapse=""),
                                        "_MoranI_spatialAutocorr_20increment_log.scale_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
          else 
            Moran.step = readRDS(paste0(results_folder,"/",
                                        paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)], collapse=""),
                                        "_MoranI_spatialAutocorr_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
          increment = Moran.step[[1]]
          I_step_observed_w.mean = Moran.step[[2]]
          I_step_relative_w.mean = Moran.step[[3]]
          I_step_p.value_w.mean = Moran.step[[4]]
        } else
        {
          if (log.scale)
            Moran.step = readRDS(paste0(results_folder,"/MoranI_spatialAutocorr_20increment_log.scale_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
          else 
            Moran.step = readRDS(paste0(results_folder,"/MoranI_spatialAutocorr_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
          increment.allTaxa = Moran.step[[1]][[1]]
          I_step_observed_w.mean.allTaxa = Moran.step[[1]][[2]]
          I_step_relative_w.mean.allTaxa = Moran.step[[1]][[3]]
          I_step_p.value_w.mean.allTaxa = Moran.step[[1]][[4]]
          increment = Moran.step[[2]][[1]]
          I_step_observed_w.mean = Moran.step[[2]][[2]]
          I_step_relative_w.mean = Moran.step[[2]][[3]]
          I_step_p.value_w.mean = Moran.step[[2]][[4]]
        }
      } else
      {
        if (log.scale)
          Moran.step = readRDS(paste0(results_folder,"/",short_marker,"MoranI_spatialAutocorr_20increment_log.scale_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        else 
          Moran.step = readRDS(paste0(results_folder,"/",short_marker,"MoranI_spatialAutocorr_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        increment = Moran.step[[1]]
        I_step_observed_w.mean = Moran.step[[2]]
        I_step_relative_w.mean = Moran.step[[3]]
        I_step_p.value_w.mean = Moran.step[[4]]
      }
      
      # Plot autocorrelation as a function of spatial scale:
      #########################
      Moran.step.observed.plot.w.spline = list()
      Moran.step.observed.SUR.plot.w.spline = list()
      Moran.step.observed.DCM.plot.w.spline = list()
      Moran.step.relative.plot.w.spline = list()
      Moran.step.relative.SUR.plot.w.spline = list()
      Moran.step.relative.DCM.plot.w.spline = list()
      if (log.scale)
      {
        spatial_scale = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = NA)
        spatial_scale.allTaxa = vector(length = 3, mode = "numeric")
      } else
      {
        charac_scale = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = NA)
        charac_scale.allTaxa = vector(length = 3, mode = "numeric")
        slope = intercept = matrix(nrow = length(taxo_groups), ncol = 3, dimnames = list(taxo_groups,c("SUR","DCM","Weighted.mean")), data = NA)
        slope.allTaxa = intercept.allTaxa = vector(length = 3, mode = "numeric")
      }
      ii_taxon = 0
      # for (taxon in c("AllTaxa",taxo_groups[selected_groups]))
      for (taxon in raref_taxo_groups)
      # for (taxon in taxo_groups[1:11])
      # for (taxon in taxo_groups[1:54])
      {
        
        if (!is.null(raref) && raref != "random.group.div")
        {
          true_taxon = strsplit(taxon,split=".",fixed=T)[[1]][1]
          if (!is.null(reals))
            real = as.numeric(strsplit(taxon,split=".",fixed=T)[[1]][length(strsplit(taxon,split=".",fixed=T)[[1]])])
          ii_taxon = ii_taxon+1
        } else if (!is.null(raref) && raref == "random.group.div")
        {
          ii_taxon = as.numeric(strsplit(taxon,split=".",fixed=T)[[1]][length(strsplit(taxon,split=".",fixed=T)[[1]])])
          true_taxon = taxo_groups[selected_groups][ii_taxon]
        } else
        {
          true_taxon = taxon
          ii_taxon = ii_taxon+1
        }
        if (true_taxon != "AllTaxa")
          i_taxon = which(true_taxon == taxo_groups)
        
        if (true_taxon != "AllTaxa")
        {
          increment_taxon = increment[[i_taxon]]
          I_step_observed_w.mean_taxon = I_step_observed_w.mean[[i_taxon]]
          I_step_relative_w.mean_taxon = I_step_relative_w.mean[[i_taxon]]
          I_step_p.value_w.mean_taxon = I_step_p.value_w.mean[[i_taxon]]
        } else
        {
          increment_taxon = increment.allTaxa
          I_step_observed_w.mean_taxon = I_step_observed_w.mean.allTaxa
          I_step_relative_w.mean_taxon = I_step_relative_w.mean.allTaxa
          I_step_p.value_w.mean_taxon = I_step_p.value_w.mean.allTaxa
        }
        cat("\n",ifelse(true_taxon=="AllTaxa","AllTaxa",paste0(i_taxon,if (!is.null(reals)) paste0(".",real) else "","/",length(taxo_groups))))
        
        ######################
        # Observed Moran's I
        #####################
        
        # Mean Sur and DCM
        ################
        col.vect = rep("black",nb_increment)
        col.vect[I_step_p.value_w.mean_taxon[,3] > 0.05 | is.na(I_step_p.value_w.mean_taxon[,3])] = "red"
        if (log.scale)
        {
          y.smooth = smooth.spline(log10(increment_taxon[,3]),I_step_observed_w.mean_taxon[,3],df=5)$y
          if (true_taxon != "AllTaxa")
          {
            spatial_scale[i_taxon,3] = increment_taxon[,3][sort.int(y.smooth,decreasing=T,index.return=T)$ix[1]] 
          } else
            spatial_scale.allTaxa[3] = increment_taxon[,3][sort.int(y.smooth,decreasing=T,index.return=T)$ix[1]] 
          
          Moran.step.observed.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = log10(increment_taxon[,3]), y = I_step_observed_w.mean_taxon[,3], y.smooth = y.smooth)) +
            labs(x="Spatial scale (log10)", y="Mean spatial autocorrelation")
        } else
        {
          y.smooth = smooth.spline(increment_taxon[,3],I_step_observed_w.mean_taxon[,3],df=5)$y
          if (true_taxon %in% c("MALV-I","Cnidaria","core_Apicomplexa","RAD-A"))
            lin.regr = lm(y.smooth[3:7] ~ increment_taxon[3:7,3])
          else if (true_taxon %in% "Nemertea")
            lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,3])
          else
            lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,3])
          b = summary(lin.regr)$coefficients[1,1]
          a = summary(lin.regr)$coefficients[2,1]
          if (true_taxon != "AllTaxa")
          {
            charac_scale[i_taxon,3] = -b/a
          } else
            charac_scale.allTaxa[3] = -b/a
          
          Moran.step.observed.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = increment_taxon[,3], y = I_step_observed_w.mean_taxon[,3],y.smooth = y.smooth)) +
            labs(x="Spatial scale", y="Mean spatial autocorrelation") +
            geom_abline(slope = a,intercept = b, linetype = "dashed", size = 0.4)
        }
        Moran.step.observed.plot.w.spline[[ii_taxon]] = Moran.step.observed.plot.w.spline[[ii_taxon]] +
          # scale_x_log10() +
          geom_point(aes(x,y), size = 0.6, col = col.vect) +
          # coord_trans(x = "log10") +
          geom_line(aes(x,y.smooth), size = 0.4) +
          geom_hline(yintercept = 0, linetype = "dashed", size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm"))
        
        # Sur
        #####
        col.vect = rep("black",nb_increment)
        col.vect[I_step_p.value_w.mean_taxon[,1] > 0.05 | is.na(I_step_p.value_w.mean_taxon[,1])] = "red"
        if (log.scale)
        {
          y.smooth = smooth.spline(log10(increment_taxon[,1]),I_step_observed_w.mean_taxon[,1],df=5)$y
          if (true_taxon != "AllTaxa")
          {
            spatial_scale[i_taxon,1] = increment_taxon[,1][sort.int(y.smooth,decreasing=T,index.return=T)$ix[1]]
          } else
            spatial_scale.allTaxa[1] = increment_taxon[,1][sort.int(y.smooth,decreasing=T,index.return=T)$ix[1]]
          
          Moran.step.observed.SUR.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = log10(increment_taxon[,1]), y = I_step_observed_w.mean_taxon[,1], y.smooth = y.smooth)) +
            labs(x="Spatial scale (log10)", y="Surf. spatial autocorrelation")
        } else
        {
          y.smooth = smooth.spline(increment_taxon[,1],I_step_observed_w.mean_taxon[,1],df=5)$y
          if (data_Federico)
          {
            if (V4_stations)
            {
              if (true_taxon %in% c("Cnidaria","Spumellaria","Picomonadida","Foraminifera","Ascomycota",
                               "RAD-B_Sticholonche_and_relatives","Mesomycetozoa_*",
                               "MALV-I","Haptophyta","Ctenophora"))
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,1])
              else
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
            } else if (psbO_stations)
            {
              if (true_taxon %in% c("Nemertea"))
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,1])
              else
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
            } else if (!is.null(raref) && raref == ".104")
            {
              if (true_taxon %in% c("Basidiomycota","Phaeodaria"))
                lin.regr = lm(y.smooth[4:6] ~ increment_taxon[4:6,1])
              else if (true_taxon %in% c("Ctenophora","Platyhelminthes","Nemertea", "Bryozoa"))
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,1])
              else
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
              
            } else if (!is.null(raref) && raref == ".105")
            {
              if (true_taxon %in% c("Ctenophora","Bryozoa"))
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,1])
              else
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
            } else if (!is.null(raref) && raref == ".200")
            {
              if (true_taxon %in% c("Ascetosporea","Oomycota","Ctenophora"))
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,1])
              else
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
            } else if (raref == "random.group.div")
            {
              
              
              
              lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
              
              
            } else
            {
              if (true_taxon %in% c("RAD-A","Ctenophora","Nemertea")) # Be careful of the -/ distinction: formerly "RADA", now "RAD-A"
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,1])
              else
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
            } 
          } else if (data_V4)
          {
            if (true_taxon %in% c("Ascomycota")) 
              lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,1])
            else
              lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
          } else if (data_psbO)
            lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
          b = summary(lin.regr)$coefficients[1,1]
          a = summary(lin.regr)$coefficients[2,1]
          if (true_taxon != "AllTaxa")
          {
            charac_scale[i_taxon,1] = -b/a
            slope[i_taxon,1] = a
            intercept[i_taxon,1] = b
          } else
          {
            charac_scale.allTaxa[1] = -b/a
            slope.allTaxa[1] = a
            intercept.allTaxa[1] = b
          }
          
          Moran.step.observed.SUR.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = increment_taxon[,1], y = I_step_observed_w.mean_taxon[,1], 
                                                                                       y.smooth = smooth.spline(increment_taxon[,1],I_step_observed_w.mean_taxon[,1],df=5)$y)) +
            labs(x="Spatial scale", y="Surf. spatial autocorrelation") +
            geom_abline(slope = a,intercept = b, linetype = "dashed", size = 0.4)
        }
        Moran.step.observed.SUR.plot.w.spline[[ii_taxon]] = Moran.step.observed.SUR.plot.w.spline[[ii_taxon]] +
          geom_point(aes(x,y), size = 0.6, col = col.vect) +
          # coord_trans(x = "log10") +
          # scale_x_log10() +
          geom_line(aes(x,y.smooth), size = 0.4) +
          geom_hline(yintercept = 0, linetype = "dashed", size = 0.4) +
          theme_bw() +
          ggtitle(paste(true_taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm"))
        
        # DCM
        #####
        col.vect = rep("black",nb_increment)
        col.vect[I_step_p.value_w.mean_taxon[,2] > 0.05 | is.na(I_step_p.value_w.mean_taxon[,2])] = "red"
        if (log.scale)
        {
          y.smooth = smooth.spline(log10(increment_taxon[,2]),I_step_observed_w.mean_taxon[,2],df=5)$y
          if (true_taxon != "AllTaxa")
          {
            spatial_scale[i_taxon,2] = increment_taxon[,2][sort.int(y.smooth,decreasing=T,index.return=T)$ix[1]]
          } else
            spatial_scale.allTaxa[2] = increment_taxon[,2][sort.int(y.smooth,decreasing=T,index.return=T)$ix[1]]
          
          Moran.step.observed.DCM.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = log10(increment_taxon[,2]), y = I_step_observed_w.mean_taxon[,2], y.smooth = y.smooth)) +
            labs(x="Spatial scale (log10)", y="DCM spatial autocorrelation")
        } else
        {
          y.smooth = smooth.spline(increment_taxon[,2],I_step_observed_w.mean_taxon[,2],df=5)$y
          if (data_Federico)
          {
            if (V4_stations)
            {
              if (true_taxon %in% c("Chordata","MALV-II","MALV-I","Haptophyta","Picomonadida","Oomycota",
                               "Dinophyceae","core_Apicomplexa","Spumellaria",
                               "Vannellida","Basidiomycota","apusozoan_*"))
                lin.regr = lm(y.smooth[3:7] ~ increment_taxon[3:7,2])
              else if (true_taxon %in% c("MALV-V","Mollusca","Foraminifera","Kinetoplastida","chrompodellids_*","RAD-C","Echinodermata"))
                lin.regr = lm(y.smooth[6:11] ~ increment_taxon[6:11,2])
              else if (true_taxon %in% c("Bryozoa","Cnidaria","Nemertea","Ascomycota",
                                    "RAD-A","Chlorarachnea","Rhodophyta","Porifera"))
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,2])
              else
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,2])
            } else if (psbO_stations)
            {
              if (true_taxon %in% c("Chordata","Telonemida","Rhodophyta"))
                lin.regr = lm(y.smooth[6:11] ~ increment_taxon[6:11,2])
              else if (true_taxon %in% c("MALV-II","Ciliophora","MALV-I","Haptophyta","Cnidaria","core_Apicomplexa",
                                    "MAST-4,_6,_7,_8,_9,_10,_11","Picomonadida","Echinodermata","Phaeodaria",
                                    "Chlorarachnea","Porifera"))
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,2])
              else  
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,2])
            } else if (!is.null(raref) && raref == ".104")
            {
              lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
            } else if (!is.null(raref) && raref == ".105")
            {
              lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
            } else if (!is.null(raref) && raref == ".200")
            {
              lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,1])
            } else
            {
              if (true_taxon %in% c("Chordata","MALV-II","MALV-I","Haptophyta","Picomonadida","Kinetoplastida","Oomycota",
                               "Echinodermata","Chlorarachnea","chrompodellids_*","Dinophyceae","core_Apicomplexa","Spumellaria",
                               "Vannellida"))
                lin.regr = lm(y.smooth[3:7] ~ increment_taxon[3:7,2])
              else if (taxon %in% "MALV-V")
                lin.regr = lm(y.smooth[6:11] ~ increment_taxon[6:11,2])
              else if (true_taxon %in% c("apusozoan_*","Bryozoa","Cnidaria","Basidiomycota","Nemertea"))
                lin.regr = lm(y.smooth[5:8] ~ increment_taxon[5:8,2])
              else
                lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,2])
            } 
          } else if (data_V4)
          {
            lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,2])
          } else if (data_psbO)
          {
            if (true_taxon %in% c("Haptophyta","Pelagophyceae"))
            {
              lin.regr = lm(y.smooth[5:9] ~ increment_taxon[5:9,2])
            } else
              lin.regr = lm(y.smooth[2:4] ~ increment_taxon[2:4,2])
          }
          b = summary(lin.regr)$coefficients[1,1]
          a = summary(lin.regr)$coefficients[2,1]
          if (true_taxon != "AllTaxa")
          {
            charac_scale[i_taxon,2] = -b/a
            slope[i_taxon,2] = a
            intercept[i_taxon,2] = b
          } else
          {
            charac_scale.allTaxa[2] = -b/a
            slope.allTaxa[2] = a
            intercept.allTaxa[2] = b
          }
            
          Moran.step.observed.DCM.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = increment_taxon[,2], y = I_step_observed_w.mean_taxon[,2], 
                                                                                       y.smooth = smooth.spline(increment_taxon[,2],I_step_observed_w.mean_taxon[,2],df=5)$y)) +
            labs(x="Spatial scale", y="DCM spatial autocorrelation") +
            geom_abline(slope = a,intercept = b, linetype = "dashed", size = 0.4)
        }
        Moran.step.observed.DCM.plot.w.spline[[ii_taxon]] = Moran.step.observed.DCM.plot.w.spline[[ii_taxon]] +
          geom_point(aes(x,y), size = 0.6, col = col.vect) +
          # coord_trans(x = "log10") +
          # scale_x_log10() +
          geom_line(aes(x,y.smooth), size = 0.4) +
          geom_hline(yintercept = 0, linetype = "dashed", size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm"))
        
        ############################################ 
        # Relative (observed - expected) Moran's I #
        ############################################
        
        # Mean Sur and DCM
        ##################
        col.vect = rep("black",nb_increment)
        col.vect[I_step_p.value_w.mean_taxon[,3] > 0.05 | is.na(I_step_p.value_w.mean_taxon[,3])] = "red"
        if (log.scale)
        {
          Moran.step.relative.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = log10(increment_taxon[,3]), y = I_step_relative_w.mean_taxon[,3], 
                                                                                   y.smooth = smooth.spline(log10(increment_taxon[,3]),I_step_relative_w.mean_taxon[,3],df=5)$y)) +
            labs(x="Spatial scale (log10)", y="Mean spatial autocorrelation")
        } else
        {
          Moran.step.relative.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = increment_taxon[,3], y = I_step_relative_w.mean_taxon[,3], 
                                                                                   y.smooth = smooth.spline(increment_taxon[,3],I_step_relative_w.mean_taxon[,3],df=5)$y)) +
            labs(x="Spatial scale", y="Mean spatial autocorrelation")
        }
        Moran.step.relative.plot.w.spline[[ii_taxon]] = Moran.step.relative.plot.w.spline[[ii_taxon]] +
          geom_point(aes(x,y), size = 0.6, col = col.vect) +
          # coord_trans(x = "log10") +
          # scale_x_log10() +
          geom_line(aes(x,y.smooth), size = 0.4) +
          geom_hline(yintercept = 0, linetype = "dashed", size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm"))
        
        # Sur
        #####
        col.vect = rep("black",nb_increment)
        col.vect[I_step_p.value_w.mean_taxon[,1] > 0.05 | is.na(I_step_p.value_w.mean_taxon[,1])] = "red"
        if (log.scale)
        {
          Moran.step.relative.SUR.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = log10(increment_taxon[,1]), y = I_step_relative_w.mean_taxon[,1], 
                                                                                       y.smooth = smooth.spline(log10(increment_taxon[,1]),I_step_relative_w.mean_taxon[,1],df=5)$y)) +
            labs(x="Spatial scale (log10)", y="Surf. spatial autocorrelation")
        } else
        {
          Moran.step.relative.SUR.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = increment_taxon[,1], y = I_step_relative_w.mean_taxon[,1], 
                                                                                       y.smooth = smooth.spline(increment_taxon[,1],I_step_relative_w.mean_taxon[,1],df=5)$y)) +
            labs(x="Spatial scale", y="Surf. spatial autocorrelation")
        }
        Moran.step.relative.SUR.plot.w.spline[[ii_taxon]] = Moran.step.relative.SUR.plot.w.spline[[ii_taxon]] +
          geom_point(aes(x,y), size = 0.6, col = col.vect) +
          # coord_trans(x = "log10") +
          # scale_x_log10() +
          geom_line(aes(x,y.smooth), size = 0.4) +
          geom_hline(yintercept = 0, linetype = "dashed", size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm"))
        
        # DCM
        #####
        col.vect = rep("black",nb_increment)
        col.vect[I_step_p.value_w.mean_taxon[,2] > 0.05 | is.na(I_step_p.value_w.mean_taxon[,2])] = "red"
        if (log.scale)
        {
          Moran.step.relative.DCM.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = log10(increment_taxon[,2]), y = I_step_relative_w.mean_taxon[,2], 
                                                                                       y.smooth = smooth.spline(log10(increment_taxon[,2]),I_step_relative_w.mean_taxon[,2],df=5)$y)) +
            labs(x="Spatial scale (log10)", y="DCM spatial autocorrelation")
        } else
        {
          Moran.step.relative.DCM.plot.w.spline[[ii_taxon]] = ggplot(data = data.frame(x = increment_taxon[,2], y = I_step_relative_w.mean_taxon[,2], 
                                                                                       y.smooth = smooth.spline(increment_taxon[,2],I_step_relative_w.mean_taxon[,2],df=5)$y)) +
            labs(x="Spatial scale", y="DCM spatial autocorrelation")
        }
        Moran.step.relative.DCM.plot.w.spline[[ii_taxon]] = Moran.step.relative.DCM.plot.w.spline[[ii_taxon]] +
          geom_point(aes(x,y), size = 0.6, col = col.vect) +
          # coord_trans(x = "log10") +
          # scale_x_log10() +
          geom_line(aes(x,y.smooth), size = 0.4) +
          geom_hline(yintercept = 0, linetype = "dashed", size = 0.4) +
          theme_bw() +
          ggtitle(paste(taxon,"-",ifelse(true_taxon=="AllTaxa",sum(diversity),as.vector(diversity)[i_taxon]),"OTUs")) +
          theme(axis.title=element_text(size=9),
                plot.title=element_text(hjust=0, size=15),
                plot.margin=unit(c(1,1,1,0.5),"mm"))
      }
      
      if (data_Federico)
      {
        if (V4_stations || psbO_stations)
        {
          saveRDS(charac_scale,file=paste0(results_folder,"/MoranI",station_insert,"_charach.autocorr.scale_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        } else if (!is.null(raref))
        {
          saveRDS(charac_scale,file=paste0(results_folder,"/",
                                           paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)], collapse=""),
                                           "_MoranI_charach.autocorr.scale_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        } else
        {
          saveRDS(list(charac_scale,charac_scale.allTaxa),file=paste0(results_folder,"/MoranI_charach.autocorr.scale_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
          saveRDS(list(slope,intercept),file=paste0(results_folder,"/MoranI_slope.intercept_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        }
      } else
      {
        saveRDS(charac_scale,file=paste0(results_folder,"/",short_marker,"MoranI_charach.autocorr.scale_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
      }
        
      # charac_scale = matrix(nrow = length(taxo_groups), ncol = 3, data = NA)
      # charac_scale.allTaxa = vector(length = 3, mode = "numeric")
      
      spl = split(Moran.step.observed.plot.w.spline[!is.na(Moran.step.observed.plot.w.spline)], 
                  (seq_along(Moran.step.observed.plot.w.spline[!is.na(Moran.step.observed.plot.w.spline)])-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
      pdf(paste0(figure_folder,"/Moran.step.observed.plot.w.spline",ifelse(log.scale,"_log",""),"_vs_spatial.scale",station_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
      
      spl = split(Moran.step.observed.SUR.plot.w.spline[!is.na(Moran.step.observed.SUR.plot.w.spline)], 
                  (seq_along(Moran.step.observed.SUR.plot.w.spline[!is.na(Moran.step.observed.SUR.plot.w.spline)])-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
      pdf(paste0(figure_folder,"/",
                 if (!is.null(raref)) paste0(paste(strsplit(raref,split="",fixed=T)[[1]][2:nchar(raref)], collapse=""),"_") else "",
                 "Moran.step.observed.SUR.plot.w.spline",ifelse(log.scale,"_log",""),"_vs_spatial.scale",station_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
      
      spl = split(Moran.step.observed.DCM.plot.w.spline[!is.na(Moran.step.observed.DCM.plot.w.spline)], 
                  (seq_along(Moran.step.observed.DCM.plot.w.spline[!is.na(Moran.step.observed.DCM.plot.w.spline)])-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
      pdf(paste0(figure_folder,"/Moran.step.observed.DCM.plot.w.spline",ifelse(log.scale,"_log",""),"_vs_spatial.scale",station_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
      
      spl = split(Moran.step.relative.plot.w.spline[!is.na(Moran.step.relative.plot.w.spline)], 
                  (seq_along(Moran.step.relative.plot.w.spline[!is.na(Moran.step.relative.plot.w.spline)])-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
      pdf(paste0(figure_folder,"/Moran.step.relative.plot.w.spline",ifelse(log.scale,"_log",""),"_vs_spatial.scale",station_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
      
      spl = split(Moran.step.relative.SUR.plot.w.spline[!is.na(Moran.step.relative.SUR.plot.w.spline)], 
                  (seq_along(Moran.step.relative.SUR.plot.w.spline[!is.na(Moran.step.relative.SUR.plot.w.spline)])-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
      pdf(paste0(figure_folder,"/Moran.step.relative.SUR.plot.w.spline",ifelse(log.scale,"_log",""),"_vs_spatial.scale",station_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
      
      spl = split(Moran.step.relative.DCM.plot.w.spline[!is.na(Moran.step.relative.DCM.plot.w.spline)], 
                  (seq_along(Moran.step.relative.DCM.plot.w.spline[!is.na(Moran.step.relative.DCM.plot.w.spline)])-1) %/% 20)
      ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5, layout_matrix = matrix(data=1:20,nrow=4,byrow=T)))
      pdf(paste0(figure_folder,"/Moran.step.relative.DCM.plot.w.spline",ifelse(log.scale,"_log",""),"_vs_spatial.scale",station_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1_AllTaxa.pdf"),height = 1.5*10, width = 1.5*10)
      print(ppl)
      dev.off()
    }
    
    if (autocorr_scale)
    {
      # weighted_mean = 0
      weighted_mean = 1
      if (weighted_mean)
      {
        weight_insert = "_weighted.mean.across.topics"
      } else 
        weight_insert = ""
      
      # Plotting scale of maximum autocorrealtion or characteristic scale of autocorrelation decay:
      ###############
      library(MASS)
      library(viridis)
      get_density <- function(x, y, n = 100) {
        dens <- MASS::kde2d(x = x, y = y, n = n)
        ix <- findInterval(x, dens$x)
        iy <- findInterval(y, dens$y)
        ii <- cbind(ix, iy)
        return(dens$z[ii])
      }
      if (log.scale)
      {
        dat = data.frame(y=spatial_scale[selected_groups,1], x=spatial_scale[selected_groups,2])
      } else 
        dat = data.frame(y=charac_scale[selected_groups,1], x=charac_scale[selected_groups,2])
      dat$density = get_density(dat$x, dat$y)
      plot.log.spatial.scale_SUR_vs_DCM = ggplot(data=dat) +
        theme_bw() +
        geom_abline(slope = 1,intercept = 0, linetype = "dashed", size = 0.4) +
        # geom_smooth(aes(x = x, y = y), method='lm') +
        geom_point(aes(x = x, y = y,color=density), size = 0.4) +
        scale_color_viridis() +
        theme(axis.title=element_text(size=9),
              axis.text = element_text(size=9),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(1,1,1,0.5),"mm"))
      if (log.scale)
      {
        plot.log.spatial.scale_SUR_vs_DCM = plot.log.spatial.scale_SUR_vs_DCM + labs(x="DCM maximum spatial autocorrelation", y="Surf. maximum spatial autocorrelation")
      } else
        plot.log.spatial.scale_SUR_vs_DCM = plot.log.spatial.scale_SUR_vs_DCM + labs(x="DCM charac. spatial autocorrelation scale", y="Surf. charac. spatial autocorrelation scale")
      
      ggsave(filename = paste0(figure_folder,"/",ifelse(log.scale,"Max","Charach.scale"),".spatial.autocorrelation_SUR_vs_DCM_optimalK_prevalence.min.crossValid_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.log.spatial.scale_SUR_vs_DCM), nrow=1)),
             height = 1.5*10/4, width = 1.5*10/4)
      
      ##################
      div_threshold = 1000
      
      plot.charach.scale.SUR_vs_DCM = ggplot(data=data.frame(x=charac_scale[selected_groups & diversity>div_threshold,2],
                                                             y=charac_scale[selected_groups & diversity>div_threshold,1])) +
        theme_bw() +
        geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
        # geom_smooth(aes(x = x, y = y), method='lm', col="black") +
        geom_point(aes(x = x, y = y)) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_blank(),
              plot.margin=unit(c(1,10,1,0.5),"mm")) +
        labs(y="Surface charac. spatial scale", x="DCM charac. spatial scale")
      pdf(file = paste0(figure_folder,"/Charach.autocorr.scale_SUR_vs_DCM_Gibbs.prevalence.min.crossValid_selected",if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
      print(plot.charach.scale.SUR_vs_DCM)
      dev.off()
      
      ############
      if (log.scale)
      {
        dat = data.frame(y=spatial_scale[selected_groups,3], x=optimalK_prevalence.min.crossValid[selected_groups])
      } else 
        dat = data.frame(y=charac_scale[selected_groups,3], x=optimalK_prevalence.min.crossValid[selected_groups])
      dat$density = get_density(dat$x, dat$y)
      plot.log.spatial.scale_vs_optimalK = ggplot(data=dat) +
        theme_bw() +
        geom_smooth(aes(x,y),method='lm') +
        geom_point(aes(x = x, y = y,color=density), size = 0.4) +
        scale_color_viridis() +
        theme(axis.title=element_text(size=9),
              axis.text = element_text(size=9),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(1,1,1,0.5),"mm"))
      if (log.scale)
      {
        plot.log.spatial.scale_vs_optimalK = plot.log.spatial.scale_vs_optimalK + labs(x="Optimal number of assemblages", y="Mean maximum spatial autocorrelation")
      } else
        plot.log.spatial.scale_vs_optimalK = plot.log.spatial.scale_vs_optimalK + labs(x="Optimal number of assemblages", y="Mean charac. spatial autocorrelation scale")
      #
      if (log.scale)
      {
        dat = data.frame(y=spatial_scale[selected_groups,1], x=optimalK_prevalence.min.crossValid[selected_groups])
      } else
        dat = data.frame(y=charac_scale[selected_groups,1], x=optimalK_prevalence.min.crossValid[selected_groups])
      dat$density = get_density(dat$x, dat$y)
      plot.SUR.log.spatial.scale_vs_optimalK = ggplot(data=dat) +
        theme_bw() +
        geom_smooth(aes(x,y),method='lm') +
        geom_point(aes(x = x, y = y,color=density), size = 0.4) +
        scale_color_viridis() +
        theme(axis.title=element_text(size=9),
              axis.text = element_text(size=9),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(1,1,1,0.5),"mm"))
        if (log.scale)
        {
          plot.SUR.log.spatial.scale_vs_optimalK = plot.SUR.log.spatial.scale_vs_optimalK + labs(x="Optimal number of assemblages", y="Surf. maximum spatial autocorrelation")
        } else
          plot.SUR.log.spatial.scale_vs_optimalK = plot.SUR.log.spatial.scale_vs_optimalK + labs(x="Optimal number of assemblages", y="Surf. charac. spatial autocorrelation scale")
      #
      if (log.scale)
      {
        dat = data.frame(y=spatial_scale[selected_groups,2], x=optimalK_prevalence.min.crossValid[selected_groups])
      } else
        dat = data.frame(y=charac_scale[selected_groups,2], x=optimalK_prevalence.min.crossValid[selected_groups])
      dat$density = get_density(dat$x, dat$y)
      plot.DCM.log.spatial.scale_vs_optimalK = ggplot(data=dat) +
        theme_bw() +
        geom_smooth(aes(x,y),method='lm') +
        geom_point(aes(x = x, y = y,color=density), size = 0.4) +
        scale_color_viridis() +
        theme(axis.title=element_text(size=9),
              axis.text = element_text(size=9),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(1,1,1,0.5),"mm"))
      if (log.scale)
      {
        plot.DCM.log.spatial.scale_vs_optimalK = plot.DCM.log.spatial.scale_vs_optimalK + labs(x="Optimal number of assemblages", y="DCM maximum spatial autocorrelation")
      }
        plot.DCM.log.spatial.scale_vs_optimalK = plot.DCM.log.spatial.scale_vs_optimalK + labs(x="Optimal number of assemblages", y="DCM charac. spatial autocorrelation scale")
      # geom_smooth(aes(x = x, y = y), method='lm')
      plot.list = list(list(plot.log.spatial.scale_vs_optimalK),list(plot.SUR.log.spatial.scale_vs_optimalK),list(plot.DCM.log.spatial.scale_vs_optimalK))
      ppl = lapply(plot.list, function(g) marrangeGrob(grobs = g, nrow = 1, ncol = 1))
      # spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
      pdf(file = paste0(figure_folder,"/",ifelse(log.scale,"Max","Charach.scale"),".spatial.autocorrelation_vs_optimalK_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1.pdf"),height = 1.5*10/4, width = 1.5*10/4)
      print(ppl)
      dev.off()
      
      ############
      plot.log.spatial.scale_vs_log_size = ggplot(data=data.frame(y=if (log.scale) spatial_scale[selected_groups,3] else charac_scale[selected_groups,3],
                                                                  x=log10(size_absoluteAbund)[selected_groups])) +
        theme_bw() +
        geom_smooth(aes(x,y),method='lm') +
        geom_point(aes(x = x, y = y), size = 0.4) +
        theme(axis.title=element_text(size=9),
              axis.text = element_text(size=9),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(1,1,1,0.5),"mm"))
      if (log.scale)
      {
        plot.log.spatial.scale_vs_log_size = plot.log.spatial.scale_vs_log_size + labs(x="Mean group body size (log10)", y="Mean maximum spatial autocorrelation")
      } else
        plot.log.spatial.scale_vs_log_size = plot.log.spatial.scale_vs_log_size + labs(x="Mean group body size (log10)", y="Mean charac. spatial autocorrelation scale")
      # 
      plot.SUR.log.spatial.scale_vs_log_size = ggplot(data=data.frame(y=if (log.scale) spatial_scale[selected_groups,1] else charac_scale[selected_groups,1],
                                                                      x=log10(size_absoluteAbund)[selected_groups])) +
        theme_bw() +
        geom_smooth(aes(x,y),method='lm') +
        geom_point(aes(x = x, y = y), size = 0.4) +
        theme(axis.title=element_text(size=9),
              axis.text = element_text(size=9),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(1,1,1,0.5),"mm"))
      if (log.scale)
      {
        plot.SUR.log.spatial.scale_vs_log_size = plot.SUR.log.spatial.scale_vs_log_size + labs(x="Mean group body size (log10)", y="Surf. maximum spatial autocorrelation")
      } else
        plot.SUR.log.spatial.scale_vs_log_size = plot.SUR.log.spatial.scale_vs_log_size + labs(x="Mean group body size (log10)", y="Surf. charac. spatial autocorrelation scale")
      #
      plot.DCM.log.spatial.scale_vs_log_size = ggplot(data=data.frame(y=if (log.scale) spatial_scale[selected_groups,2] else charac_scale[selected_groups,2],
                                                                      x=log10(size_absoluteAbund)[selected_groups])) +
        theme_bw() +
        geom_smooth(aes(x,y),method='lm') +
        geom_point(aes(x = x, y = y), size = 0.4) +
        theme(axis.title=element_text(size=9),
              axis.text = element_text(size=9),
              plot.title=element_text(hjust=0, size=12),
              plot.margin=unit(c(1,1,1,0.5),"mm"))
      if (log.scale)
      {
        plot.DCM.log.spatial.scale_vs_log_size = plot.DCM.log.spatial.scale_vs_log_size + labs(x="Mean group body size (log10)", y="DCM maximum spatial autocorrelation")
      } else
        plot.DCM.log.spatial.scale_vs_log_size = plot.DCM.log.spatial.scale_vs_log_size + labs(x="Mean group body size (log10)", y="DCM charac. spatial autocorrelation scale")
      # geom_smooth(aes(x = x, y = y), method='lm')
      plot.list = list(list(plot.log.spatial.scale_vs_log_size),list(plot.SUR.log.spatial.scale_vs_log_size),list(plot.DCM.log.spatial.scale_vs_log_size))
      ppl = lapply(plot.list, function(g) marrangeGrob(grobs = g, nrow = 1, ncol = 1))
      # spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
      pdf(file = paste0(figure_folder,"/",ifelse(log.scale,"Max","Charach.scale"),".spatial.autocorrelation_vs_log.size_Gibbs100r_optimalK_prevalence.min.crossValid_selected100+1.pdf"),height = 1.5*10/4, width = 1.5*10/4)
      print(ppl)
      dev.off()
      
      ################
      plot.log.spatial.scale_vs_log_diversity = ggplot(data=data.frame(y=if (log.scale) spatial_scale[selected_groups,3] else charac_scale[selected_groups,3],
                                                                       x=as.vector(diversity)[selected_groups])) +
        theme_bw() +
        scale_x_log10() +
        geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
        geom_point(aes(x = x, y = y)) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_blank(),
              plot.margin=unit(c(1,10,1,0.5),"mm"))
      if (log.scale)
      {
        plot.log.spatial.scale_vs_log_diversity = plot.log.spatial.scale_vs_log_diversity + labs(x="Number of OTUs", y="Mean maximum spatial autocorrelation")
      } else
        plot.log.spatial.scale_vs_log_diversity = plot.log.spatial.scale_vs_log_diversity + labs(x="Number of OTUs", y="Mean charac. spatial scale")
      # geom_smooth(aes(x = x, y = y), method='lm')
      plot.SUR.log.spatial.scale_vs_log_diversity = ggplot(data=data.frame(y=if (log.scale) spatial_scale[selected_groups,1] else charac_scale[selected_groups,1],
                                                                           x=as.vector(diversity)[selected_groups])) +
        theme_bw() +
        scale_x_log10() +
        geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
        # geom_smooth(aes(x,y),method='lm',col="black") +
        geom_point(aes(x = x, y = y)) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_blank(),
              plot.margin=unit(c(1,10,1,0.5),"mm"))
      if (log.scale)
      {
        plot.SUR.log.spatial.scale_vs_log_diversity = plot.SUR.log.spatial.scale_vs_log_diversity + labs(x="Number of OTUs", y="Surface maximum spatial autocorrelation")
      } else
        plot.SUR.log.spatial.scale_vs_log_diversity = plot.SUR.log.spatial.scale_vs_log_diversity + labs(x="Number of OTUs", y="Surface charac. spatial scale")
      # geom_smooth(aes(x = x, y = y), method='lm')
      plot.DCM.log.spatial.scale_vs_log_diversity = ggplot(data=data.frame(y=if (log.scale) spatial_scale[selected_groups,2] else charac_scale[selected_groups,2],
                                                                           x=as.vector(diversity)[selected_groups])) +
        theme_bw() +
        scale_x_log10() +
        geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
        # geom_smooth(aes(x,y),method='lm',col="black") +
        geom_point(aes(x = x, y = y)) +
        theme(axis.text = element_text(size=16),
              axis.title=element_text(size=24),
              plot.title=element_blank(),
              plot.margin=unit(c(1,10,1,0.5),"mm"))
      if (log.scale)
      {
        plot.DCM.log.spatial.scale_vs_log_diversity = plot.DCM.log.spatial.scale_vs_log_diversity + labs(x="Number of OTUs", y="DCM maximum spatial autocorrelation")
      } else 
        plot.DCM.log.spatial.scale_vs_log_diversity = plot.DCM.log.spatial.scale_vs_log_diversity + labs(x="Number of OTUs", y="DCM charac. spatial scale")
      # geom_smooth(aes(x = x, y = y), method='lm')
      pdf(file = paste0(figure_folder,"/",ifelse(log.scale,"Max.autocorr","Charach.autocorr.scale"),"._vs_log.div_Gibbs.prevalence.min.crossValid_selected100+1.pdf"))
      print(plot.log.spatial.scale_vs_log_diversity)
      print(plot.SUR.log.spatial.scale_vs_log_diversity)
      print(plot.DCM.log.spatial.scale_vs_log_diversity)
      dev.off()

      if (!log.scale)
      {
        col.vect = rep("black",length(which(selected_groups)))
        col.vect[I_square.p.value_w.mean[selected_groups,3] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,3])] = "red"
        plot.mean.Moran.square.I_vs_charach.scale = ggplot(data=data.frame(x=if (weighted_mean) I_square.observed_w.mean[selected_groups,3] else I_square_mean[selected_groups,3],
                                                                           y=charac_scale[selected_groups,3])) +
          theme_bw() +
          geom_smooth(aes(x = x, y = y), method='lm', col="black") +
          geom_point(aes(x = x, y = y), col=col.vect) +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_blank(),
                plot.margin=unit(c(1,10,1,0.5),"mm")) +
          labs(y="Mean charac. spatial scale", x="Mean spatial autocorrelation")
        # 
        col.vect = rep("black",length(which(selected_groups)))
        col.vect[I_square.p.value_w.mean[selected_groups,1] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,1])] = "red"
        plot.SUR.Moran.square.I_vs_charach.scale = ggplot(data=data.frame(x=if (weighted_mean) I_square.observed_w.mean[selected_groups,1] else I_square_mean[selected_groups,1],
                                                                          y=charac_scale[selected_groups,1])) +
          theme_bw() +
          geom_smooth(aes(x = x, y = y), method='lm', col="black") +
          geom_point(aes(x = x, y = y), col=col.vect) +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_blank(),
                plot.margin=unit(c(1,10,1,0.5),"mm")) +
          labs(y="Surface charac. spatial scale", x="Surface spatial autocorrelation")
        # 
        col.vect = rep("black",length(which(selected_groups)))
        col.vect[I_square.p.value_w.mean[selected_groups,2] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,2])] = "red"
        plot.DCM.Moran.square.I_vs_charach.scale = ggplot(data=data.frame(x=if (weighted_mean) I_square.observed_w.mean[selected_groups,2] else I_square_mean[selected_groups,2],
                                                                          y=charac_scale[selected_groups,2])) +
          theme_bw() +
          geom_smooth(aes(x = x, y = y), method='lm', col="black") +
          geom_point(aes(x = x, y = y), col=col.vect) +
          theme(axis.text = element_text(size=16),
                axis.title=element_text(size=24),
                plot.title=element_blank(),
                plot.margin=unit(c(1,10,1,0.5),"mm")) +
          labs(y="DCM charac. spatial scale", x="DCM spatial autocorrelation")
        #
        pdf(file = paste0(figure_folder,"/Charach.autocorr.scale_vs_MoranI.square",weight_insert,"_Gibbs.prevalence.min.crossValid_selected100+1.pdf"))
        print(plot.mean.Moran.square.I_vs_charach.scale)
        print(plot.SUR.Moran.square.I_vs_charach.scale)
        print(plot.DCM.Moran.square.I_vs_charach.scale)
        dev.off()
        
        # Functional boxplot: 
        #####################
        div_threshold = 100
        
        dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
        dominant_function0 = dominant_function[selected_groups & diversity>div_threshold]
        # dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
        # dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
        dominant_function0[dominant_function0 == "unknown"] = NA
        dominant_function0[dominant_function0 == "photohost"] = "Collodaria"
        dominant_function0[dominant_function0 == "pteropoda"] = "Pteropoda"
        dominant_function0[dominant_function0 == "copepoda"] = "Copepoda"
        dominant_function0[dominant_function0 == "gelatineous_carnivores_filterers"] = "Gel. carn. filterers"
        dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Dinophyceae"] = "Dinophyceae"
        dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Bacillariophyta"] = "Bacillariophyta"
        dominant_function0[dominant_function0 == "phototroph"] = "Other phototrophs"
        dominant_function0[dominant_function0 == "phagotroph"] = "Phagotrophs"
        dominant_function0[dominant_function0 == "other metazoa"] = "Other metazoa"
        dominant_function0[dominant_function0 == "parasite"] = "Parasites"
        # alpha = rep(1,length(taxo_groups[selected_groups]))
        # alpha[dominant_function0 %in% c("copepoda","pteropoda")] = 0 
        # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them by deceasing number of groups:
        # dominant_function0 = factor(dominant_function0,names(sort(table(as.factor(dominant_function0)),decreasing = T)))
        # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them in the specified order:
        if (div_threshold == 100)
        {
          dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Pteropoda","Copepoda","Other metazoa","Parasites"))
          point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")
        } else if (div_threshold == 1000)
        {
          dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Copepoda","Parasites"))
          point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta")
        } 
        
        boxplot.spatial.charac = list()
        for (i_case in 1:2)
        {
          boxplot.spatial.charac[[i_case]] = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                      y = charac_scale[selected_groups & diversity>div_threshold,i_case][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
            scale_x_discrete(limits=levels(dominant_function0)) +
            geom_boxplot(aes(x,y)) +
            geom_point(data = data.frame(x = factor(point_groups),
                                         y = charac_scale[selected_groups & diversity>div_threshold,i_case][dominant_function0 %in% point_groups]),
                       aes(x,y)) +
            theme_bw() +
            theme(axis.title=element_text(size=24),
                  axis.text=element_text(size=22),
                  axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
                  plot.margin=unit(c(2,1,1,1),"mm")) +
            labs(x="", y=paste(if (i_case == 1) "Surface" else "DCM","charac. spatial scale"))
        }
        pdf(paste0(figure_folder,"/Charac.spatial.scale_boxplot_allFunctionalGroups_selected",
                   if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
        print(boxplot.spatial.charac[[1]])
        print(boxplot.spatial.charac[[2]])
        dev.off()
      }
    }
    
    ##################################
    # Prevalence-corrected nb of community types
    #################################
    
    plot.nb.community.types.SUR_vs_DCM = ggplot(data=data.frame(x=prevalence.corrected_K[selected_groups,2],
                                                                y=prevalence.corrected_K[selected_groups,1])) +
                                                  theme_bw() +
                                                  geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
                                                  # geom_smooth(aes(x = x, y = y), method='lm', col="black") +
                                                  geom_point(aes(x = x, y = y)) +
                                                  theme(axis.text = element_text(size=16),
                                                        axis.title=element_text(size=24),
                                                        plot.title=element_blank(),
                                                        plot.margin=unit(c(1,10,1,0.5),"mm")) +
                                                  labs(y="Surface number of assemblages", x="DCM number of assemblages")
    pdf(file = paste0(figure_folder,"/Prevalence-corrected.K_SUR_vs_DCM_Gibbs.prevalence.min.crossValid_selected100+1.pdf"))
    print(plot.nb.community.types.SUR_vs_DCM)
    dev.off()
    
    plot.nb.community.types.SUR_vs_DCM = ggplot(data=data.frame(x=(prevalence.corrected_K[selected_groups,2]/optimalK_prevalence.min.crossValid[selected_groups])/(nb_stat[selected_groups,2]/(nb_stat[selected_groups,1]*nb_stat[selected_groups,2])),
                                                                y=(prevalence.corrected_K[selected_groups,1]/optimalK_prevalence.min.crossValid[selected_groups])/(nb_stat[selected_groups,1]/(nb_stat[selected_groups,1]*nb_stat[selected_groups,2])))) +
      theme_bw() +
      geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
      # geom_smooth(aes(x = x, y = y), method='lm', col="black") +
      geom_point(aes(x = x, y = y)) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,10,1,0.5),"mm")) +
      labs(y="Observed over expected\n surface number of assemblages", x="Observed over expected\n DCM number of assemblages")
    pdf(file = paste0(figure_folder,"/Prevalence-corrected.K.observed.over.expected_SUR_vs_DCM_Gibbs.prevalence.min.crossValid_selected100+1.pdf"))
    print(plot.nb.community.types.SUR_vs_DCM)
    dev.off()
    
    #########
    
    ##########
    # Diversity plots:
    ##########
    # plot.Moran.I_vs_log_diversity = list()
    # plot.mean.Moran.linear.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_linear.observed_w.mean[selected_groups,3] else I_linear_mean[selected_groups,3],
    #                                                                    x=log10(as.vector(diversity))[selected_groups])) +
    #   theme_bw() +
    #   geom_point(aes(x = x, y = y), size = 0.4) +
    #   theme(axis.title=element_text(size=9),
    #         axis.text = element_text(size=9),
    #         plot.title=element_text(hjust=0, size=12),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="Diversity (log10)", y="Mean Moran's I linear weights")
    # # geom_smooth(aes(x = x, y = y), method='lm')
    # plot.SUR.Moran.linear.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_linear.observed_w.mean[selected_groups,1] else I_linear_mean[selected_groups,1],
    #                                                                   x=log10(as.vector(diversity))[selected_groups])) +
    #   theme_bw() +
    #   geom_point(aes(x = x, y = y), size = 0.4) +
    #   theme(axis.title=element_text(size=9),
    #         axis.text = element_text(size=9),
    #         plot.title=element_text(hjust=0, size=12),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="Diversity (log10)", y="Surf. Moran's I linear weights")
    # # geom_smooth(aes(x = x, y = y), method='lm')
    # plot.DCM.Moran.linear.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_linear.observed_w.mean[selected_groups,2] else I_linear_mean[selected_groups,2],
    #                                                                   x=log10(as.vector(diversity))[selected_groups])) +
    #   theme_bw() +
    #   geom_point(aes(x = x, y = y), size = 0.4) +
    #   theme(axis.title=element_text(size=9),
    #         axis.text = element_text(size=9),
    #         plot.title=element_text(hjust=0, size=12),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="Diversity (log10)", y="DCM Moran's I linear weights")
    # # geom_smooth(aes(x = x, y = y), method='lm')
    # 
    # plot.list = list(list(plot.mean.Moran.linear.I_vs_log_diversity),list(plot.SUR.Moran.linear.I_vs_log_diversity),list(plot.DCM.Moran.linear.I_vs_log_diversity))
    # ppl = lapply(plot.list, function(g) marrangeGrob(grobs = g, nrow = 1, ncol = 1))
    # # spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
    # pdf(file = paste0(figure_folder,"/MoranI_linear",weight_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_vs_diversity_selected100+1.pdf"),height = 1.5*10/4, width = 1.5*10/4)
    # print(ppl)
    # dev.off()
    
    # plot.mean.Moran.inverse.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_inverse.observed_w.mean[selected_groups,3] else I_inverse_mean[selected_groups,3],
    #                                                                     x=log10(as.vector(diversity))[selected_groups])) +
    #   # ggtitle("") +
    #   theme_bw() +
    #   geom_point(aes(x = x, y = y), size = 0.4) +
    #   theme(axis.title=element_text(size=9),
    #         axis.text = element_text(size=9),
    #         plot.title=element_text(hjust=0, size=12),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="Diversity (log10)", y="Mean Moran's I inverse weights")
    # # geom_smooth(aes(x = x, y = y), method='lm')
    # plot.SUR.Moran.inverse.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_inverse.observed_w.mean[selected_groups,1] else I_inverse_mean[selected_groups,1],
    #                                                                    x=log10(as.vector(diversity))[selected_groups])) +
    #   theme_bw() +
    #   geom_point(aes(x = x, y = y), size = 0.4) +
    #   theme(axis.title=element_text(size=9),
    #         axis.text = element_text(size=9),
    #         plot.title=element_text(hjust=0, size=12),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="Diversity (log10)", y="Surf. Moran's I inverse weights")
    # # geom_smooth(aes(x = x, y = y), method='lm')
    # plot.DCM.Moran.inverse.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_inverse.observed_w.mean[selected_groups,2] else I_inverse_mean[selected_groups,2],
    #                                                                    x=log10(as.vector(diversity))[selected_groups])) +
    #   theme_bw() +
    #   geom_point(aes(x = x, y = y), size = 0.4) +
    #   theme(axis.title=element_text(size=9),
    #         axis.text = element_text(size=9),
    #         plot.title=element_text(hjust=0, size=12),
    #         plot.margin=unit(c(1,1,1,0.5),"mm")) +
    #   labs(x="Diversity (log10)", y="DCM Moran's I inverse weights")
    # # geom_smooth(aes(x = x, y = y), method='lm')
    # 
    # plot.list = list(list(plot.mean.Moran.inverse.I_vs_log_diversity),list(plot.SUR.Moran.inverse.I_vs_log_diversity),list(plot.DCM.Moran.inverse.I_vs_log_diversity))
    # ppl = lapply(plot.list, function(g) marrangeGrob(grobs = g, nrow = 1, ncol = 1))
    # # spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
    # pdf(file = paste0(figure_folder,"/MoranI_inverse",weight_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_vs_diversity_selected100+1.pdf"),height = 1.5*10/4, width = 1.5*10/4)
    # print(ppl)
    # dev.off()
    
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,3] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,3])] = "red"
    plot.mean.Moran.square.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_square.observed_w.mean[selected_groups,3] else I_square_mean[selected_groups,3],
                                                                       x=as.vector(diversity)[selected_groups])) +
      theme_bw() +
      scale_x_log10() +
      geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
      geom_point(aes(x = x, y = y), col=col.vect) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,10,1,0.5),"mm")) +
      # labs(x="Diversity (log10)", y="Mean Moran's I square weights")
      labs(x="Number of OTUs", y="Mean surface-DCM spatial autocorrelation")
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,1] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,1])] = "red"
    plot.SUR.Moran.square.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_square.observed_w.mean[selected_groups,1] else I_square_mean[selected_groups,1],
                                                                      x=as.vector(diversity)[selected_groups])) +
      theme_bw() +
      scale_x_log10() +
      geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
      geom_point(aes(x = x, y = y), col=col.vect) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,10,1,0.5),"mm")) +
      # labs(x="Diversity (log10)", y="Surf. Moran's I square weights")
      labs(x="Number of OTUs", y="Surface spatial autocorrelation")
    # geom_smooth(aes(x = x, y = y), method='lm')
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,2] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,2])] = "red"
    plot.DCM.Moran.square.I_vs_log_diversity = ggplot(data=data.frame(y=if (weighted_mean) I_square.observed_w.mean[selected_groups,2] else I_square_mean[selected_groups,2],
                                                                      x=as.vector(diversity)[selected_groups])) +
      theme_bw() +
      scale_x_log10() +
      geom_smooth(aes(x,y), method = "lm", formula = y ~ splines::bs(x, 4), se = F, col = "black") +
      geom_point(aes(x = x, y = y), col=col.vect) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,10,1,0.5),"mm")) +
      # labs(x="Diversity (log10)", y="DCM Moran's I square weights")
      labs(x="Number of OTUs", y="DCM spatial autocorrelation")
    # geom_smooth(aes(x = x, y = y), method='lm')
    
    # spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
    pdf(file = paste0(figure_folder,"/MoranI.square",weight_insert,"_vs_diversity_Gibbs.prevalence.min.crossValid_selected100+1.pdf"))
    print(plot.mean.Moran.square.I_vs_log_diversity)
    print(plot.SUR.Moran.square.I_vs_log_diversity)
    print(plot.DCM.Moran.square.I_vs_log_diversity)
    dev.off()
    
    ############
    # Body size plots:
    #############
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,3] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,3])] = "red"
    plot.mean.Moran.square.I_vs_log_size = ggplot(data=data.frame(y=if (weighted_mean) I_square.expected_w.mean[selected_groups,3] else I_square_mean[selected_groups,3],
                                                                       x=log10(size_absoluteAbund)[selected_groups])) +
      theme_bw() +
      geom_point(aes(x = x, y = y), size = 0.4, col=col.vect) +
      theme(axis.title=element_text(size=9),
            axis.text = element_text(size=9),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean group body size (log10)", y="Mean Moran's I square weights")
    # geom_smooth(aes(x = x, y = y), method='lm')
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,1] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,1])] = "red"
    plot.SUR.Moran.square.I_vs_log_size = ggplot(data=data.frame(y=if (weighted_mean) I_square.expected_w.mean[selected_groups,1] else I_square_mean[selected_groups,1],
                                                                      x=log10(size_absoluteAbund)[selected_groups])) +
      theme_bw() +
      geom_point(aes(x = x, y = y), size = 0.4, col=col.vect) +
      theme(axis.title=element_text(size=9),
            axis.text = element_text(size=9),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean group body size (log10)", y="Surf. Moran's I square weights")
    # geom_smooth(aes(x = x, y = y), method='lm')
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,2] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,2])] = "red"
    plot.DCM.Moran.square.I_vs_log_size = ggplot(data=data.frame(y=if (weighted_mean) I_square.expected_w.mean[selected_groups,2] else I_square_mean[selected_groups,2],
                                                                      x=log10(size_absoluteAbund)[selected_groups])) +
      theme_bw() +
      geom_point(aes(x = x, y = y), size = 0.4, col=col.vect) +
      theme(axis.title=element_text(size=9),
            axis.text = element_text(size=9),
            plot.title=element_text(hjust=0, size=12),
            plot.margin=unit(c(1,1,1,0.5),"mm")) +
      labs(x="Mean group body size (log10)", y="DCM Moran's I square weights")
    # geom_smooth(aes(x = x, y = y), method='lm')
    
    plot.list = list(list(plot.mean.Moran.square.I_vs_log_size),list(plot.SUR.Moran.square.I_vs_log_size),list(plot.DCM.Moran.square.I_vs_log_size))
    ppl = lapply(plot.list, function(g) marrangeGrob(grobs = g, nrow = 1, ncol = 1))
    # spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
    pdf(file = paste0(figure_folder,"/MoranI_square",weight_insert,"_Gibbs100r_optimalK_prevalence.min.crossValid_vs_size_selected100+1.pdf"),height = 1.5*10/4, width = 1.5*10/4)
    print(ppl)
    dev.off()
    
    ############
    # Stability plots:
    ############
    # mean_sim = readRDS(paste0(results_folder,"/mean_sim_Gibbs_optimalK_min.crossValid10sampleFolds_2plusOTUs_noLagoon.rds"))
    mean_sim = readRDS(paste0(results_folder,"/mean_sim_optimalK_Gibbs.prevalence.min.crossValid10sampleFolds_2plusOTUs_noLagoon.rds"))
    
    plot.Moran.I_mean.sim = ggplot(data=data.frame(y=I_square.observed_w.mean[selected_groups,1],
                                                   x=mean_sim[selected_groups])) +
      geom_point(aes(x,y)) +
      geom_smooth(aes(x,y), method = "lm", col = "black") +
      theme_bw() +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,17,1,0.5),"mm")) +
      labs(x="Mean spatial similarity across\n 100 MCMC chains w. random initial conditions", y="Surface spatial autocorrelation")
    ggsave(filename = paste0(figure_folder,"/MoranI.square_vs_stability_Gibbs.prevalence.min.crossValid_selected100+1.pdf"), do.call("arrangeGrob", c(list(plot.Moran.I_mean.sim), nrow=1)),
           height = 7, width = 7, units = "in")
    
    ##########
    # SUR-DCM JSD plots:
    ##########
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,3] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,3])] = "red"
    plot.mean.Moran.square.I_vs_VI.over.K = ggplot(data=data.frame(y=if (weighted_mean) I_square.observed_w.mean[selected_groups,3] else I_square_mean[selected_groups,3],
                                                                       x=VI_over_K[selected_groups])) +
      theme_bw() +
      geom_smooth(aes(x,y), method = "lm", col = "black") +
      geom_point(aes(x = x, y = y), col=col.vect) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,10,1,0.5),"mm")) +
      # labs(x="Diversity (log10)", y="Mean Moran's I square weights")
      labs(x="Dissimilarity between surface and DCM", y="Mean surface-DCM spatial autocorrelation")
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,1] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,1])] = "red"
    plot.SUR.Moran.square.I_vs_VI.over.K = ggplot(data=data.frame(y=if (weighted_mean) I_square.observed_w.mean[selected_groups,1] else I_square_mean[selected_groups,1],
                                                                      x=VI_over_K[selected_groups])) +
      theme_bw() +
      geom_smooth(aes(x,y), method = "lm", col = "black") +
      geom_point(aes(x = x, y = y), col=col.vect) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,10,1,0.5),"mm")) +
      # labs(x="Diversity (log10)", y="Surf. Moran's I square weights")
      labs(x="Dissimilarity between surface and DCM", y="Surface spatial autocorrelation")
    # geom_smooth(aes(x = x, y = y), method='lm')
    col.vect = rep("black",length(which(selected_groups)))
    col.vect[I_square.p.value_w.mean[selected_groups,2] > 0.05 | is.na(I_square.p.value_w.mean[selected_groups,2])] = "red"
    plot.DCM.Moran.square.I_vs_VI.over.K = ggplot(data=data.frame(y=if (weighted_mean) I_square.observed_w.mean[selected_groups,2] else I_square_mean[selected_groups,2],
                                                                      x=VI_over_K[selected_groups])) +
      theme_bw() +
      geom_smooth(aes(x,y), method = "lm", col = "black") +
      geom_point(aes(x = x, y = y), col=col.vect) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,10,1,0.5),"mm")) +
      # labs(x="Diversity (log10)", y="DCM Moran's I square weights")
      labs(x="Dissimilarity between surface and DCM", y="DCM spatial autocorrelation")
    # geom_smooth(aes(x = x, y = y), method='lm')
    
    # spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
    pdf(file = paste0(figure_folder,"/MoranI.square",weight_insert,"_vs_VI.over.K_Gibbs.prevalence.min.crossValid_selected100+1.pdf"))
    print(plot.mean.Moran.square.I_vs_VI.over.K)
    print(plot.SUR.Moran.square.I_vs_VI.over.K)
    print(plot.DCM.Moran.square.I_vs_VI.over.K)
    dev.off()
    
    #########
    # Surf.-DCM comparison:
    ##########
    # mean_sim = readRDS(paste0(results_folder,"/mean_sim_Gibbs_optimalK_min.crossValid10sampleFolds_2plusOTUs_noLagoon.rds"))
    
    div_threshold = 1000
    
    plot.Moran.I_SUR.DCM = ggplot(data=data.frame(y=I_square.observed_w.mean[selected_groups & diversity>div_threshold,1],
                                                  x=I_square.observed_w.mean[selected_groups & diversity>div_threshold,2])) +
      theme_bw() +
      geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
      # geom_smooth(aes(x,y), method = "lm", col = "black") +
      geom_point(aes(x = x, y = y)) +
      theme(axis.text = element_text(size=16),
            axis.title=element_text(size=24),
            plot.title=element_blank(),
            plot.margin=unit(c(1,10,1,0.5),"mm")) +
      labs(x="DCM spatial autocorrelation", y="Surface spatial autocorrelation")
    ggsave(filename = paste0(figure_folder,"/MoranI.square_SUR_vs_DCM_Gibbs.prevalence.min.crossValid_selected",
                             if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"), 
           do.call("arrangeGrob", c(list(plot.Moran.I_SUR.DCM), nrow=1)), height = 7, width = 7, units = "in")
    
    ###########
    # Functional boxplots
    ############
    div_threshold = 100
    
    dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
    dominant_function0 = dominant_function[selected_groups & diversity>div_threshold]
    # dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
    # dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
    dominant_function0[dominant_function0 == "unknown"] = NA
    dominant_function0[dominant_function0 == "photohost"] = "Collodaria"
    dominant_function0[dominant_function0 == "pteropoda"] = "Pteropoda"
    dominant_function0[dominant_function0 == "copepoda"] = "Copepoda"
    dominant_function0[dominant_function0 == "gelatineous_carnivores_filterers"] = "Gel. carn. filterers"
    dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Dinophyceae"] = "Dinophyceae"
    dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Bacillariophyta"] = "Bacillariophyta"
    dominant_function0[dominant_function0 == "phototroph"] = "Other phototrophs"
    dominant_function0[dominant_function0 == "phagotroph"] = "Phagotrophs"
    dominant_function0[dominant_function0 == "other metazoa"] = "Other metazoa"
    dominant_function0[dominant_function0 == "parasite"] = "Parasites"
    # alpha = rep(1,length(taxo_groups[selected_groups]))
    # alpha[dominant_function0 %in% c("copepoda","pteropoda")] = 0 
    # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them by deceasing number of groups:
    # dominant_function0 = factor(dominant_function0,names(sort(table(as.factor(dominant_function0)),decreasing = T)))
    # Changes how the factors are stored (order of levels()) so that geom_boxplot plots them in the specified order:
    if (div_threshold == 100)
    {
      dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Pteropoda","Copepoda","Other metazoa","Parasites"))
      point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta","Pteropoda")
    } else if (div_threshold == 1000)
    {
      dominant_function0 = factor(dominant_function0,c("Bacillariophyta","Other phototrophs","Collodaria","Phagotrophs","Dinophyceae","Gel. carn. filterers","Copepoda","Parasites"))
      point_groups = c("Dinophyceae","Copepoda","Collodaria","Bacillariophyta")
    } 
    
    boxplot.Moran.I = list()
    for (i_case in 1:2)
    {
      boxplot.Moran.I[[i_case]] = ggplot(data = data.frame(x = dominant_function0[!is.na(dominant_function0) & !dominant_function0 %in% point_groups],
                                                                y = I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case][!is.na(dominant_function0) & !dominant_function0 %in% point_groups])) +
        scale_x_discrete(limits=levels(dominant_function0)) +
        geom_boxplot(aes(x,y)) +
        geom_point(data = data.frame(x = factor(point_groups),
                                     y = I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case][dominant_function0 %in% point_groups]),
                   aes(x,y)) +
        theme_bw() +
        theme(axis.title=element_text(size=24),
              axis.text=element_text(size=22),
              axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
              plot.margin=unit(c(2,1,1,6),"mm")) +
        labs(x="", y=paste(if (i_case == 1) "Surface" else "DCM","spatial autocorrelation"))
    }
    pdf(paste0(figure_folder,"/MoranI.square_boxplot_allFunctionalGroups_selected",
               if (div_threshold == 100) "100+1" else if (div_threshold == 1000) "1000",".pdf"))
    print(boxplot.Moran.I[[1]])
    print(boxplot.Moran.I[[2]])
    dev.off()
    #################
  }
}

if (correlation_tables)
{
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  load(paste0(results_folder,"/group_sizes_byStationByDepth_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100 
  
  Gibbs_VEM_insert = "_Gibbs.prevalence.min.crossValid10sampleFolds"
  optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
  optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
  optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]]   
    
  mean_sim = readRDS(paste0(results_folder,"/mean_sim_optimalK_Gibbs.prevalence.min.crossValid10sampleFolds_2plusOTUs_noLagoon.rds"))
  # SUR.DCM_VI_over_K = readRDS(paste0(results_folder,"/VI.over.K_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  SUR.DCM_Normalized.VI = readRDS(paste0(results_folder,"/Normalized.VI_SUR.DCM_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  Moran.I = readRDS(paste0(results_folder,"/Moran.I_inverse.squares_weighted.mean.over.topics_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  I_square.observed_w.mean_allTaxa = Moran.I[[1]]
  I_square.observed_w.mean = Moran.I[[2]]
  I_square.p.value_w.mean_allTaxa = Moran.I[[3]]
  I_square.p.value_w.mean = Moran.I[[4]]
  autocorr.scale = readRDS(paste0(results_folder,"/MoranI_charach.autocorr.scale_20increment_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  charac_scale = autocorr.scale[[1]]
  charac_scale.allTaxa = autocorr.scale[[2]]  
  lat_I.result = readRDS(paste0(results_folder,"/Lat_I_sigma2.25",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  lat_I = lat_I.result[[1]]
  basin_I.result = readRDS(paste0(results_folder,"/Basin_I",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  basin_I = basin_I.result[[1]]
  
  abiotic_pca_insert = "_abioticPCA"
  biotic_pca_insert = "_bioticPCA"
  stdzation_insert = ""
  dis_MEM_insert = "_dist-based.MEM"
  div_threshold = 100
  
  # varpart.indSelec = readRDS(paste0(results_folder,"/varpart_lda_environment-currents_bothDirectionsIndependentSelection_PCA0",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  varpart.indSelec = readRDS(paste0(results_folder,"/varpart_lda",Gibbs_VEM_insert,
                                    "_separate.SUR.DCM_both.directions.independent.selection_PCA0",
                                    abiotic_pca_insert,biotic_pca_insert,dis_MEM_insert,stdzation_insert,noArcticNoBiomark_insert,"_eigenvalueThres0.8",noLagoon_insert,".rds"))
  varpart.env.spatial = varpart.indSelec[[1]]
  varpart.env.spatial[[1]][varpart.env.spatial[[1]]<0] = 0
  varpart.env.spatial[[2]][varpart.env.spatial[[2]]<0] = 0
  varpart.env.spatial.pval = varpart.indSelec[[2]]
  
  sub.varpart.biotic.abiotic = varpart.indSelec[[3]]
  sub.varpart.biotic.abiotic[[1]][sub.varpart.biotic.abiotic[[1]]<0] = 0
  sub.varpart.biotic.abiotic[[2]][sub.varpart.biotic.abiotic[[2]]<0] = 0
  sub.varpart.biotic.abiotic.pval = varpart.indSelec[[4]]
  
  # sub.varpart.SUR.DCM = varpart.indSelec[[5]]
  # sub.varpart.SUR.DCM[sub.varpart.SUR.DCM<0] = 0
  # sub.varpart.SUR.DCM.pval = varpart.indSelec[[6]]
  
  varpart.biotic.abiotic = varpart.indSelec[[5]]
  varpart.biotic.abiotic[[1]][varpart.biotic.abiotic[[1]]<0] = 0
  varpart.biotic.abiotic[[2]][varpart.biotic.abiotic[[2]]<0] = 0
  varpart.biotic.abiotic.pval = varpart.indSelec[[6]]
  
  VI_over_K = readRDS(paste0(results_folder,"/VI.over.K_group.comparison_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  Normalized_VI = readRDS(paste0(results_folder,"/Normalized.VI_group.comparison_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  VI = readRDS(paste0(results_folder,"/VI_group.comparison_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  
  # Using PCoA:
  #############
  library(ape)
  NormalizedVI_pcoa = vector(length = 3, mode = "list")
  names(NormalizedVI_pcoa) = c("SUR","DCM","All")
  VIoverK_pcoa = vector(length = 3, mode = "list")
  names(VIoverK_pcoa) = c("SUR","DCM","All")
  VIoverlogK_pcoa = vector(length = 3, mode = "list")
  names(VIoverlogK_pcoa) = c("SUR","DCM","All")
  VI_pcoa = vector(length = 3, mode = "list")
  names(VI_pcoa) = c("SUR","DCM","All")
  for (i_case in 1:3)
  {
    # VI_pcoa = pcoa(as.dist(Normalized_VI[selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    VI.pcoa = pcoa(as.dist(VI_over_K[[i_case]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    VIoverK_pcoa[[i_case]] = matrix(nrow=length(taxo_groups),ncol=4,data=NA,dimnames=list(taxo_groups,1:4))
    VIoverK_pcoa[[i_case]][selected_groups & diversity>div_threshold,][-69,] = VI.pcoa$vectors[-69,1:4]
    
    VI.pcoa = pcoa(as.dist(Normalized_VI[[i_case]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    # VI_pcoa = pcoa(as.dist(VI_over_K[selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    # NormalizedVI_pcoa[[i_case]] = matrix(nrow=length(taxo_groups),ncol=4,data=NA,dimnames=list(taxo_groups,1:4))
    # NormalizedVI_pcoa[[i_case]][selected_groups & diversity>div_threshold,][-69,] = VI.pcoa$vectors[-69,1:4]
    NormalizedVI_pcoa[[i_case]] = matrix(nrow=length(taxo_groups),ncol=ncol(VI.pcoa$vectors),data=NA,dimnames=list(taxo_groups,1:ncol(VI.pcoa$vectors)))
    NormalizedVI_pcoa[[i_case]][selected_groups & diversity>div_threshold,][-69,] = VI.pcoa$vectors[-69,]
    
    VI.pcoa = pcoa(as.dist(VI[[i_case]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    VI_pcoa[[i_case]] = matrix(nrow=length(taxo_groups),ncol=4,data=NA,dimnames=list(taxo_groups,1:4))
    VI_pcoa[[i_case]][selected_groups & diversity>div_threshold,][-69,] = VI.pcoa$vectors[-69,1:4]
    
    # VI.pcoa = pcoa(as.dist(VI_over_logK[[i_case]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    # VIoverlogK_pcoa[[i_case]] = matrix(nrow=length(taxo_groups),ncol=4,data=NA,dimnames=list(taxo_groups,1:4))
    # VIoverlogK_pcoa[[i_case]][selected_groups & diversity>div_threshold,][-69,] = VI.pcoa$vectors[-69,1:4]
  }
  
  # Using NMDS:
  ############
  # NormalizedVI_NMDS = matrix(nrow=length(taxo_groups),ncol=5,data=NA,dimnames=list(taxo_groups,1:5))
  # NormalizedVI_NMDS[selected_groups & diversity>div_threshold,][-69,] = VI.NMDS$points[-69,1:5]
  
  descriptors3 = list()
  descriptors3.noVI = list()
  fractions = list()
  for (i_case in 1:2)
  {
    descriptors3.noVI[[i_case]] = cbind(`Spatial.autocorrelation` = I_square.observed_w.mean[,i_case],
                                   `Charac.spatial.scale` = charac_scale[,i_case],
                                   `Latitudinal.symmetry.I` = lat_I[,i_case]/I_square.observed_w.mean[,i_case],
                                   `Basin.scale.similarity.I` = basin_I[,i_case]/I_square.observed_w.mean[,i_case],
                                   # `Weighted.mean.MEM.charac.scale` = weighted_mean_MEM_dist_scale,
                                   # `Spatial heterogeneity` = mean_JSD_stations[,i_case],
                                   `OTU.richness.log10` = log10(as.vector(diversity)),
                                   # `SUR.DCM.similarity` = 1 - SUR.DCM_Normalized.VI,
                                   `Body.size.log10` = log10(size_relativeAbund))
                                   # `Stability.of.the.decomposition` = mean_sim,
                                   # `Prevalence-corr. nb of assemblages` = prevalence.corrected_K[,i_case],
                                   # `Total.nb.of.assemblages` = optimalK_prevalence.min.crossValid)
    descriptors3[[i_case]] = cbind(descriptors3.noVI[[i_case]],
                                   # `VI over K - PCoA axis 1` = VIoverK_pcoa[[i_case]][,1],
                                   # `VI over K - PCoA axis 2` = VIoverK_pcoa[[i_case]][,2],
                                   # `VI over K - PCoA axis 3` = VIoverK_pcoa[[i_case]][,3],
                                   # `VI over K - PCoA axis 4` = VIoverK_pcoa[[i_case]][,4])
                                   # `VI over logK - PCoA axis 1` = VIoverlogK_pcoa[[i_case]][,1],
                                   # `VI over logK - PCoA axis 2` = VIoverlogK_pcoa[[i_case]][,2],
                                   # `VI over logK - PCoA axis 3` = VIoverlogK_pcoa[[i_case]][,3],
                                   # `VI over logK - PCoA axis 4` = VIoverlogK_pcoa[[i_case]][,4])
                                   # NormalizedVI_pcoa[[3]])
                                   `Normalized VI - PCoA axis 1` = NormalizedVI_pcoa[[3]][,1],
                                   `Normalized VI - PCoA axis 2` = NormalizedVI_pcoa[[3]][,2],
                                   `Normalized VI - PCoA axis 3` = NormalizedVI_pcoa[[3]][,3],
                                   `Normalized VI - PCoA axis 4` = NormalizedVI_pcoa[[3]][,4],
                                   `Normalized VI - PCoA axis 5` = NormalizedVI_pcoa[[3]][,5],
                                   `Normalized VI - PCoA axis 6` = NormalizedVI_pcoa[[3]][,6])
                                   # `Normalized VI - NMDS axis 1` = NormalizedVI_NMDS[,1],
                                   # `Normalized VI - NMDS axis 2` = NormalizedVI_NMDS[,2],
                                   # `Normalized VI - NMDS axis 3` = NormalizedVI_NMDS[,3],
                                   # `Normalized VI - NMDS axis 4` = NormalizedVI_NMDS[,4],
                                   # `Normalized VI - NMDS axis 5` = NormalizedVI_NMDS[,5])
                                   # `Normalized I - PCoA axis 1` = 1 - NormalizedVI_pcoa[[3]][,1],
                                   # `Normalized I - PCoA axis 2` = 1 - NormalizedVI_pcoa[[3]][,2],
                                   # `Normalized I - PCoA axis 3` = 1 - NormalizedVI_pcoa[[3]][,3],
                                   # `Normalized I - PCoA axis 4` = 1 - NormalizedVI_pcoa[[3]][,4])
                                   # `VI - PCoA axis 1` = VI_pcoa[[i_case]][,1],
                                   # `VI - PCoA axis 2` = VI_pcoa[[i_case]][,2],
                                   # `VI - PCoA axis 3` = VI_pcoa[[i_case]][,3],
                                   # `VI - PCoA axis 4` = VI_pcoa[[i_case]][,4])
                                   # `Latitudinal skewness` = lat.skewness[[i_case]],
                                   # `Abs. latitudinal skewness` = abs(lat.skewness[[i_case]]),
                                   # `Proportion of high-lat. assemblages` = latitudinal_topic_distribution[[i_case]][,1]/latitudinal_topic_distribution.expected[[i_case]][1])
    descriptors3.noVI[[i_case]] = descriptors3.noVI[[i_case]][,rev(1:ncol(descriptors3.noVI[[i_case]]))]
    descriptors3[[i_case]] = descriptors3[[i_case]][,rev(1:ncol(descriptors3[[i_case]]))]
    
    # if (i_case == 1)
    # {
    #   fractions[[1]] = cbind(`Environment only SUR` = varpart.env.spatial[[1]][1,]/colSums(varpart.env.spatial[[1]]),
    #                          `Currents and environment SUR` = varpart.env.spatial[[1]][2,]/colSums(varpart.env.spatial[[1]]),
    #                          `Currents only SUR` = varpart.env.spatial[[1]][3,]/colSums(varpart.env.spatial[[1]]),
    #                          `Tot. explained variance SUR` = colSums(varpart.env.spatial[[1]]),
    #                          `Biotic only SUR` = varpart.biotic.abiotic[[1]][3,]/colSums(varpart.biotic.abiotic[[1]]),
    #                          `Mixed biotic-abiotic SUR` = varpart.biotic.abiotic[[1]][2,]/colSums(varpart.biotic.abiotic[[1]]),
    #                          `Abiotic only SUR` = varpart.biotic.abiotic[[1]][1,]/colSums(varpart.biotic.abiotic[[1]]),
    #                          `Tot. env. explained variance SUR` = colSums(varpart.biotic.abiotic[[1]]))
    # } else if (i_case == 2)
    # {
    #   fractions[[2]]= cbind(`Environment only DCM` = varpart.env.spatial[[2]][1,]/colSums(varpart.env.spatial[[2]]),
    #                         `Currents and environment DCM` = varpart.env.spatial[[2]][2,]/colSums(varpart.env.spatial[[2]]),
    #                         `Currents only DCM` = varpart.env.spatial[[2]][3,]/colSums(varpart.env.spatial[[2]]),
    #                         `Tot. explained variance DCM` = colSums(varpart.env.spatial[[2]]),
    #                         `Biotic only DCM` = varpart.biotic.abiotic[[2]][3,]/colSums(varpart.biotic.abiotic[[2]]),
    #                         `Mixed biotic-abiotic DCM` = varpart.biotic.abiotic[[2]][2,]/colSums(varpart.biotic.abiotic[[2]]),
    #                         `Abiotic only DCM` = varpart.biotic.abiotic[[2]][1,]/colSums(varpart.biotic.abiotic[[2]]),
    #                         `Tot. env. explained variance DCM` = colSums(varpart.biotic.abiotic[[2]]))
    # }
    
    # if (i_case == 1)
    # {
    #   fractions[[1]] = cbind(`Environment only SUR` = varpart.env.spatial[[1]][1,],
    #                          `Currents and environment SUR` = varpart.env.spatial[[1]][2,],
    #                          `Currents only SUR` = varpart.env.spatial[[1]][3,],
    #                          `Tot. explained variance SUR` = colSums(varpart.env.spatial[[1]]),
    #                          `Biotic only SUR` = varpart.biotic.abiotic[[1]][3,],
    #                          `Mixed biotic-abiotic SUR` = varpart.biotic.abiotic[[1]][2,],
    #                          `Abiotic only SUR` = varpart.biotic.abiotic[[1]][1,],
    #                          `Tot. env. explained variance SUR` = colSums(varpart.biotic.abiotic[[1]]))
    # } else if (i_case == 2)
    # {
    #   fractions[[2]]= cbind(`Environment only DCM` = varpart.env.spatial[[2]][1,],
    #                         `Currents and environment DCM` = varpart.env.spatial[[2]][2,],
    #                         `Currents only DCM` = varpart.env.spatial[[2]][3,],
    #                         `Tot. explained variance DCM` = colSums(varpart.env.spatial[[2]]),
    #                         `Biotic only DCM` = varpart.biotic.abiotic[[2]][3,],
    #                         `Mixed biotic-abiotic DCM` = varpart.biotic.abiotic[[2]][2,],
    #                         `Abiotic only DCM` = varpart.biotic.abiotic[[2]][1,],
    #                         `Tot. env. explained variance DCM` = colSums(varpart.biotic.abiotic[[2]]))
    # }
    
    if (i_case == 1)
    {
      fractions[[1]] = cbind(`Currents.vs.environment.SUR` = varpart.env.spatial[[1]][3,]/varpart.env.spatial[[1]][1,],
                             `Tot.explained.variance.SUR` = colSums(varpart.env.spatial[[1]]),
                             `Biotic.vs.abiotic.SUR` = varpart.biotic.abiotic[[1]][3,]/varpart.biotic.abiotic[[1]][1,],
                             `Tot.env.explained.variance.SUR` = colSums(varpart.biotic.abiotic[[1]]),
                             `Sub.biotic.vs.abiotic.SUR` = sub.varpart.biotic.abiotic[[1]][3,]/sub.varpart.biotic.abiotic[[1]][1,])
    } else if (i_case == 2)
    {
      fractions[[2]]= cbind(`Currents.vs.environment.DCM` = varpart.env.spatial[[1]][3,]/varpart.env.spatial[[1]][1,],
                            `Tot.explained.variance.DCM` = colSums(varpart.env.spatial[[1]]),
                            `Biotic.vs.abiotic.DCM` = varpart.biotic.abiotic[[1]][3,]/varpart.biotic.abiotic[[1]][1,],
                            `Tot.env.explained.variance.DCM` = colSums(varpart.biotic.abiotic[[1]]),
                            `Sub.biotic.vs.abiotic.DCM` = sub.varpart.biotic.abiotic[[1]][3,]/sub.varpart.biotic.abiotic[[1]][1,])
    }
  }
  
  ################################################
  # Statistical comparison between PCoA axes and descriptors #
  ################################################
  library(vegan)
  pcoa_axes = scale(NormalizedVI_pcoa[[3]][selected_groups & diversity>div_threshold,][-69,],center=T,scale=F)
  
  # Comparing all PCoA axes to all descriptors (global test):
  global.pval = list()
  for (i_case in 1:2)
  {
    scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
    RDA = rda(pcoa_axes ~ scaled_descriptors, na.action = na.exclude)
    global.pval[[i_case]] = c(as.numeric(RsquareAdj(RDA)[2]),as.numeric(anova(RDA)$'Pr(>F)'[1]))
  }
  
  # PLS:
  # Used to compare the two sets of axes in a symmetric way, and in a fully multivariate way (no need to discard any PCoA axis)
  # library(pls)
  library(geomorph) # Dean Adam's package, gives surprinsinlgy high p-value
  library(Morpho) # Gives suprisingly high correlation coefficients for all PLS axes
  pls1 = list()
  pls2 = list()
  for (i_case in 1:2)
  {
    scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
    pls1[[i_case]] = two.b.pls(pcoa_axes,scaled_descriptors) 
    pls2[[i_case]] = pls2B(pcoa_axes,scaled_descriptors,rounds=1000) #rounds defines the number of permutations
  }
  # geomorph:
  # pls1[[1]]$left.pls.vectors
  # pls1[[1]]$right.pls.vectors
  # Morpho:
  # pls2[[1]]$svd$u  # Same as pls1[[1]]$left.pls.vectors
  # pls2[[1]]$svd$v  # Same as pls1[[1]]$right.pls.vectors
  # Significance:
  # pls2[[1]]$CoVar 
  # Plotting observations onto PLS axis 1 
  # (Could be used to ordinate clades with respect to explanatory variables - PCoA is then only used as an intermediate step):
  # plot(pls2[[1]]$Xscores[,1],pls2[[1]]$Yscores[,1])
  
  # Comparing each PCoA axis with its linear model using all descriptors:
  # (Not well justified)
  fitted.cor = list()
  for (i_case in 1:2)
  {
    scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
    LM = lm(pcoa_axes ~ scaled_descriptors, na.action = na.exclude)
    fitted.cor[[i_case]] = matrix(nrow = ncol(pcoa_axes), ncol = 2, data = 0, 
                                  dimnames = list(colnames(pcoa_axes),c("Corr.","p.val")))
    for (i in 1:ncol(pcoa_axes))
    {
      cor.test = cor.test(LM$fitted.values[,i],pcoa_axes[,i])
      fitted.cor[[i_case]][i,] = c(cor.test$estimate,cor.test$p.value)
    }
  }
  
  # Comparing each PCoA axis to all descriptors:
  PCoA.axis.pval = list()
  PCoA.axis.pval.fractions = list()
  for (i_case in 1:2)
  {
    scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
    pcoa_axes.fractions = scale(NormalizedVI_pcoa[[3]]
                                       [taxo_groups %in% rownames(pcoa_axes) & !apply(is.infinite(fractions[[i_case]]),1,any) & !apply(is.na(fractions[[i_case]]),1,any),],center=T,scale=F)
    scaled_descriptors.fractions = scale(cbind(descriptors3.noVI[[i_case]],fractions[[i_case]])
                                         [taxo_groups %in% rownames(scaled_descriptors) & !apply(is.infinite(fractions[[i_case]]),1,any) & !apply(is.na(fractions[[i_case]]),1,any),])
    PCoA.axis.pval[[i_case]] = matrix(nrow = ncol(pcoa_axes), ncol = 6, data = 0, 
                                      dimnames = list(colnames(pcoa_axes),c("No.fraction.R2","No.fraction.adj.R2","No.fraction.p.val","R2","Adj.R2","p.val")))
    for (i in 1:ncol(pcoa_axes))
    {
      LM = lm(as.vector(pcoa_axes[,i]) ~ scaled_descriptors, na.action = na.exclude)
      PCoA.axis.pval[[i_case]][i,1] = summary(LM)$r.squared
      PCoA.axis.pval[[i_case]][i,2] = summary(LM)$adj.r.squared #as.numeric(RsquareAdj(RDA)[2])
      PCoA.axis.pval[[i_case]][i,3] = as.numeric(anova(LM)$'Pr(>F)'[1]) #as.numeric(anova(RDA)$'Pr(>F)'[1])
      LM = lm(as.vector(pcoa_axes.fractions[,i]) ~ scaled_descriptors.fractions, na.action = na.exclude)
      PCoA.axis.pval[[i_case]][i,4] = summary(LM)$r.squared 
      PCoA.axis.pval[[i_case]][i,5] = summary(LM)$adj.r.squared #as.numeric(RsquareAdj(RDA)[2])
      PCoA.axis.pval[[i_case]][i,6] = as.numeric(anova(LM)$'Pr(>F)'[1]) #as.numeric(anova(RDA)$'Pr(>F)'[1])
    }
  }
  
  # Comparing all PCoA axes to each descriptor:
  pcoa_axes = scale(NormalizedVI_pcoa[[3]][selected_groups & diversity>div_threshold,][-69,],center=T,scale=F)
  descriptor.pval = list()
  for (i_case in 1:2)
  {
    scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
    descriptor.pval[[i_case]] = matrix(nrow = ncol(descriptors3.noVI[[i_case]]), ncol = 2, data = 0, 
                                       dimnames = list(colnames(descriptors3.noVI[[i_case]]),c("Adj.R2","p.val")))
    for (i in 1:ncol(descriptors3.noVI[[i_case]]))
    {
      RDA = rda(pcoa_axes ~ as.vector(scaled_descriptors[,i]), na.action = na.exclude)
      descriptor.pval[[i_case]][i,1] = as.numeric(RsquareAdj(RDA)[2])
      descriptor.pval[[i_case]][i,2] = as.numeric(anova(RDA)$'Pr(>F)'[1])
    }
  }
  
  # Comparing a progressively larger number of PCoA axes (ordered by eigenvalue) to all descriptors:
  descriptor.cumulative.pval = list()
  for (i_case in 1:2)
  {
    scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
    descriptor.cumulative.pval[[i_case]] = matrix(nrow = ncol(pcoa_axes), ncol = 2, data = 0, 
                                                  dimnames = list(colnames(pcoa_axes),c("Adj.R2","p.val")))
    for (i in 1:ncol(pcoa_axes))
    {
      RDA = rda(pcoa_axes[,1:i] ~ scaled_descriptors, na.action = na.exclude)
      descriptor.cumulative.pval[[i_case]][i,1] = as.numeric(RsquareAdj(RDA)[2])
      descriptor.cumulative.pval[[i_case]][i,2] = as.numeric(anova(RDA)$'Pr(>F)'[1])
    }
  }
  plot(descriptor.cumulative.pval[[1]][,1],col=ifelse(descriptor.cumulative.pval[[1]][,2]<0.05,"black","red"))
  
  # Comparing a progressively larger number of PCoA axes (ordered by individual adj.R2) to all descriptors:
  descriptor.aR2ordered.cumulative.pval = list()
  for (i_case in 1:2)
  {
    scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
    descriptor.aR2ordered.cumulative.pval[[i_case]] = matrix(nrow = ncol(pcoa_axes), ncol = 2, data = 0, 
                                                  dimnames = list(colnames(pcoa_axes),c("Adj.R2","p.val")))
    axis.order = sort.int(PCoA.axis.pval[[i_case]][,1],index.return=T,decreasing=T)$ix
    for (i in 1:ncol(pcoa_axes))
    {
      RDA = rda(pcoa_axes[,axis.order[1:i]] ~ scaled_descriptors, na.action = na.exclude)
      descriptor.aR2ordered.cumulative.pval[[i_case]][i,1] = as.numeric(RsquareAdj(RDA)[2])
      descriptor.aR2ordered.cumulative.pval[[i_case]][i,2] = as.numeric(anova(RDA)$'Pr(>F)'[1])
    }
  }
  plot(descriptor.aR2ordered.cumulative.pval[[1]][,1],col=ifelse(descriptor.aR2ordered.cumulative.pval[[1]][,2]<0.05,"black","red"))
  
  # Stepwise variable selection for each PCoA axis
  # (Would be better to use AIC, for instance using function 'dredge')
  global_descriptor_selection = list()
  global_descriptor.fractions_selection = list()
  PerAxis_descriptor_selection = list()
  PerAxis_descriptor.fractions_selection = list()
  for (i_case in 1:2)
  {
    scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
    pcoa_axes.fractions = scale(NormalizedVI_pcoa[[3]]
                                       [taxo_groups %in% rownames(pcoa_axes) & !apply(is.infinite(fractions[[i_case]]),1,any) & !apply(is.na(fractions[[i_case]]),1,any),],center=T,scale=F)
    scaled_descriptors.fractions = scale(cbind(descriptors3.noVI[[i_case]],fractions[[i_case]])
                                         [taxo_groups %in% rownames(scaled_descriptors) & !apply(is.infinite(fractions[[i_case]]),1,any) & !apply(is.na(fractions[[i_case]]),1,any),])
    #
    RDA0 = rda(pcoa_axes ~ 1, data = as.data.frame(scaled_descriptors), na.action = na.exclude)
    RDA_selected = ordiR2step(RDA0, scope = as.formula(paste("pcoa_axes ~", paste(colnames(scaled_descriptors), collapse = " + "))), 
                              # direction = "forward", trace = F)
                              direction = "both", trace = F)
    global_descriptor_selection[[i_case]] = rownames(RDA_selected$CCA$biplot)
    #
    RDA0 = rda(pcoa_axes.fractions ~ 1, data = as.data.frame(scaled_descriptors.fractions), na.action = na.exclude)
    RDA_selected = ordiR2step(RDA0, scope = as.formula(paste("pcoa_axes.fractions ~", paste(colnames(scaled_descriptors.fractions), collapse = " + "))), 
                              # direction = "forward", trace = F)
                              direction = "both", trace = F)
    global_descriptor.fractions_selection[[i_case]] = rownames(RDA_selected$CCA$biplot)
    #
    PerAxis_descriptor_selection[[i_case]] = list()
    PerAxis_descriptor.fractions_selection[[i_case]] = list()
    for (i in 1:6)
    {
      RDA0 = rda(pcoa_axes[,i] ~ 1, data = as.data.frame(scaled_descriptors), na.action = na.exclude)
      RDA_selected = ordiR2step(RDA0, scope = as.formula(paste("pcoa_axes[,i] ~", paste(colnames(scaled_descriptors), collapse = " + "))), 
                                # direction = "forward", trace = F)
                                direction = "both", trace = F)
      PerAxis_descriptor_selection[[i_case]][[i]] = rownames(RDA_selected$CCA$biplot)
      #
      RDA0 = rda(pcoa_axes.fractions[,i] ~ 1, data = as.data.frame(scaled_descriptors.fractions), na.action = na.exclude)
      RDA_selected = ordiR2step(RDA0, scope = as.formula(paste("pcoa_axes.fractions[,i] ~", paste(colnames(scaled_descriptors.fractions), collapse = " + "))), 
                                # direction = "forward", trace = F)
                                direction = "both", trace = F)
      PerAxis_descriptor.fractions_selection[[i_case]][[i]] = rownames(RDA_selected$CCA$biplot)
    }
  }

  # library(MuMIn)
  # for (i_case in 1:2)
  # {
  #   for (i in 1:6)
  #   {
  #     scaled_descriptors = scale(descriptors3.noVI[[i_case]][selected_groups & diversity>div_threshold,][-69,])
  #     LM[[i_case]][[i]] = lm(as.vector(pcoa_axes[,i]) ~ scaled_descriptors, na.action = na.fail)
  #     dredge(LM[[i_case]][[i]]) 
  #   }
  # }
  # models = lapply(dredge(LM, evaluate = FALSE), eval)
  # model.avg(models)
    
  ############
  
  cor_fractions_descriptors = list()
  signed_adjR2_fractions_descriptors = list()
  for (i_case in 1:2)
  {
    descriptors.fractions = cbind(descriptors3[[i_case]],fractions[[i_case]])
    
    # cor_fractions_descriptors[[i_case]] = cor(fractions[[i_case]][selected_groups,],descriptors.fractions[selected_groups,])
    # Removing the 2 selected groups with NA values in varpart for DCM:
    cor_fractions_descriptors[[i_case]] = cor(descriptors.fractions[selected_groups & diversity>div_threshold & !is.na(fractions[[i_case]][,3]) & !is.na(descriptors3[[i_case]][,1]) & !is.infinite(fractions[[i_case]][,5]),],
                                              descriptors.fractions[selected_groups & diversity>div_threshold & !is.na(fractions[[i_case]][,3]) & !is.na(descriptors3[[i_case]][,1]) & !is.infinite(fractions[[i_case]][,5]),])
    # for (i in 1:ncol(fractions[[i_case]]))
    #   cor_fractions_descriptors[[i_case]][i,ncol(descriptors3[[i_case]])+i] = NA
    diag(cor_fractions_descriptors[[i_case]]) = NA
    signed_adjR2_fractions_descriptors[[i_case]] = cor_fractions_descriptors[[i_case]]
    # R2_fractions_descriptors = cor_fractions_descriptors[[i_case]]
    pval_fractions_descriptors = cor_fractions_descriptors[[i_case]]
    for (i in 1:nrow(signed_adjR2_fractions_descriptors[[i_case]]))
    {
      for (j in 1:ncol(signed_adjR2_fractions_descriptors[[i_case]]))
      {
        if (!is.na(signed_adjR2_fractions_descriptors[[i_case]][i,j]))
        {
          # result =lm(fractions[[i_case]][selected_groups,i] ~ descriptors.fractions[selected_groups,j])
          result =lm(descriptors.fractions[selected_groups & diversity>div_threshold & !is.na(fractions[[i_case]][,3]) & !is.infinite(fractions[[i_case]][,5]) & !is.na(descriptors3[[i_case]][,1]),i] 
                     ~ descriptors.fractions[selected_groups & diversity>div_threshold & !is.na(fractions[[i_case]][,3]) & !is.infinite(fractions[[i_case]][,5]) & !is.na(descriptors3[[i_case]][,1]),j])
          signed_adjR2_fractions_descriptors[[i_case]][i,j] =  summary(result)$adj.r.squared*sign(summary(result)$coefficients[2,1])
          # R2_fractions_descriptors[i,j] = result$r.squared
          pval_fractions_descriptors[i,j] = anova(result)$`Pr(>F)`[1]
        }
      }
    }
    signed_adjR2_fractions_descriptors[[i_case]][pval_fractions_descriptors > 0.05] = 0
    # plot(adjR2_fractions_descriptors,abs(cor_fractions_descriptors))
  }
  
  library(scales)
  library(ggplot2)
  
  # Plotting Adj. R2 between frations and descriptors, for Surf. and DCM:
  for (i_case in 1:2)
  {
    plot.adjR2.fractions.descriptors = ggplot(data = melt(signed_adjR2_fractions_descriptors[[i_case]]), aes(x = Var1, y = Var2, fill = value)) +
      geom_tile(color = "white") +
      # scale_fill_gradientn(colours = c("blue","grey90","red"), values = c(-1,0,1), name = "Correlation") +
      scale_fill_gradient2(low = "blue", mid = "grey90", high = "red", midpoint = 0, 
                           limits = c(-max(abs(signed_adjR2_fractions_descriptors[[i_case]])),max(abs(signed_adjR2_fractions_descriptors[[i_case]]))), 
                           na.value = "white" , name = "Adj.R^2*sign(cor)") +
      coord_equal() +
      theme_minimal() +
      theme(axis.title=element_blank(),
            axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size=10),
            axis.text.y = element_text(size = 10),
            legend.text=element_text(size=10),
            legend.title=element_text(size=10),
            plot.margin=unit(c(2,5,1,0.5),"mm"))
    # pdf("fractions_vs_descriptors2_signed.adjR2_doubleSelected.pdf")
    # pdf("fractions.env.pure.currents_vs_descriptors2_signed.adjR2_doubleSelected.pdf")
    # pdf("fractions.pure.env.currents_vs_descriptors2_signed.adjR2_doubleSelected.pdf")
    # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents",ifelse(ncol(fractions)==4,"_wTotVar",""),"_vs_descriptors3_signed.adjR2_selected",ifelse(div_threshold == 2,"",div_threshold),".pdf"))
    # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents",if (i_case==1) "_SUR" else "_DCM","_vs_descriptors3_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected100+1.pdf"))
    # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents",if (i_case==1) "_SUR" else "_DCM","_vs_descriptors3_signed.adjR2",
    pdf(paste0(figure_folder,"/fractions.abs.pure.env.currents",if (i_case==1) "_SUR" else "_DCM","_vs_descriptors3_signed.adjR2",
               Gibbs_VEM_insert,"_eigenvalueThres0.8_selected",if (div_threshold == 100) "100+1" else if (div_threshold) "1000",".pdf"))
    print(plot.adjR2.fractions.descriptors)
    dev.off()
  }
  
  # Plotting Adj. R2 between frations and descriptors, with color range restricted  to (-0.5,0.5), for Surf. and DCM:
  plot.adjR2.fractions.descriptors = list()
  for (i_case in 1:2)
  {
    plot.adjR2.fractions.descriptors[[i_case]] = ggplot(data = melt(signed_adjR2_fractions_descriptors[[i_case]]), aes(x = Var1, y = Var2, fill = value)) +
      geom_tile(color = "white") +
      # scale_fill_gradientn(colours = c("blue","grey90","red"), values = c(-1,0,1), name = "Correlation") +
      scale_fill_gradient2(low = "blue", mid = "grey90", high = "red", midpoint = 0, 
                           # limits = c(-max(abs(signed_adjR2_fractions_descriptors)),max(abs(signed_adjR2_fractions_descriptors))),
                           limits = (c(-0.5,0.5)),oob=squish,
                           na.value = "white" , name = "Adj.R^2*sign(cor)") +
      coord_equal() +
      theme_minimal() +
      theme(axis.title=element_blank(),
            axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, 
                                       size=10),
                                       # size=2),
            axis.text.y = element_text(size = 10),
            # axis.text.y = element_text(size = 2),
            legend.text=element_text(size=10),
            legend.title=element_text(size=10),
            plot.margin=unit(c(2,5,1,0.5),"mm"))
    # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents_wTotVar_wBioticAbiotic_vs_descriptors3_signed.adjR2_selected",ifelse(div_threshold == 2,"",div_threshold),".pdf"))
    # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents_wTotVar_wBioticAbiotic_vs_descriptors3OTUrichnessStability_signed.adjR2_selected",ifelse(div_threshold == 2,"",div_threshold),"_eigenvalueThres0.8.pdf"))
    # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents",if (i_case==1) "_SUR" else "_DCM","_wTotVar_wBioticAbiotic_vs_descriptors3OTUrichnessStability_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected100+1.pdf"))
    # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents",if (i_case==1) "_SUR" else "_DCM",
  }
  pdf(paste0(figure_folder,"/fractions.ratio.currents.env.biotic.abiotic",
             # "_vs_descriptors3.w.NormalizedVI.AllStations.NMDS.k=5.and.NormalizedI.SUR.DCM_range-0.5-0.5_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected",
             # "_vs_descriptors3.w.NormalizedVI.AllStations.PCoA.allAxes.and.NormalizedI.SUR.DCM_range-0.5-0.5_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected",
             "_vs_descriptors3.w.NormalizedVI.AllStations.PCoA.6axes_range-0.5-0.5_signed.adjR2",Gibbs_VEM_insert,dis_MEM_insert,"_eigenvalueThres0.8_selected",
             # "_vs_descriptors3.w.VIoverKPCoA_range-0.5-0.5_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected",
             # "_vs_descriptors3.w.Normalized2VI.PCoA_range-0.5-0.5_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected",
             # "_vs_descriptors3.w.VI.PCoA_range-0.5-0.5_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected",
             if (div_threshold == 100) "100+1" else if (div_threshold) "1000",".pdf"))
  print(plot.adjR2.fractions.descriptors[[1]])
  print(plot.adjR2.fractions.descriptors[[2]])
  dev.off()
  
  # Plotting correlations between frations and descriptors, for Surf. and DCM:
  # for (i_case in 1:2)
  # {
  #   plot.cor.fractions.descriptors = ggplot(data = melt(cor_fractions_descriptors[[i_case]]), aes(x = Var1, y = Var2, fill = value)) +
  #     geom_tile(color = "white") +
  #     # scale_fill_gradientn(colours = c("blue","grey90","red"), values = c(-1,0,1), name = "Correlation") +
  #     scale_fill_gradient2(low = "blue", mid = "grey90", high = "red", midpoint = 0, limits = c(-1,1), na.value = "white" , name = "Correlation") +
  #     theme_minimal() +
  #     theme(axis.title=element_blank(),
  #           axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size=10),
  #           axis.text.y = element_text(size = 10),
  #           legend.text=element_text(size=16),
  #           legend.title=element_text(size=16),
  #           plot.margin=unit(c(2,5,1,0.5),"mm"))
  #   # pdf("fractions_vs_descriptors2_correlations_doubleSelected.pdf")
  #   # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents",ifelse(ncol(fractions)==4,"_wTotVar",""),"_vs_descriptors3_correlations_selected",ifelse(div_threshold == 2,"",div_threshold),".pdf"))
  #   pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents",if (i_case==1) "_SUR" else "_DCM","_vs_descriptors3_correlations",
  #              Gibbs_VEM_insert,"_eigenvalueThres0.8_selected",if (div_threshold == 100) "100+1" else if (div_threshold) "1000",".pdf"))
  #   print(plot.cor.fractions.descriptors)
  #   dev.off()
  # }
  
  # Computing Adj. R2 between Surf. and DCM fractions:
  signed_adjR2_fractions_SUR.DCM =list()
  fractions_SUR.DCM = cbind(fractions[[1]],fractions[[2]])
  cor_fractions_SUR.DCM = cor(fractions_SUR.DCM[selected_groups & diversity>div_threshold & !is.na(fractions[[2]][,1]),],
                              fractions_SUR.DCM[selected_groups & diversity>div_threshold & !is.na(fractions[[2]][,1]),])
  diag(cor_fractions_SUR.DCM) = NA
  signed_adjR2_fractions_SUR.DCM = cor_fractions_SUR.DCM
  pval_fractions_SUR.DCM = cor_fractions_SUR.DCM
  for (i in 1:nrow(signed_adjR2_fractions_SUR.DCM))
  {
    for (j in 1:ncol(signed_adjR2_fractions_SUR.DCM))
    {
      if (!is.na(signed_adjR2_fractions_SUR.DCM[i,j]))
      {
        result =lm(fractions_SUR.DCM[selected_groups & diversity>div_threshold & !is.na(fractions[[2]][,1]),i] ~ 
                     fractions_SUR.DCM[selected_groups & diversity>div_threshold & !is.na(fractions[[2]][,1]),j])
        signed_adjR2_fractions_SUR.DCM[i,j] =  summary(result)$adj.r.squared*sign(summary(result)$coefficients[2,1])
        pval_fractions_SUR.DCM[i,j] = anova(result)$`Pr(>F)`[1]
      }
    }
  }
  signed_adjR2_fractions_SUR.DCM[pval_fractions_SUR.DCM > 0.05] = 0
  
  # Plotting Adj. R2 between Surf. and DCM fractions:
  plot.adjR2.fractions.SUR.DCM = ggplot(data = melt(signed_adjR2_fractions_SUR.DCM), aes(x = Var1, y = Var2, fill = value)) +
    geom_tile(color = "white") +
    # scale_fill_gradientn(colours = c("blue","grey90","red"), values = c(-1,0,1), name = "Correlation") +
    scale_fill_gradient2(low = "blue", mid = "grey90", high = "red", midpoint = 0, 
                         # limits = c(-max(abs(signed_adjR2_fractions_descriptors)),max(abs(signed_adjR2_fractions_descriptors))),
                         limits = (c(-0.5,0.5)),oob=squish,
                         na.value = "white" , name = "Adj.R^2*sign(cor)") +
    coord_equal() +
    theme_minimal() +
    theme(axis.title=element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size=10),
          axis.text.y = element_text(size = 10),
          legend.text=element_text(size=12),
          legend.title=element_text(size=12),
          plot.margin=unit(c(2,5,1,0.5),"mm"))
  # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents_wTotVar_wBioticAbiotic_vs_descriptors3_signed.adjR2_selected",ifelse(div_threshold == 2,"",div_threshold),".pdf"))
  # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents_wTotVar_wBioticAbiotic_vs_descriptors3OTUrichnessStability_signed.adjR2_selected",ifelse(div_threshold == 2,"",div_threshold),"_eigenvalueThres0.8.pdf"))
  # pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents",if (i_case==1) "_SUR" else "_DCM","_wTotVar_wBioticAbiotic_vs_descriptors3OTUrichnessStability_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected100+1.pdf"))
  pdf(paste0(figure_folder,"/fractions.rel.pure.env.currents_SUR_vs_DCM_range-0.5-0.5_signed.adjR2",Gibbs_VEM_insert,"_eigenvalueThres0.8_selected100+1.pdf"))
  print(plot.adjR2.fractions.SUR.DCM)
  dev.off()
  
  ######################
  prop_within_OTU_vect0 = readRDS(paste0(results_folder,"/Connectivity_1.5yearTminThres_10particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))[[1]]
  prop_within_OTU_list = readRDS(paste0(results_folder,"/Connectivity_expTmin_1.5yearTminThres_10particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  prop_within_OTU_vect = prop_within_OTU_list[[1]]
  prop_within_OTU_null = prop_within_OTU_list[[2]]
  prop_within_OTU_allOTUs = prop_within_OTU_list[[3]]
  
  hist.connectivity = ggplot(data = data.frame(x = prop_within_OTU_vect[selected_groups])) + 
    geom_histogram(aes(x, fill = I("white"), col = I("black")), binwidth = 0.025, na.rm = T) +
    theme_classic() +
    xlim(c(0,1)) +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Mean within-group OTU connectivity", y="Number of groups")
  pdf("ExpTmin_group_connectivity_hist_selected.pdf")
  print(hist.connectivity)
  dev.off()
  
  hist.connectivity.functions = ggplot(data = data.frame(x = prop_within_OTU_vect[selected_groups], y = dominant_function[selected_groups])) + 
    geom_histogram(aes(x, fill = y, col = I("black")), binwidth = 0.025, na.rm = T) +
    theme_classic() +
    xlim(c(0,1)) +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Mean within-group OTU connectivity", y="Number of groups")
  pdf("ExpTmin_group_connectivity_hist_selected_functions.pdf")
  print(hist.connectivity.functions)
  dev.off()
  
  hist.OTU.connectivity = ggplot(data = data.frame(x = unlist(prop_within_OTU_allOTUs[selected_groups]))) + 
    geom_histogram(aes(x, fill = I("white"), col = I("black")), bins = 20, na.rm = T) +
    theme_classic() +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="OTU connectivity through currents", y="Number of OTUs")
  pdf("ExpTmin_OTU_connectivity_hist_selected.pdf")
  print(hist.OTU.connectivity)
  dev.off()
  
  hist.size = ggplot(data = data.frame(x = size_relativeAbund[selected_groups],y = dominant_function0)) + 
    # geom_histogram(aes(x, fill = I("white"), col = I("black")), bins = 15, na.rm = T) +
    geom_histogram(aes(x, fill = dominant_function0, col = I("black")), bins = 15, na.rm = T) +
    scale_x_log10() +
    theme_classic() +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x=expression("Mean within-group body size ("*mu*"m)"), y="Number of groups")
  # pdf("size_hist_selected.pdf")
  pdf("size_hist_selected_functions.pdf")
  print(hist.size)
  dev.off()
  
  hist.abundance = ggplot(data = data.frame(x = colMeans(relativeAbund,na.rm = T)[selected_groups])) + 
    geom_histogram(aes(x, fill = I("white"), col = I("black")), bins = 20, na.rm = T) +
    scale_x_log10() +
    theme_classic() +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(2,5,1,0.5),"mm")) +
    labs(x="Mean group relative abundance", y="Number of groups")
  pdf("relativeAbund_hist_selected.pdf")
  print(hist.abundance)
  dev.off()
  
  hist.diversity = ggplot(data = data.frame(x = as.vector(diversity)[selected_groups])) + 
    geom_histogram(aes(x, fill = I("white"), col = I("black")), bins = 20, na.rm = T) +
    scale_x_log10() +
    theme_classic() +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(2,5,1,0.5),"mm")) +
    labs(x="OTU richness", y="Number of groups")
  pdf("diversity_hist_selected.pdf")
  print(hist.diversity)
  dev.off()
  
  hist.stability = ggplot(data = data.frame(x = mean_sim[selected_groups])) + 
    geom_histogram(aes(x, fill = I("white"), col = I("black")), bins = 20, na.rm = T) +
    theme_classic() +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(2,5,1,0.5),"mm")) +
    labs(x="Convergence", y="Number of groups")
  pdf("stability_hist_selected.pdf")
  print(hist.stability)
  dev.off()
  
  #############################
  plot.richness.vs.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=log10(as.vector(diversity))[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Mean group relative abundance (log10)", y="OTU richness (log10)") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("varpart.groups.expTmin_OTU.richness.log10_vs_abundance.log10_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.richness.vs.abundance)
  dev.off()
  
  plot.K.vs.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=optimalK[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Mean group relative abundance (log10)", y="Number of community types") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("varpart.groups.expTmin_optimalK_vs_abundance.log10_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.K.vs.abundance)
  dev.off()
  
  plot.K.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund)[selected_groups & significant_global_model_indSelec],y=optimalK[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x=expression("Mean within-group body size ("*mu*"m, log10)"), y="Number of community types") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("varpart.groups.expTmin_optimalK_vs_body.size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.K.vs.size)
  dev.off()
  
  plot.stability.vs.abundance = ggplot(data=data.frame(x=log10(colMeans(relativeAbund,na.rm = T))[selected_groups & significant_global_model_indSelec],y=mean_sim[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x="Mean group relative abundance (log10)", y="Convergence") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("varpart.groups.expTmin_stability_vs_abundance.log10_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.stability.vs.abundance)
  dev.off()
  
  plot.stability.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund)[selected_groups & significant_global_model_indSelec],y=mean_sim[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x=expression("Mean within-group body size ("*mu*"m, log10)"), y="Convergence") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("varpart.groups.expTmin_stability_vs_body.size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.stability.vs.size)
  dev.off()
  
  plot.connectivity.vs.size = ggplot(data=data.frame(x=log10(size_relativeAbund)[selected_groups & significant_global_model_indSelec],y=1-prop_within_OTU_vect[selected_groups & significant_global_model_indSelec])) +
    geom_point(aes(x,y)) +
    theme_bw() +
    # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
    # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
    theme(axis.text = element_text(size=16),
          axis.title=element_text(size=24),
          plot.title=element_text(hjust=0, size=24),
          plot.margin=unit(c(1,1,1,0.5),"mm")) +
    labs(x=expression("Mean within-group body size ("*mu*"m, log10)"), y="OTU connectivity through currents") +
    geom_smooth(aes(x,y),method='lm') 
  # pdf(paste0("RDA_adjR2_abiotic_3_vs_2_PCAaxes.pdf"))
  pdf(paste0("varpart.groups.expTmin_connectivity_vs_body.size_ggplot",abiotic_pca_insert,biotic_pca_insert,stdzation_insert,"_independentVariableSelection_doubleSelected_noNegativeAdjR2.pdf"))
  print(plot.connectivity.vs.size)
  dev.off()
  ######################
}

if (group_comparison)
{
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  load(paste0(results_folder,"/group_sizes_byStationByDepth_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100 
  
  optimalK = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  Gibbs_VEM_insert = "_Gibbs.prevalence.min.crossValid10sampleFolds"
  optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
  optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
  optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]]   
  
  nb_iter = 1000
  nb_real = 100
  thin = 25
  burnin = 2000
  
  documents_allgroups = list()
  # ii_taxon = 0
  for (taxon in taxo_groups)
  {
    i_taxon = which(taxon == taxo_groups)
    # taxon = "AllTaxa"
    
    # if (taxon %in% taxo_groups)
    if (!is.na(optimalK_prevalence.min.crossValid[i_taxon]))
    {
      # ii_taxon = ii_taxon+1
      
      data.folder_name = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      # nb_topics = optimalK[i_taxon]
      # nb_topics = optimalK_min.crossValid[i_taxon]
      nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
      spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds"))
      
      # selecting the z.pred columns in all topics:
      documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
      # setting one topic per column
      documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics)))
      documents_allgroups[[i_taxon]] = documents
      
      if (i_taxon == 1)
        load(paste0(data.folder_name,"/coord.Rdata"))
      
      # load(paste0(data.folder_name,"/data2m.Rdata"))
      # data2m[data2m>0] = 1
      # sum_data2m = sum(data2m)
      # 
      # # Setting the minimal proportion of a topic in a sample as 1/total#reads (respectively 1/total#occurrences) in documents:
      # documents[documents < 1/sum_data2m] = 1/sum_data2m
      # # KL_documents : proportion of each site/document in a topic (sums to 1 over sites/documents for each topic)
      # KL_documents = sweep(documents,MARGIN=2,colSums(documents),`/`)
      # 
      # KL_documents_allgroups[[ii_taxon]] = KL_documents
    } else
      documents_allgroups[[i_taxon]] = NA
  }
  
  VI = vector(length = 3, mode = "list")
  names(VI) = c("SUR","DCM","All")
  VI_over_K = vector(length = 3, mode = "list")
  names(VI_over_K) = c("SUR","DCM","All")
  VI_over_logK = vector(length = 3, mode = "list")
  names(VI_over_logK) = c("SUR","DCM","All")
  Normalized_VI = vector(length = 3, mode = "list")
  names(Normalized_VI) = c("SUR","DCM","All")
  for (case in c("SUR","DCM","All"))
  {
    i_case = which(c("SUR","DCM","All") == case)
    VI[[i_case]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data = NA)
    VI_over_K[[i_case]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data = NA)
    VI_over_logK[[i_case]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data = NA)
    Normalized_VI[[i_case]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data = NA)
    for (i in 2:length(taxo_groups))
    {
      for (j in 1:(i-1))
      {
        if (!is.na(optimalK_prevalence.min.crossValid[i]) && !is.na(optimalK_prevalence.min.crossValid[j]))
        {
          Pk_i = colMeans(documents_allgroups[[i]])
          Pk1_j = colMeans(documents_allgroups[[j]])
          if (i_case %in% c(1,2))
          {
            selected_stations_ij = rownames(coord)[rownames(coord) %in% rownames(documents_allgroups[[i]]) &
                                                     rownames(coord) %in% rownames(documents_allgroups[[j]]) &
                                                     stations_depths[,2] == case]
          } else
          {
            selected_stations_ij = rownames(coord)[rownames(coord) %in% rownames(documents_allgroups[[i]]) & 
                                                     rownames(coord) %in% rownames(documents_allgroups[[j]])]
          } 
          if (length(selected_stations_ij)>1)
          {
            # Pk_i = colMeans(documents_allgroups[[i]][selected_stations_ij,])
            # Pk1_j = colMeans(documents_allgroups[[j]][selected_stations_ij,])
            ###
            # Pkk1 = matrix(nrow = ncol(documents_allgroups[[i]]), ncol = ncol(documents_allgroups[[j]]), data = NA)
            # Pkk1_over_PkPk1 = matrix(nrow = ncol(documents_allgroups[[i]]), ncol = ncol(documents_allgroups[[j]]), data = NA)
            # for (k in 1:ncol(documents_allgroups[[i]]))
            # {
            #   for (k1 in 1:ncol(documents_allgroups[[j]]))
            #   {
            #     Pkk1[k,k1] = mean(documents_allgroups[[i]][selected_stations_ij,k]*documents_allgroups[[j]][selected_stations_ij,k1])
            #     Pkk1_over_PkPk1[k,k1] = Pkk1[k,k1]/(Pk_i[k]*Pk1_j[k1])
            #   }
            # }
            sum_Pkk1_times_log_Pkk1_over_PkPk1 = 0
            for (k in 1:ncol(documents_allgroups[[i]]))
            {
              for (k1 in 1:ncol(documents_allgroups[[j]]))
              {
                Pkk1 = mean(documents_allgroups[[i]][selected_stations_ij,k]*documents_allgroups[[j]][selected_stations_ij,k1])
                # Pkk1_over_PkPk1[k,k1] = Pkk1[k,k1]/(Pk_SUR[k]*Pk1_DCM[k1])
                if (Pkk1>0)
                  sum_Pkk1_times_log_Pkk1_over_PkPk1 = sum_Pkk1_times_log_Pkk1_over_PkPk1 + Pkk1*(log(Pkk1) - log(Pk_i[k]) - log(Pk1_j[k1]))
              }
            }
            # Computing the Variation of Information using probability values 
            H_i = -sum(Pk_i*log(Pk_i))
            H_j = -sum(Pk1_j*log(Pk1_j))
            # VI[i,j] = H_i + H_j - 2*sum(Pkk1*log(Pkk1_over_PkPk1))
            I = sum_Pkk1_times_log_Pkk1_over_PkPk1
            VI[[i_case]][i,j] = H_i + H_j - 2*I  
            # I[i,j] = sum(Pkk1*log(Pkk1_over_PkPk1))
            Normalized_VI[[i_case]][i,j] = VI[[i_case]][i,j]/(H_i + H_j - I)
            VI_over_K[[i_case]][i,j] = VI[[i_case]][i,j]/(ncol(documents_allgroups[[j]]) + ncol(documents_allgroups[[i]]))*2
            VI_over_logK[[i_case]][i,j] = VI[[i_case]][i,j]/log((ncol(documents_allgroups[[j]]) + ncol(documents_allgroups[[i]]))/2)
          } 
        }
      }
    }
  }
  
  saveRDS(VI,paste0(results_folder,"/VI_group.comparison_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  saveRDS(VI_over_K,paste0(results_folder,"/VI.over.K_group.comparison_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  saveRDS(VI_over_logK,paste0(results_folder,"/VI.over.K_group.comparison_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  # saveRDS(Normalized_VI,paste0(results_folder,"/Normalized.VI.consistent_group.comparison_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  saveRDS(Normalized_VI,paste0(results_folder,"/Normalized.VI_group.comparison_Gibbs.prevalence.min.crossValid10sampleFolds_new.rds"))
  
  #############################
  # VI matrix decomposition:  #
  ############################
  
  pdf(paste0("VI_selected_groups",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  rgb.palette = colorRampPalette(c("blue", "red"), space = "rgb")
  levelplot(VI, main="Variation of Information between group decompositions", xlab="", ylab="", col.regions=rgb.palette(120), cuts=100, 
            at=seq(min(VI,na.rm = T),max(VI,na.rm = T),(max(VI,na.rm = T)-min(VI,na.rm = T))/100))
  dev.off()
  
  pdf(paste0("Normalized_VI_selected_groups",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  rgb.palette = colorRampPalette(c("blue", "red"), space = "rgb")
  levelplot(Normalized_VI, main="Variation of Information between group decompositions", xlab="", ylab="", col.regions=rgb.palette(120), cuts=100, 
            at=seq(min(Normalized_VI,na.rm = T),max(Normalized_VI,na.rm = T),(max(Normalized_VI,na.rm = T)-min(Normalized_VI,na.rm = T))/100))
  dev.off()
  
  div_threshold = 100
  
  library(ape)
  NormalizedVI_pcoa = vector(length = 3, mode = "list")
  names(NormalizedVI_pcoa) = c("SUR","DCM","All")
  VIoverK_pcoa = vector(length = 3, mode = "list")
  names(VIoverK_pcoa) = c("SUR","DCM","All")
  VIoverlogK_pcoa = vector(length = 3, mode = "list")
  names(VIoverlogK_pcoa) = c("SUR","DCM","All")
  VI_pcoa = vector(length = 3, mode = "list")
  names(VI_pcoa) = c("SUR","DCM","All")
  for (i_case in 1:3)
  {
    # VI_pcoa = pcoa(as.dist(Normalized_VI[selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    VI.pcoa = pcoa(as.dist(VI_over_K[[i_case]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    VIoverK_pcoa[[i_case]] = matrix(nrow=length(taxo_groups),ncol=4,data=NA,dimnames=list(taxo_groups,1:4))
    VIoverK_pcoa[[i_case]][selected_groups & diversity>div_threshold,][-69,] = VI.pcoa$vectors[-69,1:4]
    
    VI.pcoa = pcoa(as.dist(Normalized_VI[[i_case]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    # VI_pcoa = pcoa(as.dist(VI_over_K[selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    NormalizedVI_pcoa[[i_case]] = VI.pcoa$vectors[-69,]
    
    VI.pcoa = pcoa(as.dist(VI[[i_case]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    VI_pcoa[[i_case]] = matrix(nrow=length(taxo_groups),ncol=4,data=NA,dimnames=list(taxo_groups,1:4))
    VI_pcoa[[i_case]][selected_groups & diversity>div_threshold,][-69,] = VI.pcoa$vectors[-69,1:4]
    
    VI.pcoa = pcoa(as.dist(VI_over_logK[[i_case]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    VIoverlogK_pcoa[[i_case]] = matrix(nrow=length(taxo_groups),ncol=4,data=NA,dimnames=list(taxo_groups,1:4))
    VIoverlogK_pcoa[[i_case]][selected_groups & diversity>div_threshold,][-69,] = VI.pcoa$vectors[-69,1:4]
  }
  
  # pdf(paste0(figure_folder,"/biplot_VI_selected_groups",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  # biplot(VI_pcoa)
  # dev.off()
  
  dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
  ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
  
  library(gridExtra)
  pdf(paste0(figure_folder,"/Normalized_PCoA.axes1.2.vs.struct.div.size.varpart_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected100+1.pdf"),
      width=7.5*2.2/1.2*3/2,height=12/3*4/1.2*3/2)
  for (i_case in 1:2)
  {
    plot.norm.VI.PCoA.axis1.2.vs.SUR.DCM.dissim = ggplot(data = data.frame(x = SUR.DCM_VI_over_K[selected_groups & diversity>div_threshold][-69],
                                                                           y1 = NormalizedVI_pcoa[[i_case]][,1],
                                                                           y2 = NormalizedVI_pcoa[[i_case]][,2])) +
      geom_point(aes(x,y1)) +
      geom_point(aes(x,y2), col = "red") +
      # scale_x_log10() +
      # scale_y_log10() +
      theme_bw() +
      ggtitle(LETTERS[1]) +
      # geom_hline(yintercept = 1, linetype="dashed") +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=22),
            axis.title=element_text(size=22),
            # axis.title.x=element_text(vjust = 45),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(0.5,0.5,0.5,0.5),"mm")) +
      #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
      labs(x="Dissimilarity between surface and DCM", y="PCoA axes 1 and 2") +
      geom_smooth(aes(x,y1),method='lm',col="black") +
      geom_smooth(aes(x,y2),method='lm',col="red")
    
    plot.norm.VI.PCoA.axis1.2.vs.spatial.autocorr = ggplot(data = data.frame(x = I_square.observed_w.mean[selected_groups & diversity>div_threshold,i_case][-69],
                                                                             y1 = NormalizedVI_pcoa[[i_case]][,1],
                                                                             y2 = NormalizedVI_pcoa[[i_case]][,2])) +
      geom_point(aes(x,y1)) +
      geom_point(aes(x,y2), col = "red") +
      # scale_x_log10() +
      # scale_y_log10() +
      theme_bw() +
      ggtitle(LETTERS[2]) +
      # geom_hline(yintercept = 1, linetype="dashed") +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=22),
            axis.title=element_text(size=22),
            # axis.title.x=element_text(vjust = 45),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(0.5,0.5,0.5,0.5),"mm")) +
      #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
      labs(x=paste("Short-distance spatial autocorr. -",c("Surf.","DCM")[i_case]), y="PCoA axes 1 and 2") +
      geom_smooth(aes(x,y1),method='lm',col="black") +
      geom_smooth(aes(x,y2),method='lm',col="red")
    
    plot.norm.VI.PCoA.axis1.2.vs.spatial.scale = ggplot(data = data.frame(x = charac_scale[selected_groups & diversity>div_threshold,i_case][-69],
                                                                             y1 = NormalizedVI_pcoa[[i_case]][,1],
                                                                             y2 = NormalizedVI_pcoa[[i_case]][,2])) +
      geom_point(aes(x,y1)) +
      geom_point(aes(x,y2), col = "red") +
      # scale_x_log10() +
      # scale_y_log10() +
      theme_bw() +
      ggtitle(LETTERS[3]) +
      # geom_hline(yintercept = 1, linetype="dashed") +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=22),
            axis.title=element_text(size=22),
            # axis.title.x=element_text(vjust = 45),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(0.5,0.5,0.5,0.5),"mm")) +
      #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
      labs(x=paste("Charac. scale of spatial autocorr. -",c("Surf.","DCM")[i_case]), y="PCoA axes 1 and 2") +
      geom_smooth(aes(x,y1),method='lm',col="black") +
      geom_smooth(aes(x,y2),method='lm',col="red")
    
    plot.norm.VI.PCoA.axis1.2.vs.diversity = ggplot(data = data.frame(x = as.vector(diversity)[selected_groups & diversity>div_threshold][-69],
                                                                          y1 = NormalizedVI_pcoa[[i_case]][,1],
                                                                          y2 = NormalizedVI_pcoa[[i_case]][,2])) +
      geom_point(aes(x,y1)) +
      # geom_point(aes(x,y2), col = "red") +
      scale_x_log10() +
      # scale_y_log10() +
      theme_bw() +
      ggtitle(LETTERS[4]) +
      # geom_hline(yintercept = 1, linetype="dashed") +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=22),
            axis.title=element_text(size=22),
            # axis.title.x=element_text(vjust = 45),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(0.5,0.5,0.5,0.5),"mm")) +
      #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
      labs(x="Clade diversity", y="PCoA axis 1") +
      geom_smooth(aes(x,y1),method='lm',col="black")
      # geom_smooth(aes(x,y2),method='lm',col="red")
    
    plot.norm.VI.PCoA.axis1.2.vs.tot.explained = ggplot(data = data.frame(x = colSums(varpart.env.spatial[[i_case]])[selected_groups & diversity>div_threshold][-69],
                                                                          y1 = NormalizedVI_pcoa[[i_case]][,1],
                                                                          y2 = NormalizedVI_pcoa[[i_case]][,2])) +
      geom_point(aes(x,y1)) +
      # geom_point(aes(x,y2), col = "red") +
      # scale_x_log10() +
      # scale_y_log10() +
      theme_bw() +
      ggtitle(LETTERS[5]) +
      # geom_hline(yintercept = 1, linetype="dashed") +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=22),
            axis.title=element_text(size=22),
            # axis.title.x=element_text(vjust = 45),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(0.5,0.5,0.5,0.5),"mm")) +
      #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
      labs(x=paste("Variance explained by connectivity and env. -",c("Surf.","DCM")[i_case]), y="") +
      geom_smooth(aes(x,y1),method='lm',col="black")
      # geom_smooth(aes(x,y2),method='lm',col="red")
    
    plot.norm.VI.PCoA.axis1.2.vs.body.size = ggplot(data = data.frame(x = size_relativeAbund[selected_groups & diversity>div_threshold][-69],
                                                                      y1 = NormalizedVI_pcoa[[i_case]][,1],
                                                                      y2 = NormalizedVI_pcoa[[i_case]][,2])) +
      # geom_point(aes(x,y1)) +
      geom_point(aes(x,y2), col = "red") +
      scale_x_log10() +
      # scale_y_log10() +
      theme_bw() +
      ggtitle(LETTERS[6]) +
      # geom_hline(yintercept = 1, linetype="dashed") +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=22),
            axis.title=element_text(size=22),
            # axis.title.x=element_text(vjust = 45),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(0.5,0.5,0.5,0.5),"mm")) +
      #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
      labs(x="Clade mean body size", y="PCoA axis 2") +
      # geom_smooth(aes(x,y1),method='lm',col="black") +
      geom_smooth(aes(x,y2),method='lm',col="red")
    
    plot.norm.VI.PCoA.axis1.2.vs.currents.over.env = ggplot(data = data.frame(x = (varpart.env.spatial[[i_case]][3,]/varpart.env.spatial[[i_case]][1,])[selected_groups & diversity>div_threshold][-69],
                                                                          y1 = NormalizedVI_pcoa[[i_case]][,1],
                                                                          y2 = NormalizedVI_pcoa[[i_case]][,2])) +
      # geom_point(aes(x,y1)) +
      geom_point(aes(x,y2), col = "red") +
      scale_x_log10() +
      # scale_y_log10() +
      theme_bw() +
      ggtitle(LETTERS[7]) +
      # geom_hline(yintercept = 1, linetype="dashed") +
      # ggtitle("RDA adjR2 3 vs 2 abiotic PCA axes with stdzation") +
      # ggtitle("Pure abiotic vs. total abiotic adjR2 3 axes") +
      theme(axis.text = element_text(size=22),
            axis.title=element_text(size=22),
            # axis.title.x=element_text(vjust = 45),
            plot.title=element_text(hjust=0, size=24),
            plot.margin=unit(c(0.5,0.5,0.5,0.5),"mm")) +
      #labs(x="Mean size (micron)", y=paste("Ratio of",c("surface","DCM")[i_case],"variance\n purely explained by currents vs. envir.")) +
      labs(x=paste("Relative variance explained\n purely by connectivity vs. env. -",c("Surf.","DCM")[i_case]), y="") +
      # geom_smooth(aes(x,y1),method='lm',col="black") +
      geom_smooth(aes(x,y2),method='lm',col="red")
    
    g1 = ggplotGrob(plot.norm.VI.PCoA.axis1.2.vs.SUR.DCM.dissim)
    g2 = ggplotGrob(plot.norm.VI.PCoA.axis1.2.vs.spatial.autocorr)
    g3 = ggplotGrob(plot.norm.VI.PCoA.axis1.2.vs.spatial.scale)
    g4 = ggplotGrob(plot.norm.VI.PCoA.axis1.2.vs.diversity)
    g5 = ggplotGrob(plot.norm.VI.PCoA.axis1.2.vs.tot.explained)
    g6 = ggplotGrob(plot.norm.VI.PCoA.axis1.2.vs.body.size)
    g7 = ggplotGrob(plot.norm.VI.PCoA.axis1.2.vs.currents.over.env)
    grid.arrange(grobs = list(g1,g2,g3,g4,g5,g6,g7),
                 # widths = rep(1,7),
                 layout_matrix = rbind(c(1, 2, 3),c(4, 5, NA),c(6, 7, NA)))
    # grid::grid.draw(gtable_rbind(gtable_cbind(g1, g2, g3), gtable_cbind(g4, g5), gtable_cbind(g6, g7)),recording=F)    
  }
  #grid::grid.newpage()
  dev.off()
  
  # ggsave(filename = paste0("VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"), 
  # ggsave(filename = paste0(figure_folder,"/Normalized_VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"), 
  # ggsave(filename = paste0(figure_folder,"/VI_over_K_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"),     
  #        do.call("arrangeGrob", c(list(plot.VI.PCoA.biplot), nrow=1)), height = 1.5*4, width = 1.5*4)
  # 
  # pdf(paste0(figure_folder,"/VI_over_K_PCoA_axes1.2_vs_body.size.pdf"))
  # plot(log10(size_relativeAbund)[selected_groups & diversity>div_threshold][-69],VI_pcoa$vectors[-69,1], ylab = "PCoA axis 1", xlab = "Mean size (micron, log10)")
  # plot(log10(size_relativeAbund)[selected_groups & diversity>div_threshold][-69],VI_pcoa$vectors[-69,2], ylab = "PCoA axis 2", xlab = "Mean size (micron, log10)")
  # dev.off()
  
  #pdf(paste0("biplot1_VI_selected_groups",noArcticNoBiomark_insert,noLagoon_insert,".pdf"))
  plot.VI.PCoA.biplot = ggplot(data = data.frame(x = NormalizedVI_pcoa[[i_case]][,1], y = NormalizedVI_pcoa[[i_case]][,2])) + 
    geom_point(aes(x,y, colour = dominant_function[selected_groups & diversity>div_threshold][-69])) +
    theme_bw() +
    ggtitle("Variation of Information between groups") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 10)) +
    labs(x="PCoA axis 1", y="PCoA axis 2") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    # geom_smooth(method='lm') +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = paste0("VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"), 
  ggsave(filename = paste0(figure_folder,"/Normalized.VI.SUR_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"),
  # ggsave(filename = paste0(figure_folder,"/VI_over_K_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"),     
         do.call("arrangeGrob", c(list(plot.VI.PCoA.biplot), nrow=1)), height = 1.5*4, width = 1.5*4)
  
  
  plot.VI.PCoA.biplot = ggplot(data = data.frame(x = NormalizedVI_pcoa[[i_case]][,1], y = NormalizedVI_pcoa[[i_case]][,2])) + 
    geom_point(aes(x,y, colour = log10(size_relativeAbund)[selected_groups & diversity>div_threshold][-69])) +
    theme_bw() +
    ggtitle("Variation of Information between groups") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 0)) +
    labs(x="PCoA axis 1", y="PCoA axis 2") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Mean size (micron, log10)") +
    # geom_smooth(method='lm') +
    guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
  
  # ggsave(filename = paste0("VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),
  ggsave(filename = paste0(figure_folder,"/Normalized.VI.SUR_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),
  # ggsave(filename = paste0(figure_folder,"/VI_over_K_PCoA_axis4_vs_axis1_no_Apuzozoans_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),  
         do.call("arrangeGrob", c(list(plot.VI.PCoA.biplot), nrow=1)), height = 1.5*4, width = 1.5*4)
  
  plot.VI.PCoA.biplot = ggplot(data = data.frame(x = NormalizedVI_pcoa[[i_case]][,1], y = NormalizedVI_pcoa[[i_case]][,2])) + 
    geom_point(aes(x,y, colour = charac_scale[selected_groups & diversity>div_threshold,i_case][-69])) +
    theme_bw() +
    ggtitle("Variation of Information between groups") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 0)) +
    labs(x="PCoA axis 1", y="PCoA axis 2") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Charac. autocorr. scale") +
    # geom_smooth(method='lm') +
    guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
  
  # ggsave(filename = paste0("VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),
  ggsave(filename = paste0(figure_folder,"/Normalized.VI.SUR_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_characScaleColors_selected.pdf"),
         # ggsave(filename = paste0(figure_folder,"/VI_over_K_PCoA_axis4_vs_axis1_no_Apuzozoans_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),  
         do.call("arrangeGrob", c(list(plot.VI.PCoA.biplot), nrow=1)), height = 1.5*4, width = 1.5*4)
  
  plot.VI.PCoA.biplot = ggplot(data = data.frame(x = NormalizedVI_pcoa[[i_case]][,1], y = NormalizedVI_pcoa[[i_case]][,2])) + 
    geom_point(aes(x,y, colour = SUR.DCM_VI_over_K[selected_groups & diversity>div_threshold][-69])) +
    theme_bw() +
    ggtitle("Variation of Information between groups") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 0)) +
    labs(x="PCoA axis 1", y="PCoA axis 2") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "SUR-DCM dissimilarity") +
    # geom_smooth(method='lm') +
    guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
  
  # ggsave(filename = paste0("VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),
  ggsave(filename = paste0(figure_folder,"/Normalized.VI.SUR_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_SUR.DCM.dissimColors_selected.pdf"),
         # ggsave(filename = paste0(figure_folder,"/VI_over_K_PCoA_axis4_vs_axis1_no_Apuzozoans_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),  
         do.call("arrangeGrob", c(list(plot.VI.PCoA.biplot), nrow=1)), height = 1.5*4, width = 1.5*4)
  
  plot.VI.PCoA.biplot = ggplot(data = data.frame(x = VI_pcoa$vectors[-69,1], y = VI_pcoa$vectors[-69,2])) + 
    geom_point(aes(x,y, colour = optimalK_prevalence.min.crossValid[selected_groups & diversity>div_threshold][-69])) +
    theme_bw() +
    ggtitle("Variation of Information between groups") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 0)) +
    labs(x="PCoA axis 1", y="PCoA axis 2") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Number of community types") +
    # geom_smooth(method='lm') +
    guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
  
  # ggsave(filename = paste0("VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),
  # ggsave(filename = paste0(figure_folder,"/Normalized_VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),
  ggsave(filename = paste0(figure_folder,"/VI_over_K_PCoA_axis2_vs_axis1_no_Apuzozoans_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_KColors_selected.pdf"),  
         do.call("arrangeGrob", c(list(plot.VI.PCoA.biplot), nrow=1)), height = 1.5*4, width = 1.5*4)
  
  
  plot.VI.PCoA.biplot = ggplot(data = data.frame(x = VI_pcoa$vectors[-69,1], y = VI_pcoa$vectors[-69,3])) + 
    geom_point(aes(x,y, colour = log10(as.vector(diversity))[selected_groups & diversity>div_threshold][-69])) +
    theme_bw() +
    ggtitle("Variation of Information between groups") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 0)) +
    labs(x="PCoA axis 1", y="PCoA axis 3") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_gradient(low = "blue", high ="red", na.value = "grey50", guide = "colourbar", name = "Number of OTUs (log10)") +
    # geom_smooth(method='lm') +
    guides(colour = guide_colorbar(barwidth = 14, barheight = 0.7, title.position="bottom"))
  
  # ggsave(filename = paste0("VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),
  # ggsave(filename = paste0(figure_folder,"/Normalized_VI_PCoA_axis2_vs_axis1_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_sizeColors_selected.pdf"),
  ggsave(filename = paste0(figure_folder,"/VI_over_K_PCoA_axis3_vs_axis1_no_Apuzozoans_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_diversityColors_selected.pdf"),  
         do.call("arrangeGrob", c(list(plot.VI.PCoA.biplot), nrow=1)), height = 1.5*4, width = 1.5*4)
  
  ####################
  # Clustering:      #
  ####################
  library(vegan)
  library(cluster)
  
  div_threshold = 100
  
  upgma_VI_over_K = agnes(as.dist(VI_over_K[selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]), diss =T, method = "average", keep.diss =F, keep.data =F)
  upgma_Normalized_VI = agnes(as.dist(Normalized_VI[[3]][selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold][-69,-69]), diss =T, method = "average", keep.diss =F, keep.data =F)
  
  pdf(paste0(figure_folder,"/UPGMA_VIoverK_groups_Gibbs100r_prevalence.min.crossValid.K_",div_threshold,"thres.pdf"))
  plot(upgma_VI_over_K, which.plots=2, ann=F, cex=0.5, cex.axis = 0.5, lwd=1.5)
  title("Average VI/K")
  dev.off()
  
  pdf(paste0(figure_folder,"/UPGMA_NormalizedVI_groups_Gibbs100r_prevalence.min.crossValid.K_",div_threshold,"thres.pdf"))
  plot(upgma_Normalized_VI, which.plots=2, ann=F, cex=0.6, cex.axis = 1.3, lwd=1.5)
  # title("Average normalized VI")
  dev.off()
  
  nb_clust_range = 2:10
  ii = 0
  mean_sd_sil_Normalized_VI = matrix(nrow = length(nb_clust_range), ncol = 2, data = 0, dimnames = list(nb_clust_range,c("Mean","sd")))
  for (nb_clust in nb_clust_range)
  {
    ii = ii+1
    grp_Normalized_VI = cutree(upgma_Normalized_VI, k = nb_clust)
    sil_Normalized_VI = silhouette(grp_Normalized_VI, as.dist(Normalized_VI[selected_groups & diversity>div_threshold,selected_groups & diversity>div_threshold]))
    mean_sd_sil_Normalized_VI[ii,] = c(mean(sil_Normalized_VI[,3]),sd(sil_Normalized_VI[,3]))
  }
  
  library(Hmisc)
  pdf(paste0(figure_folder,"/UPGMA_NormalizedVI_groups_Gibbs100r_prevalence.min.crossValid.K_",div_threshold,"thres_nbClustSilhouette.pdf"))
  errbar(nb_clust_range,mean_sd_sil_Normalized_VI[,1],
         yplus=mean_sd_sil_Normalized_VI[,1]+mean_sd_sil_Normalized_VI[,2],
         yminus=mean_sd_sil_Normalized_VI[,1]-mean_sd_sil_Normalized_VI[,2],ylab = "Mean silhouette", xlab = "Number of clusters")
  dev.off()
  
  dominant_function = readRDS(paste0(results_folder,"/dominant_function_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  dominant_function0 = dominant_function[selected_groups & diversity>div_threshold]
  # dominant_function0[dominant_function0 %in% c("other metazoa","gelatineous_carnivores_filterers","copepoda","pteropoda")] = "metazoa"
  # dominant_function0[dominant_function0 %in% c("unknown","photohost")] = NA
  # dominant_color0 = rep(NA,length(taxo_groups))
  dominant_function0[dominant_function0 == "unknown"] = NA
  dominant_function0[dominant_function0 == "photohost"] = "Collodaria"
  dominant_function0[dominant_function0 == "pteropoda"] = "Pteropoda"
  dominant_function0[dominant_function0 == "copepoda"] = "Copepoda"
  dominant_function0[dominant_function0 == "gelatineous_carnivores_filterers"] = "Gel. carn. filterers"
  dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Dinophyceae"] = "Dinophyceae"
  dominant_function0[taxo_groups[selected_groups & diversity>div_threshold] == "Bacillariophyta"] = "Bacillariophyta"
  dominant_function0[dominant_function0 == "phototroph"] = "Other phototrophs"
  dominant_function0[dominant_function0 == "phagotroph"] = "Phagotrophs"
  dominant_function0[dominant_function0 == "other metazoa"] = "Other metazoa"
  dominant_function0[dominant_function0 == "parasite"] = "Parasites"
  
  functions0 = c("Collodaria","Pteropoda","Copepoda","Gel. carn. filterers","Dinophyceae","Bacillariophyta","Other phototrophs","Phagotrophs","Other metazoa","Parasites")
  # "Bacillariophyta"   "Collodaria"   "Copepoda"   "Dinophyceae"   "Gel. carn. filterers" "Other phototrophs"    "Parasites"    "Phagotrophs" 
  ten_colors = c("darkorange","cadetblue","darkblue","darkturquoise","deeppink1","darkgreen","chartreuse2","firebrick2","dodgerblue1","darkgoldenrod1")
  dominant_color0 = rep(NA,length(dominant_function0))
  for (i in 1:length(functions0))
  {
    dominant_color0[dominant_function0 == functions0[i]] = ten_colors[i]
  }
  
  library(factoextra)
  pdf(paste0(figure_folder,"/UPGMA_Normalized_VI_coloredGroups_Gibbs100r_prevalence.min.crossValid.K_",div_threshold,"thres.pdf"))
  # plot(upgma_Normalized_VI, which.plots=2, ann=F, cex=0.5, cex.axis = 0.5, lwd=1.5)
  fviz_dend(upgma_Normalized_VI, ylab = "Average normalized VI", label_cols = dominant_color0[upgma_Normalized_VI$order], cex = 0.5)
  dev.off()
  
  pdf(paste0(figure_folder,"/UPGMA_VIoverK_coloredGroups_Gibbs100r_prevalence.min.crossValid.K_",div_threshold,"thres.pdf"))
  # plot(upgma_Normalized_VI, which.plots=2, ann=F, cex=0.5, cex.axis = 0.5, lwd=1.5)
  fviz_dend(upgma_VI_over_K, ylab = "Average VI/K", label_cols = dominant_color0[upgma_VI_over_K$order], cex = 0.5)
  dev.off()
  
  # Hierarchical clustering
  # pdf(paste0("VI_UPGMA_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"))
  # plot(hclust(as.dist(VI),method = "average"),ann=F)
  # title(ylab="Variation of Information between groups",cex.lab=1.5)
  # dev.off()
  # 
  # pdf(paste0("Normalized_VI_UPGMA_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"))
  # plot(hclust(as.dist(Normalized_VI),method = "average"),ann=F)
  # title(ylab="Normalized Variation of Information between groups",cex.lab=1.5)
  # dev.off()
  
  # Clustering using igraph
  library(igraph)
  #graph_edges = t(as.matrix(expand.grid(1:length(which(selected_groups)),1:length(which(selected_groups)))))
  group_VI_graph = graph_from_adjacency_matrix(Normalized_VI, mode = "undirected", weighted = T, diag = F)
  infomap_VI_graph_cluster = cluster_infomap(group_VI_graph, e.weights = NULL, v.weights = NULL, nb.trials = 10, modularity = TRUE)
  
  #######################
  # Pairwise analysis:  #
  #######################
  
  library(lattice)
  library(ggplot2)
  library(gridExtra)
  library(grid)
  
  write.table(VI, file = paste0("VI_selected_groups",noArcticNoBiomark_insert,noLagoon_insert,".csv"), quote = F, sep = ";", col.names = T, row.names = T)
  Normalized_VI1 = Normalized_VI
  Normalized_VI1[Normalized_VI1 > 0.5] = NA
  write.table(Normalized_VI1, file = paste0("Normalized_VI_lowerThan0.5_selected_groups",noArcticNoBiomark_insert,noLagoon_insert,".csv"), quote = F, sep = ";", col.names = T, row.names = T)
  
  dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # dominant_function_simplified  = dominant_function
  # dominant_function_simplified[dominant_function == "copepoda" & "other metazoa" & "pteropoda"] = "Metazoa"
  functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
  ten_colors = c("cadetblue",NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","dodgerblue1","deeppink1")
  edges_functions = c("parasitism","photosymbiosis","predation","herbivory","phagotrophy","unspecified")
  # five_colors = c("darkgoldenrod1","darkgreen","darkblue","chartreuse2","firebrick2","grey50")
  five_colors = c("darkgoldenrod1","darkgreen","darkblue","chartreuse2","firebrick2",NA)
  particle_thres = 1000
  prop_within_OTU_vect = readRDS(paste0(results_folder,"/Connectivity_",particle_thres,"particlesThres_meanPerOTU_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # prop_within_OTU_vect = prop_within_OTU_list[[1]]
  # prop_within_OTU_null = prop_within_OTU_list[[2]]
  
  VI0 = VI
  best_matching_groups_list = list()
  group_pair_functions_list = list()
  pair_connectivity_difference_list = list()
  mean_pair_connectivity_list = list()
  for (index in c(1,2))
  {
    if (index == 1)
      VI = VI0
    else if (index == 2)
      VI = Normalized_VI
    
    best_matching_groups = data.frame(VI = sort(VI), group1 = "NA", group1.diversity = NA, group1.K = NA, group1.function = "NA", group2 = "NA", group2.diversity = NA, group2.K = NA, group2.function = "NA", stringsAsFactors = F)
    group_pair_functions = vector(length = length(which(!is.na(VI))), mode = "character")
    pair_connectivity_difference = vector(length = length(which(!is.na(VI))), mode = "numeric")
    mean_pair_connectivity = vector(length = length(which(!is.na(VI))), mode = "numeric")
    # length(which(!is.na(VI))) = length(which(selected_groups))*(length(which(selected_groups)) - 1)/2
    for (i_edge in 1:length(which(!is.na(VI))))
    {
      i = which(VI == sort(VI)[i_edge]) %% ncol(VI)
      j = which(VI == sort(VI)[i_edge]) %/% ncol(VI) + 1
      if (i == 0)
      {
        i = nrow(VI)
        j = j-1
      }
      best_matching_groups$group1[i_edge] = rownames(VI)[i]
      best_matching_groups$group1.diversity[i_edge] = diversity[taxo_groups == rownames(VI)[i]]
      best_matching_groups$group1.K[i_edge] = optimalK[taxo_groups == rownames(VI)[i]]  
      best_matching_groups$group1.function[i_edge] = dominant_function[taxo_groups == rownames(VI)[i]]
      best_matching_groups$group2[i_edge] = colnames(VI)[j]
      best_matching_groups$group2.diversity[i_edge] = diversity[taxo_groups == colnames(VI)[j]]
      best_matching_groups$group2.K[i_edge] = optimalK[taxo_groups == colnames(VI)[j]]  
      best_matching_groups$group2.function[i_edge] = dominant_function[taxo_groups == colnames(VI)[j]]
      
      if (length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) == "parasite")) == 1)
        group_pair_functions[i_edge] = "parasitism"
      else if (length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) == "endophotosymbiont")) == 1
               && length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) == "photohost")) == 1)
        group_pair_functions[i_edge] = "photosymbiosis"
      else if (length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) == "gelatineous_carnivores_filterers")) == 1 
               && length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) == "phagotroph")) == 1)
        group_pair_functions[i_edge] = "predation"
      else if (length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) %in% c("copepoda","pteropoda","other metazoa"))) == 1 
               && length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) %in% c("phototroph","photohost")) == 1))
        group_pair_functions[i_edge] = "herbivory"
      else if (length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) == "phagotroph")) == 1 
               && length(which(c(best_matching_groups$group1.function[i_edge],best_matching_groups$group2.function[i_edge]) %in% c("phototroph","photohost"))) == 1)
        group_pair_functions[i_edge] = "phagotrophy"
      else 
        group_pair_functions[i_edge] = "unspecified"
      
      pair_connectivity_difference[i_edge] = abs(prop_within_OTU_vect[taxo_groups == colnames(VI)[j]] - prop_within_OTU_vect[taxo_groups == rownames(VI)[i]])/
        (prop_within_OTU_vect[taxo_groups == colnames(VI)[j]] + prop_within_OTU_vect[taxo_groups == rownames(VI)[i]])
      mean_pair_connectivity[i_edge] = (prop_within_OTU_vect[taxo_groups == colnames(VI)[j]] + prop_within_OTU_vect[taxo_groups == rownames(VI)[i]])/2
      
      # VI[which(VI == sort(VI,decreasing=T)[i]) %% ncol(VI), which(VI == sort(VI,decreasing=T)[i]) %/% ncol(VI) + 1]
      # VI[which(VI == max(VI,na.rm=T)) %% ncol(VI),which(VI == max(VI,na.rm=T)) %/% ncol(VI) + 1]
    }
    rownames(best_matching_groups) = apply(cbind(best_matching_groups$group1,best_matching_groups$group2),1,paste,collapse = " ")
    # best_matching_groups[best_matching_groups$group1.diversity > 100 & best_matching_groups$group2.diversity > 100 & rownames(best_matching_groups) %in% 1:30,]
    
    best_matching_groups_list[[index]] = best_matching_groups
    group_pair_functions_list[[index]] = group_pair_functions
    pair_connectivity_difference_list[[index]] = pair_connectivity_difference
    mean_pair_connectivity_list[[index]] = mean_pair_connectivity
  }
  VI = VI0
  # Choosing whether to use VI or normalized VI:
  best_matching_groups = best_matching_groups_list[[2]]
  group_pair_functions = group_pair_functions_list[[2]]
  pair_connectivity_difference = pair_connectivity_difference_list[[2]]
  mean_pair_connectivity = mean_pair_connectivity_list[[2]]
  
  pdf(figure_folder,"/VI_vs_K_diff.pdf")
  plot(abs(best_matching_groups$group1.K - best_matching_groups$group2.K), best_matching_groups$VI, ann = F)
  title(ylab = "VI", xlab = "Difference in optimal K")
  dev.off()
  
  pdf(figure_folder,"/VI_vs_mean_K.pdf")
  plot((best_matching_groups$group1.K + best_matching_groups$group2.K)/2, best_matching_groups$VI, ann = F)
  title(ylab = "VI", xlab = "Average optimal K")
  dev.off()
  
  pdf(figure_folder,"/VI_over_log(meanK)_vs_mean_K.pdf")
  plot((best_matching_groups$group1.K + best_matching_groups$group2.K)/2, best_matching_groups$VI/log((best_matching_groups$group1.K + best_matching_groups$group2.K)/2), ann = F)
  title(ylab = "VI/log(av. K)", xlab = "Average optimal K")
  dev.off()
  
  pdf(figure_folder,"/Normalized_VI_vs_mean_K.pdf")
  plot((best_matching_groups$group1.K + best_matching_groups$group2.K)/2, best_matching_groups$VI, ann = F)
  title(ylab = "Normalized VI", xlab = "Average optimal K")
  dev.off()
  
  pdf(figure_folder,"/VI_over_log(meanK)_vs_Normalized_K.pdf")
  plot(best_matching_groups_list[[2]][rownames(best_matching_groups),"VI"], best_matching_groups$VI/log((best_matching_groups$group1.K + best_matching_groups$group2.K)/2), ann = F)
  title(ylab = "VI/log(av. K)", xlab = "Normalized K")
  dev.off()
  
  plot.VI.pairs.vs.connectivity.diff = ggplot(data = data.frame(x = pair_connectivity_difference, y = best_matching_groups$VI)) + 
    geom_point(aes(x,y, colour = group_pair_functions)) +
    theme_bw() +
    #ggtitle("Variation of Information vs. ") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 10)) +
    labs(x = "Relative difference in\n connectivity through currents", y = "Variation of Information between groups") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_manual(values = setNames(five_colors,edges_functions), na.translate = F, na.value = "grey50", guide = "colourbar", name = "Interaction") +
    # geom_smooth(method='lm') +
    guides(colour = guide_legend(title.position="bottom"))
  
  ggsave(filename = paste0(figure_folder,"/VI_vs_connectivity_difference_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_PairFunctionColorsNoGrey_selected.pdf"), do.call("arrangeGrob", c(list(plot.VI.pairs.vs.connectivity.diff), nrow=1)),
         height = 1.5*4, width = 1.5*4)
  
  plot.VI.pairs.vs.average.connectivity = ggplot(data = data.frame(x = mean_pair_connectivity, y = best_matching_groups$VI)) + 
    geom_point(aes(x,y, colour = group_pair_functions)) +
    theme_bw() +
    #ggtitle("Variation of Information vs. ") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 10)) +
    # labs(x = "Average connectivity through currents", y = "Variation of Information between groups") +
    labs(x = "Average connectivity through currents", y = "Relative Variation of Information between groups") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_manual(values = setNames(five_colors,edges_functions), na.translate = T, na.value = "grey50", guide = "colourbar", name = "Interaction") +
    # geom_smooth(method='lm') +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = paste0("VI_vs_average_connectivity_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_PairFunctionColorsNoGrey_selected.pdf"), 
  # ggsave(filename = paste0("Normalized_VI_vs_average_connectivity_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_PairFunctionColorsNoGrey_selected.pdf"), 
  ggsave(filename = paste0(figure_folder,"/Normalized_VI_vs_average_connectivity_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_PairFunctionColors_selected.pdf"),
         do.call("arrangeGrob", c(list(plot.VI.pairs.vs.average.connectivity), nrow=1)), height = 1.5*4, width = 1.5*4)
  
  #plot(VI/log(optimalK[selected_groups]),Normalized_VI)
  
  ############################################
  # Looking at VI against all other groups:  #
  ############################################
  
  mean_normalized_VI_to_other_groups = vector(length = length(taxo_groups[selected_groups]), mode = "numeric")
  mean_VI_to_other_groups = vector(length = length(taxo_groups[selected_groups]), mode = "numeric")
  for (i in 1:length(taxo_groups[selected_groups]))
  {
    mean_VI_to_other_groups[i] = mean(c(VI[i,],VI[,i]),na.rm = T)
    mean_normalized_VI_to_other_groups[i] = mean(c(Normalized_VI[i,],Normalized_VI[,i]),na.rm = T)
  }
  
  plot.mean.VI_log_size = ggplot(data = data.frame(x = log10(size_absoluteAbund)[selected_groups], y = mean_VI_to_other_groups)) + 
    geom_point(aes(x,y)) +
    theme_bw() +
    #ggtitle("Mean similarity across real. vs. size") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm")) +
    labs(x="Mean body size (log10)", y="Mean Variation of Information to other groups") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    geom_smooth(aes(x,y),method='lm')
  
  ggsave(filename = paste0(figure_folder,"/Mean_VI_vs_size_log10_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"), do.call("arrangeGrob", c(list(plot.mean.VI_log_size), nrow=1)),
         height = 1.5*4, width = 1.5*4)
  
  plot.mean.VI_OTU_connectivity = ggplot(data = data.frame(x = prop_within_OTU_vect[selected_groups], y = mean_VI_to_other_groups)) + 
    geom_point(aes(x,y)) +
    theme_bw() +
    #ggtitle("Mean similarity across real. vs. size") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm")) +
    labs(x="Mean OTU connectivity per group", y="Mean Variation of Information to other groups") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    geom_smooth(aes(x,y),method='lm')
  
  ggsave(filename = paste0(figure_folder,"/Mean_VI_vs_travel_time_prop_OTU_",particle_thres,"particlesThres_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_selected.pdf"), do.call("arrangeGrob", c(list(plot.mean.VI_OTU_connectivity), nrow=1)),
         height = 1.5*4, width = 1.5*4)
  
  plot.mean.VI_OTU_connectivity = ggplot(data = data.frame(x = prop_within_OTU_vect[selected_groups], y = mean_VI_to_other_groups)) + 
    geom_point(aes(x,y, colour = dominant_function[selected_groups])) +
    theme_bw() +
    #ggtitle("Mean similarity across real. vs. size") +
    theme(axis.title=element_text(size=16),
          text = element_text(size=12),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(7,20,1,10),"mm"),
          legend.position="bottom",
          legend.text=element_text(size=10),
          legend.title=element_text(size=16, hjust = 10)) +
    labs(x="Mean OTU connectivity per group", y="Mean Variation of Information to other groups") +
    # geom_vline(xintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    # geom_smooth(method='lm') +
    guides(colour = guide_legend(title.position="bottom"))
  
  ggsave(filename = paste0(figure_folder,"/Mean_VI_vs_travel_time_prop_OTU_",particle_thres,"particlesThres_ggplot_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,"_functionColors_selected.pdf"), do.call("arrangeGrob", c(list(plot.mean.VI_OTU_connectivity), nrow=1)),
         height = 1.5*4, width = 1.5*4)
}

if (marker_comparison)
{
  load(paste0(results_folder,"/group_sizes_byStationByDepth_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata"))
  
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  taxo_groups_psbO = readRDS(paste0(results_folder,"/psbO_taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  taxo_groups_V4 = readRDS(paste0(results_folder,"/V4_taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & as.vector(diversity) > 100 
  selected_groups_psbO = 1:6
  selected_groups_V4 = 1:41
  
  optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
  optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
  optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]]   
  optimalK_prevalence.min.crossValid_psbO = readRDS(paste0(results_folder,"/psbO_optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-30t_iter1000thin25burnin2000_2plusOTUs_noLagoon.rds"))
  optimalK_prevalence.min.crossValid_V4 = readRDS(paste0(results_folder,"/V4_optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-30t_iter1000thin25burnin2000_2plusOTUs_noLagoon.rds"))
  #
  
  nb_iter = 1000
  nb_real = 100
  thin = 25
  burnin = 2000
  
  documents_V9 = vector(length = length(taxo_groups), mode = "list")
  for (taxon in taxo_groups[selected_groups])
  {
    i_taxon = which(taxon == taxo_groups)
    # taxon = "AllTaxa"
    data.folder_name = paste0(data_folder_workspace3,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    nb_topics = optimalK_prevalence.min.crossValid[i_taxon]
    spatial_topicmix_kriged_file = paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds")
    if (file.exists(spatial_topicmix_kriged_file))
    {
      spatial_topicmix_kriged = readRDS(spatial_topicmix_kriged_file)
      # selecting the z.pred columns in all topics:
      documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
      # setting one topic per column
      documents_V9[[i_taxon]] = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics)))
    }
  }
  
  documents_psbO = vector(length = length(taxo_groups_psbO), mode = "list")
  for (taxon in taxo_groups_psbO[selected_groups_psbO])
  {
    i_taxon = which(taxon == taxo_groups_psbO)
    data.folder_name_psbO = paste0(data_folder_workspace3,"/Donnees_Tara/psbO_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    nb_topics_psbO = optimalK_prevalence.min.crossValid_psbO[i_taxon]
    spatial_topicmix_kriged_file_psbO = paste0(data.folder_name_psbO,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics_psbO,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds")
    if (file.exists(spatial_topicmix_kriged_file_psbO))
    {
      spatial_topicmix_kriged = readRDS(spatial_topicmix_kriged_file_psbO)
      # selecting the z.pred columns in all topics:
      documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
      # setting one topic per column
      documents_psbO[[i_taxon]] = matrix(documents,ncol=nb_topics_psbO,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics_psbO)))
    }
  }
  
  documents_V4 = vector(length = length(taxo_groups_V4), mode = "list")
  for (taxon in taxo_groups_V4[selected_groups_V4])
  {
    i_taxon = which(taxon == taxo_groups_V4)
    data.folder_name_V4 = paste0(data_folder_workspace3,"/18S_V4_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    nb_topics_V4 = optimalK_prevalence.min.crossValid_V4[i_taxon]
    spatial_topicmix_kriged_file_V4 = paste0(data.folder_name_V4,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics_V4,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds")
    if (file.exists(spatial_topicmix_kriged_file_V4))
    {
      spatial_topicmix_kriged = readRDS(spatial_topicmix_kriged_file_V4)
      # selecting the z.pred columns in all topics:
      documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
      # setting one topic per column
      documents_V4[[i_taxon]] = matrix(documents,ncol=nb_topics_V4,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics_V4)))
    }
  }
  
  ###############
  Normalized_VI_V9.psbO = matrix(nrow = length(taxo_groups_psbO), 
                                 ncol = length(taxo_groups_psbO), 
                                 dimnames = list(taxo_groups_psbO,taxo_groups_psbO),
                                 data=0)
  for (taxon in taxo_groups_psbO[selected_groups_psbO])
  {
    i_taxon_psbO = which(taxon == taxo_groups_psbO)
    for (taxon_V9 in taxo_groups_psbO[selected_groups_psbO])
    {
      ii_taxon_V9 = which(taxon_V9 == taxo_groups)
      ii_taxon_psbO = which(taxon_V9 == taxo_groups_psbO)
      Normalized_VI_V9.psbO[ii_taxon_psbO,i_taxon_psbO] = normalized_VI_fun(documents_V9[[ii_taxon_V9]],documents_psbO[[i_taxon_psbO]],stations.means="same",SUR.DCM.all="SUR",stations_depths_psbO,coord_psbO)
    }
  }
  
  Normalized_VI_V9.V4 = matrix(nrow = length(taxo_groups_V4), 
                               ncol = length(taxo_groups_V4), 
                               dimnames = list(taxo_groups_V4,taxo_groups_V4),
                               data=0)
  for (taxon in taxo_groups_V4[selected_groups_V4])
  {
    i_taxon_V4 = which(taxon == taxo_groups_V4)
    for (taxon_V9 in taxo_groups_V4[selected_groups_V4])
    {
      ii_taxon_V9 = which(taxon_V9 == taxo_groups)
      ii_taxon_V4 = which(taxon_V9 == taxo_groups_V4)
      Normalized_VI_V9.V4[ii_taxon_V4,i_taxon_V4] = normalized_VI_fun(documents_V9[[ii_taxon_V9]],documents_V4[[i_taxon_V4]],stations.means="same",SUR.DCM.all="SUR",stations_depths_V4,coord_V4)
    }
  }
  
  saveRDS(list(Normalized_VI_V9.V4,Normalized_VI_V9.psbO),paste0(results_folder,"/Normalized.VI_marker.comparison.SUR_V9-V4_V9-psbO_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
  
  ###########
  Normalized_VI_psbO = matrix(nrow = length(taxo_groups_psbO), 
                              ncol = length(taxo_groups_psbO), 
                              dimnames = list(taxo_groups_psbO,taxo_groups_psbO),
                              data=0)
  for (i in 2:length(taxo_groups_psbO[selected_groups_psbO]))
  {
    ii = which(taxo_groups_psbO[selected_groups_psbO][i] == taxo_groups_psbO)
    for (j in 1:(i-1))
    {
      jj = which(taxo_groups_psbO[selected_groups_psbO][j] == taxo_groups_psbO)
      Normalized_VI_psbO[i,j] = normalized_VI_fun(documents_psbO[[ii]],documents_psbO[[jj]],stations.means="same",SUR.DCM.all="SUR",stations_depths_psbO,coord_psbO)
    }
  }
  
  Normalized_VI_V4 = matrix(nrow = length(taxo_groups_V4), 
                            ncol = length(taxo_groups_V4), 
                            dimnames = list(taxo_groups_V4,taxo_groups_V4),
                            data=0)
  for (i in 2:length(taxo_groups_V4[selected_groups_V4]))
  {
    ii = which(taxo_groups_V4[selected_groups_V4][i] == taxo_groups_V4)
    for (j in 1:(i-1))
    {
      jj = which(taxo_groups_V4[selected_groups_V4][j] == taxo_groups_V4)
      Normalized_VI_V4[i,j] = normalized_VI_fun(documents_V4[[ii]],documents_V4[[jj]],stations.means="same",SUR.DCM.all="SUR",stations_depths_V4,coord_V4)
    }
  }
  
  saveRDS(list(Normalized_VI_V4,Normalized_VI_psbO),paste0(results_folder,"/Normalized.VI_group.comparison.SUR_V4.psbO_Gibbs.prevalence.min.crossValid10sampleFolds.rds"))
}

if (random_groups_comparison)
{
  library(ape)
  
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  selected_groups = !(taxo_groups %in% groups_to_remove) & diversity > 100 
  
  optimalK_prevalence.min.crossValid_random.groups = readRDS("/Users/guilhemsommeria-klein/Desktop/Code/Projects/eDNA_LDA/Tara_LDA/Saved_results/random.group.div_optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-25t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds")
  
  # optimalK = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  # Gibbs_VEM_insert = "_Gibbs.prevalence.min.crossValid10sampleFolds"
  # optimalK_prevalence.min.crossValid.complete = readRDS(paste0(results_folder,"/optimalK_prevalence.min.crossValid_Gibbs10sampleFolds2-35t_iter1000thin25burnin500_2plusOTUs_noLagoon.rds"))
  # optimalK_prevalence.min.crossValid.allTaxa = optimalK_prevalence.min.crossValid.complete[[1]]  
  # optimalK_prevalence.min.crossValid = optimalK_prevalence.min.crossValid.complete[[2]]   
  
  nb_iter = 1000
  nb_real = 100
  thin = 25
  burnin = 2000
  
  documents_random.groups = list()
  div = 0
  for (ii_taxon in 1:length(which(selected_groups)))
  {
    taxon = paste0("random.group.div.",ii_taxon)
    
    # Assigning unique i_taxon to each random group:
    i_taxon = which(as.vector(diversity) == as.vector(diversity)[selected_groups][ii_taxon])
    if (length(i_taxon)>1)
    {
      if (div != as.vector(diversity)[selected_groups][ii_taxon])
      {
        div = as.vector(diversity)[selected_groups][ii_taxon]
        ii_div = 1
      } else
      {
        ii_div = ii_div + 1
      }
      i_taxon = i_taxon[ii_div]
    }
    
    data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,"_noLagoon")
    
    if (!is.na(optimalK_prevalence.min.crossValid_random.groups[i_taxon]))
    {
      data.folder_name = paste0(data_folder_workspace2,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
      nb_topics = optimalK_prevalence.min.crossValid_random.groups[i_taxon]
      spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_Gibbs_alpha0.1_delta0.1_nb_topics",nb_topics,"_nb_iter",nb_iter,"_nb_real",nb_real,"_meanPosteriorDistributedLlh_thin",thin,"_burnin",burnin,"_occurrence/1st_closestToMean_realization/Spatial_topicmix_kriged.rds"))
      
      # selecting the z.pred columns in all topics:
      documents = unlist(lapply(spatial_topicmix_kriged,function(g) g$z.pred))
      # setting one topic per column
      documents = matrix(documents,ncol=nb_topics,dimnames=list(rownames(spatial_topicmix_kriged[[1]]),paste0("topic",1:nb_topics)))
      documents_random.groups[[i_taxon]] = documents
    }
  }
  
  # VI = vector(length = 3, mode = "list")
  # names(VI) = c("SUR","DCM","All")
  # VI_over_K = vector(length = 3, mode = "list")
  # names(VI_over_K) = c("SUR","DCM","All")
  # VI_over_logK = vector(length = 3, mode = "list")
  # names(VI_over_logK) = c("SUR","DCM","All")
  Normalized_VI_random.groups = vector(length = 3, mode = "list")
  names(Normalized_VI_random.groups) = c("SUR","DCM","All")
  for (case in c("SUR","DCM","All"))
  {
    i_case = which(c("SUR","DCM","All") == case)
    # VI[[i_case]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data = NA)
    # VI_over_K[[i_case]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data = NA)
    # VI_over_logK[[i_case]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data = NA)
    Normalized_VI_random.groups[[i_case]] = matrix(nrow = length(taxo_groups), ncol = length(taxo_groups), dimnames = list(taxo_groups,taxo_groups), data = NA)
    for (i in 2:length(taxo_groups))
    {
      for (j in 1:(i-1))
      {
        if (selected_groups[i] & selected_groups[j] & !is.na(optimalK_prevalence.min.crossValid_random.groups[i]) & !is.na(optimalK_prevalence.min.crossValid_random.groups[j]))
        {
          Pk_i = colMeans(documents_random.groups[[i]])
          Pk1_j = colMeans(documents_random.groups[[j]])
          if (i_case %in% c(1,2))
          {
            selected_stations_ij = rownames(coord)[rownames(coord) %in% rownames(documents_random.groups[[i]]) &
                                                     rownames(coord) %in% rownames(documents_random.groups[[j]]) &
                                                     stations_depths[,2] == case]
          } else
          {
            selected_stations_ij = rownames(coord)[rownames(coord) %in% rownames(documents_random.groups[[i]]) & 
                                                     rownames(coord) %in% rownames(documents_random.groups[[j]])]
          } 
          if (length(selected_stations_ij)>1)
          {
            sum_Pkk1_times_log_Pkk1_over_PkPk1 = 0
            for (k in 1:ncol(documents_random.groups[[i]]))
            {
              for (k1 in 1:ncol(documents_random.groups[[j]]))
              {
                Pkk1 = mean(documents_random.groups[[i]][selected_stations_ij,k]*documents_random.groups[[j]][selected_stations_ij,k1])
                if (Pkk1>0)
                  sum_Pkk1_times_log_Pkk1_over_PkPk1 = sum_Pkk1_times_log_Pkk1_over_PkPk1 + Pkk1*(log(Pkk1) - log(Pk_i[k]) - log(Pk1_j[k1]))
              }
            }
            # Computing the Variation of Information using probability values 
            H_i = -sum(Pk_i*log(Pk_i))
            H_j = -sum(Pk1_j*log(Pk1_j))
            I = sum_Pkk1_times_log_Pkk1_over_PkPk1
            Normalized_VI_random.groups[[i_case]][i,j] = (H_i + H_j - 2*I)/(H_i + H_j - I)
            # VI_over_K[[i_case]][i,j] = VI[[i_case]][i,j]/(ncol(documents_allgroups[[j]]) + ncol(documents_allgroups[[i]]))*2
            # VI_over_logK[[i_case]][i,j] = VI[[i_case]][i,j]/log((ncol(documents_allgroups[[j]]) + ncol(documents_allgroups[[i]]))/2)
          } 
        }
      }
    }
  }
  
  NormalizedVI_random.groups_pcoa = vector(length = 3, mode = "list")
  names(NormalizedVI_random.groups_pcoa) = c("SUR","DCM","All")
  i_case = 3
  for (i_case in 1:3)
  {
    VI.pcoa = pcoa(as.dist(Normalized_VI_random.groups[[i_case]][selected_groups,selected_groups][-(1:2),-(1:2)]))
    NormalizedVI_random.groups_pcoa[[i_case]] = VI.pcoa$vectors
  }
  
  plot(NormalizedVI_random.groups_pcoa[[3]][,1],NormalizedVI_random.groups_pcoa[[3]][,2])
  #
  plot(log10(as.vector(diversity))[selected_groups][-(1:2)],NormalizedVI_random.groups_pcoa[[3]][,2])
  plot(log(as.vector(size_relativeAbund))[selected_groups][-(1:2)],NormalizedVI_random.groups_pcoa[[3]][,2])
  plot(log(size_relativeAbund)[selected_groups][as.vector(log10(diversity))[selected_groups] > 2.5][-(1:2)],
       NormalizedVI_random.groups_pcoa[[3]][,2][as.vector(log10(diversity))[selected_groups][-(1:2)] > 2.5])
  #
  plot(I_square.observed_w.mean.random.groups[selected_groups,1][-(1:2)],NormalizedVI_random.groups_pcoa[[3]][,1])
  plot((lat_I_random.groups[selected_groups,1]/I_square.observed_w.mean.random.groups[selected_groups,1])[-(1:2)],
       NormalizedVI_random.groups_pcoa[[3]][,2])
  plot((basin_I_random.groups[selected_groups,1]/I_square.observed_w.mean.random.groups[selected_groups,1])[-(1:2)],
       NormalizedVI_random.groups_pcoa[[3]][,2])
}

if (Arctic_analyses)
{
  ######################################################
  # Investigating the distinctiveness of Arctic stations
  
  overlap_index = vector(length = length(taxo_groups), mode = "numeric")
  Arctic_dominant_topic = vector(length = length(taxo_groups), mode = "numeric")
  NorthAtlantic_dominant_topic = vector(length = length(taxo_groups), mode = "numeric")
  Arctic_dominant_topic_occupancy = vector(length = length(taxo_groups), mode = "numeric")
  NorthAtlantic_dominant_topic_occupancy = vector(length = length(taxo_groups), mode = "numeric")
  assemblage_distinctiveness_index = vector(length = length(taxo_groups), mode = "numeric")
  Arctic_distinctiveness_index1 = vector(length = length(taxo_groups), mode = "numeric")
  Arctic_distinctiveness_index2 = vector(length = length(taxo_groups), mode = "numeric")
  Sorensen_ArcticNonArctic = vector(length = length(taxo_groups), mode = "numeric")
  Sorensen_155_158 = vector(length = length(taxo_groups), mode = "numeric")
  relative_Sorensen_155_158 = vector(length = length(taxo_groups), mode = "numeric")
  proportion_Arctic_assemb = matrix(nrow = length(taxo_groups), ncol = 4, data = NA, dimnames = list(taxo_groups,c("152","155","158","163")))
  proportion_NorthAtlantic_assemb = matrix(nrow = length(taxo_groups), ncol = 4, data = NA, dimnames = list(taxo_groups,c("152","155","158","163")))
  dominant_topic_152_to_163 = matrix(nrow = length(taxo_groups), ncol = 4, data = NA, dimnames = list(taxo_groups,c("152","155","158","163")))
  dominant_topic_158_SUR_DCM = matrix(nrow = length(taxo_groups), ncol = 2, dimnames = list(taxo_groups,c("SUR","DCM")), data = NA)
  taxo_groups = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  increasing_llh = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  alpha_best_real = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  optimalK = readRDS(paste0(results_folder,"/OptimalK_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  mean_sim = readRDS(paste0(results_folder,"/mean_sim_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  diversity = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".Rdata")) 
  selected_groups = !(taxo_groups %in% groups_to_remove) & alpha_best_real<1 & increasing_llh
  for (taxon in taxo_groups[selected_groups])
  {
    i_taxon = which(taxo_groups == taxon)
    #par(mar = c(2.1, 2.1, 2.1, 1.1))
    data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    nb_topics = optimalK[i_taxon]
    spatial_topicmix_kriged = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/Spatial_topicmix_kriged.rds"))
    load(paste0(data.folder_name,"/coord.Rdata"))
    
    if (i_taxon == 1)
    {
      Arctic_stations = rownames(coord)[which(rownames(coord) == "TARA_158 SUR"):nrow(coord)]
      NorthAtlantic_stations = rownames(coord)[which(rownames(coord) == "TARA_141 SUR"):which(rownames(coord) == "TARA_155 DCM")]
    }
    
    coord_taxon = coord[rownames(spatial_topicmix_kriged[[1]]),]
    
    # AllTaxa_topics = c("Upwelling","Indian Ocean","Medit.","Temp. Atlantic","Tropical DCM","Tropical Surf.","C. Pacific","E. Pacific","W. Atlantic","Red Sea")
    topicmix = matrix(nrow = nrow(coord_taxon), ncol = nb_topics, dimnames = list(rownames(coord_taxon),1:nb_topics), data = 0)
    for (k in 1:nb_topics)
      topicmix[,k] = spatial_topicmix_kriged[[k]]$z.pred
    
    dominant_topic = vector(length = nrow(topicmix), mode = "numeric")
    for (i in 1:length(dominant_topic))
    {
      if (length(which(topicmix[i,] == max(topicmix[i,]))) == 1)
        dominant_topic[i] = which(topicmix[i,] == max(topicmix[i,]))
      else
        dominant_topic[i] = sample(which(topicmix[i,] == max(topicmix[i,])),1)
    }
    
    # The overlap index is the Sorensen similarity between the dominant Arctic assemblage and the Arctic stations,
    # i.e. twice the number of stations in commmon divided by the number of Arctic stations plus the number of stations dominated by the dominant Arctic assemblage
    Arctic_dominant_topic_occupancy_table = sort(table(as.factor(dominant_topic[which(rownames(coord_taxon) %in% Arctic_stations)])),decreasing = T) 
    Arctic_dominant_topic[i_taxon] = names(Arctic_dominant_topic_occupancy_table)[1]
    overlap_index[i_taxon] = 2*Arctic_dominant_topic_occupancy_table[1]/(length(which(rownames(coord_taxon) %in% Arctic_stations)) + length(which(dominant_topic == Arctic_dominant_topic[i_taxon])))
    # The proportion of Arctic stations that are dominanted by the dominant Arctic assemblage:
    Arctic_dominant_topic_occupancy[i_taxon] = Arctic_dominant_topic_occupancy_table[1]/length(which(rownames(coord_taxon) %in% Arctic_stations))
    
    # Same computation as for the Arctic dominant assemblage, but for the North Atlantic dominant assemblage
    # No overlap index is computed, because the assemblage that dominates North Atlantic is typically also found in South Atlantic
    NorthAtlantic_dominant_topic_occupancy_table = sort(table(as.factor(dominant_topic[which(rownames(coord_taxon) %in% NorthAtlantic_stations)])),decreasing = T)
    NorthAtlantic_dominant_topic[i_taxon] = names(NorthAtlantic_dominant_topic_occupancy_table)[1]
    NorthAtlantic_dominant_topic_occupancy[i_taxon] = NorthAtlantic_dominant_topic_occupancy_table[1]/length(which(rownames(coord_taxon) %in% NorthAtlantic_stations))
    
    # Proportion of the dominant Arctic and North Atlantic assemblages in stations 153, 155, 158 and 163 (averaged over SURF and DCM):
    station_list = list(c("TARA_152 SUR","TARA_152 DCM"),c("TARA_155 SUR","TARA_155 DCM"),c("TARA_158 SUR","TARA_158 DCM"),c("TARA_163 SUR","TARA_163 DCM"))
    for (i_station in 1:4)
    {
      if (any(station_list[[i_station]] %in% rownames(topicmix)))
      {
        proportion_Arctic_assemb[i_taxon,i_station] = mean(topicmix[rownames(topicmix) %in% station_list[[i_station]],Arctic_dominant_topic[i_taxon]])
        proportion_NorthAtlantic_assemb[i_taxon,i_station] = mean(topicmix[rownames(topicmix) %in% station_list[[i_station]],NorthAtlantic_dominant_topic[i_taxon]])
        if (proportion_Arctic_assemb[i_taxon,i_station] > 0.5)
          dominant_topic_152_to_163[i_taxon,i_station] = "Arctic"
        else if (proportion_NorthAtlantic_assemb[i_taxon,i_station] > 0.5)
          dominant_topic_152_to_163[i_taxon,i_station] = "NorthAtlantic"
        else
          dominant_topic_152_to_163[i_taxon,i_station] = "Other"
      } else 
      {
        proportion_Arctic_assemb[i_taxon,i_station] = NA
        proportion_NorthAtlantic_assemb[i_taxon,i_station] = NA
        dominant_topic_152_to_163[i_taxon,i_station] = NA
      }
    }
    
    # Proportion of the dominant 158 assemblage in station 155 (averaged over SURF and DCM):
    if (any(c("TARA_158 SUR","TARA_158 DCM") %in% rownames(topicmix)))
    {
      # The dominant assemblage in 158 is chosen at random between the dominant assemblage in SURF and DCM:
      dominant_topic_158 = sample(dominant_topic[rownames(topicmix) %in% c("TARA_158 SUR","TARA_158 DCM")],1)
      if (any(c("TARA_155 SUR","TARA_155 DCM") %in% rownames(topicmix)))
        proportion_158_assemb_in_155[i_taxon] = mean(topicmix[rownames(topicmix) %in% c("TARA_155 SUR","TARA_155 DCM"),Arctic_dominant_topic[i_taxon]])
      else 
        proportion_158_assemb_in_155[i_taxon] = NA
    } else
      proportion_158_assemb_in_155[i_taxon] = NA
    
    # Dominant assemblage in stations 158 SURF and 158 DCM:
    dominant_topic_158_SUR_DCM[i_taxon,1] = ifelse(length(dominant_topic[rownames(topicmix) == "TARA_158 SUR"]) == 1,dominant_topic[rownames(topicmix) == "TARA_158 SUR"],NA)
    dominant_topic_158_SUR_DCM[i_taxon,2] = ifelse(length(dominant_topic[rownames(topicmix) == "TARA_158 DCM"]) == 1,dominant_topic[rownames(topicmix) == "TARA_158 DCM"],NA)
    
    ###########
    load(paste0(data.folder_name,"/data2m.Rdata"))
    data2m = data2m[,colSums(data2m) != 0]
    colnames(data2m) = rownames(coord_taxon)
    
    # Sorensen similarity between all stations, between Arctic stations, between Arctic and non-Arctic stations, and between non-Arctic stations:
    Sorensen_stations = 1-as.matrix(vegan::designdist(t(data2m), "(b+c)/(2*a+b+c)", abcd=TRUE))
    Sorensen_Arctic_stations = Sorensen_stations[colnames(data2m) %in% Arctic_stations,colnames(data2m) %in% Arctic_stations]
    Sorensen_Arctic_to_nonArctic_stations = Sorensen_stations[!(colnames(data2m) %in% Arctic_stations),colnames(data2m) %in% Arctic_stations]
    Sorensen_nonArctic_stations = Sorensen_stations[!(colnames(data2m) %in% Arctic_stations),!(colnames(data2m) %in% Arctic_stations)]
    # Arctic_distinctiveness_index1 is the mean Sorensen similarity between Artic stations, divided by the mean Sorensen similarity between Arctic stations and all other stations ("distinctiveness of Arctic stations"):
    Arctic_distinctiveness_index1[i_taxon] = mean(Sorensen_Arctic_stations[lower.tri(Sorensen_Arctic_stations,diag=F)])/mean(Sorensen_Arctic_to_nonArctic_stations)
    # Arctic_distinctiveness_index2 is the mean Sorensen similarity between Artic stations, divided by the mean Sorensen similarity between all non-Arctic stations ("relative similarity of Arctic stations"):
    Arctic_distinctiveness_index2[i_taxon] = mean(Sorensen_Arctic_stations[lower.tri(Sorensen_Arctic_stations,diag=F)])/mean(Sorensen_nonArctic_stations[lower.tri(Sorensen_nonArctic_stations,diag=F)])
    
    # Sorensen similarity Arctic and non-Arctic stations:
    topic_compo_ArcticNonArctic = rbind(rowSums(data2m[,colnames(data2m) %in% Arctic_stations]),rowSums(data2m[,!(colnames(data2m) %in% Arctic_stations)]))
    rownames(topic_compo_ArcticNonArctic) = c("Arctic","non-Arctic")
    Sorensen_ArcticNonArctic[i_taxon] = 1-as.matrix(vegan::designdist(topic_compo_ArcticNonArctic), "(b+c)/(2*a+b+c)", abcd=TRUE)[1,2]
    
    # Sorensen similarity between stations 155 and 158:
    if (length(which(colnames(data2m) %in% c("TARA_155 SUR","TARA_155 DCM"))) == 2)
      topic_compo_155 = rowSums(data2m[,colnames(data2m) %in% c("TARA_155 SUR","TARA_155 DCM")])
    else if (length(which(colnames(data2m) %in% c("TARA_155 SUR","TARA_155 DCM"))) == 1)
      topic_compo_155 = data2m[,colnames(data2m) %in% c("TARA_155 SUR","TARA_155 DCM")]
    else if (length(which(colnames(data2m) %in% c("TARA_155 SUR","TARA_155 DCM"))) == 0)
      topic_compo_155 = NA
    if (length(which(colnames(data2m) %in% c("TARA_158 SUR","TARA_158 DCM"))) == 2)
      topic_compo_158 = rowSums(data2m[,colnames(data2m) %in% c("TARA_158 SUR","TARA_158 DCM")])
    else if (length(which(colnames(data2m) %in% c("TARA_158 SUR","TARA_158 DCM"))) == 1)
      topic_compo_158 = data2m[,colnames(data2m) %in% c("TARA_158 SUR","TARA_158 DCM")]
    else if (length(which(colnames(data2m) %in% c("TARA_158 SUR","TARA_158 DCM"))) == 0)
      topic_compo_158 = NA
    Sorensen_no155_158_stations = Sorensen_stations[!(colnames(data2m) %in% c("TARA_155 SUR","TARA_155 DCM","TARA_158 SUR","TARA_158 DCM")),!(colnames(data2m) %in% c("TARA_155 SUR","TARA_155 DCM","TARA_158 SUR","TARA_158 DCM"))]
    if (all(!is.na(c(topic_compo_155,topic_compo_158))))
    {
      topic_compo_155_158 = rbind(topic_compo_155,topic_compo_158)
      rownames(topic_compo_155_158) = c("TARA_155","TARA_158")
      Sorensen_155_158[i_taxon] = 1-as.matrix(vegan::designdist(topic_compo_155_158), "(b+c)/(2*a+b+c)", abcd=TRUE)[1,2]
      relative_Sorensen_155_158[i_taxon] = Sorensen_155_158[i_taxon]/mean(Sorensen_no155_158_stations[lower.tri(Sorensen_no155_158_stations,diag=F)])
    } else
    {
      Sorensen_155_158[i_taxon] = NA
      relative_Sorensen_155_158[i_taxon] = NA
    }
    
    ###########
    # The assemblage distinctiveness index is the mean Hellinger dissimilarity between the dominant Arctic assemblage and the other assemblages, divided by the mean Hellinger dissimilarity among all other assemblages
    # data.folder_name = paste0(data_folder_workspace0,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_",taxon,noArcticNoBiomark_insert,noLagoon_insert)
    assemblage_composition = readRDS(paste0(data.folder_name,"/Rtopicmodels_LDA_VEM_nb_topics",nb_topics,"_nb_real100_em_tol1e-06_var_tol1e-08_best_keep_occurrence/1st_best_realization/assemblage_composition.rds"))
    # topic_compo = data.frame(lapply(Ordered_topic_compo_taxo_full,function(g) g$proba))
    topic_compo = assemblage_composition[,1:nb_topics]
    colnames(topic_compo) = 1:nb_topics
    # Reordering OTUs in Ordered_topic_compo_taxo_full:
    # for (k in 2:nb_topics)
    # {
    #   rownames(topic_compo) = Ordered_topic_compo_taxo_full[[k]][,2]
    #   topic_compo[,k] = topic_compo[Ordered_topic_compo_taxo_full[[1]][,2],k]
    # }
    # rownames(topic_compo) = Ordered_topic_compo_taxo_full[[1]][,2]
    Hellinger_assemblages = 1/sqrt(2)*dist(t(sqrt(topic_compo)), method = "euclidean", diag = FALSE, upper = FALSE)
    selected_matrix = lower.tri(as.matrix(Hellinger_assemblages), diag = F)
    dimnames(selected_matrix) = list(rownames(as.matrix(Hellinger_assemblages)),colnames(as.matrix(Hellinger_assemblages)))
    # ! Not the same as selected_matrix[Arctic_dominant_topic[i_taxon],Arctic_dominant_topic[i_taxon]], which selects only the intersection
    selected_matrix[Arctic_dominant_topic[i_taxon],] = F
    selected_matrix[,Arctic_dominant_topic[i_taxon]] =  F
    assemblage_distinctiveness_index[i_taxon] = mean(as.matrix(Hellinger_assemblages)[rownames(as.matrix(Hellinger_assemblages)) != Arctic_dominant_topic[i_taxon],Arctic_dominant_topic[i_taxon]])/mean(as.matrix(Hellinger_assemblages)[selected_matrix])
  }
  
  dominant_function = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noArcticNoBiomark_insert,noLagoon_insert,".rds"))
  dominant_function_simplified  = dominant_function
  dominant_function_simplified[dominant_function %in% c("copepoda","other metazoa","pteropoda")] = "metazoa"
  # functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
  functions = c("endophotosymbiont","gelatineous_carnivores_filterers","metazoa","parasite","phagotroph","photohost","phototroph","unknown")
  ten_colors = c(NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","deeppink1")
  
  setwd(paste0(figure_path,"/Arctic"))
  
  library(ggplot2)
  library(gridExtra)
  
  # Spatial overlap between the dominant Arctic assemblage and Arctic stations: 
  ################################################################
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = overlap_index[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    # tmp.plot = ggplot(data = data.frame(x = optimalK[selected_groups], y = overlap_index[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    # geom_point(aes(x,y)) + theme_bw() + labs(x="Optimal number of assemblages", y="Spatial overlap between dominant Arctic assemblage\n and Arctic stations") +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Spatial overlap between dominant Arctic assemblage\n and Arctic stations") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    ylim(c(0,1)) +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_optimalK_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #        height = 1.5*10/3, width = 1.5*10/3)
  
  # Distinctiveness of the dominant Arctic assemblage:
  ###################################################
  tmp.plot = ggplot(data = data.frame(x = assemblage_distinctiveness_index[selected_groups], y = overlap_index[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    # tmp.plot = ggplot(data = data.frame(x = assemblage_distinctiveness_index[selected_groups & Arctic_dominant_topic_occupancy>0.6], y = overlap_index[selected_groups & Arctic_dominant_topic_occupancy>0.6]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups & Arctic_dominant_topic_occupancy>0.6])) +
    # tmp.plot = ggplot(data = data.frame(x = assemblage_distinctiveness_index[selected_groups & optimalK>4], y = overlap_index[selected_groups & optimalK>4]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups & optimalK>4])) +  
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Taxonomic distinctiveness of dominant Arctic assemblage", y="Spatial overlap between dominant Arctic assemblage\n and Arctic stations") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_distinctiveness_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_distinctiveness_ggplot_functionColors_selected_optimalK>4.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #        height = 1.5*10/3, width = 1.5*10/3)
  
  # tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups & Arctic_dominant_topic_occupancy>0.8]), y = assemblage_distinctiveness_index[selected_groups & Arctic_dominant_topic_occupancy>0.8]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups & Arctic_dominant_topic_occupancy>0.8])) +
  # tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups & optimalK > 4]), y = assemblage_distinctiveness_index[selected_groups & optimalK > 4]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups & optimalK > 4])) +  
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = assemblage_distinctiveness_index[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +  
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Taxonomic distinctiveness of\n Arctic dominant assemblage") +
    geom_hline(yintercept = 1, linetype = "dashed") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  # ggsave(filename = "Arctic_dominant_assemblage_distinctiveness_vs_size_ggplot_functionColors_selected_>0.8ArcticOccupancy.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #        height = 1.5*10/3, width = 1.5*10/3)
  # ggsave(filename = "Arctic_dominant_assemblage_distinctiveness_vs_size_ggplot_functionColors_selected_optimalK>4.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #        height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_dominant_assemblage_distinctiveness_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = assemblage_distinctiveness_index[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Taxonomic distinctiveness of Arctic dominant assemblage") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm")) +
    geom_smooth(method='lm', aes(x,y))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_dominant_assemblage_distinctiveness_vs_size_ggplot_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # Distinctiveness of Arctic stations
  ####################################
  tmp.plot = ggplot(data = data.frame(x = Arctic_distinctiveness_index1[selected_groups], y = Arctic_distinctiveness_index2[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Distinctiveness of Arctic stations", y="Normalized similarity of Arctic stations") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_stations_similarity_vs_distinctiveness_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = Arctic_distinctiveness_index2[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = Arctic_distinctiveness_index1[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    # geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Relative similarity of Arctic stations") +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Distinctiveness of Arctic stations") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    geom_hline(yintercept = prop_within_OTU_null, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_stations_similarity_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #        height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_stations_distinctiveness_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # Overall similarity between Arctic and non-Arctic, and between stations 155 and 158
  ####################################################################################
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = Sorensen_ArcticNonArctic[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Overall similarity between Arctic and non-Arctic") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_nonArctic_similarity_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # Test plot to test the advantage of LDA over similarity analysis:
  # tmp.plot = ggplot(data = data.frame(x = assemblage_distinctiveness_index[selected_groups], y = Sorensen_ArcticNonArctic[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +  
  # tmp.plot = ggplot(data = data.frame(x = assemblage_distinctiveness_index[selected_groups], y = Arctic_distinctiveness_index1[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +  
  tmp.plot = ggplot(data = data.frame(x = assemblage_distinctiveness_index[selected_groups], y = Arctic_distinctiveness_index2[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +  
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Taxonomic distinctiveness of Arctic dominant assemblage", y="Relative similarity of Arctic stations") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  # ggsave(filename = "Arctic_nonArctic_similarity_vs_Arctic_dominant_assemblage_distinctiveness_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #        height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_stations_similarity_vs_Arctic_dominant_assemblage_distinctiveness_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = Sorensen_155_158[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Similarity between stations 155 and 158") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "155_vs_158_similarity_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = relative_Sorensen_155_158[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Relative similarity between stations 155 and 158") +
    geom_hline(yintercept = 1, linetype = "dashed") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "155_vs_158_relative_similarity_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # proportion of station 158's dominant assemblage in station 155
  ########################################################
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = proportion_158_assemb_in_155[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Proportion of station 158's dominant assemblage\n in station 155") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Proportion_assemb_158_in_155_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # Proportion of Arctic dominant assemblage in stations 152, 155, 158 and 163
  ############################################################################
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = proportion_Arctic_assemb_in_152[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Proportion of the dominant Arctic assemblage\n in station 152") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Proportion_dominant_Arctic_in_152_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = proportion_Arctic_assemb_in_155[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Proportion of the dominant Arctic assemblage\n in station 155") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Proportion_dominant_Arctic_in_155_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = proportion_Arctic_assemb_in_158[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Proportion of the dominant Arctic assemblage\n in station 158") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Proportion_dominant_Arctic_in_158_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund[selected_groups]), y = proportion_Arctic_assemb_in_163[selected_groups]), mapping = aes(x,y,colour = dominant_function_simplified[selected_groups])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size (log10)", y="Proportion of the dominant Arctic assemblage\n in station 163") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Proportion_dominant_Arctic_in_163_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # Proportion of Artic and North Atlantic dominant assemblages in stations 152, 155, 158 and 163
  ###############################################################################################
  # Mean proportion of each assemblage across groups in the four stations
  mean_proportion_assemb = matrix(nrow = 4, ncol = 3, data = 0, dimnames = list(c("152","155","158","163"),c("Arctic","Other","North Atlantic")))
  for (i_station in 1:4)
    mean_proportion_assemb[i_station,] = c(mean(proportion_Arctic_assemb[selected_groups,i_station], na.rm = T),1-mean(proportion_Arctic_assemb[selected_groups,i_station], na.rm = T)-mean(proportion_NorthAtlantic_assemb[selected_groups,i_station], na.rm = T),mean(proportion_NorthAtlantic_assemb[selected_groups,i_station], na.rm = T))
  
  tmp.plot = ggplot(data = data.frame(x = c(rep("152",3),rep("155",3),rep("158",3),rep("163",3)), 
                                      y = as.vector(t(mean_proportion_assemb)),
                                      Assemblage = rep(c("Arctic","Other","North Atlantic"),4)),
                    mapping = aes(x,y,fill = Assemblage)) +
    geom_bar(stat = "identity") +
    # theme_bw() +
    theme_classic() +
    ggtitle("Mean across groups") +
    labs(x="Station", y="Assemblage proportion") +
    theme(axis.title=element_text(size=16),
          text=element_text(size=15),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=14),
          legend.title=element_text(size=16))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Assemblage_proportion_NorthAtlantic_Arctic_transition_barplot_ggplot_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # Proportion of each assemblage in the four stations, for each group
  tmp.plot.taxon = list()
  ii_taxon = 0
  for (i_taxon in 1:length(taxo_groups))
  {
    if (selected_groups[i_taxon])
    {
      ii_taxon = ii_taxon+1
      proportion_assemb = matrix(nrow = 4, ncol = 3, data = 0, dimnames = list(c("152","155","158","163"),c("Arctic","Other","North Atlantic")))
      for (i_station in 1:4)
        proportion_assemb[i_station,] = c(proportion_Arctic_assemb[i_taxon,i_station],1-proportion_Arctic_assemb[i_taxon,i_station]-proportion_NorthAtlantic_assemb[i_taxon,i_station],proportion_NorthAtlantic_assemb[i_taxon,i_station])
      
      tmp.plot.taxon[[ii_taxon]] = ggplot(data = data.frame(x = c(rep("152",3),rep("155",3),rep("158",3),rep("163",3)), 
                                                            y = as.vector(t(proportion_assemb)),
                                                            Assemblage = rep(c("Arctic","Other","North Atlantic"),4)),
                                          mapping = aes(x,y,fill = Assemblage)) +
        geom_bar(stat = "identity") +
        theme_classic() +
        ggtitle(taxo_groups[i_taxon]) +
        labs(x="Station", y="Assemblage proportion")
      
      if (ii_taxon == 1)
      {
        tmp.plot.taxon[[ii_taxon]] = tmp.plot.taxon[[ii_taxon]] + theme(axis.title=element_text(size=16),
                                                                        text=element_text(size=15),
                                                                        plot.title=element_text(hjust=0, size=16),
                                                                        plot.margin=unit(c(10,10,1,0.5),"mm"),
                                                                        legend.position="bottom",
                                                                        # legend.text=element_text(size=16),
                                                                        legend.text=element_text(size=14),
                                                                        legend.title=element_text(size=16))
      } else
      {
        tmp.plot.taxon[[ii_taxon]] = tmp.plot.taxon[[ii_taxon]] + theme(axis.title=element_text(size=16),
                                                                        text=element_text(size=15),
                                                                        plot.title=element_text(hjust=0, size=16),
                                                                        plot.margin=unit(c(10,10,1,0.5),"mm"),
                                                                        legend.position="none")
      }
    }
  }
  
  spl = split(tmp.plot.taxon, (seq_along(tmp.plot.taxon)-1) %/% 20)
  ppl = lapply(spl, function(g) marrangeGrob(grobs = g, nrow = 4, ncol = 5))
  pdf(file = "Assemblage_proportion_NorthAtlantic_Arctic_transition_barplot_ggplot_all_groups_selected.pdf",height = 1.5*10, width = 1.5*10)
  print(ppl)
  dev.off()
  #########
  
  groups_to_plot = c("Bacillariophyta","Chordata","Dinophyceae","Spumellaria")
  for (i_taxon in which(taxo_groups %in% groups_to_plot))
  {  
    proportion_assemb = matrix(nrow = 4, ncol = 3, data = 0, dimnames = list(c("152","155","158","163"),c("Arctic","Other","North Atlantic")))
    for (i_station in 1:4)
      proportion_assemb[i_station,] = c(proportion_Arctic_assemb[i_taxon,i_station],1-proportion_Arctic_assemb[i_taxon,i_station]-proportion_NorthAtlantic_assemb[i_taxon,i_station],proportion_NorthAtlantic_assemb[i_taxon,i_station])
    
    tmp.plot = ggplot(data = data.frame(x = c(rep("152",3),rep("155",3),rep("158",3),rep("163",3)), 
                                        y = as.vector(t(proportion_assemb)),
                                        Assemblage = rep(c("Arctic","Other","North Atlantic"),4)),
                      mapping = aes(x,y,fill = Assemblage)) +
      geom_bar(stat = "identity") +
      theme_classic() +
      ggtitle(taxo_groups[i_taxon]) +
      labs(x="Station", y="Assemblage proportion") +
      theme(axis.title=element_text(size=16),
            text=element_text(size=15),
            plot.title=element_text(hjust=0, size=16),
            plot.margin=unit(c(10,10,1,0.5),"mm"),
            legend.position="bottom",
            # legend.text=element_text(size=16),
            legend.text=element_text(size=14),
            legend.title=element_text(size=16))
    
    ggsave(filename = paste0("Assemblage_proportion_NorthAtlantic_Arctic_transition_barplot_ggplot_",taxo_groups[i_taxon],"_selected.pdf"), do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
           height = 1.5*10/3, width = 1.5*10/3)
  }
  
  # Proportion of groups where each assemblage is dominant, for the four stations
  # Counting the number of groups where each assemblage is dominant:
  distribution_of_dominant_assemblages = matrix(nrow = 4, ncol = 3, data = 0, dimnames = list(c("152","155","158","163"),c("Arctic","Other","North Atlantic")))
  for (i_station in 1:4)
    distribution_of_dominant_assemblages[i_station,] = (table(as.factor(dominant_topic_152_to_163[selected_groups & !is.na(dominant_topic_152_to_163[,i_station]),i_station]))/nrow(dominant_topic_152_to_163[selected_groups & !is.na(dominant_topic_152_to_163[,i_station]),]))[c("Arctic","Other","NorthAtlantic")]
  
  tmp.plot = ggplot(data = data.frame(x = c(rep("152",3),rep("155",3),rep("158",3),rep("163",3)), 
                                      y = as.vector(t(distribution_of_dominant_assemblages)),
                                      Assemblage = rep(c("Arctic","Other","North Atlantic"),4)),
                    mapping = aes(x,y,fill = Assemblage)) +
    geom_bar(stat = "identity") +
    theme_classic() +
    #ggtitle() +
    labs(x="Station", y="Proportion of taxonomic groups\n where the assemblage is dominant") +
    theme(axis.title=element_text(size=16),
          text=element_text(size=15),
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(10,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=14),
          legend.title=element_text(size=16))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Dominant_assemblage_across_groups_NorthAtlantic_Arctic_transition_barplot_ggplot_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # Estimated group body size in Arctic vs non-Artic
  ##################################################
  load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs_noArcticNoBiomark",noLagoon_insert,".Rdata"))
  size_absoluteAbund_noArctic = size_absoluteAbund
  load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs_noArcticNoBiomark",noLagoon_insert,"_0.8inf.Rdata"))
  size_absoluteAbund_noArctic_0.8inf = size_absoluteAbund
  load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs_noArcticNoBiomark",noLagoon_insert,"_NoSmallSizeFraction.Rdata"))
  size_absoluteAbund_noArctic_NoSmallSizeFraction = size_absoluteAbund
  taxo_groups_noArctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
  names(size_absoluteAbund_noArctic) = taxo_groups_noArctic
  names(size_absoluteAbund_noArctic_0.8inf) = taxo_groups_noArctic
  names(size_absoluteAbund_noArctic_NoSmallSizeFraction) = taxo_groups_noArctic
  increasing_llh_noArctic = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
  alpha_best_real_noArctic = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
  selected_groups_noArctic = !(taxo_groups_noArctic %in% groups_to_remove) & alpha_best_real_noArctic<1 & increasing_llh_noArctic
  dominant_function_noArctic = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds"))
  dominant_function_simplified_noArctic  = dominant_function_noArctic
  dominant_function_simplified_noArctic[dominant_function_noArctic %in% c("copepoda","other metazoa","pteropoda")] = "metazoa"
  
  load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs_ArcticOnly",noLagoon_insert,".Rdata"))
  size_absoluteAbund_ArcticOnly_0.8inf = size_absoluteAbund
  load(paste0(results_folder,"/group_sizes_byStationByDepth_",div_threshold,"plusOTUs_ArcticOnly",noLagoon_insert,"_No0.8inf.Rdata"))
  size_absoluteAbund_ArcticOnly_No0.8inf = size_absoluteAbund
  taxo_groups_Arctic = readRDS(paste0(results_folder,"/taxo_groups_modif_2plusOTUs",noLagoon_insert,".rds"))
  names(size_absoluteAbund_ArcticOnly_0.8inf) = taxo_groups_Arctic
  increasing_llh_Arctic = readRDS(paste0(results_folder,"/Increasing_llh_2plusOTUs",noLagoon_insert,".rds"))
  alpha_best_real_Arctic = readRDS(paste0(results_folder,"/alpha_best_real_2plusOTUs",noLagoon_insert,".rds"))
  selected_groups_Arctic = !(taxo_groups_Arctic %in% groups_to_remove) & alpha_best_real_Arctic<1 & increasing_llh_Arctic
  dominant_function_Arctic = readRDS(paste0(results_folder,"/dominant_function_",div_threshold,"plusOTUs",noLagoon_insert,".rds"))
  dominant_function_simplified_Arctic  = dominant_function_Arctic
  dominant_function_simplified_Arctic[dominant_function_Arctic %in% c("copepoda","other metazoa","pteropoda")] = "metazoa"
  
  # functions = c("copepoda","endophotosymbiont","gelatineous_carnivores_filterers","other metazoa","parasite","phagotroph","photohost","phototroph","pteropoda","unknown")
  functions = c("endophotosymbiont","gelatineous_carnivores_filterers","metazoa","parasite","phagotroph","photohost","phototroph","unknown")
  ten_colors = c(NA,"darkblue","dodgerblue1","darkgoldenrod1","firebrick2","darkgreen","chartreuse2","deeppink1")
  
  #########
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_noArctic[taxo_groups_Arctic[selected_groups_Arctic]]),
                                      y = log10(size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic])), mapping = aes(x,y,colour = dominant_function_simplified_Arctic[selected_groups_Arctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size outside Arctic (log10)", y="Mean body size in Arctic (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_log_size_vs_nonArctic_log_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  #########
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_noArctic[taxo_groups_Arctic[selected_groups_Arctic]]),
                                      y = size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic]/size_absoluteAbund_noArctic[taxo_groups_Arctic[selected_groups_Arctic]]),
                    mapping = aes(x,y,colour = dominant_function_simplified_Arctic[selected_groups_Arctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size outside Arctic (log10)", y="Arctic to non-Arctic body size ratio") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    geom_hline(yintercept = 1, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_to_nonArctic_size_ratio_vs_nonArctic_log_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  ########
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_noArctic[taxo_groups_Arctic[selected_groups_Arctic]]),
                                      y = log10(size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic]/size_absoluteAbund_noArctic[taxo_groups_Arctic[selected_groups_Arctic]])),
                    mapping = aes(x,y,colour = dominant_function_simplified_Arctic[selected_groups_Arctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size outside Arctic (log10)", y="Arctic to non-Arctic body size ratio (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    ylim(c(-0.95,0.95)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_to_nonArctic_size_ratio_log_vs_nonArctic_log_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  ########
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_noArctic_0.8inf[taxo_groups_Arctic[selected_groups_Arctic]]),
                                      y = log10(size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic]/size_absoluteAbund_noArctic_0.8inf[taxo_groups_Arctic[selected_groups_Arctic]])),
                    mapping = aes(x,y,colour = dominant_function_simplified_Arctic[selected_groups_Arctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size outside Arctic\n using 0.8-inf size fraction (log10)", y="Arctic to non-Arctic body size ratio\n using 0.8-inf size fraction (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    ylim(c(-0.95,0.95)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_to_nonArctic_size_ratio_0.8-inf_log_vs_nonArctic_0.8-inf_log_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  #######
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_noArctic_NoSmallSizeFraction[taxo_groups_Arctic[selected_groups_Arctic]]),
                                      y = log10(size_absoluteAbund_ArcticOnly_No0.8inf[selected_groups_Arctic]/size_absoluteAbund_noArctic_NoSmallSizeFraction[taxo_groups_Arctic[selected_groups_Arctic]])),
                    mapping = aes(x,y,colour = dominant_function_simplified_Arctic[selected_groups_Arctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size outside Arctic\n without small size fraction (log10)", y="Arctic to non-Arctic body size ratio\n without small size fraction (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    ylim(c(-0.95,0.95)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_to_nonArctic_size_ratio_log_noSmallSizeFraction_vs_nonArctic_log_size_noSmallSizeFraction_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  
  # diversity_Arctic[selected_groups_Arctic][sort.int(size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic]/
  #                                                     size_absoluteAbund_noArctic[taxo_groups_Arctic[selected_groups_Arctic][taxo_groups_Arctic[selected_groups_Arctic] %in% taxo_groups_noArctic]],
  #                                                   decreasing = T, index.return = T)$ix[1:13]]
  # sort(log10(size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic]/
  #       size_absoluteAbund_noArctic[taxo_groups_Arctic[selected_groups_Arctic][taxo_groups_Arctic[selected_groups_Arctic] %in% taxo_groups_noArctic]]),decreasing=T)[1]
  
  #######
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic]),
                                      y = log10(size_absoluteAbund_ArcticOnly_No0.8inf[selected_groups_Arctic])), mapping = aes(x,y,colour = dominant_function_simplified_Arctic[selected_groups_Arctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size in Arctic\n using 0.8-inf size fraction (log10)", y="Mean body size in Arctic\n without 0.8-inf size fraction (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_log_size_no0.8-inf_vs_with0.8-inf_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  #######
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic]),
                                      y = log10(size_absoluteAbund_ArcticOnly_No0.8inf[selected_groups_Arctic]/size_absoluteAbund_ArcticOnly_0.8inf[selected_groups_Arctic])), 
                    mapping = aes(x,y,colour = dominant_function_simplified_Arctic[selected_groups_Arctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size in Arctic\n using 0.8-inf size fraction (log10)", y="Arctic body size ratio\n no 0.8-inf to 0.8-inf (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    geom_hline(yintercept = 0, linetype = "dashed") +
    ylim(c(0,0.85)) +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Arctic_size_ratio_no0.8-inf_to_0.8-inf_log_vs_with0.8-inf_log_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  #######
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_noArctic_0.8inf[selected_groups_noArctic]),
                                      y = log10(size_absoluteAbund_noArctic_NoSmallSizeFraction[selected_groups_noArctic]/size_absoluteAbund_noArctic_0.8inf[selected_groups_noArctic])), 
                    mapping = aes(x,y,colour = dominant_function_simplified_noArctic[selected_groups_noArctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size outside Arctic\n using 0.8-5 size fraction (log10)", y="Non-Arctic body size ratio\n no-small-size-fraction to 0.8-5 (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    geom_hline(yintercept = 0, linetype = "dashed") +
    ylim(c(0,0.85)) +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "NonArctic_size_ratio_noSmallSizeFraction_to_0.8-5_log_vs_0.8-5_log_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  #########
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_noArctic[selected_groups_noArctic]), y = log10(size_absoluteAbund_noArctic_0.8inf[selected_groups_noArctic])), 
                    mapping = aes(x,y,colour = dominant_function_simplified_noArctic[selected_groups_noArctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size outside Arctic\n using 0.8-5 size fraction only (log10)", y="Mean body size outside Arctic\n using 0.8-inf size fraction (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "NonArctic_log_size_using_0.8-inf_vs_0.8-5_log_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  ##########
  tmp.plot = ggplot(data = data.frame(x = log10(size_absoluteAbund_noArctic[selected_groups_noArctic]), 
                                      y = log10(size_absoluteAbund_noArctic_0.8inf[selected_groups_noArctic]/size_absoluteAbund_noArctic[selected_groups_noArctic])), 
                    mapping = aes(x,y,colour = dominant_function_simplified_noArctic[selected_groups_noArctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Mean body size outside Arctic\n using 0.8-5 size fraction only (log10)", y="0.8-inf-based to 0.8-5-based\n body size ratio outside Arctic (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    ylim(c(-0.95,0.95)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "NonArctic_0.8-inf_to_0.8-5_size_ratio_log_vs_NonArctic_0.8-5_log_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  # Selected groups Arctic vs non-Arctic:
  ###########
  diversity_noArctic = readRDS(paste0(results_folder,"/diversity_2plusOTUs_noArcticNoBiomark",noLagoon_insert,".rds")) 
  names(diversity_noArctic) = taxo_groups_noArctic
  diversity_Arctic = readRDS(paste0(results_folder,"/diversity_2plusOTUs",noLagoon_insert,".rds"))
  names(diversity_Arctic) = taxo_groups_Arctic
  
  tmp.plot = ggplot(data = data.frame(x = log10(as.vector(diversity_noArctic[taxo_groups_Arctic[selected_groups_Arctic]])),
                                      y = log10(as.vector(diversity_Arctic[selected_groups_Arctic]))), 
                    mapping = aes(x,y,colour = dominant_function_simplified_Arctic[selected_groups_Arctic])) +
    #ggtitle() +
    geom_point(aes(x,y)) + theme_bw() + labs(x="Group OTU richness outside Arctic (log10)", y="Group OTU richness including Arctic (log10)") +
    theme(axis.title=element_text(size=12),
          text=element_text(size=15), 
          plot.title=element_text(hjust=0, size=16),
          plot.margin=unit(c(1,10,1,0.5),"mm"),
          legend.position="bottom",
          # legend.text=element_text(size=16),
          legend.text=element_text(size=10),
          legend.title=element_text(size=13)) + 
    geom_abline(slope = 1,intercept = 0, linetype = "dashed") +
    scale_colour_manual(values = setNames(ten_colors,functions), na.value = "grey50", guide = "colourbar", name = "Functional group") +
    guides(colour = guide_legend(title.position="bottom"))
  
  # ggsave(filename = "Arctic_dominant_assemblage_overlap_vs_size_ggplot_functionColors_selected.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
  #          height = 1.5*10/3, width = 1.5*10/3)
  ggsave(filename = "Diversity_log_Arctic_vs_nonArctic_ggplot_functionColors_selectedArctic.pdf", do.call("arrangeGrob", c(list(tmp.plot), nrow=1)),
         height = 1.5*10/3, width = 1.5*10/3)
  
  
  #####################################
  #####################################
  
  # Computing mean connectivity between stations
  
  data.folder_name = paste0(data_folder,"/18S_V9_TARA_CompleteSizeRange_byStationByDepth_AllTaxa",noLagoon_insert)
  load(paste0(data.folder_name,"/coord.Rdata"))
  
  particle_thres = 1000
  travel_time_thres = max_travel_time_matrix
  
  travel.folder_name = paste0(data_folder,"/Abiotic_data")
  
  if (particle_thres == 1000 && travel_time_thres > 0)
  {
    travel_time_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_1000.csv"),sep="\t",header=T,row.names=1)
    travel_time_matrix = travel_time_matrix[,-ncol(travel_time_matrix)]
    
    travel_time_matrix_75m = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_75m_1000.csv"),sep="\t",header=T,row.names=1)
    travel_time_matrix_75m = travel_time_matrix_75m[,-ncol(travel_time_matrix_75m)]
    DCM_indices = which(matrix(unlist(strsplit(rownames(travel_time_matrix),split="_",fixed=T)),nrow=2)[2,] == "DCM")
    travel_time_matrix[DCM_indices,DCM_indices] = travel_time_matrix_75m[DCM_indices,DCM_indices]
    max_travel_time_matrix = max(travel_time_matrix[!is.nan(as.matrix(travel_time_matrix))])
  } else if (particle_thres == 10 && travel_time_thres > 0)
  {
    travel_time_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_min_surface_10.csv"),sep="\t",header=T,row.names=1)
    travel_time_matrix = travel_time_matrix[,-ncol(travel_time_matrix)]
    max_travel_time_matrix = max(travel_time_matrix[!is.nan(as.matrix(travel_time_matrix))])
  } else if (travel_time_thres == 0)
  {
    exchanged_particle_matrix = read.table(paste0(travel.folder_name,"/minAijji_tarrive_num_points_surface_10.csv"),sep="\t",header=T,row.names=1)
    exchanged_particle_matrix = exchanged_particle_matrix[,-ncol(exchanged_particle_matrix)]
  }
  
  all(which(as.matrix(exchanged_particle_matrix) > 1000) == which(!is.nan(as.matrix(travel_time_matrix))))
  
  if (particle_thres > 0)
  {
    selected_travel_time_matrix = travel_time_matrix[selected_stations,paste0("X",selected_stations)]
    selected_travel_time_matrix0 = selected_travel_time_matrix
  } else
  {
    selected_exchanged_particle_matrix = exchanged_particle_matrix[selected_stations,paste0("X",selected_stations)]
    selected_exchanged_particle_matrix0 = selected_exchanged_particle_matrix
  }
  
  Arctic_stations = rownames(coord)[which(rownames(coord) == "TARA_155 SUR"):nrow(coord)]
  for (i in 1:length(Arctic_stations))
    Arctic_stations[i] = strsplit(strsplit(Arctic_stations[i],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
  # Computing the 'null' connectivity value obtained for an OTU present in every station-depth
  ik_Arctic_nonArctic = 0
  prop_connected_Arctic_nonArctic = 0
  for (i in 2:nrow(coord))
  {
    for (j in 1:(i-1))
    {
      station_i = strsplit(strsplit(rownames(coord)[i],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
      station_j = strsplit(strsplit(rownames(coord)[j],split=" ",fixed=T)[[1]][1],split="_",fixed=T)[[1]][2]
      # if (station_i %in% Arctic_stations && !(station_j %in% Arctic_stations) || !(station_i %in% Arctic_stations) && station_j %in% Arctic_stations)
      # if (station_i %in% Arctic_stations && station_j %in% Arctic_stations && station_i != station_j)
      # if (!(station_i %in% Arctic_stations) && !(station_j %in% Arctic_stations) && station_i != station_j)
      if (station_i != station_j)
      {
        ik_Arctic_nonArctic = ik_Arctic_nonArctic+1
        if (travel_time_thres > 0)
        {
          travel_time_ij = selected_travel_time_matrix[i,j]
          if (is.nan(travel_time_ij))
            travel_time_ij = max_travel_time_matrix
          if (travel_time_ij < travel_time_thres)
            prop_connected_Arctic_nonArctic = prop_connected_Arctic_nonArctic + 1
        } else 
        {
          exchanged_particle_ij = selected_exchanged_particle_matrix[i,j]
          if (is.nan(exchanged_particle_ij))
            exchanged_particle_ij = 0
          if (particle_thres > 0)
          {
            if (exchanged_particle_ij > particle_thres) 
              prop_connected_Arctic_nonArctic = prop_connected_Arctic_nonArctic + 1
          } else
          {
            prop_connected_Arctic_nonArctic = prop_connected_Arctic_nonArctic + exchanged_particle_ij
          }
        }
      }
    }
  }
  prop_connected_Arctic_nonArctic = prop_connected_Arctic_nonArctic/ik_Arctic_nonArctic
  
}

# Retreat word cloud:
# word_string = c(rep("biodiversity",10),rep("microbial",9),rep("spatial structure",9),
#                 rep("probabilistic models",8),rep("macroecology",8),rep("OTU",8),rep("community ecology",6),rep("LDA",6),rep("beta-diversity",5),
#                 rep("biogeography",5),rep("metabarcoding",5),rep("high-throughput sequencing",3),rep("neutral biodiversity models",3),rep("dispersal",5),
#                 rep("statistical inference",3),rep("tropical forest",3),rep("Amazonia",2),rep("Ocean",5),rep("plankton",7),rep("currents",3),rep("environmental filtering",3),
#                 rep("environmental DNA",7),rep("soil",3),rep("frogs",1),rep("data",7))
# pdf("Word_cloud_Guilhem.pdf")
# res1 = rquery.wordcloud(word_string, type ="text", lang = "english",max.words=100)
# dev.off()



